<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 11]
- [cs.CL](#cs.CL) [Total: 15]
- [cs.CR](#cs.CR) [Total: 30]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.GT](#cs.GT) [Total: 2]
- [cs.CE](#cs.CE) [Total: 2]
- [stat.CO](#stat.CO) [Total: 1]
- [q-fin.ST](#q-fin.ST) [Total: 3]
- [cs.SD](#cs.SD) [Total: 5]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.DS](#cs.DS) [Total: 2]
- [cs.CY](#cs.CY) [Total: 6]
- [stat.ML](#stat.ML) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [q-fin.RM](#q-fin.RM) [Total: 2]
- [quant-ph](#quant-ph) [Total: 6]
- [cs.LG](#cs.LG) [Total: 76]
- [cs.SE](#cs.SE) [Total: 3]
- [cs.DB](#cs.DB) [Total: 3]
- [cs.HC](#cs.HC) [Total: 4]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.SI](#cs.SI) [Total: 4]
- [stat.ME](#stat.ME) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Detecting Deepfake Talking Heads from Facial Biometric Anomalies](https://arxiv.org/abs/2507.08917)
*Justin D. Norman,Hany Farid*

Main category: cs.CV

TL;DR: 提出了一种新的机器学习方法来检测深度伪造视频，该方法通过分析面部生物特征中的不自然模式来识别身份模仿。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术（如声音克隆和面部替换）的结合使得冒充他人变得容易，常被用于欺诈、诈骗和政治虚假信息。

Method: 利用面部生物特征中不自然模式的取证机器学习技术

Result: 该技术已被评估用于各种深度伪造技术和身份模仿，并评估了其在视频清洗和对先前未见过的视频深度伪造生成器上的泛化能力。

Conclusion: 提出了一种利用面部生物特征中不自然模式的深度伪造视频身份识别的取证机器学习技术，并评估了其在各种深度伪造技术和身份模仿上的可靠性以及对先前未见过的视频深度伪造生成器的泛化能力。

Abstract: The combination of highly realistic voice cloning, along with visually
compelling avatar, face-swap, or lip-sync deepfake video generation, makes it
relatively easy to create a video of anyone saying anything. Today, such
deepfake impersonations are often used to power frauds, scams, and political
disinformation. We propose a novel forensic machine learning technique for the
detection of deepfake video impersonations that leverages unnatural patterns in
facial biometrics. We evaluate this technique across a large dataset of
deepfake techniques and impersonations, as well as assess its reliability to
video laundering and its generalization to previously unseen video deepfake
generators.

</details>


### [2] [Consistent and Invariant Generalization Learning for Short-video Misinformation Detection](https://arxiv.org/abs/2507.04061)
*Hanghui Guo,Weijie Shi,Mengze Li,Juncheng Li,Hao Chen,Yue Cui,Jiajie Xu,Jia Zhu,Jiawei Shen,Zhangze Chen,Sirui Han*

Main category: cs.CV

TL;DR: 针对短视频虚假信息检测中的跨领域泛化难题，提出DOCTOR模型，利用跨模态特征插值、蒸馏和扩散模型增强领域不变性，有效解决了跨领域性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 当前短视频虚假信息检测模型在不同领域（源域和目标域）之间存在性能差距，主要是由于模型在特定领域训练，而不同领域可能依赖不同的模态（视频或音频），并且跨模态融合过程中会累积领域偏见。

Method: DOCTOR模型包含两个核心模块：1. 跨模态特征插值与插值蒸馏，用于将多模态映射到共享空间并同步多模态学习。2. 扩散模型，通过添加噪声保留多模态核心特征，并利用跨模态引导去噪增强领域不变特征。

Result: 实验结果证明了DOCTOR模型的有效性，表明该模型能够提升短视频虚假信息检测的跨领域泛化能力。

Conclusion: 该研究提出了DOCTOR模型，通过跨模态特征插值、插值蒸馏和扩散模型进行跨模态引导去噪，有效提高了短视频虚假信息检测的跨领域泛化能力。

Abstract: Short-video misinformation detection has attracted wide attention in the
multi-modal domain, aiming to accurately identify the misinformation in the
video format accompanied by the corresponding audio. Despite significant
advancements, current models in this field, trained on particular domains
(source domains), often exhibit unsatisfactory performance on unseen domains
(target domains) due to domain gaps. To effectively realize such domain
generalization on the short-video misinformation detection task, we propose
deep insights into the characteristics of different domains: (1) The detection
on various domains may mainly rely on different modalities (i.e., mainly
focusing on videos or audios). To enhance domain generalization, it is crucial
to achieve optimal model performance on all modalities simultaneously. (2) For
some domains focusing on cross-modal joint fraud, a comprehensive analysis
relying on cross-modal fusion is necessary. However, domain biases located in
each modality (especially in each frame of videos) will be accumulated in this
fusion process, which may seriously damage the final identification of
misinformation. To address these issues, we propose a new DOmain generalization
model via ConsisTency and invariance learning for shORt-video misinformation
detection (named DOCTOR), which contains two characteristic modules: (1) We
involve the cross-modal feature interpolation to map multiple modalities into a
shared space and the interpolation distillation to synchronize multi-modal
learning; (2) We design the diffusion model to add noise to retain core
features of multi modal and enhance domain invariant features through
cross-modal guided denoising. Extensive experiments demonstrate the
effectiveness of our proposed DOCTOR model. Our code is public available at
https://github.com/ghh1125/DOCTOR.

</details>


### [3] [3D Arena: An Open Platform for Generative 3D Evaluation](https://arxiv.org/abs/2506.18787)
*Dylan Ebert*

Main category: cs.CV

TL;DR: 评估生成式 3D 模型很困难。我们创建了 3D Arena 平台，收集了超过 12 万张选票，以了解人类偏好。我们发现高斯泼泼和纹理模型更受欢迎，并为未来的评估提供了建议。


<details>
  <summary>Details</summary>
Motivation: 评估生成式 3D 模型仍然是一个挑战，因为自动评估指标与人类对质量的感知之间存在不匹配，现有的基于图像或几何的指标未能捕捉感知吸引力和实际效用。

Method: 本研究提出了 3D Arena，一个通过大规模众包的人类偏好收集（使用成对比较）来评估图像到 3D 生成模型的开放平台，并推出了包含 100 个评估提示的 iso3d 数据集，利用基于 ELO 的排名系统进行模型评估。

Result: 3D Arena 收集了来自 8,096 位用户、123,243 票的投票，覆盖了 19 个最先进的模型，并发现了人类偏好模式，例如，高斯泼泼模型比网格模型具有 16.6 ELO 优势，纹理模型比无纹理模型具有 144.1 ELO 优势。

Conclusion: 3D Arena 平台已成为生成式 3D 领域的基准，通过大规模众包的人类偏好收集，为改进评估方法（如多标准评估、面向任务的评估和感知格式的比较）提供了见解和建议，并增进了对以人为本的评估的理解。

Abstract: Evaluating Generative 3D models remains challenging due to misalignment
between automated metrics and human perception of quality. Current benchmarks
rely on image-based metrics that ignore 3D structure or geometric measures that
fail to capture perceptual appeal and real-world utility. To address this gap,
we present 3D Arena, an open platform for evaluating image-to-3D generation
models through large-scale human preference collection using pairwise
comparisons.
  Since launching in June 2024, the platform has collected 123,243 votes from
8,096 users across 19 state-of-the-art models, establishing the largest human
preference evaluation for Generative 3D. We contribute the iso3d dataset of 100
evaluation prompts and demonstrate quality control achieving 99.75% user
authenticity through statistical fraud detection. Our ELO-based ranking system
provides reliable model assessment, with the platform becoming an established
evaluation resource.
  Through analysis of this preference data, we present insights into human
preference patterns. Our findings reveal preferences for visual presentation
features, with Gaussian splat outputs achieving a 16.6 ELO advantage over
meshes and textured models receiving a 144.1 ELO advantage over untextured
models. We provide recommendations for improving evaluation methods, including
multi-criteria assessment, task-oriented evaluation, and format-aware
comparison. The platform's community engagement establishes 3D Arena as a
benchmark for the field while advancing understanding of human-centered
evaluation in Generative 3D.

</details>


### [4] [RAID: A Dataset for Testing the Adversarial Robustness of AI-Generated Image Detectors](https://arxiv.org/abs/2506.03988)
*Hicham Eddoubi,Jonas Ricker,Federico Cocchi,Lorenzo Baraldi,Angelo Sotgiu,Maura Pintor,Marcella Cornia,Lorenzo Baraldi,Asja Fischer,Rita Cucchiara,Battista Biggio*

Main category: cs.CV

TL;DR: 本研究提出了RAID数据集和评估方法，以评估AI生成图像检测器的鲁棒性。研究发现，现有检测器容易受到对抗性样本的欺骗，强调了开发更鲁棒方法的重要性。


<details>
  <summary>Details</summary>
Motivation: AI生成图像的质量已经达到人类无法可靠区分的水平，这带来了欺诈和虚假信息的风险。现有检测方法的评估通常在理想条件下进行，忽略了对抗性鲁棒性，因此需要一种评估检测器鲁棒性的更简单的方法。

Method: 提出了一种评估AI生成图像检测器鲁棒性的方法，称为RAID（鲁棒评估AI生成图像检测器）。RAID是一个包含72,000个多样化且高度可迁移的对抗性样本的数据集，通过针对七个最先进的检测器和四个不同的文本到图像模型生成的图像运行攻击来创建。

Result: RAID数据集包含的对抗性图像能够以很高的成功率迁移到未知的检测器，从而可以快速提供对检测器对抗性鲁棒性的近似但可靠的估计。实验表明，当前的检测器很容易被欺骗。

Conclusion: 目前最先进的AI生成图像检测器很容易被对抗性样本欺骗，这凸显了开发更鲁棒的方法的迫切需求。

Abstract: AI-generated images have reached a quality level at which humans are
incapable of reliably distinguishing them from real images. To counteract the
inherent risk of fraud and disinformation, the detection of AI-generated images
is a pressing challenge and an active research topic. While many of the
presented methods claim to achieve high detection accuracy, they are usually
evaluated under idealized conditions. In particular, the adversarial robustness
is often neglected, potentially due to a lack of awareness or the substantial
effort required to conduct a comprehensive robustness analysis. In this work,
we tackle this problem by providing a simpler means to assess the robustness of
AI-generated image detectors. We present RAID (Robust evaluation of
AI-generated image Detectors), a dataset of 72k diverse and highly transferable
adversarial examples. The dataset is created by running attacks against an
ensemble of seven state-of-the-art detectors and images generated by four
different text-to-image models. Extensive experiments show that our methodology
generates adversarial images that transfer with a high success rate to unseen
detectors, which can be used to quickly provide an approximate yet still
reliable estimate of a detector's adversarial robustness. Our findings indicate
that current state-of-the-art AI-generated image detectors can be easily
deceived by adversarial examples, highlighting the critical need for the
development of more robust methods. We release our dataset at
https://huggingface.co/datasets/aimagelab/RAID and evaluation code at
https://github.com/pralab/RAID.

</details>


### [5] [Deepfake-Eval-2024: A Multi-Modal In-the-Wild Benchmark of Deepfakes Circulated in 2024](https://arxiv.org/abs/2503.02857)
*Nuria Alina Chandra,Ryan Murtfeldt,Lin Qiu,Arnab Karmakar,Hannah Lee,Emmanuel Tanumihardja,Kevin Farhat,Ben Caffee,Sejin Paik,Changyeon Lee,Jongwook Choi,Aerin Kim,Oren Etzioni*

Main category: cs.CV

TL;DR: 现有的深度伪造检测模型在新的野外数据集上表现不佳，需要新的检测方法。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI日益逼真，鲁棒的深度伪造检测对于遏制欺诈和虚假信息至关重要，但现有学术基准已过时且不具代表性。

Method: 提出了一个新的深度伪造检测基准Deepfake-Eval-2024，包含2024年在社交媒体和用户提交的野外深度伪造数据，涵盖了最新的操纵技术、多样的媒体内容、语言和网站。

Result: 在Deepfake-Eval-2024基准上，开源最先进的深度伪造检测模型的性能急剧下降，视频、音频和图像模型的AUC分别下降了50%、48%和45%。

Conclusion: 现有公开的深度伪造检测模型在真实世界数据集上的表现显著下降，商业模型和经过微调的模型表现更优，但仍未达到专业分析师的准确水平。

Abstract: In the age of increasingly realistic generative AI, robust deepfake detection
is essential for mitigating fraud and disinformation. While many deepfake
detectors report high accuracy on academic datasets, we show that these
academic benchmarks are out of date and not representative of real-world
deepfakes. We introduce Deepfake-Eval-2024, a new deepfake detection benchmark
consisting of in-the-wild deepfakes collected from social media and deepfake
detection platform users in 2024. Deepfake-Eval-2024 consists of 45 hours of
videos, 56.5 hours of audio, and 1,975 images, encompassing the latest
manipulation technologies. The benchmark contains diverse media content from 88
different websites in 52 different languages. We find that the performance of
open-source state-of-the-art deepfake detection models drops precipitously when
evaluated on Deepfake-Eval-2024, with AUC decreasing by 50% for video, 48% for
audio, and 45% for image models compared to previous benchmarks. We also
evaluate commercial deepfake detection models and models finetuned on
Deepfake-Eval-2024, and find that they have superior performance to
off-the-shelf open-source models, but do not yet reach the accuracy of deepfake
forensic analysts. The dataset is available at
https://github.com/nuriachandra/Deepfake-Eval-2024.

</details>


### [6] [SelfMAD: Enhancing Generalization and Robustness in Morphing Attack Detection via Self-Supervised Learning](https://arxiv.org/abs/2504.05504)
*Marija Ivanovska,Leon Todorov,Naser Damer,Deepak Kumar Jain,Peter Peer,Vitomir Štruc*

Main category: cs.CV

TL;DR: 提出了一种名为SelfMAD的新型自监督方法，用于检测脸部混淆攻击。该方法通过模拟通用攻击伪影，提高了模型的泛化能力和鲁棒性，在实验中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的混淆攻击检测（MAD）方法通常依赖于在真实和混淆图像样本上训练的监督、判别模型，这些模型在面对新的、未知的混淆技术时性能不佳。无监督模型虽然泛化性更好，但错误率较高。为了解决这些问题，需要一种能够有效处理各种混淆技术并保持低错误率的方法。

Method: 提出了一种名为SelfMAD的新型自监督方法，该方法通过模拟通用的混淆攻击伪影，使分类器能够学习通用的、鲁棒的决策边界，而不过度拟合特定的脸部混淆方法所引起的伪影。

Result: SelfMAD在跨混淆设置下，相比于最强的无监督竞争者，错误率降低了64%（以EER衡量）；相比于表现最佳的判别式MAD模型，错误率降低了66%。

Conclusion: SelfMAD通过模拟通用的混淆攻击伪影，使分类器能够学习通用的、鲁棒的决策边界，而不过度拟合特定的脸部混淆方法所引起的伪影。实验证明，SelfMAD在跨混淆设置下，相比于最强的无监督竞争者和表现最佳的判别式MAD模型，分别降低了64%和66%的错误率。

Abstract: With the continuous advancement of generative models, face morphing attacks
have become a significant challenge for existing face verification systems due
to their potential use in identity fraud and other malicious activities.
Contemporary Morphing Attack Detection (MAD) approaches frequently rely on
supervised, discriminative models trained on examples of bona fide and morphed
images. These models typically perform well with morphs generated with
techniques seen during training, but often lead to sub-optimal performance when
subjected to novel unseen morphing techniques. While unsupervised models have
been shown to perform better in terms of generalizability, they typically
result in higher error rates, as they struggle to effectively capture features
of subtle artifacts. To address these shortcomings, we present SelfMAD, a novel
self-supervised approach that simulates general morphing attack artifacts,
allowing classifiers to learn generic and robust decision boundaries without
overfitting to the specific artifacts induced by particular face morphing
methods. Through extensive experiments on widely used datasets, we demonstrate
that SelfMAD significantly outperforms current state-of-the-art MADs, reducing
the detection error by more than 64% in terms of EER when compared to the
strongest unsupervised competitor, and by more than 66%, when compared to the
best performing discriminative MAD model, tested in cross-morph settings. The
source code for SelfMAD is available at https://github.com/LeonTodorov/SelfMAD.

</details>


### [7] [Autonomous and Self-Adapting System for Synthetic Media Detection and Attribution](https://arxiv.org/abs/2504.03615)
*Aref Azizpour,Tai D. Nguyen,Matthew C. Stamm*

Main category: cs.CV

TL;DR: 提出了一种自主的、自我适应的合成媒体识别系统，能够检测合成图像、归因于已知来源，并自主识别整合新的生成器，以应对不断变化的生成模型格局。


<details>
  <summary>Details</summary>
Motivation: 现有的静态合成图像识别系统依赖于从已知生成器学习到的特征表示，当新的生成模型出现时，性能会严重下降。因此，需要一种能够自主识别和整合新生成器的自我适应系统。

Method: 该方法利用开放集识别策略和可演化嵌入空间来区分已知和未知来源，通过无监督聚类方法将未知样本聚合成高置信度簇，并持续优化决策边界。

Result: 实验证明，该方法显著优于现有方法，能够自主识别和整合新的生成器，并在生成环境不断演变的情况下，保持鲁棒的检测和归因性能。

Conclusion: 该方法在不断发展的生成模型时代，朝着实现通用、适应性强的取证系统迈出了关键一步，通过持续优化决策边界，在生成环境不断演变的情况下，保持了鲁棒的检测和归因性能。

Abstract: Rapid advances in generative AI have enabled the creation of highly realistic
synthetic images, which, while beneficial in many domains, also pose serious
risks in terms of disinformation, fraud, and other malicious applications.
Current synthetic image identification systems are typically static, relying on
feature representations learned from known generators; as new generative models
emerge, these systems suffer from severe performance degradation. In this
paper, we introduce the concept of an autonomous self-adaptive synthetic media
identification system -- one that not only detects synthetic images and
attributes them to known sources but also autonomously identifies and
incorporates novel generators without human intervention. Our approach
leverages an open-set identification strategy with an evolvable embedding space
that distinguishes between known and unknown sources. By employing an
unsupervised clustering method to aggregate unknown samples into
high-confidence clusters and continuously refining its decision boundaries, our
system maintains robust detection and attribution performance even as the
generative landscape evolves. Extensive experiments demonstrate that our method
significantly outperforms existing approaches, marking a crucial step toward
universal, adaptable forensic systems in the era of rapidly advancing
generative models.

</details>


### [8] [Evolving from Single-modal to Multi-modal Facial Deepfake Detection: Progress and Challenges](https://arxiv.org/abs/2406.06965)
*Ping Liu,Qiqi Tao,Joey Tianyi Zhou*

Main category: cs.CV

TL;DR: 本调查全面概述了深度伪造检测的最新进展，重点介绍了多模态方法和视觉-语言模型在应对日益复杂的深度伪造攻击方面的作用。


<details>
  <summary>Details</summary>
Motivation: 随着包括视频、音频和文本在内的合成媒体与真实内容的区别越来越小，错误信息、身份欺诈和社会操纵的风险不断升级，因此有必要进行这项研究。

Method: 本研究通过追踪深度伪造检测从早期单一模态方法到整合音视频和文本视觉线索的多模态方法的演变，并对检测技术进行了结构化分类。

Result: 本调查全面研究了从单一模态到多模态的深度伪造检测方法，涵盖了最新的进展，如多模态检测、泛化挑战、主动防御机制和新的数据集，并强调了视觉-语言模型和多模态大语言模型在增强检测方面的作用。

Conclusion: 本调查全面研究了多模态深度伪造检测的最新进展，包括视觉-语言模型和多模态大语言模型的作用，为未来应对人工智能生成的面部伪造提供了基础。

Abstract: As synthetic media, including video, audio, and text, become increasingly
indistinguishable from real content, the risks of misinformation, identity
fraud, and social manipulation escalate. This survey traces the evolution of
deepfake detection from early single-modal methods to sophisticated multi-modal
approaches that integrate audio-visual and text-visual cues. We present a
structured taxonomy of detection techniques and analyze the transition from
GAN-based to diffusion model-driven deepfakes, which introduce new challenges
due to their heightened realism and robustness against detection. Unlike prior
surveys that primarily focus on single-modal detection or earlier deepfake
techniques, this work provides the most comprehensive study to date,
encompassing the latest advancements in multi-modal deepfake detection,
generalization challenges, proactive defense mechanisms, and emerging datasets
specifically designed to support new interpretability and reasoning tasks. We
further explore the role of Vision-Language Models (VLMs) and Multimodal Large
Language Models (MLLMs) in strengthening detection robustness against
increasingly sophisticated deepfake attacks. By systematically categorizing
existing methods and identifying emerging research directions, this survey
serves as a foundation for future advancements in combating AI-generated facial
forgeries. A curated list of all related papers can be found at
\href{https://github.com/qiqitao77/Comprehensive-Advances-in-Deepfake-Detection-Spanning-Diverse-Modalities}{https://github.com/qiqitao77/Awesome-Comprehensive-Deepfake-Detection}.

</details>


### [9] [ExDDV: A New Dataset for Explainable Deepfake Detection in Video](https://arxiv.org/abs/2503.14421)
*Vlad Hondru,Eduard Hogea,Darian Onchis,Radu Tudor Ionescu*

Main category: cs.CV

TL;DR: 提出ExDDV数据集和基准，用于可解释的深度伪造视频检测，并证明文本和点击监督对于构建鲁棒模型至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有的深度伪造检测器容易出错且缺乏可解释性，使人类容易受到欺诈和错误信息的影响。

Method: 提出了一种名为ExDDV的新数据集和基准，包含约5.4K个真实和深度伪造视频，并附有文本描述和点击注释。评估了几种视觉-语言模型在ExDDV上的表现，并进行了各种微调和上下文学习策略的实验。

Result: 研究结果表明，文本和点击监督对于开发能够定位和描述伪影的可解释性深度伪造视频模型是必需的。

Conclusion: 研究表明，文本和点击监督对于开发鲁棒的可解释性深度伪造视频模型至关重要，这些模型能够定位和描述所观察到的伪影。

Abstract: The ever growing realism and quality of generated videos makes it
increasingly harder for humans to spot deepfake content, who need to rely more
and more on automatic deepfake detectors. However, deepfake detectors are also
prone to errors, and their decisions are not explainable, leaving humans
vulnerable to deepfake-based fraud and misinformation. To this end, we
introduce ExDDV, the first dataset and benchmark for Explainable Deepfake
Detection in Video. ExDDV comprises around 5.4K real and deepfake videos that
are manually annotated with text descriptions (to explain the artifacts) and
clicks (to point out the artifacts). We evaluate a number of vision-language
models on ExDDV, performing experiments with various fine-tuning and in-context
learning strategies. Our results show that text and click supervision are both
required to develop robust explainable models for deepfake videos, which are
able to localize and describe the observed artifacts. Our novel dataset and
code to reproduce the results are available at
https://github.com/vladhondru25/ExDDV.

</details>


### [10] [Pathology-Aware Adaptive Watermarking for Text-Driven Medical Image Synthesis](https://arxiv.org/abs/2503.08346)
*Chanyoung Kim,Dayun Ju,Jinyeong Kim,Woojung Han,Roberto Alcover-Couso,Seong Jae Hwang*

Main category: cs.CV

TL;DR: MedSign是一种用于文本到医学图像合成的深度学习水印框架，它通过病理定位图自适应地调整水印强度，以保留关键的病理区域，从而在防止滥用的同时保持诊断的完整性。


<details>
  <summary>Details</summary>
Motivation: 现有的水印技术在医学领域面临挑战，因为微小的失真可能会导致临床误解，影响诊断完整性。因此，需要一种能够保留细微病变特征的水印技术，以防止对生成的医学图像的滥用。

Method: MedSign是一个深度学习框架，通过生成病理定位图来适应性地调整水印强度，从而在文本到医学图像合成过程中整合水印，最大限度地减少对关键区域的干扰。病理定位图是利用跨注意力和聚合标记间的注意力来生成的。

Result: MedSign框架在MIMIC-CXR和OIA-ODIR数据集上实现了最先进的性能，在图像质量和检测准确性方面均表现出色，同时能够保留诊断的完整性并确保水印的鲁棒性。

Conclusion: MedSign框架在MIMIC-CXR和OIA-ODIR数据集上实现了最先进的性能，在图像质量和检测准确性方面均表现出色，同时能够保留诊断的完整性并确保水印的鲁棒性。

Abstract: As recent text-conditioned diffusion models have enabled the generation of
high-quality images, concerns over their potential misuse have also grown. This
issue is critical in the medical domain, where text-conditioned generated
medical images could enable insurance fraud or falsified records, highlighting
the urgent need for reliable safeguards against unethical use. While
watermarking techniques have emerged as a promising solution in general image
domains, their direct application to medical imaging presents significant
challenges. A key challenge is preserving fine-grained disease manifestations,
as even minor distortions from a watermark may lead to clinical
misinterpretation, which compromises diagnostic integrity. To overcome this
gap, we present MedSign, a deep learning-based watermarking framework
specifically designed for text-to-medical image synthesis, which preserves
pathologically significant regions by adaptively adjusting watermark strength.
Specifically, we generate a pathology localization map using cross-attention
between medical text tokens and the diffusion denoising network, aggregating
token-wise attention across layers, heads, and time steps. Leveraging this map,
we optimize the LDM decoder to incorporate watermarking during image synthesis,
ensuring cohesive integration while minimizing interference in diagnostically
critical regions. Experimental results show that our MedSign preserves
diagnostic integrity while ensuring watermark robustness, achieving
state-of-the-art performance in image quality and detection accuracy on
MIMIC-CXR and OIA-ODIR datasets.

</details>


### [11] [FaceTracer: Unveiling Source Identities from Swapped Face Images and Videos for Fraud Prevention](https://arxiv.org/abs/2412.08082)
*Zhongyi Zhang,Jie Zhang,Wenbo Zhou,Xinghui Zhou,Qing Guo,Weiming Zhang,Tianwei Zhang,Nenghai Yu*

Main category: cs.CV

TL;DR: FaceTracer 是第一个非侵入性框架，专门用于从交换后的人脸图像或视频中追踪源身份，以识别和追踪欺诈活动中的恶意行为者。


<details>
  <summary>Details</summary>
Motivation: 现有的换脸检测方法不足以追踪欺诈活动背后的恶意用户，基于水印的方法也无法追踪未标记的身份，限制了其实际应用。为了解决这些挑战，需要一个能够追踪换脸图像或视频来源身份的非侵入性框架。

Method: FaceTracer 框架利用一个解耦模块，有效抑制了与目标人脸相关的信息，同时分离出源人脸的身份特征，从而提取能够将交换后的人脸与原始个体联系起来的鲁棒身份信息。

Result: FaceTracer 能够成功识别各种人脸交换技术中的源身份，并追踪欺诈活动中的恶意行为者。该方法还表现出对未知人脸交换方法（包括商业应用）的强大迁移能力，以及对传输失真和自适应攻击的鲁棒性。

Conclusion: FaceTracer 成功识别了被交换内容中的源身份，并能追踪涉及欺诈活动的恶意行为者。该方法在各种人脸交换技术上都有效，并且在面对未知的、商业化的人脸交换方法、传输失真和自适应攻击时，表现出了很强的迁移能力和鲁棒性。

Abstract: Face-swapping techniques have advanced rapidly with the evolution of deep
learning, leading to widespread use and growing concerns about potential
misuse, especially in cases of fraud. While many efforts have focused on
detecting swapped face images or videos, these methods are insufficient for
tracing the malicious users behind fraudulent activities. Intrusive
watermark-based approaches also fail to trace unmarked identities, limiting
their practical utility. To address these challenges, we introduce FaceTracer,
the first non-intrusive framework specifically designed to trace the identity
of the source person from swapped face images or videos. Specifically,
FaceTracer leverages a disentanglement module that effectively suppresses
identity information related to the target person while isolating the identity
features of the source person. This allows us to extract robust identity
information that can directly link the swapped face back to the original
individual, aiding in uncovering the actors behind fraudulent activities.
Extensive experiments demonstrate FaceTracer's effectiveness across various
face-swapping techniques, successfully identifying the source person in swapped
content and enabling the tracing of malicious actors involved in fraudulent
activities. Additionally, FaceTracer shows strong transferability to unseen
face-swapping methods including commercial applications and robustness against
transmission distortions and adaptive attacks.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [12] [Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding](https://arxiv.org/abs/2507.12295)
*Feng Xiao,Jicong Fan*

Main category: cs.CL

TL;DR: 该研究构建了一个文本异常检测基准，评估了不同嵌入模型的性能。发现嵌入质量是关键，LLM嵌入并未使深度学习方法优于传统方法。研究还发现模型性能矩阵具有低秩特性，可用于高效模型选择。研究开源了相关工具包。


<details>
  <summary>Details</summary>
Motivation: 尽管在大型语言模型（LLM）和异常检测算法方面取得了显著进展，但缺乏标准化的、全面的基准来评估现有文本数据异常检测方法的性能，这阻碍了严格的比较和创新方法的开发。

Method: 该研究进行了一项全面的实证研究，并引入了一个文本异常检测基准。该基准利用了来自多种预训练语言模型（包括早期语言模型如GloVe、BERT，以及LLaMa-2、LLama-3、Mistral、OpenAI等LLM）的嵌入，并覆盖了广泛的文本数据集（新闻、社交媒体、科学出版物等）。研究评估了基于嵌入的文本异常检测的有效性，并使用了AUROC、AUPRC等全面的评估指标。

Result: 研究结果表明，嵌入质量显著影响异常检测的有效性。深度学习方法在使用LLM嵌入时，并未比KNN、Isolation Forest等传统浅层算法表现出性能优势。此外，跨模型性能矩阵的低秩特性为快速评估和选择模型提供了可能。

Conclusion: 现有的文本异常检测方法在利用大型语言模型（LLM）的嵌入时，深度学习方法并未表现出比传统浅层算法（如KNN、Isolation Forest）更优越的性能。此外，跨模型性能矩阵表现出显著的低秩特性，这为实际应用中快速评估和选择模型提供了有效策略。

Abstract: Text anomaly detection is a critical task in natural language processing
(NLP), with applications spanning fraud detection, misinformation
identification, spam detection and content moderation, etc. Despite significant
advances in large language models (LLMs) and anomaly detection algorithms, the
absence of standardized and comprehensive benchmarks for evaluating the
existing anomaly detection methods on text data limits rigorous comparison and
development of innovative approaches. This work performs a comprehensive
empirical study and introduces a benchmark for text anomaly detection,
leveraging embeddings from diverse pre-trained language models across a wide
array of text datasets. Our work systematically evaluates the effectiveness of
embedding-based text anomaly detection by incorporating (1) early language
models (GloVe, BERT); (2) multiple LLMs (LLaMa-2, LLama-3, Mistral, OpenAI
(small, ada, large)); (3) multi-domain text datasets (news, social media,
scientific publications); (4) comprehensive evaluation metrics (AUROC, AUPRC).
Our experiments reveal a critical empirical insight: embedding quality
significantly governs anomaly detection efficacy, and deep learning-based
approaches demonstrate no performance advantage over conventional shallow
algorithms (e.g., KNN, Isolation Forest) when leveraging LLM-derived
embeddings.In addition, we observe strongly low-rank characteristics in
cross-model performance matrices, which enables an efficient strategy for rapid
model evaluation (or embedding evaluation) and selection in practical
applications. Furthermore, by open-sourcing our benchmark toolkit that includes
all embeddings from different models and code at
https://github.com/jicongfan/Text-Anomaly-Detection-Benchmark, this work
provides a foundation for future research in robust and scalable text anomaly
detection systems.

</details>


### [13] [Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection](https://arxiv.org/abs/2506.21443)
*Ali Şenol,Garima Agrawal,Huan Liu*

Main category: cs.CL

TL;DR: 该研究提出了一个结合领域知识和漂移检测的LLM框架，用于在动态平台（如SEConvo数据集）上检测欺诈和垃圾邮件对话，实现了98%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有技术在检测动态平台上的欺骗性对话方面存在困难，因为语言模式不断演变，并且存在概念漂移（CD），即语义或主题的转移会改变互动的上下文或意图。这使得准确分类具有挑战性。虽然大语言模型（LLM）在自然语言任务中表现出色，但它们在风险敏感场景中常常难以处理语境歧义和幻觉。

Method: 提出了一种领域知识（DK）增强的大语言模型（LLM）框架，该框架包含三个组件：1. DK-LLM模块用于检测欺诈或欺骗性对话；2. 漂移检测单元（OCDD）用于确定是否发生语义漂移；3. 第二个DK-LLM模块用于将漂移分类为良性或欺诈性。该框架首先在虚假评论数据集上验证领域知识的价值，然后应用于SEConvo数据集，该数据集包含各种欺诈和垃圾邮件攻击的多轮对话。

Result: 实验结果表明，该系统能够高精度地检测虚假对话，并有效对其漂移的性质进行分类。基于LLaMA的实现，在结构化提示的指导下，达到了98%的分类准确率。与零样本基线的比较研究表明，结合领域知识和漂移意识显著提高了性能、可解释性和鲁棒性。

Conclusion: 通过整合领域知识和概念漂移检测，该框架在欺诈和垃圾邮件检测方面实现了98%的准确率，显著优于零样本基线，提高了高风险自然语言处理应用的可解释性和鲁棒性。

Abstract: Detecting deceptive conversations on dynamic platforms is increasingly
difficult due to evolving language patterns and Concept Drift (CD)-i.e.,
semantic or topical shifts that alter the context or intent of interactions
over time. These shifts can obscure malicious intent or mimic normal dialogue,
making accurate classification challenging. While Large Language Models (LLMs)
show strong performance in natural language tasks, they often struggle with
contextual ambiguity and hallucinations in risk-sensitive scenarios. To address
these challenges, we present a Domain Knowledge (DK)-Enhanced LLM framework
that integrates pretrained LLMs with structured, task-specific insights to
perform fraud and concept drift detection. The proposed architecture consists
of three main components: (1) a DK-LLM module to detect fake or deceptive
conversations; (2) a drift detection unit (OCDD) to determine whether a
semantic shift has occurred; and (3) a second DK-LLM module to classify the
drift as either benign or fraudulent. We first validate the value of domain
knowledge using a fake review dataset and then apply our full framework to
SEConvo, a multiturn dialogue dataset that includes various types of fraud and
spam attacks. Results show that our system detects fake conversations with high
accuracy and effectively classifies the nature of drift. Guided by structured
prompts, the LLaMA-based implementation achieves 98% classification accuracy.
Comparative studies against zero-shot baselines demonstrate that incorporating
domain knowledge and drift awareness significantly improves performance,
interpretability, and robustness in high-stakes NLP applications.

</details>


### [14] [Explainability in Practice: A Survey of Explainable NLP Across Various Domains](https://arxiv.org/abs/2502.00837)
*Hadi Mohammadi,Ayoub Bagheri,Anastasia Giachanou,Daniel L. Oberski*

Main category: cs.CL

TL;DR: Advanced NLP models are crucial but opaque, driving the need for explainable NLP (XNLP). This review covers XNLP's real-world applications, challenges, and future directions, emphasizing its importance in sectors like healthcare and finance.


<details>
  <summary>Details</summary>
Motivation: The black-box nature of advanced NLP models like GPT and BERT necessitates transparency and explainability, creating an urgent need for XNLP.

Method: This review explores explainable NLP (XNLP), focusing on its practical deployment and real-world applications, examining its implementation and challenges in domain-specific contexts. It also discusses underrepresented areas like real-world applicability, metric evaluation, and the role of human interaction in model assessment.

Result: The paper provides a comprehensive perspective on how XNLP can be designed to meet the unique demands of various sectors, highlighting the importance of explainability in NLP.

Conclusion: The review concludes by suggesting future research directions to improve the understanding and application of explainable NLP (XNLP).

Abstract: Natural Language Processing (NLP) has become a cornerstone in many critical
sectors, including healthcare, finance, and customer relationship management.
This is especially true with the development and use of advanced models such as
GPT-based architectures and BERT, which are widely used in decision-making
processes. However, the black-box nature of these advanced NLP models has
created an urgent need for transparency and explainability. This review
explores explainable NLP (XNLP) with a focus on its practical deployment and
real-world applications, examining its implementation and the challenges faced
in domain-specific contexts. The paper underscores the importance of
explainability in NLP and provides a comprehensive perspective on how XNLP can
be designed to meet the unique demands of various sectors, from healthcare's
need for clear insights to finance's emphasis on fraud detection and risk
assessment. Additionally, this review aims to bridge the knowledge gap in XNLP
literature by offering a domain-specific exploration and discussing
underrepresented areas such as real-world applicability, metric evaluation, and
the role of human interaction in model assessment. The paper concludes by
suggesting future research directions that could enhance the understanding and
broader application of XNLP.

</details>


### [15] [Fraud-R1 : A Multi-Round Benchmark for Assessing the Robustness of LLM Against Augmented Fraud and Phishing Inducements](https://arxiv.org/abs/2502.12904)
*Shu Yang,Shenzhe Zhu,Zeyu Wu,Keyu Wang,Junchi Yao,Junchao Wu,Lijie Hu,Mengdi Li,Derek F. Wong,Di Wang*

Main category: cs.CL

TL;DR: 介绍了一个名为Fraud-R1的基准，用于评估大型语言模型（LLM）防御网络欺诈和网络钓鱼的能力。该基准包含8,564个欺诈案例，并采用多轮评估。研究评估了15个LLM，发现在角色扮演场景和虚假招聘信息方面LLM表现不佳，并且中文和英文模型之间存在性能差距。


<details>
  <summary>Details</summary>
Motivation: 为了评估大型语言模型（LLM）在动态、真实世界的场景中抵御互联网欺诈和网络钓鱼的能力，并揭示当前模型在这一领域的局限性。

Method: 本研究引入了一个名为Fraud-R1的基准，其中包含8,564个来自网络钓鱼诈骗、虚假招聘、社交媒体和新闻的欺诈案例，并将其分为5种主要欺诈类型。该基准采用多轮评估流程，以评估LLM在不同阶段（包括建立可信度、制造紧迫感和情感操控）的抗欺诈能力。研究在两种设置下评估了15个LLM：1. 乐于助人的助手（LLM提供一般的决策支持），2. 角色扮演（模型扮演特定角色）。

Result: 评估结果显示，在防御欺诈和网络钓鱼诱导方面存在重大挑战，尤其是在角色扮演场景和虚假招聘信息方面。研究还观察到中文和英文模型之间存在显著的性能差距，这表明需要改进多语言欺诈检测能力。

Conclusion: 该研究表明，在防御互联网欺诈和网络钓鱼方面，大型语言模型（LLM）面临重大挑战，尤其是在角色扮演场景和虚假招聘信息方面。此外，中文和英文模型之间存在显著的性能差距，这凸显了提高多语言欺诈检测能力的重要性。

Abstract: We introduce Fraud-R1, a benchmark designed to evaluate LLMs' ability to
defend against internet fraud and phishing in dynamic, real-world scenarios.
Fraud-R1 comprises 8,564 fraud cases sourced from phishing scams, fake job
postings, social media, and news, categorized into 5 major fraud types. Unlike
previous benchmarks, Fraud-R1 introduces a multi-round evaluation pipeline to
assess LLMs' resistance to fraud at different stages, including credibility
building, urgency creation, and emotional manipulation. Furthermore, we
evaluate 15 LLMs under two settings: 1. Helpful-Assistant, where the LLM
provides general decision-making assistance, and 2. Role-play, where the model
assumes a specific persona, widely used in real-world agent-based interactions.
Our evaluation reveals the significant challenges in defending against fraud
and phishing inducement, especially in role-play settings and fake job
postings. Additionally, we observe a substantial performance gap between
Chinese and English, underscoring the need for improved multilingual fraud
detection capabilities.

</details>


### [16] [AD-AGENT: A Multi-agent Framework for End-to-end Anomaly Detection](https://arxiv.org/abs/2505.12594)
*Tiankai Yang,Junjun Liu,Wingchun Siu,Jiahang Wang,Zhuangzhuang Qian,Chanjuan Song,Cheng Cheng,Xiyang Hu,Yue Zhao*

Main category: cs.CL

TL;DR: AD-AGENT是一个LLM驱动的框架，使用多代理方法将自然语言指令转换为异常检测管道，简化了跨不同AD库（如PyOD、PyGOD、TSLib）的工作流程。


<details>
  <summary>Details</summary>
Motivation: 为了解决非专业用户在面对多样化的数据模式和专业AD库时，因缺乏特定知识和高级编程技能而面临的挑战。

Method: AD-AGENT框架通过协调专门的代理来处理意图解析、数据准备、库和模型选择、文档挖掘以及迭代代码生成和调试。它使用共享的短期工作区和长期缓存来集成不同的AD库。

Result: AD-AGENT能够生成可靠的脚本，并跨库推荐有竞争力的模型。

Conclusion: AD-AGENT是一个由LLM驱动的多代理框架，可以将自然语言指令转换为完全可执行的异常检测（AD）管道，并集成了PyOD、PyGOD和TSLib等流行AD库。实验证明，AD-AGENT能够生成可靠的脚本并推荐有竞争力的模型。

Abstract: Anomaly detection (AD) is essential in areas such as fraud detection, network
monitoring, and scientific research. However, the diversity of data modalities
and the increasing number of specialized AD libraries pose challenges for
non-expert users who lack in-depth library-specific knowledge and advanced
programming skills. To tackle this, we present AD-AGENT, an LLM-driven
multi-agent framework that turns natural-language instructions into fully
executable AD pipelines. AD-AGENT coordinates specialized agents for intent
parsing, data preparation, library and model selection, documentation mining,
and iterative code generation and debugging. Using a shared short-term
workspace and a long-term cache, the agents integrate popular AD libraries like
PyOD, PyGOD, and TSLib into a unified workflow. Experiments demonstrate that
AD-AGENT produces reliable scripts and recommends competitive models across
libraries. The system is open-sourced to support further research and practical
applications in AD.

</details>


### [17] [AD-LLM: Benchmarking Large Language Models for Anomaly Detection](https://arxiv.org/abs/2412.11142)
*Tiankai Yang,Yi Nian,Shawn Li,Ruiyao Xu,Yuangang Li,Jiaqi Li,Zhuo Xiao,Xiyang Hu,Ryan Rossi,Kaize Ding,Xia Hu,Yue Zhao*

Main category: cs.CL

TL;DR: 首个评估LLM在NLP异常检测任务中应用的基准，展示了LLM在零样本检测方面的潜力，并指出了数据增强和模型选择的挑战及未来方向。


<details>
  <summary>Details</summary>
Motivation: LLM在NLP任务中影响巨大，但其在异常检测（AD）方面的潜力尚未得到充分研究。

Method: 评估LLM在NLP异常检测中的应用，包括零样本检测、数据增强和模型选择。

Result: LLM在零样本AD任务中表现出潜力，数据增强方法有效，但模型选择仍需改进。

Conclusion: LLM在零样本AD方面表现良好，但模型选择仍具挑战性，并提出了六个未来研究方向。

Abstract: Anomaly detection (AD) is an important machine learning task with many
real-world uses, including fraud detection, medical diagnosis, and industrial
monitoring. Within natural language processing (NLP), AD helps detect issues
like spam, misinformation, and unusual user activity. Although large language
models (LLMs) have had a strong impact on tasks such as text generation and
summarization, their potential in AD has not been studied enough. This paper
introduces AD-LLM, the first benchmark that evaluates how LLMs can help with
NLP anomaly detection. We examine three key tasks: (i) zero-shot detection,
using LLMs' pre-trained knowledge to perform AD without tasks-specific
training; (ii) data augmentation, generating synthetic data and category
descriptions to improve AD models; and (iii) model selection, using LLMs to
suggest unsupervised AD models. Through experiments with different datasets, we
find that LLMs can work well in zero-shot AD, that carefully designed
augmentation methods are useful, and that explaining model selection for
specific datasets remains challenging. Based on these results, we outline six
future research directions on LLMs for AD.

</details>


### [18] [Joint Detection of Fraud and Concept Drift inOnline Conversations with LLM-Assisted Judgment](https://arxiv.org/abs/2505.07852)
*Ali Senol,Garima Agrawal,Huan Liu*

Main category: cs.CL

TL;DR: 提出一个两阶段框架，利用集成分类和概念漂移检测来识别和区分数字通信中的欺诈性对话和良性对话转换，提高了检测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 数字通信平台中检测虚假交互是一个严峻且未得到充分解决的问题。传统的检测方法难以适应动态的对话转换，容易将良性的概念漂移误判为欺诈行为。

Method: 提出一个两阶段检测框架，首先使用定制的集成分类模型识别可疑对话，然后利用单类漂移检测器（OCDD）进行概念漂移分析，最后通过大型语言模型（LLM）判断漂移是否为欺诈性操纵或合法的对话转换。

Result: 使用包含社会工程聊天场景的数据集验证了该框架，并证明了其在提高实时欺诈检测的准确性和可解释性方面的实际优势，并与仅使用大型语言模型的基线方法进行了比较。

Conclusion: 该框架通过结合集成分类模型和概念漂移分析，提高了欺诈检测的准确性和可解释性，有效解决了数字通信平台中虚假交互的检测难题。

Abstract: Detecting fake interactions in digital communication platforms remains a
challenging and insufficiently addressed problem. These interactions may appear
as harmless spam or escalate into sophisticated scam attempts, making it
difficult to flag malicious intent early. Traditional detection methods often
rely on static anomaly detection techniques that fail to adapt to dynamic
conversational shifts. One key limitation is the misinterpretation of benign
topic transitions referred to as concept drift as fraudulent behavior, leading
to either false alarms or missed threats. We propose a two stage detection
framework that first identifies suspicious conversations using a tailored
ensemble classification model. To improve the reliability of detection, we
incorporate a concept drift analysis step using a One Class Drift Detector
(OCDD) to isolate conversational shifts within flagged dialogues. When drift is
detected, a large language model (LLM) assesses whether the shift indicates
fraudulent manipulation or a legitimate topic change. In cases where no drift
is found, the behavior is inferred to be spam like. We validate our framework
using a dataset of social engineering chat scenarios and demonstrate its
practical advantages in improving both accuracy and interpretability for real
time fraud detection. To contextualize the trade offs, we compare our modular
approach against a Dual LLM baseline that performs detection and judgment using
different language models.

</details>


### [19] [Application of AI-based Models for Online Fraud Detection and Analysis](https://arxiv.org/abs/2409.19022)
*Antonis Papasavva,Shane Johnson,Ed Lowther,Samantha Lundrigan,Enrico Mariconti,Anna Markovska,Nilufer Tuptuk*

Main category: cs.CL

TL;DR: 一项系统性文献回顾，分析了AI和NLP在在线欺诈检测中的应用，发现研究侧重于特定欺诈类型，缺乏通用性，且模型效果受数据和评估方法的影响。


<details>
  <summary>Details</summary>
Motivation: 随着在线通信技术和AI（如ChatGPT）的发展，在线欺诈手段日益复杂（例如深度伪造），对AI在在线欺诈检测中的应用研究不足，因此需要系统性地梳理和分析该领域的研究现状。

Method: 本研究采用系统性文献回顾（SLR）方法，遵循PRISMA-ScR协议，筛选了2,457篇学术记录，最终纳入223篇相关研究，旨在分析人工智能（AI）和自然语言处理（NLP）技术在在线欺诈检测中的应用。

Result: 研究确定了16种研究者关注的不同在线欺诈类型，并报告了用于分析各类欺诈的最新NLP技术、训练数据来源、NLP算法和模型，以及模型评估所采用的性能指标。研究发现，当前研究侧重于具体的诈骗活动，缺乏通用性。

Conclusion: 当前在线欺诈研究侧重于特定类型的诈骗，缺乏通用性，需要多种模型来应对不同类型的欺诈。此外，诈骗手段的不断演变限制了使用过时数据训练的模型的效果。数据限制、训练偏差报告以及模型性能评估指标的选择性呈现也可能导致潜在的评估偏差。

Abstract: Fraud is a prevalent offence that extends beyond financial loss, causing
psychological and physical harm to victims. The advancements in online
communication technologies alowed for online fraud to thrive in this vast
network, with fraudsters increasingly using these channels for deception. With
the progression of technologies like AI, there is a growing concern that fraud
will scale up, using sophisticated methods, like deep-fakes in phishing
campaigns, all generated by language generation models like ChatGPT. However,
the application of AI in detecting and analyzing online fraud remains
understudied. We conduct a Systematic Literature Review on AI and NLP
techniques for online fraud detection. The review adhered the PRISMA-ScR
protocol, with eligibility criteria including relevance to online fraud, use of
text data, and AI methodologies. We screened 2,457 academic records, 350 met
our eligibility criteria, and included 223. We report the state-of-the-art NLP
techniques for analysing various online fraud categories; the training data
sources; the NLP algorithms and models built; and the performance metrics
employed for model evaluation. We find that current research on online fraud is
divided into various scam activitiesand identify 16 different frauds that
researchers focus on. This SLR enhances the academic understanding of AI-based
detection methods for online fraud and offers insights for policymakers, law
enforcement, and businesses on safeguarding against such activities. We
conclude that focusing on specific scams lacks generalization, as multiple
models are required for different fraud types. The evolving nature of scams
limits the effectiveness of models trained on outdated data. We also identify
issues in data limitations, training bias reporting, and selective presentation
of metrics in model performance reporting, which can lead to potential biases
in model evaluation.

</details>


### [20] [Detecting AI-Generated Text: Factors Influencing Detectability with Current Methods](https://arxiv.org/abs/2406.15583)
*Kathleen C. Fraser,Hillary Dawkins,Svetlana Kiritchenko*

Main category: cs.CL

TL;DR: 本篇调查总结了人工智能生成文本（AIGT）检测的最新方法，强调了该任务的挑战性和重要性，并为未来研究提供了建议。


<details>
  <summary>Details</summary>
Motivation: 随着 LLM 的发展，区分人类和 AI 生成文本变得困难但至关重要，这关系到文本的可信度、欺诈和学术不端行为的检测以及错误信息和政治宣传的传播。

Method: 对人工智能生成文本（AIGT）检测的现有方法进行总结，包括水印、统计和风格分析以及机器学习分类。

Result: 对 AIGT 检测的最新方法进行了总结，并提供了相关数据集信息，旨在为不同场景下 AIGT 的可检测性提供见解，并为未来的工作提出实际建议。

Conclusion: LLM 文本的检测是一个具有重大技术和社会意义的挑战。

Abstract: Large language models (LLMs) have advanced to a point that even humans have
difficulty discerning whether a text was generated by another human, or by a
computer. However, knowing whether a text was produced by human or artificial
intelligence (AI) is important to determining its trustworthiness, and has
applications in many domains including detecting fraud and academic dishonesty,
as well as combating the spread of misinformation and political propaganda. The
task of AI-generated text (AIGT) detection is therefore both very challenging,
and highly critical. In this survey, we summarize state-of-the art approaches
to AIGT detection, including watermarking, statistical and stylistic analysis,
and machine learning classification. We also provide information about existing
datasets for this task. Synthesizing the research findings, we aim to provide
insight into the salient factors that combine to determine how "detectable"
AIGT text is under different scenarios, and to make practical recommendations
for future work towards this significant technical and societal challenge.

</details>


### [21] [Pub-Guard-LLM: Detecting Fraudulent Biomedical Articles with Reliable Explanations](https://arxiv.org/abs/2502.15429)
*Lihu Chen,Shuojie Fu,Gabriel Freedman,Cemre Zor,Guy Martin,James Kinross,Uddhav Vaghela,Ovidiu Serban,Francesca Toni*

Main category: cs.CL

TL;DR: Pub-Guard-LLM是首个基于大型语言模型的生物医学论文欺诈检测系统，通过三种模式提供可解释的预测，并在PubMed Retraction基准测试中表现优于基线方法，有助于维护科研诚信。


<details>
  <summary>Details</summary>
Motivation: 随着越来越多的科学文章涉及欺诈行为，对医学等领域研究的可信度和安全性构成了严重威胁。

Method: 提出了一种名为Pub-Guard-LLM的大型语言模型系统，用于生物医学科学论文的欺诈检测，并提供了三种应用模式：纯推理、检索增强生成和多智能体辩论。该系统能够对预测进行文本解释。

Result: Pub-Guard-LLM在PubMed Retraction基准测试中，所有模式的表现均持续优于各种基线方法，并提供更可靠的解释（根据多种评估方法的评估，其解释更相关、更连贯）。

Conclusion: Pub-Guard-LLM通过提高检测性能和可解释性，为保障科研诚信提供了一个新颖、有效的开源工具。

Abstract: A significant and growing number of published scientific articles is found to
involve fraudulent practices, posing a serious threat to the credibility and
safety of research in fields such as medicine. We propose Pub-Guard-LLM, the
first large language model-based system tailored to fraud detection of
biomedical scientific articles. We provide three application modes for
deploying Pub-Guard-LLM: vanilla reasoning, retrieval-augmented generation, and
multi-agent debate. Each mode allows for textual explanations of predictions.
To assess the performance of our system, we introduce an open-source benchmark,
PubMed Retraction, comprising over 11K real-world biomedical articles,
including metadata and retraction labels. We show that, across all modes,
Pub-Guard-LLM consistently surpasses the performance of various baselines and
provides more reliable explanations, namely explanations which are deemed more
relevant and coherent than those generated by the baselines when evaluated by
multiple assessment methods. By enhancing both detection performance and
explainability in scientific fraud detection, Pub-Guard-LLM contributes to
safeguarding research integrity with a novel, effective, open-source tool.

</details>


### [22] [TeleAntiFraud-28k: An Audio-Text Slow-Thinking Dataset for Telecom Fraud Detection](https://arxiv.org/abs/2503.24115)
*Zhiming Ma,Peidong Wang,Minhua Huang,Jingpeng Wang,Kai Wu,Xiangzhao Lv,Yachun Pang,Yin Yang,Wenjie Tang,Yuchen Kang*

Main category: cs.CL

TL;DR: 为解决电信欺诈检测中多模态数据不足的问题，研究提出了包含28,511个语音-文本对的TeleAntiFraud-28k数据集和TeleAntiFraud-Bench评估基准，并通过多种策略（隐私保护文本生成、LLM语义增强、多智能体对抗合成）构建数据集，同时开源了数据处理框架和SFT模型。


<details>
  <summary>Details</summary>
Motivation: 电信欺诈检测面临缺乏高质量、整合音频信号和面向推理的文本分析的多模态训练数据的挑战。

Method: 通过隐私保护的文本-事实样本生成（ASR转录+TTS）、LLM驱动的语义增强以及多智能体对抗合成来构建包含28,511个语音-文本对的数据集，并将其划分为场景分类、欺诈检测和欺诈类型分类三个任务。同时，构建了标准的TeleAntiFraud-Bench基准进行模型评估，并贡献了一个在混合真实/合成数据上训练的SFT模型。

Result: 构建了首个开源的、专门用于自动化电信欺诈分析的音频-文本慢思考数据集TeleAntiFraud-28k，包含28,511个高质量语音-文本对，并进行了详细的欺诈推理标注。同时，提出了TeleAntiFraud-Bench基准，并贡献了一个优化的SFT模型。

Conclusion: 该研究提出了TeleAntiFraud-28k数据集和TeleAntiFraud-Bench基准，为电信欺诈检测提供了基础，解决了数据隐私和场景多样性挑战，并开源了数据处理框架以促进社区贡献。

Abstract: The detection of telecom fraud faces significant challenges due to the lack
of high-quality multimodal training data that integrates audio signals with
reasoning-oriented textual analysis. To address this gap, we present
TeleAntiFraud-28k, the first open-source audio-text slow-thinking dataset
specifically designed for automated telecom fraud analysis. Our dataset is
constructed through three strategies: (1) Privacy-preserved text-truth sample
generation using automatically speech recognition (ASR)-transcribed call
recordings (with anonymized original audio), ensuring real-world consistency
through text-to-speech (TTS) model regeneration; (2) Semantic enhancement via
large language model (LLM)-based self-instruction sampling on authentic ASR
outputs to expand scenario coverage; (3) Multi-agent adversarial synthesis that
simulates emerging fraud tactics through predefined communication scenarios and
fraud typologies. The generated dataset contains 28,511 rigorously processed
speech-text pairs, complete with detailed annotations for fraud reasoning. The
dataset is divided into three tasks: scenario classification, fraud detection,
fraud type classification. Furthermore, we construct TeleAntiFraud-Bench, a
standardized evaluation benchmark comprising proportionally sampled instances
from the dataset, to facilitate systematic testing of model performance on
telecom fraud detection tasks. We also contribute a production-optimized
supervised fine-tuning (SFT) model trained on hybrid real/synthetic data, while
open-sourcing the data processing framework to enable community-driven dataset
expansion. This work establishes a foundational framework for multimodal
anti-fraud research while addressing critical challenges in data privacy and
scenario diversity. The project will be released at
https://github.com/JimmyMa99/TeleAntiFraud.

</details>


### [23] [ConSCompF: Consistency-focused Similarity Comparison Framework for Generative Large Language Models](https://arxiv.org/abs/2503.13923)
*Alexey Karev,Dong Xu*

Main category: cs.CL

TL;DR: 提出了一种名为ConSCompF的一致性关注的相似性比较框架，用于比较大型语言模型（LLM）。该框架可以在少量无标签数据上运行，并且不需要LLM开发者披露任何产品信息。ConSCompF可以帮助比较LLM，可视化LLM的相似性，并可能有助于检测投资欺诈。


<details>
  <summary>Details</summary>
Motivation: 随着市场上新LLM的频繁推出，区分它们变得越来越困难，这产生了对新的LLM比较方法的需求。

Method: 提出了一致性关注的相似性比较框架(ConSCompF)，用于比较生成式大型语言模型。该框架通过比较两个LLM生成的文本来产生相似性分数，表明它们响应之间整体的相似程度。该框架可以在少量无标签数据上运行，并且不需要LLM开发者披露任何产品信息。

Result: 进行了两次旨在识别多个LLM之间相似性的实验，并检查了ConSCompF生成的相似性分数与ROUGE-L等其他基准技术产生的输出差异之间的相关性。最后，进行了一系列少样本LLM比较实验，以评估ConSCompF在少样本LLM比较场景中的性能。

Conclusion: 该框架可用于计算多个LLM的相似性矩阵，并通过主成分分析(PCA)进行有效可视化。ConSCompF的输出可以为LLM训练数据提供有用的见解，并有助于检测潜在的投资欺诈行为。

Abstract: Large language models (LLMs) have been one of the most important discoveries
in machine learning in recent years. LLM-based artificial intelligence (AI)
assistants, such as ChatGPT, have consistently attracted the attention from
researchers, investors, and the general public, driving the rapid growth of
this industry. With the frequent introduction of new LLMs to the market, it
becomes increasingly difficult to differentiate between them, creating a demand
for new LLM comparison methods.
  In this research, the Consistency-focused Similarity Comparison Framework
(ConSCompF) for generative large language models is proposed. It compares texts
generated by two LLMs and produces a similarity score, indicating the overall
degree of similarity between their responses. The main advantage of this
framework is that it can operate on a small number of unlabeled data, such as
chatbot instruction prompts, and does not require LLM developers to disclose
any information about their product.
  To evaluate the efficacy of ConSCompF, two experiments aimed at identifying
similarities between multiple LLMs are conducted. Additionally, these
experiments examine the correlation between the similarity scores generated by
ConSCompF and the differences in the outputs produced by other benchmarking
techniques, such as ROUGE-L. Finally, a series of few-shot LLM comparison
experiments is conducted to evaluate the performance of ConSCompF in a few-shot
LLM comparison scenario.
  The proposed framework can be used for calculating similarity matrices of
multiple LLMs, which can be effectively visualized using principal component
analysis (PCA). The ConSCompF output may provide useful insights into data that
might have been used during LLM training and help detect possible investment
fraud attempts.

</details>


### [24] [Unmask It! AI-Generated Product Review Detection in Dravidian Languages](https://arxiv.org/abs/2503.09289)
*Somsubhra De,Advait Vats*

Main category: cs.CL

TL;DR: 本研究探索了使用各种机器学习和 Transformer 模型（包括 Indic-BERT、IndicSBERT、MuRIL、XLM-RoBERTa 和 MalayalamBERT）来检测泰米尔语和马来语等低资源语言中的人工智能生成产品评论。研究结果表明，Transformer 模型在识别此类虚假评论方面非常有效，有助于提高低资源语言环境中的检测能力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决人工智能生成评论日益增多的问题，这些评论对在线平台的信誉构成了严重威胁，并专注于检测泰米尔语和马来语（两种资源匮乏的语言）中的人工智能生成产品评论。

Method: 本研究采用了一系列方法，从传统的机器学习方法到先进的基于 Transformer 的模型，例如 Indic-BERT、IndicSBERT、MuRIL、XLM-RoBERTa 和 MalayalamBERT。

Result: 本研究的结果强调了利用最先进的 Transformer 模型在准确识别人工智能生成内容方面的有效性。

Conclusion: 本研究的发现强调了利用最先进的 Transformer 模型在准确识别人工智能生成内容方面的有效性，证明了在低资源语言环境中提高虚假评论检测潜力的可能性。

Abstract: The rise of Generative AI has led to a surge in AI-generated reviews, often
posing a serious threat to the credibility of online platforms. Reviews serve
as the primary source of information about products and services. Authentic
reviews play a vital role in consumer decision-making. The presence of
fabricated content misleads consumers, undermines trust and facilitates
potential fraud in digital marketplaces. This study focuses on detecting
AI-generated product reviews in Tamil and Malayalam, two low-resource languages
where research in this domain is relatively under-explored. We worked on a
range of approaches - from traditional machine learning methods to advanced
transformer-based models such as Indic-BERT, IndicSBERT, MuRIL, XLM-RoBERTa and
MalayalamBERT. Our findings highlight the effectiveness of leveraging the
state-of-the-art transformers in accurately identifying AI-generated content,
demonstrating the potential in enhancing the detection of fake reviews in
low-resource language settings.

</details>


### [25] [NLP-ADBench: NLP Anomaly Detection Benchmark](https://arxiv.org/abs/2412.04784)
*Yuangang Li,Jiaqi Li,Zhuo Xiao,Tiankai Yang,Yi Nian,Xiyang Hu,Yue Zhao*

Main category: cs.CL

TL;DR: NLP-ADBench是一个全面的NLP异常检测基准，包含八个数据集和十九种算法的评估。研究发现，两步法结合OpenAI的语言嵌入在性能上优于端到端方法，并为NLP异常检测的未来研究提供了方向。


<details>
  <summary>Details</summary>
Motivation: 为了解决自然语言处理（NLP）中异常检测（AD）任务的不足，该研究提出了NLP-ADBench，这是一个全面的基准，旨在促进NLP异常检测的进展，特别是在检测有害内容、网络钓鱼尝试或垃圾评论等方面。

Method: NLP-ADBench基准包含八个精心策划的数据集，并评估了十九种最先进的算法，其中包括三种端到端方法和十六种两步算法。两步算法将传统的异常检测技术应用于由bert-base-uncased和OpenAI的text-embedding-3-large模型生成的语言嵌入。

Result: 研究结果表明，没有单一模型能在所有数据集上表现最佳，这强调了自动化模型选择的必要性。此外，利用基于Transformer的嵌入的两步法在性能上持续优于专门的端到端方法，其中OpenAI嵌入的性能优于BERT嵌入。

Conclusion: 该研究发布了一个名为NLP-ADBench的NLP异常检测基准，包含八个数据集和十九种算法的评估，旨在为NLP异常检测提供标准化评估框架，推动该领域发展，尤其是在提升Web系统安全性和可靠性方面。

Abstract: Anomaly detection (AD) is a critical machine learning task with diverse
applications in web systems, including fraud detection, content moderation, and
user behavior analysis. Despite its significance, AD in natural language
processing (NLP) remains underexplored, limiting advancements in detecting
anomalies in text data such as harmful content, phishing attempts, or spam
reviews. In this paper, we introduce NLP-ADBench, the most comprehensive
benchmark for NLP anomaly detection (NLP-AD), comprising eight curated datasets
and evaluations of nineteen state-of-the-art algorithms. These include three
end-to-end methods and sixteen two-step algorithms that apply traditional
anomaly detection techniques to language embeddings generated by
bert-base-uncased and OpenAI's text-embedding-3-large models.
  Our results reveal critical insights and future directions for NLP-AD.
Notably, no single model excels across all datasets, highlighting the need for
automated model selection. Moreover, two-step methods leveraging
transformer-based embeddings consistently outperform specialized end-to-end
approaches, with OpenAI embeddings demonstrating superior performance over BERT
embeddings. By releasing NLP-ADBench at
https://github.com/USC-FORTIS/NLP-ADBench, we provide a standardized framework
for evaluating NLP-AD methods, fostering the development of innovative
approaches. This work fills a crucial gap in the field and establishes a
foundation for advancing NLP anomaly detection, particularly in the context of
improving the safety and reliability of web-based systems.

</details>


### [26] [Information Extraction from Heterogeneous Documents without Ground Truth Labels using Synthetic Label Generation and Knowledge Distillation](https://arxiv.org/abs/2411.14957)
*Aniket Bhattacharyya,Anurag Tripathi*

Main category: cs.CL

TL;DR: 该研究提出了一种名为 TAIL 的新方法，用于在缺乏标签的视觉丰富文档（如收据）中生成合成标签，并通过知识蒸馏训练了一个文档理解模型。该模型在实际应用中表现优于现有技术，成本更低、速度更快，并能有效防止过度支付。


<details>
  <summary>Details</summary>
Motivation: 为了防范欺诈和滥用风险，组织需要从提交的发票和收据中有效提取信息，以评估费用报销的适当性、支出和交易策略的遵守情况、收据的有效性，以及进行下游的各级异常检测。然而，这些文档格式和语言异构，图像质量不一，并且通常缺乏用于有效训练模型的地面真实标签。

Method: 提出了一种名为“任务感知指令式标注”（TAIL）的方法，用于在没有标签的 VRD 语料库中生成合成标签，并使用基于响应的知识蒸馏（不使用教师模型的权重或训练数据集）对多模态视觉丰富的文档理解模型（VRDU）进行微调，以条件化生成适当格式的注释。

Result: 通过在具有地面真实标签的基准外部数据集上进行实证研究，证明了该方法在特定条件下能与 Claude 3 Sonnet 媲美。

Conclusion: 该方法在大型跨国组织的内部费用文档上表现优于最先进的大型多模态模型 Claude 3 Sonnet，成本降低 85%，速度提高 5 倍，并且在平均归一化 Levenshtein 相似度 (ANLS) 分数方面比最先进的布局感知基线提高了 10% 以上，这得益于其推理和从稀有格式提取信息的能力。最后，我们说明了该方法在防止过度支付方面的应用。

Abstract: Invoices and receipts submitted by employees are visually rich documents
(VRDs) with textual, visual and layout information. To protect against the risk
of fraud and abuse, it is crucial for organizations to efficiently extract
desired information from submitted receipts. This helps in the assessment of
key factors such as appropriateness of the expense claim, adherence to spending
and transaction policies, the validity of the receipt, as well as downstream
anomaly detection at various levels. These documents are heterogeneous, with
multiple formats and languages, uploaded with different image qualities, and
often do not contain ground truth labels for the efficient training of models.
In this paper we propose Task Aware Instruction-based Labelling (TAIL), a
method for synthetic label generation in VRD corpuses without labels, and
fine-tune a multimodal Visually Rich Document Understanding Model (VRDU) on
TAIL labels using response-based knowledge distillation without using the
teacher model's weights or training dataset to conditionally generate
annotations in the appropriate format. Using a benchmark external dataset where
ground truth labels are available, we demonstrate conditions under which our
approach performs at par with Claude 3 Sonnet through empirical studies. We
then show that the resulting model performs at par or better on the internal
expense documents of a large multinational organization than state-of-the-art
LMM (large multimodal model) Claude 3 Sonnet while being 85% less costly and
~5X faster, and outperforms layout-aware baselines by more than 10% in Average
Normalized Levenshtein Similarity (ANLS) scores due to its ability to reason
and extract information from rare formats. Finally, we illustrate the usage of
our approach in overpayment prevention.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [27] [A Technique for the Detection of PDF Tampering or Forgery](https://arxiv.org/abs/2507.00827)
*Gabriel Grobler,Sheunesu Makura,Hein Venter*

Main category: cs.CR

TL;DR: 提出了一种利用PDF页面对象检测文本、图像和元数据篡改的新技术。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有哈希或水印技术无法检测PDF签名或其他非视觉方面（如元数据）的篡改问题。

Method: 提出了一种利用PDF文档页面对象进行篡改检测的新技术，并开发了一个原型系统。

Result: 该技术能够检测PDF文档中的篡改，包括文本、图像或元数据。

Conclusion: 该技术利用PDF文档的页面对象来检测PDF文档中的篡改，可以检测文本、图像或元数据等更改。

Abstract: Tampering or forgery of digital documents has become widespread, most
commonly through altering images without any malicious intent such as enhancing
the overall appearance of the image. However, there are occasions when
tampering of digital documents can have negative consequences, such as
financial fraud and reputational damage. Tampering can occur through altering a
digital document's text or editing an image's pixels. Many techniques have been
developed to detect whether changes have been made to a document. Most of these
techniques rely on generating hashes or watermarking the document. These
techniques, however, have limitations in that they cannot detect alterations to
portable document format (PDF) signatures or other non-visual aspects, such as
metadata. This paper presents a new technique that can be used to detect
tampering within a PDF document by utilizing the PDF document's file page
objects. The technique employs a prototype that can detect changes to a PDF
document, such as changes made to the text, images, or metadata of the said
file.

</details>


### [28] [AI-Governed Agent Architecture for Web-Trustworthy Tokenization of Alternative Assets](https://arxiv.org/abs/2507.00096)
*Ailiya Borjigin,Wei Zhou,Cong He*

Main category: cs.CR

TL;DR: 提出了一种AI治理代理架构，利用区块链和智能代理来提高另类资产代币化的可信度、安全性和合规性。


<details>
  <summary>Details</summary>
Motivation: 确保基于Web的代币化生态系统的可信度带来了重大挑战，从验证链下资产数据到执行法规遵从性。

Method: 提出了一种AI治理的代理架构，该架构将智能代理与区块链集成，以实现另类资产的Web信任代币化。自主代理负责代币化过程（资产验证、估值、合规性检查和生命周期管理），而AI驱动的治理层则通过自适应策略和加密经济激励措施来监控代理行为并强制执行信任。

Result: 该方法增强了资产代币化的透明度、安全性和合规性，解决了数据真实性和欺诈方面的关键问题。在对房地产资产进行代币化进行的案例研究中，说明了该架构如何通过实时AI异常检测和链上执行来减轻风险（例如，欺诈性列表和洗钱）。

Conclusion: 该框架为Web上的资产代币化提供了新的信任机制，并为旨在部署安全、合规的代币化平台的从业者提供了见解。

Abstract: Alternative Assets tokenization is transforming non-traditional financial
instruments are represented and traded on the web. However, ensuring
trustworthiness in web-based tokenized ecosystems poses significant challenges,
from verifying off-chain asset data to enforcing regulatory compliance. This
paper proposes an AI-governed agent architecture that integrates intelligent
agents with blockchain to achieve web-trustworthy tokenization of alternative
assets. In the proposed architecture, autonomous agents orchestrate the
tokenization process (asset verification, valuation, compliance checking, and
lifecycle management), while an AI-driven governance layer monitors agent
behavior and enforces trust through adaptive policies and cryptoeconomic
incentives. We demonstrate that this approach enhances transparency, security,
and compliance in asset tokenization, addressing key concerns around data
authenticity and fraud. A case study on tokenizing real estate assets
illustrates how the architecture mitigates risks (e.g., fraudulent listings and
money laundering) through real-time AI anomaly detection and on-chain
enforcement. Our evaluation and analysis suggest that combining AI governance
with multi-agent systems and blockchain can significantly bolster trust in
tokenized asset ecosystems. This work offers a novel framework for trustworthy
asset tokenization on the web and provides insights for practitioners aiming to
deploy secure, compliant tokenization platforms.

</details>


### [29] [An Attack Method for Medical Insurance Claim Fraud Detection based on Generative Adversarial Network](https://arxiv.org/abs/2506.19871)
*Yining Pang,Chenghan Li*

Main category: cs.CR

TL;DR: 本研究提出了一种基于GAN的对抗性攻击方法，能够以99%的成功率生成能够绕过保险欺诈检测系统的伪造案例，凸显了提高检测模型鲁棒性的必要性。


<details>
  <summary>Details</summary>
Motivation: 尽管人工智能和机器学习算法在检测欺诈索赔方面表现出色，但缺乏标准化的防御机制使当前系统容易受到新兴的对抗性威胁。因此，有必要研究对抗性攻击对保险欺诈检测系统的影响，以提高其鲁棒性。

Method: 提出了一种基于生成对抗网络（GAN）的方法来对欺诈检测系统进行对抗性攻击。

Result: 攻击者可以在不知道训练数据或内部模型细节的情况下，以99%的攻击成功率（ASR）生成被归类为合法的欺诈案例。通过对真实的保险记录和索赔进行细微的修改，攻击者可以显著增加欺诈风险，从而绕过被攻击的检测系统。

Conclusion: 本研究结果表明，在无需了解训练数据或内部模型细节的情况下，攻击者可以通过生成伪造案例并将其归类为合法案例，成功率高达99%。通过对真实保险记录和索赔进行细微修改，攻击者能够显著增加欺诈风险，有可能绕过被攻击的检测系统。这些发现强调了增强保险欺诈检测模型对抗对抗性操纵的鲁棒性的紧迫需求，从而确保不同保险系统的稳定性和可靠性。

Abstract: Insurance fraud detection represents a pivotal advancement in modern
insurance service, providing intelligent and digitalized monitoring to enhance
management and prevent fraud. It is crucial for ensuring the security and
efficiency of insurance systems. Although AI and machine learning algorithms
have demonstrated strong performance in detecting fraudulent claims, the
absence of standardized defense mechanisms renders current systems vulnerable
to emerging adversarial threats. In this paper, we propose a GAN-based approach
to conduct adversarial attacks on fraud detection systems. Our results indicate
that an attacker, without knowledge of the training data or internal model
details, can generate fraudulent cases that are classified as legitimate with a
99\% attack success rate (ASR). By subtly modifying real insurance records and
claims, adversaries can significantly increase the fraud risk, potentially
bypassing compromised detection systems. These findings underscore the urgent
need to enhance the robustness of insurance fraud detection models against
adversarial manipulation, thereby ensuring the stability and reliability of
different insurance systems.

</details>


### [30] [Secure Energy Transactions Using Blockchain Leveraging AI for Fraud Detection and Energy Market Stability](https://arxiv.org/abs/2506.19870)
*Md Asif Ul Hoq Khan,MD Zahedul Islam,Istiaq Ahmed,Md Masud Karim Rabbi,Farhana Rahman Anonna,MD Abdul Fahim Zeeshan,Mehedi Hasan Ridoy,Bivash Ranjan Chowdhury,Md Nazmul Shakir Rabbi,GM Alamin Sadnan*

Main category: cs.CR

TL;DR: 利用区块链和人工智能技术，为去中心化能源市场创建一个安全、智能的交易系统，以解决安全、欺诈和市场可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 去中心化能源市场和点对点交易带来了新的挑战，尤其是在能源交易的安全性和真实性方面。本研究旨在为去中心化美国能源市场开发一个安全、智能且高效的能源交易系统。

Method: 本研究提出了一种双层系统架构，结合了区块链层和人工智能层。区块链层用于确保交易安全，人工智能层则用于市场情报和欺诈行为检测。研究中使用了在分类任务方面表现优异的机器学习模型来识别欺诈行为。

Result: 研究表明，结合区块链和人工智能的技术能够有效应对去中心化能源市场面临的安全、欺诈和市场可靠性挑战。

Conclusion: 本研究提出了一种结合区块链和人工智能的能源交易系统，旨在解决去中心化能源市场的安全和欺诈问题，提高了市场可靠性。

Abstract: Peer-to-peer trading and the move to decentralized grids have reshaped the
energy markets in the United States. Notwithstanding, such developments lead to
new challenges, mainly regarding the safety and authenticity of energy trade.
This study aimed to develop and build a secure, intelligent, and efficient
energy transaction system for the decentralized US energy market. This research
interlinks the technological prowess of blockchain and artificial intelligence
(AI) in a novel way to solve long-standing challenges in the distributed energy
market, specifically those of security, fraudulent behavior detection, and
market reliability. The dataset for this research is comprised of more than 1.2
million anonymized energy transaction records from a simulated peer-to-peer
(P2P) energy exchange network emulating real-life blockchain-based American
microgrids, including those tested by LO3 Energy and Grid+ Labs. Each record
contains detailed fields of transaction identifier, timestamp, energy volume
(kWh), transaction type (buy/sell), unit price, prosumer/consumer identifier
(hashed for privacy), smart meter readings, geolocation regions, and settlement
confirmation status. The dataset also includes system-calculated behavior
metrics of transaction rate, variability of energy production, and historical
pricing patterns. The system architecture proposed involves the integration of
two layers, namely a blockchain layer and artificial intelligence (AI) layer,
each playing a unique but complementary function in energy transaction securing
and market intelligence improvement. The machine learning models used in this
research were specifically chosen for their established high performance in
classification tasks, specifically in the identification of energy transaction
fraud in decentralized markets.

</details>


### [31] [FAA Framework: A Large Language Model-Based Approach for Credit Card Fraud Investigations](https://arxiv.org/abs/2506.11635)
*Shaun Shuster,Eyal Zaloof,Asaf Shabtai,Rami Puzis*

Main category: cs.CR

TL;DR: 该研究提出了一个名为FAA的框架，利用多模态大语言模型（LLMs）来自动化信用卡欺诈调查，以解决欺诈分析师的警报疲劳问题。评估结果显示，该框架能够高效可靠地完成调查，并减轻分析师的工作负担。


<details>
  <summary>Details</summary>
Motivation: 为了解决欺诈分析师在处理大量欺诈警报时遇到的警报疲劳问题，我们提出了FAA框架。

Method: 提出了一种名为FAA（欺诈分析师助手）的框架，该框架采用多模态大语言模型（LLMs）来自动执行信用卡欺诈调查并生成解释性报告。FAA框架利用LLMs的推理、代码执行和视觉能力，在每个调查步骤中进行规划、证据收集和分析。

Result: 通过对500起信用卡欺诈调查进行的全面实证评估表明，FAA框架能够进行可靠且高效的调查，平均包含七个步骤。

Conclusion: 该FAA框架能够自动化大部分工作负载，并帮助减轻欺诈分析师面临的挑战。

Abstract: The continuous growth of the e-commerce industry attracts fraudsters who
exploit stolen credit card details. Companies often investigate suspicious
transactions in order to retain customer trust and address gaps in their fraud
detection systems. However, analysts are overwhelmed with an enormous number of
alerts from credit card transaction monitoring systems. Each alert
investigation requires from the fraud analysts careful attention, specialized
knowledge, and precise documentation of the outcomes, leading to alert fatigue.
To address this, we propose a fraud analyst assistant (FAA) framework, which
employs multi-modal large language models (LLMs) to automate credit card fraud
investigations and generate explanatory reports. The FAA framework leverages
the reasoning, code execution, and vision capabilities of LLMs to conduct
planning, evidence collection, and analysis in each investigation step. A
comprehensive empirical evaluation of 500 credit card fraud investigations
demonstrates that the FAA framework produces reliable and efficient
investigations comprising seven steps on average. Thus we found that the FAA
framework can automate large parts of the workload and help reduce the
challenges faced by fraud analysts.

</details>


### [32] [Risks & Benefits of LLMs & GenAI for Platform Integrity, Healthcare Diagnostics, Cybersecurity, Privacy & AI Safety: A Comprehensive Survey, Roadmap & Implementation Blueprint](https://arxiv.org/abs/2506.12088)
*Kiarash Ahi*

Main category: cs.CR

TL;DR: LLM和GenAI技术在带来巨大机遇的同时，也引发了网络安全、隐私和平台完整性等方面的严峻挑战。论文分析了这些风险，并提出了一套集成的解决方案，包括政策审计、欺诈检测、合规自动化以及一个先进的LLM-DA堆栈，以增强平台安全和负责任的创新。


<details>
  <summary>Details</summary>
Motivation: 随着LLM和GenAI（如ChatGPT、Claude、Gemini、LLaMA和Copilot）的出现，它们在重塑数字平台和应用程序生态系统的同时，也带来了网络安全、隐私和平台完整性方面的关键挑战。特别是，LLM辅助恶意软件、AI生成的评论、AI诈骗报告和错误信息网站呈指数级增长，同时LLM也促进了移动应用程序的提交量增长。此外，将LLM集成到临床诊断中也引发了对准确性、偏见和安全性的担忧。

Method: 该论文基于对455篇参考文献的全面分析，对LLM和GenAI的风险进行了调查。

Result: 分析显示LLM辅助恶意软件预计将从2021年的2%上升到2025年的50%；AI生成的Google评论从2021年的1.2%增长到2023年的12.21%，预计到2025年将达到30%；AI诈骗报告激增456%；错误信息网站增加了1500%以上，其中深度伪造内容在2024年增加了50-60%。与此同时，移动应用程序的提交量从2020年的180万增加到2024年的300万，预计到2025年将达到360万。

Conclusion: 该论文提出了一项战略路线图和操作蓝图，集成了政策审计（CCPA、GDPR）、欺诈检测和合规自动化，以及一个先进的LLM-DA堆栈，其中包含多LLM路由、代理记忆和治理层等模块化组件，以增强平台完整性。论文还提供了可操作的见解、跨职能的最佳实践和真实案例研究，旨在为数字平台提供可扩展的信任、安全和负责任的创新途径。

Abstract: Large Language Models (LLMs) and generative AI (GenAI) systems such as
ChatGPT, Claude, Gemini, LLaMA, and Copilot, developed by OpenAI, Anthropic,
Google, Meta, and Microsoft are reshaping digital platforms and app ecosystems
while introducing key challenges in cybersecurity, privacy, and platform
integrity. Our analysis shows alarming trends: LLM-assisted malware is
projected to rise from 2% in 2021 to 50% by 2025; AI-generated Google reviews
grew from 1.2% in 2021 to 12.21% in 2023, with an expected 30% by 2025; AI scam
reports surged 456%; and misinformation sites increased over 1500%, with a
50-60% increase in deepfakes in 2024. Concurrently, as LLMs have facilitated
code development, mobile app submissions grew from 1.8 million in 2020 to 3.0
million in 2024, with 3.6 million expected by 2025. To address AI threats,
platforms from app stores like Google Play and Apple to developer hubs like
GitHub Copilot, and social platforms like TikTok and Facebook, to marketplaces
like Amazon are deploying AI and LLM-based defenses. This highlights the dual
nature of these technologies as both the source of new threats and the
essential tool for their mitigation. Integrating LLMs into clinical diagnostics
also raises concerns about accuracy, bias, and safety, needing strong
governance. Drawing on a comprehensive analysis of 455 references, this paper
presents a survey of LLM and GenAI risks. We propose a strategic roadmap and
operational blueprint integrating policy auditing (CCPA, GDPR), fraud
detection, and compliance automation, and an advanced LLM-DA stack with modular
components including multi LLM routing, agentic memory, and governance layers
to enhance platform integrity. We also provide actionable insights,
cross-functional best practices, and real-world case studies. These
contributions offer paths to scalable trust, safety, and responsible innovation
across digital platforms.

</details>


### [33] [FIST: A Structured Threat Modeling Framework for Fraud Incidents](https://arxiv.org/abs/2506.05740)
*Yu-Chen Dai,Lu-An Chen,Sy-Jye Her,Yu-Xian Jiang*

Main category: cs.CR

TL;DR: FIST 是一个新颖的、开源的欺诈威胁建模框架，它整合了技术和心理方面，以提高欺诈检测和情报共享的效率，并促进协作。


<details>
  <summary>Details</summary>
Motivation: 欺诈活动正在迅速演变，采用越来越多样化和复杂的方法，对个人、组织和社会构成严重威胁。本研究的动机是提高欺诈检测的效率和威胁情报共享的标准化，以促进组织和部门之间的协作和统一语言。

Method: FIST（欺诈事件结构化威胁框架）是一个结构化威胁建模方法，它系统地将社会工程策略、基于阶段的行为分解和详细的攻击技术映射到一个可重用的知识库中。它整合了网络安全、犯罪学和行为科学的跨学科见解，以分析欺诈事件，支持自动化检测、量化风险评估和标准化的事件报告。

Result: FIST 框架通过真实案例研究进行了有效性验证，证明了其在弥合学术研究与实际应用之间的差距方面的价值。它为构建由情报驱动的反欺诈生态系统奠定了基础，实现了对欺诈事件的细粒度分析、自动化检测、量化风险评估和标准化的事件报告。

Conclusion: FIST是通过结合网络安全、犯罪学和行为科学的跨学科见解，为欺诈场景设计的开创性结构化威胁建模方法。它通过整合社会工程策略、基于阶段的行为分解和详细的攻击技术映射到一个可重用的知识库中，旨在提高欺诈检测效率和威胁情报共享的标准化，促进组织和部门之间的协作和统一语言。该框架通过真实案例研究得到验证，在学术研究和实际应用之间架起了桥梁，并为由情报驱动的反欺诈生态系统奠定了基础。FIST 是第一个统一技术和心理方面的系统性、开源欺诈威胁建模框架，旨在促进学术界和工业界之间的合作。

Abstract: Fraudulent activities are rapidly evolving, employing increasingly diverse
and sophisticated methods that pose serious threats to individuals,
organizations, and society. This paper proposes the FIST Framework (Fraud
Incident Structured Threat Framework), an innovative structured threat modeling
methodology specifically designed for fraud scenarios. Inspired by MITRE
ATT\&CK and DISARM, FIST systematically incorporates social engineering
tactics, stage-based behavioral decomposition, and detailed attack technique
mapping into a reusable knowledge base. FIST aims to enhance the efficiency of
fraud detection and the standardization of threat intelligence sharing,
promoting collaboration and a unified language across organizations and
sectors. The framework integrates interdisciplinary insights from
cybersecurity, criminology, and behavioral science, addressing both technical
vectors and psychological manipulation mechanisms in fraud. This approach
enables fine-grained analysis of fraud incidents, supporting automated
detection, quantitative risk assessment, and standardized incident reporting.
The effectiveness of the framework is further validated through real-world case
studies, demonstrating its value in bridging academic research and practical
applications, and laying the foundation for an intelligence-driven anti-fraud
ecosystem. To the best of our knowledge, FIST is the first systematic,
open-source fraud threat modeling framework that unifies both technical and
psychological aspects, and is made freely available to foster collaboration
between academia and industry.

</details>


### [34] [Browser Fingerprinting Using WebAssembly](https://arxiv.org/abs/2506.00719)
*Mordechai Guri,Dor Fibert*

Main category: cs.CR

TL;DR: 本文提出了一种利用 WebAssembly（Wasm）进行客户端指纹识别的新方法，即使在 User-Agent 被伪造的情况下，也能通过分析 Wasm 的 JavaScript API 实现精确的设备识别。该方法结合了 CPU、内存和 I/O 活动，在多种平台和虚拟环境中均表现出色，准确率高，误报率低，并提出了相应的隐私保护建议。


<details>
  <summary>Details</summary>
Motivation: 随着 Web 客户端指纹识别技术在欺诈检测和个性化体验等方面的广泛应用，其引发的隐私问题也日益突出。该研究旨在提出一种更有效的指纹识别方法，以应对现有的隐私挑战，并为未来的浏览器设计提供隐私保护的解决方案。

Method: 本文提出了一种利用 WebAssembly 的计算能力和 JavaScript API 实现的客户端指纹识别方法。该方法通过结合 CPU 密集型操作、内存任务和 I/O 活动来捕捉独特的浏览器行为，以区分不同的设备和浏览器实例，即使在 User-Agent 被伪造的情况下也能达到低于 1% 的误报率。研究在 Intel、AMD、ARM CPU、Windows、macOS、Android、iOS 等多种平台和 VMWare、KVM、VirtualBox 等虚拟化环境中进行了验证。

Result: 基于 WebAssembly 的指纹识别方法在多种平台和环境下进行了广泛评估，结果表明该方法能够高精度地识别设备，即使在 User-Agent 被伪造的情况下也能区分 Chromium 内核的浏览器，误报率低于 1%。与现有方法相比，该技术显著提高了识别准确性。

Conclusion: 该研究提出了一种基于 WebAssembly 的新颖的客户端指纹识别方法，能够高精度地识别设备，即使在用户代理被欺骗的情况下也能区分不同的浏览器。该方法通过利用 WebAssembly 的计算能力、CPU 密集型操作、内存任务和 I/O 活动来捕捉独特的浏览器行为，并在多种平台和环境下进行了验证，显著提高了识别准确性。此外，研究还提出了缓解隐私风险的策略。

Abstract: Web client fingerprinting has become a widely used technique for uniquely
identifying users, browsers, operating systems, and devices with high accuracy.
While it is beneficial for applications such as fraud detection and
personalized experiences, it also raises privacy concerns by enabling
persistent tracking and detailed user profiling. This paper introduces an
advanced fingerprinting method using WebAssembly (Wasm) - a low-level
programming language that offers near-native execution speed in modern web
browsers. With broad support across major browsers and growing adoption,
WebAssembly provides a strong foundation for developing more effective
fingerprinting methods.
  In this work, we present a new approach that leverages WebAssembly's
computational capabilities to identify returning devices-such as smartphones,
tablets, laptops, and desktops across different browsing sessions. Our method
uses subtle differences in the WebAssembly JavaScript API implementation to
distinguish between Chromium-based browsers like Google Chrome and Microsoft
Edge, even when identifiers such as the User-Agent are completely spoofed,
achieving a false-positive rate of less than 1%. The fingerprint is generated
using a combination of CPU-bound operations, memory tasks, and I/O activities
to capture unique browser behaviors. We validate this approach on a variety of
platforms, including Intel, AMD, and ARM CPUs, operating systems such as
Windows, macOS, Android, and iOS, and in environments like VMWare, KVM, and
VirtualBox. Extensive evaluation shows that WebAssembly-based fingerprinting
significantly improves identification accuracy. We also propose mitigation
strategies to reduce the privacy risks associated with this method, which could
be integrated into future browser designs to better protect user privacy.

</details>


### [35] [GNNBleed: Inference Attacks to Unveil Private Edges in Graphs with Realistic Access to GNN Models](https://arxiv.org/abs/2311.16139)
*Zeyu Song,Ehsanul Kabir,Shagufta Mehnaz*

Main category: cs.CR

TL;DR: 本研究提出了一种新的攻击方法，用于在对手仅拥有黑盒访问权限和访问控制的情况下，以及在动态图场景中，损害 GNN 模型中的边隐私，并在各种 GNN 架构和真实世界数据集上证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于 GNN 模型中的边（例如社交网络或金融交易）包含敏感信息，需要隐私保障，但这些边也可能被对手利用来损害隐私。因此，本研究旨在解决 GNN 中的边隐私问题，特别是在对手仅拥有黑盒访问权限和访问控制的情况下，以及在不断演变的动态图场景中。

Method: 提出了一系列利用 GNN 的消息传递机制的攻击方法，并针对具有黑盒访问权限和访问控制的 GNN 模型进行了评估，同时考虑了不断演变的图结构。

Result: 所提出的攻击方法在九个真实世界数据集（包括静态和动态图）和四种不同的 GNN 架构上进行了评估，结果证明了其有效性。

Conclusion: 研究结果表明，所提出的攻击方法在各种 GNN 架构上均优于现有方法，在静态场景下始终保持至少 0.8 的 F1 分数，并在动态图场景下保持高达 0.8 的 F1 分数，而先前的方法仅能达到 0.2 左右。

Abstract: Graph Neural Networks (GNNs) have become indispensable tools for learning
from graph structured data, catering to various applications such as social
network analysis and fraud detection for financial services. At the heart of
these networks are the edges, which are crucial in guiding GNN models'
predictions. In many scenarios, these edges represent sensitive information,
such as personal associations or financial dealings, which require privacy
assurance. However, their contributions to GNN model predictions may, in turn,
be exploited by the adversary to compromise their privacy. Motivated by these
conflicting requirements, this paper investigates edge privacy in contexts
where adversaries possess only black-box access to the target GNN model,
restricted further by access controls, preventing direct insights into
arbitrary node outputs. Moreover, we are the first to extensively examine
situations where the target graph continuously evolves, a common trait of many
real-world graphs. In this setting, we present a range of attacks that leverage
the message-passing mechanism of GNNs. We evaluated the effectiveness of our
attacks using nine real-world datasets, encompassing both static and dynamic
graphs, across four different GNN architectures. The results demonstrate that
our attack outperforms existing methods across various GNN architectures,
consistently achieving an F1 score of at least 0.8 in static scenarios.
Furthermore, our attack retains robustness in dynamic graph scenarios,
maintaining F1 scores up to 0.8, unlike previous methods that only achieve F1
scores around 0.2.

</details>


### [36] [Generative AI in Financial Institution: A Global Survey of Opportunities, Threats, and Regulation](https://arxiv.org/abs/2504.21574)
*Bikash Saha,Nanda Rani,Sandeep Kumar Shukla*

Main category: cs.CR

TL;DR: 生成式人工智能正在改变金融业，但也带来了风险，需要良好的管理。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能（GenAI）在金融领域的快速发展，理解其机遇、风险和监管挑战至关重要。

Method: 对金融行业采用GenAI的现状进行了广泛调查，分析了其在银行、保险、资产管理和金融科技等领域的应用，并深入研究了相关的风险、监管和最佳实践。

Result: GenAI在金融领域的应用广泛，但存在网络安全和伦理风险，需要健全的治理和最佳实践来应对。

Conclusion: 金融行业正在通过生成式人工智能（GenAI）进行转型，虽然带来了机遇，但也伴随着网络安全和伦理风险。本篇论文探讨了GenAI在金融领域的应用、风险以及监管和最佳实践。

Abstract: Generative Artificial Intelligence (GenAI) is rapidly reshaping the global
financial landscape, offering unprecedented opportunities to enhance customer
engagement, automate complex workflows, and extract actionable insights from
vast financial data. This survey provides an overview of GenAI adoption across
the financial ecosystem, examining how banks, insurers, asset managers, and
fintech startups worldwide are integrating large language models and other
generative tools into their operations. From AI-powered virtual assistants and
personalized financial advisory to fraud detection and compliance automation,
GenAI is driving innovation across functions. However, this transformation
comes with significant cybersecurity and ethical risks. We discuss emerging
threats such as AI-generated phishing, deepfake-enabled fraud, and adversarial
attacks on AI systems, as well as concerns around bias, opacity, and data
misuse. The evolving global regulatory landscape is explored in depth,
including initiatives by major financial regulators and international efforts
to develop risk-based AI governance. Finally, we propose best practices for
secure and responsible adoption - including explainability techniques,
adversarial testing, auditability, and human oversight. Drawing from academic
literature, industry case studies, and policy frameworks, this chapter offers a
perspective on how the financial sector can harness GenAI's transformative
potential while navigating the complex risks it introduces.

</details>


### [37] [Watermarking for AI Content Detection: A Review on Text, Visual, and Audio Modalities](https://arxiv.org/abs/2504.03765)
*Lele Cao*

Main category: cs.CR

TL;DR: GenAI 带来了风险，但水印技术可以帮助检测它。本论文对现有水印技术进行了分类和评估，并讨论了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能（GenAI）的快速发展在文本、视觉和音频领域彻底改变了内容创作，但同时也带来了虚假信息、身份欺诈和内容操纵等重大风险。本论文旨在为用于主动检测 GenAI 内容的水印技术提供实用的调查。

Method: 提出了一种结构化分类法，对文本、视觉和音频模式的水印方法进行了分类，并根据其有效性、鲁棒性和实用性对现有方法进行了批判性评估。

Result: 对现有方法的有效性、鲁棒性和实用性进行了批判性评估，并确定了包括对抗性攻击的抵抗力、跨不同内容类型的标准化缺乏以及与隐私和内容所有权相关的伦理考量在内的关键挑战。

Conclusion: 该调查为研究人员和从业者提供了一个基础资源，以了解和推进用于 AI 生成内容检测的水印技术。

Abstract: The rapid advancement of generative artificial intelligence (GenAI) has
revolutionized content creation across text, visual, and audio domains,
simultaneously introducing significant risks such as misinformation, identity
fraud, and content manipulation. This paper presents a practical survey of
watermarking techniques designed to proactively detect GenAI content. We
develop a structured taxonomy categorizing watermarking methods for text,
visual, and audio modalities and critically evaluate existing approaches based
on their effectiveness, robustness, and practicality. Additionally, we identify
key challenges, including resistance to adversarial attacks, lack of
standardization across different content types, and ethical considerations
related to privacy and content ownership. Finally, we discuss potential future
research directions aimed at enhancing watermarking strategies to ensure
content authenticity and trustworthiness. This survey serves as a foundational
resource for researchers and practitioners seeking to understand and advance
watermarking techniques for AI-generated content detection.

</details>


### [38] [Detecting Financial Fraud with Hybrid Deep Learning: A Mix-of-Experts Approach to Sequential and Anomalous Patterns](https://arxiv.org/abs/2504.03750)
*Diego Vallarino*

Main category: cs.CR

TL;DR: 提出了一种结合RNN、Transformer和自动编码器的混合模型（MoE框架），用于信用ka欺诈检测。该模型在模拟数据集上达到了98.7%的准确率，并且能够有效识别新兴欺诈模式。该模型还符合AML和KYC协议，并有助于加强金融机构的欺诈防御能力。


<details>
  <summary>Details</summary>
Motivation: 金融欺诈检测仍然是一个关键挑战，因为欺诈行为具有动态和对抗性的特点。随着欺诈者不断演变其策略，检测系统必须结合鲁棒性、适应性和精确性。

Method: 本研究提出了一种信用ka欺诈检测的混合架构，该架构集成了专家混合（MoE）框架，并结合了循环神经网络（RNN）、Transformer编码器和自动编码器。RNN用于捕捉序列行为，Transformer提取高阶特征交互，自动编码器通过重构损耗检测异常。MoE框架动态分配专家之间的预测职责，实现自适应和上下文敏感的决策。

Result: 该混合模型在一个模拟真实交易模式和欺诈类型的高保真合成数据集上进行训练，在准确性（98.7%）、精确率（94.3%）和召回率（91.5%）方面均优于单独的模型和传统的机器学习基线。自动编码器组件显著提高了系统识别新兴欺诈策略和异常行为的能力。

Conclusion: 该混合系统提供了一种可扩展、模块化且符合法规要求的方法来检测日益复杂的欺诈模式，有助于智能系统的发展和机构欺诈防御基础设施的加强。

Abstract: Financial fraud detection remains a critical challenge due to the dynamic and
adversarial nature of fraudulent behavior. As fraudsters evolve their tactics,
detection systems must combine robustness, adaptability, and precision. This
study presents a hybrid architecture for credit card fraud detection that
integrates a Mixture of Experts (MoE) framework with Recurrent Neural Networks
(RNNs), Transformer encoders, and Autoencoders. Each expert module contributes
a specialized capability: RNNs capture sequential behavior, Transformers
extract high-order feature interactions, and Autoencoders detect anomalies
through reconstruction loss. The MoE framework dynamically assigns predictive
responsibility among the experts, enabling adaptive and context-sensitive
decision-making.
  Trained on a high-fidelity synthetic dataset that simulates real-world
transaction patterns and fraud typologies, the hybrid model achieved 98.7
percent accuracy, 94.3 percent precision, and 91.5 percent recall,
outperforming standalone models and classical machine learning baselines. The
Autoencoder component significantly enhanced the system's ability to identify
emerging fraud strategies and atypical behaviors.
  Beyond technical performance, the model contributes to broader efforts in
financial governance and crime prevention. It supports regulatory compliance
with Anti-Money Laundering (AML) and Know Your Customer (KYC) protocols and
aligns with routine activity theory by operationalizing AI as a capable
guardian within financial ecosystems. The proposed hybrid system offers a
scalable, modular, and regulation-aware approach to detecting increasingly
sophisticated fraud patterns, contributing both to the advancement of
intelligent systems and to the strengthening of institutional fraud defense
infrastructures.

</details>


### [39] [Unveiling Latent Information in Transaction Hashes: Hypergraph Learning for Ethereum Ponzi Scheme Detection](https://arxiv.org/abs/2503.21463)
*Junhao Wu,Yixin Yang,Chengxiang Jin,Silu Mu,Xiaolei Qian,Jiajun Zhou,Shanqing Yu,Qi Xuan*

Main category: cs.CR

TL;DR: HyperDet通过超图模型和双通道检测，比传统方法更有效地检测以太坊上的庞氏骗局。


<details>
  <summary>Details</summary>
Motivation: 鉴于以太坊金融欺诈（如庞氏骗局）日益猖獗，对现有基于图的方法在捕捉以太坊复杂多方交互模式方面的不足进行改进，以提高欺诈检测的准确性。

Method: 提出了一种名为HyperDet的超图建模方法，将交易哈希视为连接相关账户的超边，并设计了双通道检测模块（超图检测和超同质图检测）以处理复杂的账户交互模式和降低计算复杂度。

Result: 实验结果表明，与传统的同质图方法相比，超同质图检测通道在庞氏骗局检测方面取得了显著的性能提升，证明了超图在处理区块链数据复杂关系方面的优越性。

Conclusion: 现有的基于图的方法未能充分捕捉以太坊中固有的复杂多方交互模式，而我们提出的超图模型和双通道检测方法在检测以太坊庞氏骗局方面表现出优越性，并在实验中得到了验证。

Abstract: With the widespread adoption of Ethereum, financial frauds such as Ponzi
schemes have become increasingly rampant in the blockchain ecosystem, posing
significant threats to the security of account assets. Existing Ethereum fraud
detection methods typically model account transactions as graphs, but this
approach primarily focuses on binary transactional relationships between
accounts, failing to adequately capture the complex multi-party interaction
patterns inherent in Ethereum. To address this, we propose a hypergraph
modeling method for the Ponzi scheme detection method in Ethereum, called
HyperDet. Specifically, we treat transaction hashes as hyperedges that connect
all the relevant accounts involved in a transaction. Additionally, we design a
two-step hypergraph sampling strategy to significantly reduce computational
complexity. Furthermore, we introduce a dual-channel detection module,
including the hypergraph detection channel and the hyper-homo graph detection
channel, to be compatible with existing detection methods. Experimental results
show that, compared to traditional homogeneous graph-based methods, the
hyper-homo graph detection channel achieves significant performance
improvements, demonstrating the superiority of hypergraph in Ponzi scheme
detection. This research offers innovations for modeling complex relationships
in blockchain data.

</details>


### [40] [Assessing the influence of cybersecurity threats and risks on the adoption and growth of digital banking: a systematic literature review](https://arxiv.org/abs/2503.22710)
*Md. Waliullah,Md Zahin Hossain George,Md Tarek Hasan,Md Khorshed Alam,Mosa Sumaiya Khatun Munira,Noor Alam Siddiqui*

Main category: cs.CR

TL;DR: 本研究通过对 78 篇同行评审文章进行系统性审查，分析了网络安全威胁对数字银行的影响。研究发现，网络钓鱼和恶意软件攻击是主要威胁，多因素身份验证、生物识别、人工智能和区块链技术是有效的防御手段。同时，第三方金融科技解决方案和遵守全球法规对数字银行安全至关重要。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在系统地审查网络安全威胁对数字银行安全、采用和监管合规性的影响，以应对银行业快速数字化转型所带来的日益严峻的网络安全挑战。

Method: 本研究采用系统性方法，通过对 2015 年至 2024 年间发表的 78 篇同行评审文章进行全面审查，并遵循 PRISMA（Preferred Reporting Items for Systematic Reviews and Meta-Analyses）方法学，系统地检查了网络安全威胁对数字银行安全、采用和监管合规性的影响。

Result: 研究结果表明，网络钓鱼和恶意软件攻击是主要的网络威胁，造成了重大的经济损失和客户不信任。多因素身份验证和生物识别技术已被广泛采用，而人工智能和区块链技术显示出良好的应用前景。第三方金融科技解决方案的整合增加了安全风险，需要加强监管。遵守全球网络安全法规（如 GDPR、PSD2 和 GLBA）有助于提高数字银行的安全性。

Conclusion: 网络钓鱼和恶意软件攻击仍然是数字银行面临的最常见网络威胁，这会导致重大的经济损失和客户不信任。虽然多因素身份验证和生物识别技术已被广泛采用，但人工智能驱动的欺诈检测和区块链技术为保护金融交易提供了有前景的解决方案。然而，第三方金融科技解决方案的整合带来了额外的安全风险，需要严格的监管审查和网络安全协议。此外，遵守 GDPR、PSD2 和 GLBA 等全球网络安全法规，通过强制执行严格的身份验证措施、加密协议和实时欺诈监控，可以提高数字银行的安全性。

Abstract: The rapid digitalization of banking services has significantly transformed
financial transactions, offering enhanced convenience and efficiency for
consumers. However, the increasing reliance on digital banking has also exposed
financial institutions and users to a wide range of cybersecurity threats,
including phishing, malware, ransomware, data breaches, and unauthorized
access. This study systematically examines the influence of cybersecurity
threats on digital banking security, adoption, and regulatory compliance by
conducting a comprehensive review of 78 peer-reviewed articles published
between 2015 and 2024. Using the Preferred Reporting Items for Systematic
Reviews and Meta-Analyses (PRISMA) methodology, this research critically
evaluates the most prevalent cyber threats targeting digital banking platforms,
the effectiveness of modern security measures, and the role of regulatory
frameworks in mitigating financial cybersecurity risks. The findings reveal
that phishing and malware attacks remain the most commonly exploited cyber
threats, leading to significant financial losses and consumer distrust.
Multi-factor authentication (MFA) and biometric security have been widely
adopted to combat unauthorized access, while AI-driven fraud detection and
blockchain technology offer promising solutions for securing financial
transactions. However, the integration of third-party FinTech solutions
introduces additional security risks, necessitating stringent regulatory
oversight and cybersecurity protocols. The study also highlights that
compliance with global cybersecurity regulations, such as GDPR, PSD2, and GLBA,
enhances digital banking security by enforcing strict authentication measures,
encryption protocols, and real-time fraud monitoring.

</details>


### [41] [Early-MFC: Enhanced Flow Correlation Attacks on Tor via Multi-view Triplet Networks with Early Network Traffic](https://arxiv.org/abs/2503.16847)
*Yali Yuan,Qianqi Niu,Yachao Yuan*

Main category: cs.CR

TL;DR: 提出Early-MFC和Early-MFC+，用于网络早期流量关联攻击，即使数据量少也能高精度关联。


<details>
  <summary>Details</summary>
Motivation: 网络通信早期阶段的流量关联攻击对于网络犯罪检测和金融欺诈预防等需要快速决策的场景至关重要。然而，现有技术在处理早期网络流量关联方面存在局限性，无法直接应用于此场景，主要因为模型复杂度、训练成本和实时性要求等问题。

Method: 本研究提出了一种名为Early-MFC的多视图三元组网络方法，该方法从传输层的payload和包间隔延迟中提取多视图流量特征，并将这些特征整合为共享的嵌入表示。通过度量学习和对比学习优化嵌入空间，使相似流量距离更近，不相似流量距离更远。最后，利用贝叶斯决策理论进行流量关联判断。针对仅有少量数据的“额外早期”网络流量，提出了Early-MFC+，利用payload数据构建嵌入特征表示，以保证鲁棒性。

Result: 所提出的Early-MFC和Early-MFC+方法能够实现高精度的流量关联，即使在网络通信早期甚至数据量极少的情况下也能有效工作，为需要快速响应的网络安全应用提供了解决方案。

Conclusion: 本研究提出了Early-MFC和Early-MFC+两种基于多视图三元组网络的方法，用于在网络通信早期进行流量关联攻击，即使在仅有少量数据的情况下也能实现高精度的流量关联。

Abstract: Flow correlation attacks is an efficient network attacks, aiming to expose
those who use anonymous network services, such as Tor. Conducting such attacks
during the early stages of network communication is particularly critical for
scenarios demanding rapid decision-making, such as cybercrime detection or
financial fraud prevention. Although recent studies have made progress in flow
correlation attacks techniques, research specifically addressing flow
correlation with early network traffic flow remains limited. Moreover, due to
factors such as model complexity, training costs, and real-time requirements,
existing technologies cannot be directly applied to flow correlation with early
network traffic flow. In this paper, we propose flow correlation attack with
early network traffic, named Early-MFC, based on multi-view triplet networks.
The proposed approach extracts multi-view traffic features from the payload at
the transport layer and the Inter-Packet Delay. It then integrates multi-view
flow information, converting the extracted features into shared embeddings. By
leveraging techniques such as metric learning and contrastive learning, the
method optimizes the embeddings space by ensuring that similar flows are mapped
closer together while dissimilar flows are positioned farther apart. Finally,
Bayesian decision theory is applied to determine flow correlation, enabling
high-accuracy flow correlation with early network traffic flow. Furthermore, we
investigate flow correlation attacks under extra-early network traffic flow
conditions. To address this challenge, we propose Early-MFC+, which utilizes
payload data to construct embedded feature representations, ensuring robust
performance even with minimal packet availability.

</details>


### [42] [Enforcing Cybersecurity Constraints for LLM-driven Robot Agents for Online Transactions](https://arxiv.org/abs/2503.15546)
*Shraddha Pradipbhai Shah,Aditya Vilas Deshpande*

Main category: cs.CR

TL;DR: 大型语言模型机器人在线交易存在网络安全风险，本研究提出了一种结合区块链、多因素认证和实时异常检测的混合安全架构，可将欺诈交易减少90%，提高漏洞检测准确性至98%，并能在0.05秒内完成安全交易验证。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在电子商务、金融和服1务行业中日益普及，其驱动的机器人代理在进行在线交易时带来了严重的数据泄露、交易欺诈和系统操纵等网络安全风险。本研究旨在通过实施严格的网络安全措施来降低这些风险。

Method: 提出了一种结合区块链技术、多因素认证（MFA）和实时异常检测的新型安全架构，用于保护大型语言模型驱动的机器人代理的在线交易。

Result: 所提出的安全架构成功将欺诈交易减少了90%，将漏洞检测准确性提高到98%，并确保了在0.05秒延迟内的安全交易验证，同时提高了系统性能。

Conclusion: 该研究提出了一个结合区块链、多因素认证和实时异常检测的安全架构，以应对大型语言模型驱动的机器人代理进行在线交易时带来的网络安全挑战。该架构在保护交易完整性、响应时间和漏洞检测准确性方面表现出色，可显著降低欺诈风险并提高系统性能。

Abstract: The integration of Large Language Models (LLMs) into autonomous robotic
agents for conducting online transactions poses significant cybersecurity
challenges. This study aims to enforce robust cybersecurity constraints to
mitigate the risks associated with data breaches, transaction fraud, and system
manipulation. The background focuses on the rise of LLM-driven robotic systems
in e-commerce, finance, and service industries, alongside the vulnerabilities
they introduce. A novel security architecture combining blockchain technology
with multi-factor authentication (MFA) and real-time anomaly detection was
implemented to safeguard transactions. Key performance metrics such as
transaction integrity, response time, and breach detection accuracy were
evaluated, showing improved security and system performance. The results
highlight that the proposed architecture reduced fraudulent transactions by
90%, improved breach detection accuracy to 98%, and ensured secure transaction
validation within a latency of 0.05 seconds. These findings emphasize the
importance of cybersecurity in the deployment of LLM-driven robotic systems and
suggest a framework adaptable to various online platforms.

</details>


### [43] [Detecting and Preventing Data Poisoning Attacks on AI Models](https://arxiv.org/abs/2503.09302)
*Halima I. Kure,Pradipta Sarkar,Ahmed B. Ndanusa,Augustine O. Nwajana*

Main category: cs.CR

TL;DR: 本研究提出并验证了新的AI数据中毒攻击检测和防御技术，通过异常检测、对抗性训练和集成学习，提高了模型在图像识别和欺诈检测中的准确性和鲁棒性，抵御了高达27%的性能下降。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在各行业的广泛应用，AI模型面临着日益增长的数据中毒攻击威胁。本研究旨在提出有效的防御策略，以增强AI系统应对恶意数据篡改的能力，确保其安全性和可靠性。

Method: 本研究结合了理论分析与实验验证，采用了包括异常检测、鲁棒优化和集成学习在内的多种方法来检测和防御数据中毒攻击。实验在CIFAR-10和保险索赔数据集上进行，以评估所提出防御机制的有效性。

Result: 实验结果表明，数据中毒攻击可将CIFAR-10数据集上的图像识别准确率降低高达27%，并将保险索赔数据集上的欺诈检测模型准确率降低22%。所提出的基于统计异常检测和对抗性训练的防御机制，成功将模型准确性平均提高了15-20%，有效缓解了中毒效应。集成学习技术进一步增强了模型的韧性，减少了由对抗性数据注入引起的误报和漏报。

Conclusion: 本研究成功开发并验证了用于检测和防御数据中毒攻击的新颖技术，通过集成异常检测、鲁棒优化和集成学习等方法，显著提高了AI模型在图像识别和欺诈检测任务中的鲁棒性，并恢复了模型的准确性。

Abstract: This paper investigates the critical issue of data poisoning attacks on AI
models, a growing concern in the ever-evolving landscape of artificial
intelligence and cybersecurity. As advanced technology systems become
increasingly prevalent across various sectors, the need for robust defence
mechanisms against adversarial attacks becomes paramount. The study aims to
develop and evaluate novel techniques for detecting and preventing data
poisoning attacks, focusing on both theoretical frameworks and practical
applications. Through a comprehensive literature review, experimental
validation using the CIFAR-10 and Insurance Claims datasets, and the
development of innovative algorithms, this paper seeks to enhance the
resilience of AI models against malicious data manipulation. The study explores
various methods, including anomaly detection, robust optimization strategies,
and ensemble learning, to identify and mitigate the effects of poisoned data
during model training. Experimental results indicate that data poisoning
significantly degrades model performance, reducing classification accuracy by
up to 27% in image recognition tasks (CIFAR-10) and 22% in fraud detection
models (Insurance Claims dataset). The proposed defence mechanisms, including
statistical anomaly detection and adversarial training, successfully mitigated
poisoning effects, improving model robustness and restoring accuracy levels by
an average of 15-20%. The findings further demonstrate that ensemble learning
techniques provide an additional layer of resilience, reducing false positives
and false negatives caused by adversarial data injections.

</details>


### [44] [Zero-to-One IDV: A Conceptual Model for AI-Powered Identity Verification](https://arxiv.org/abs/2503.08734)
*Aniket Vaidya,Anurag Awasthi*

Main category: cs.CR

TL;DR: 本文提出了“从0到1”框架，这是一个用于开发人工智能驱动的身份验证产品的概念模型，解决了安全、隐私、用户体验和合规性问题。


<details>
  <summary>Details</summary>
Motivation: 随着数字交互日益增多，对强大身份验证（IDV）的需求日益增长，而人工智能（AI）正在提高准确性和欺诈检测能力。本研究旨在为人工智能时代的IDV提供一个新的框架，以应对不断变化的身份验证演变和监管环境。

Method: 本文提出了一个名为“从0到1”的整体概念框架，用于开发人工智能（AI）驱动的身份验证（IDV）产品。该框架包含四个关键组成部分：文件验证、生物识别验证、风险评估和编排。

Result: “从0到1”框架是一个经过改进的概念模型，详细介绍了验证层以及人工智能在塑造下一代IDV产品中的变革性作用。它强调了成功的IDV平台需要对验证方法、风险管理和运营可扩展性有平衡的概念理解，并将人工智能作为关键的推动因素。

Conclusion: 该框架为构建有效的身份验证（IDV）解决方案提供了一种结构化方法，解决了安全性、隐私性、用户体验和合规性问题，并指出了未来在框架的进一步开发和应用方面的研究方向。

Abstract: In today's increasingly digital interactions, robust Identity Verification
(IDV) is crucial for security and trust. Artificial Intelligence (AI) is
transforming IDV, enhancing accuracy and fraud detection. This paper introduces
``Zero to One,'' a holistic conceptual framework for developing AI-powered IDV
products. This paper outlines the foundational problem and research objectives
that necessitate a new framework for IDV in the age of AI. It details the
evolution of identity verification and the current regulatory landscape to
contextualize the need for a robust conceptual model. The core of the paper is
the presentation of the ``Zero to One'' framework itself, dissecting its four
essential components: Document Verification, Biometric Verification, Risk
Assessment, and Orchestration. The paper concludes by discussing the
implications of this conceptual model and suggesting future research directions
focused on the framework's further development and application. The framework
addresses security, privacy, UX, and regulatory compliance, offering a
structured approach to building effective IDV solutions. Successful IDV
platforms require a balanced conceptual understanding of verification methods,
risk management, and operational scalability, with AI as a key enabler. This
paper presents the ``Zero to One'' framework as a refined conceptual model,
detailing verification layers, and AI's transformative role in shaping
next-generation IDV products.

</details>


### [45] [ESSPI: ECDSA/Schnorr Signed Program Input for BitVMX](https://arxiv.org/abs/2503.02772)
*Sergio Demian Lerner,Martin Jonas,Ariel Futoransky*

Main category: cs.CR

TL;DR: ESSPI协议利用ECDSA/Schnorr签名优化了BitVMX协议，将数据扩展率从1:200提升至1:1，并支持更广泛的验证能力。


<details>
  <summary>Details</summary>
Motivation: BitVM和BitVMX协议目前依赖Lamport和Winternitz等一次性签名（OTS）方案，这些方案存在显著的存储开销，限制了其实际应用。本研究旨在通过引入更高效的签名方案来解决这一问题。

Method: ESSPI通过引入ECDSA/Schnorr签名来优化BitVMX协议的输入签名。具体实现包括：1.修改BitVMX CPU，增加一个可挑战的哈希核心。2.提出一种新的基于分区的搜索方法来检测哈希过程中的欺诈。3.设计一种新的增强交易DAG，包含附加数据携带交易和一个欺诈验证智能合约。4.开发一种新颖的基于时间锁的方法，用于向比特币智能合约证明数据可用性。

Result: ESSPI协议实现了1:1的数据扩展率，相比于之前基于Winternitz签名的1:200，有了巨大的提升。增强后的BitVMX协议能够验证未压缩的输入，如SPV证明、NiPoPoWs或STARKs等更长的计算完整性证明。

Conclusion: ESSPI通过利用ECDSA/Schnorr签名优化了BitVMX协议的输入签名，实现了1:1的数据扩展率，显著优于之前的1:200。该协议通过CPU修改、基于分区的搜索、增强的交易DAG和基于时间锁的数据可用性证明等四项创新，使得BitVMX能够验证SPV证明、NiPoPoWs或STARKs等更长的计算完整性证明。

Abstract: The BitVM and BitVMX protocols have long relied on inefficient one-time
signature (OTS) schemes like Lamport and Winternitz for signing program inputs.
These schemes exhibit significant storage overheads, hindering their practical
application. This paper introduces ESSPI, an optimized method leveraging
ECDSA/Schnorr signatures to sign the BitVMX program input. With Schnorr
signatures we achieve an optimal 1:1 data expansion, compared to the current
known best ratio of 1:200 based on Winternitz signatures. To accomplish this we
introduce 4 innovations to BitVMX: (1) a modification of the BitVMX CPU, adding
a challengeable hashing core to it, (2) a new partition-based search to detect
fraud during hashing, (3) a new enhanced transaction DAG with added
data-carrying transactions with a fraud-verifying smart-contract and (4) a
novel timelock-based method for proving data availability to Bitcoin smart
contracts. The enhanced BitVMX protocol enables the verification of
uncompressed inputs such as SPV proofs, NiPoPoWs, or longer computation
integrity proofs, such as STARKs.

</details>


### [46] [The First Early Evidence of the Use of Browser Fingerprinting for Online Tracking](https://arxiv.org/abs/2409.15656)
*Zengrui Liu,Jimmy Dani,Yinzhi Cao,Shujiang Wu,Nitesh Saxena*

Main category: cs.CR

TL;DR: 本研究发现，广告商广泛使用浏览器指纹技术来跟踪和定位用户，即使在用户选择退出或遵守隐私法规后也是如此。研究人员开发了一个名为FPTrace的框架，通过分析指纹变化对广告竞价的影响来证明这一点。


<details>
  <summary>Details</summary>
Motivation: 在线广告已成为当今在线互动中的普遍现象，但对于浏览器指纹被用于用户跟踪和定向广告的程度的研究却明显不足。以往的研究仅测量了网站上是否运行了与指纹相关的脚本，但这并不一定意味着指纹被用于在线跟踪这一侵犯隐私的目的，因为指纹可能被用于防御目的，如机器人/欺诈检测和用户身份验证。因此，有必要解决在线广告中浏览器指纹使用日益增长的担忧。

Method: 本研究引入了一个名为“FPTrace”的框架，通过分析浏览器指纹调整引起的广告变化来评估基于指纹的用户跟踪。研究人员通过FPTrace模拟用户交互、捕获广告竞价数据并监控HTTP流量。

Result: 通过FPTrace进行的大规模研究有力地证明了浏览器指纹被用于广告跟踪和定向，这体现在竞价价值的差异和指纹信息改变后HTTP记录的减少。研究还表明，指纹技术可以绕过GDPR/CCPA的退出选项，实现侵犯隐私的跟踪。

Conclusion: 本研究揭示了浏览器指纹在在线广告中的广泛应用，引发了对数字广告领域用户隐私和数据安全的关键考量。

Abstract: While advertising has become commonplace in today's online interactions,
there is a notable dearth of research investigating the extent to which browser
fingerprinting is harnessed for user tracking and targeted advertising. Prior
studies only measured whether fingerprinting-related scripts are being run on
the websites but that in itself does not necessarily mean that fingerprinting
is being used for the privacy-invasive purpose of online tracking because
fingerprinting might be deployed for the defensive purposes of bot/fraud
detection and user authentication. It is imperative to address the mounting
concerns regarding the utilization of browser fingerprinting in the realm of
online advertising.
  This paper introduces ``FPTrace'' (fingerprinting-based tracking assessment
and comprehensive evaluation framework), a framework to assess
fingerprinting-based user tracking by analyzing ad changes from browser
fingerprinting adjustments. Using FPTrace, we emulate user interactions,
capture ad bid data, and monitor HTTP traffic. Our large-scale study reveals
strong evidence of browser fingerprinting for ad tracking and targeting, shown
by bid value disparities and reduced HTTP records after fingerprinting changes.
We also show fingerprinting can bypass GDPR/CCPA opt-outs, enabling
privacy-invasive tracking.
  In conclusion, our research unveils the widespread employment of browser
fingerprinting in online advertising, prompting critical considerations
regarding user privacy and data security within the digital advertising
landscape.

</details>


### [47] [Ethereum Fraud Detection via Joint Transaction Language Model and Graph Representation Learning](https://arxiv.org/abs/2409.07494)
*Jianguo Sun,Yifan Jia,Yanbin Wang,Yiwei Liu,Zhang Sheng,Ye Tian*

Main category: cs.CR

TL;DR: TLMG4Eth 是一种结合语言模型和图模型的新方法，用于提高以太坊的欺诈检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有的以太坊欺诈检测方法未能充分利用交易的语义信息和相似性模式，也未能结合图神经网络和序列模型等不同模型的优势。

Method: TLMG4Eth 结合了语言模型和图模型。首先，它将交易数据转换为语言模型可以理解的句子，以捕捉交易的语义信息。其次，它利用交易属性相似性图来学习交易之间的相似性。最后，它构建账户交互图来捕捉账户交易网络的结构信息。通过深度多头注意力网络融合这些信息，并采用联合训练方法，以获得协同效益。

Result: TLMG4Eth 能够捕捉以太坊交易数据的语义、相似性和结构特征，从而更有效地检测欺诈。

Conclusion: Ethereum 中的欺诈检测可以通过结合语言模型和图模型来解决，TLMG4Eth 是一种创新的方法。

Abstract: Ethereum faces growing fraud threats. Current fraud detection methods,
whether employing graph neural networks or sequence models, fail to consider
the semantic information and similarity patterns within transactions. Moreover,
these approaches do not leverage the potential synergistic benefits of
combining both types of models. To address these challenges, we propose
TLMG4Eth that combines a transaction language model with graph-based methods to
capture semantic, similarity, and structural features of transaction data in
Ethereum. We first propose a transaction language model that converts numerical
transaction data into meaningful transaction sentences, enabling the model to
learn explicit transaction semantics. Then, we propose a transaction attribute
similarity graph to learn transaction similarity information, enabling us to
capture intuitive insights into transaction anomalies. Additionally, we
construct an account interaction graph to capture the structural information of
the account transaction network. We employ a deep multi-head attention network
to fuse transaction semantic and similarity embeddings, and ultimately propose
a joint training approach for the multi-head attention network and the account
interaction graph to obtain the synergistic benefits of both.

</details>


### [48] [Network evasion detection with Bi-LSTM model](https://arxiv.org/abs/2502.10624)
*Kehua Chen,Jingping Jia*

Main category: cs.CR

TL;DR: A deep learning approach using Bi-LSTM and Softmax is proposed for network evasion detection, achieving 96.1% average accuracy by analyzing network flow features.


<details>
  <summary>Details</summary>
Motivation: To distinguish network flows that contain network evasion threats, which disguise data traffic to confuse detection systems.

Method: Extract critical information as key features from data frames and use a bidirectional long short-term memory (Bi-LSTM) neural network to encode past and future traits in network flows. A Softmax classifier is used at the bottom of the Bi-LSTM to select the correct class.

Result: The deep Bi-LSTM model achieves a significant performance in network evasion detection, with an average accuracy reaching 96.1%.

Conclusion: The proposed deep Bi-LSTM model achieves significant performance in network evasion detection, with an average accuracy of 96.1%.

Abstract: Network evasion detection aims to distinguish whether the network flow comes
from link layer exists network evasion threat, which is a means to disguise the
data traffic on detection system by confusing the signature. Since the previous
research works has all sorts of frauds, we propose a architecture with deep
learning network to handle this problem. In this paper, we extract the critical
information as key features from data frame and also specifically propose to
use bidirectional long short-term memory (Bi-LSTM) neural network which shows
an outstanding performance to trace the serial information, to encode both the
past and future trait on the network flows. Furthermore we introduce a
classifier named Softmax at the bottom of Bi-LSTM, holding a character to
select the correct class. All experiments results shows that we can achieve a
significant performance with a deep Bi-LSTM in network evasion detection and
it's average accuracy reaches 96.1%.

</details>


### [49] [Dynamic Fraud Proof](https://arxiv.org/abs/2502.10321)
*Gabriele Picco,Andrea Fortugno*

Main category: cs.CR

TL;DR: 提出了一种名为“动态欺诈证明”的新机制，通过动态调整挑战期和验证节点来加速欺诈证明过程，能在理想情况下实现亚秒级最终确定性，解决了现有汇总机制中最终确定性延迟的问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有最优汇总（optimistic rollups）中较长的欺诈挑战窗口（通常为7天）带来的最终确定性延迟问题。

Method: 提出了一种名为“动态欺诈证明”的新型断言/挑战结构，该结构具有动态挑战期和随机选择的验证节点，需要交互式地批准状态承诺。

Result: 该机制实现了亚秒级最终确定性，并能动态调整挑战期和批准标准以应对欺诈检测和挑战解决。

Conclusion: 该机制通过动态调整挑战期和验证节点交互来提高最终确定性，并能在理想情况下实现亚秒级最终确定性。

Abstract: In this paper, we present a novel fraud-proof mechanism that achieves fast
finality and, when combined with optimistic execution, enables real-time
transaction processing. State-of-the-art optimistic rollups typically adopt a
7-day challenge window, during which any honest party can raise a challenge in
case of fraud. We propose a new assert/challenge construction called "Dynamic
Fraud Proofs" that achieves sub-second finality in ideal scenarios, while
dynamically delaying settlement in the event of fraud detection and challenge
resolution. The system relies on 1) a dynamic challenge period and 2) a
configurable number of randomly selected verifier nodes who must interactively
approve a state commitment without raising a challenge. If these conditions are
not met, the state is not finalized, and the challenge period and approval
criteria are dynamically adjusted. We provide a detailed analysis of the
system's design, explaining how it maintains the assumption of a single honest
node and addresses censorship attacks by inverting the traditional challenge
process. Additionally, we formalize the system's probabilistic security model
and discuss how bonding, incentives, and slashing mechanisms can encourage
honest behavior, thereby increasing the likelihood of fast settlement in ideal
scenarios.

</details>


### [50] [detectGNN: Harnessing Graph Neural Networks for Enhanced Fraud Detection in Credit Card Transactions](https://arxiv.org/abs/2503.22681)
*Irin Sultana,Syed Mustavi Maheen,Naresh Kshetri,Md Nasim Fardous Zim*

Main category: cs.CR

TL;DR: Credit card fraud is a big problem, and old methods aren't good enough. This paper uses Graph Neural Networks (GNNs) in a model called "detectGNN" to look at transactions as a network. It's better at finding complex fraud, works in real-time, and handles issues like data imbalance and privacy. GNNs are a promising solution for safer transactions.


<details>
  <summary>Details</summary>
Motivation: Credit card fraud is a significant problem that incurs substantial financial losses and erodes trust in financial systems. Traditional fraud detection methods are often inadequate against advanced and evolving fraud techniques.

Method: The study proposes and utilizes a Graph Neural Network (GNN) model called "detectGNN" which analyzes transactions as a network of interconnected data points (accounts, traders, devices) incorporating time-based patterns and dynamic updates to detect sophisticated fraud. The model addresses challenges such as real-time processing, data imbalance, and privacy concerns.

Result: The GNN-based model, "detectGNN", shows superior performance compared to traditional methods in detecting complex and multi-layered fraud, indicating improved accuracy and effectiveness.

Conclusion: This research demonstrates that GNNs offer a powerful, accurate, and scalable solution for credit card fraud detection, outperforming traditional methods in identifying complex fraud patterns.

Abstract: Credit card fraud is a major issue nowadays, costing huge money and affecting
trust in financial systems. Traditional fraud detection methods often fail to
detect advanced and growing fraud techniques. This study focuses on using Graph
Neural Networks (GNNs) to improve fraud detection by analyzing transactions as
a network of connected data points, such as accounts, traders, and devices. The
proposed "detectGNN" model uses advanced features like time-based patterns and
dynamic updates to expose hidden fraud and improve detection accuracy. Tests
show that GNNs perform better than traditional methods in finding complex and
multi-layered fraud. The model also addresses real-time processing, data
imbalance, and privacy concerns, making it practical for real-world use. This
research shows that GNNs can provide a powerful, accurate, and a scalable
solution for detecting fraud. Future work will focus on making the models
easier to understand, privacy-friendly, and adaptable to new types of fraud,
ensuring safer financial transactions in the digital world.

</details>


### [51] [Advanced Real-Time Fraud Detection Using RAG-Based LLMs](https://arxiv.org/abs/2501.15290)
*Gurjot Singh,Prabhjot Singh,Maninder Singh*

Main category: cs.CR

TL;DR: 本研究提出了一种新颖的实时欺诈检测机制，利用检索增强生成（RAG）技术来解决AI驱动的诈骗问题。该系统通过实时通话转录和用户身份验证来防止欺诈和身份冒充。其主要优势在于无需重新训练即可更新策略，并且在测试中表现出了很高的准确性和F1分数。


<details>
  <summary>Details</summary>
Motivation: 为了应对人工智能（AI）在现代社会中被恶意行为者用于电话诈骗和身份冒充等非法活动的日益增长的威胁，需要一个强大的系统来保护个人。

Method: 使用检索增强生成（RAG）技术，通过两个主要功能来检测欺诈：1. 实时转录通话并使用RAG模型验证通话的真实性，确保对话的透明度和真实性。2. 实施一个两步验证流程，以确认来电者的身份，防止用户身份被冒用。该系统的关键创新在于能够在不重新训练整个模型的情况下更新策略，从而提高了系统的适应性。

Result: 使用合成通话录音进行的验证显示，该基于RAG的方法取得了97.98%的准确率和97.44%的F1分数，在处理100个电话的情况下优于现有技术。

Conclusion: 该系统能够适应现实世界的部署，并在欺诈检测方面表现出色。

Abstract: Artificial Intelligence has become a double edged sword in modern society
being both a boon and a bane. While it empowers individuals it also enables
malicious actors to perpetrate scams such as fraudulent phone calls and user
impersonations. This growing threat necessitates a robust system to protect
individuals In this paper we introduce a novel real time fraud detection
mechanism using Retrieval Augmented Generation technology to address this
challenge on two fronts. First our system incorporates a continuously updating
policy checking feature that transcribes phone calls in real time and uses RAG
based models to verify that the caller is not soliciting private information
thus ensuring transparency and the authenticity of the conversation. Second we
implement a real time user impersonation check with a two step verification
process to confirm the callers identity ensuring accountability. A key
innovation of our system is the ability to update policies without retraining
the entire model enhancing its adaptability. We validated our RAG based
approach using synthetic call recordings achieving an accuracy of 97.98 percent
and an F1score of 97.44 percent with 100 calls outperforming state of the art
methods. This robust and flexible fraud detection system is well suited for
real world deployment.

</details>


### [52] [Dynamic Feature Fusion: Combining Global Graph Structures and Local Semantics for Blockchain Fraud Detection](https://arxiv.org/abs/2501.02032)
*Zhang Sheng,Liangliang Song,Yanbin Wang*

Main category: cs.CR

TL;DR: 为了解决现有区块链欺诈检测方法仅关注结构或语义特征的局限性，本研究提出了一种动态特征融合模型，该模型结合了图表示学习和语义特征提取。通过整合结构关系和语义信息，该模型在处理真实区块链数据集时表现出更优越的性能，为提高区块链系统的安全性提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 目前的欺诈检测方法在捕捉交易网络中的全局结构模式和交易数据中嵌入的本地语义关系方面存在局限性。大多数现有模型仅关注结构信息或语义特征，导致在检测复杂欺诈模式方面的性能不佳。

Method: 提出了一种动态特征融合模型，该模型结合了基于图的表示学习和用于区块链欺诈检测的语义特征提取。具体来说，该模型构建了全局图表示来对账户关系进行建模，并从交易数据中提取本地上下文特征。引入了动态多模态融合机制，可以自适应地集成这些特征，从而有效地捕获结构和语义欺诈模式。此外，研究开发了一个全面的数据处理流程，包括图构建、时间特征增强和文本预处理。

Result: 在大型真实区块链数据集上的实验结果表明，我们提出的方法在准确率、F1分数和召回率等指标上优于现有的基准模型。

Conclusion: 该研究强调了整合结构关系和语义相似性对于稳健的欺诈检测的重要性，并为保护区块链系统提供了一个可扩展的解决方案。

Abstract: The advent of blockchain technology has facilitated the widespread adoption
of smart contracts in the financial sector. However, current fraud detection
methodologies exhibit limitations in capturing both global structural patterns
within transaction networks and local semantic relationships embedded in
transaction data. Most existing models focus on either structural information
or semantic features individually, leading to suboptimal performance in
detecting complex fraud patterns.In this paper, we propose a dynamic feature
fusion model that combines graph-based representation learning and semantic
feature extraction for blockchain fraud detection. Specifically, we construct
global graph representations to model account relationships and extract local
contextual features from transaction data. A dynamic multimodal fusion
mechanism is introduced to adaptively integrate these features, enabling the
model to capture both structural and semantic fraud patterns effectively. We
further develop a comprehensive data processing pipeline, including graph
construction, temporal feature enhancement, and text preprocessing.
Experimental results on large-scale real-world blockchain datasets demonstrate
that our method outperforms existing benchmarks across accuracy, F1 score, and
recall metrics. This work highlights the importance of integrating structural
relationships and semantic similarities for robust fraud detection and offers a
scalable solution for securing blockchain systems.

</details>


### [53] [Pirates of Charity: Exploring Donation-based Abuses in Social Media Platforms](https://arxiv.org/abs/2412.15621)
*Bhupendra Acharya,Dario Lazzaro,Antonio Emanuele Cinà,Thorsten Holz*

Main category: cs.CR

TL;DR: 研究分析了社交媒体上的捐款诈骗，识别了832名诈骗者，发现平台在防止欺诈方面存在漏洞，并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 随着社交媒体的广泛使用，组织和个人利用这些平台进行筹款和支持公益活动，但也导致了诈骗者利用虚假捐款的增加。因此，本研究旨在对社交媒体平台上的捐款诈骗进行大规模分析。

Method: 通过收集2024年3月至2024年5月期间151,966个与捐款相关的账户及其3,053,333条帖子数据，研究了在X、Instagram、Facebook、YouTube和Telegram上进行欺诈性捐款的个人资料创建和诈骗操作。分析了电话号码、电子邮件和外部URL等欺诈通信渠道，识别了832名诈骗者，并与PayPal和Chainabuse等行业伙伴合作，验证了诈骗行为并量化了经济损失。

Result: 研究识别了832名诈骗者，他们利用各种技术（如虚假筹款网站、众包筹款、通过电子邮件和电话进行沟通以及使用各种支付方式）欺骗用户进行欺诈性捐款。研究还通过与行业伙伴合作，验证了这些诈骗行为并量化了经济损失。

Conclusion: 该研究强调了社交媒体平台在保护用户免受欺诈性捐款方面存在的重大漏洞，并建议平台和金融服务公司采取积极措施来阻止此类活动。研究结果为安全社区和研究人员自动化检测和缓解社交媒体平台上的欺诈性捐款提供了基础。

Abstract: With the widespread use of social media, organizations, and individuals use
these platforms to raise funds and support causes. Unfortunately, this has led
to the rise of scammers in soliciting fraudulent donations. In this study, we
conduct a large-scale analysis of donation-based scams on social media
platforms. More specifically, we studied profile creation and scam operation
fraudulent donation solicitation on X, Instagram, Facebook, YouTube, and
Telegram. By collecting data from 151,966 accounts and their 3,053,333 posts
related to donations between March 2024 and May 2024, we identified 832
scammers using various techniques to deceive users into making fraudulent
donations. Analyzing the fraud communication channels such as phone number,
email, and external URL linked, we show that these scamming accounts perform
various fraudulent donation schemes, including classic abuse such as fake
fundraising website setup, crowdsourcing fundraising, and asking users to
communicate via email, phone, and pay via various payment methods. Through
collaboration with industry partners PayPal and cryptocurrency abuse database
Chainabuse, we further validated the scams and measured the financial losses on
these platforms. Our study highlights significant weaknesses in social media
platforms' ability to protect users from fraudulent donations. Additionally, we
recommended social media platforms, and financial services for taking proactive
steps to block these fraudulent activities. Our study provides a foundation for
the security community and researchers to automate detecting and mitigating
fraudulent donation solicitation on social media platforms.

</details>


### [54] [Exploration of the Dynamics of Buy and Sale of Social Media Accounts](https://arxiv.org/abs/2412.14985)
*Mario Beluri,Bhupendra Acharya,Soheil Khodayari,Giada Stivala,Giancarlo Pellegrino,Thorsten Holz*

Main category: cs.CR

TL;DR: 社交媒体账户交易市场规模庞大，总价值超6400万美元，但充斥着机器人养殖、账户收集和欺诈参与等欺诈行为。平台在检测和缓解这些威胁方面存在不足，用户面临风险。研究提出了改进检测和保护用户的建议。


<details>
  <summary>Details</summary>
Motivation: 随着在线平台允许买卖社交媒体账户的增加，本研究旨在调查这些账户交易的经济规模和相关的欺诈活动。研究的动机是理解这些市场如何运作，它们对社交媒体生态系统构成了哪些风险，以及如何改进平台的检测和缓解策略。

Method: 本研究对促进社交媒体账户买卖的在线市场进行了全面分析，重点关注了X、Instagram、Facebook、TikTok和YouTube这五个主要平台。研究时间为2024年2月至6月，共识别了11个在线市场中的38,253个账户销售广告，涵盖211个不同类别。研究人员收集了11,457个可见广告账户的元数据和超过200,000条个人资料帖子，并通过分析它们的参与模式和账户创建方法来评估与这些售出账户相关的欺诈活动。

Result: 研究发现，社交媒体账户交易的总价值超过6400万美元，单个账户的中位数价格为157美元。分析显示，这些市场助长了欺诈活动，如机器人养殖、为未来欺诈收集账户以及欺诈性参与。研究还强调了社交媒体平台在检测和阻止这些欺诈账户方面存在弱点，这对用户构成了风险。

Conclusion: 该研究揭示了社交媒体账户交易市场中普遍存在的欺诈活动，如机器人养殖、账户收集用于未来欺诈以及欺诈性参与，这些活动对用户构成了重大风险。研究还强调了社交媒体平台在检测和缓解此类欺诈账户方面的不足，并提出了包括识别和追踪这些账户的指标在内的建议，以加强主动检测并保护用户免受潜在威胁。

Abstract: There has been a rise in online platforms facilitating the buying and selling
of social media accounts. While the trade of social media profiles is not
inherently illegal, social media platforms view such transactions as violations
of their policies. They often take action against accounts involved in the
misuse of platforms for financial gain. This research conducts a comprehensive
analysis of marketplaces that enable the buying and selling of social media
accounts.
  We investigate the economic scale of account trading across five major
platforms: X, Instagram, Facebook, TikTok, and YouTube. From February to June
2024, we identified 38,253 accounts advertising account sales across 11 online
marketplaces, covering 211 distinct categories. The total value of marketed
social media accounts exceeded \$64 million, with a median price of \$157 per
account. Additionally, we analyzed the profiles of 11,457 visible advertised
accounts, collecting their metadata and over 200,000 profile posts. By
examining their engagement patterns and account creation methods, we evaluated
the fraudulent activities commonly associated with these sold accounts. Our
research reveals these marketplaces foster fraudulent activities such as bot
farming, harvesting accounts for future fraud, and fraudulent engagement. Such
practices pose significant risks to social media users, who are often targeted
by fraudulent accounts resembling legitimate profiles and employing social
engineering tactics. We highlight social media platform weaknesses in the
ability to detect and mitigate such fraudulent accounts, thereby endangering
users. Alongside this, we conducted thorough disclosures with the respective
platforms and proposed actionable recommendations, including indicators to
identify and track these accounts. These measures aim to enhance proactive
detection and safeguard users from potential threats.

</details>


### [55] [Blockchain Data Analysis in the Era of Large-Language Models](https://arxiv.org/abs/2412.09640)
*Kentaroh Toyoda,Xiao Wang,Mingzhe Li,Bo Gao,Yuan Wang,Qingsong Wei*

Main category: cs.CR

TL;DR: This paper explores how Large Language Models (LLMs) can improve blockchain data analysis, addressing current tool limitations. It systematically examines techniques and design patterns for integrating LLMs, identifies research opportunities and challenges, and aims to guide researchers, industry professionals, and policymakers.


<details>
  <summary>Details</summary>
Motivation: Existing blockchain data analysis tools face challenges like data scarcity, lack of generalizability, and reasoning capability. LLMs offer a potential solution, but there's a lack of comprehensive research on their integration.

Method: Systematically explores potential techniques and design patterns in LLM-integrated blockchain data analysis.

Result: Outlines prospective research opportunities and challenges in LLM-integrated blockchain data analysis.

Conclusion: LLMs can mitigate challenges in blockchain data analysis, but further exploration is needed.

Abstract: Blockchain data analysis is essential for deriving insights, tracking
transactions, identifying patterns, and ensuring the integrity and security of
decentralized networks. It plays a key role in various areas, such as fraud
detection, regulatory compliance, smart contract auditing, and decentralized
finance (DeFi) risk management. However, existing blockchain data analysis
tools face challenges, including data scarcity, the lack of generalizability,
and the lack of reasoning capability.
  We believe large language models (LLMs) can mitigate these challenges;
however, we have not seen papers discussing LLM integration in blockchain data
analysis in a comprehensive and systematic way. This paper systematically
explores potential techniques and design patterns in LLM-integrated blockchain
data analysis. We also outline prospective research opportunities and
challenges, emphasizing the need for further exploration in this promising
field. This paper aims to benefit a diverse audience spanning academia,
industry, and policy-making, offering valuable insights into the integration of
LLMs in blockchain data analysis.

</details>


### [56] [Artificial intelligence and cybersecurity in banking sector: opportunities and risks](https://arxiv.org/abs/2412.04495)
*Ana Kovacevic,Sonja D. Radenkovic,Dragana Nikolic*

Main category: cs.CR

TL;DR: AI in banking offers efficiency but poses cybersecurity risks (adversarial attacks). Developing secure, robust ML models and improving defenses are crucial for responsible AI integration and data protection.


<details>
  <summary>Details</summary>
Motivation: AI advancements offer opportunities for efficiency and competitiveness in banking, but also introduce cybersecurity challenges like adversarial attacks and the dual-use nature of AI tools.

Method: The paper emphasizes the importance of developing machine learning models with key characteristics such as security, trust, resilience and robustness.

Result: The findings underscore the urgent need for enhanced cybersecurity frameworks and continuous improvements in defensive mechanisms, guiding the responsible integration of AI in the banking sector while safeguarding against emerging threats.

Conclusion: The study highlights the urgent need for enhanced cybersecurity frameworks and continuous improvements in defensive mechanisms to mitigate risks and ensure the secure deployment of AI technologies in banking sectors.

Abstract: The rapid advancements in artificial intelligence (AI) have presented new
opportunities for enhancing efficiency and economic competitiveness across
various industries, espcially in banking. Machine learning (ML), as a subset of
artificial intelligence, enables systems to adapt and learn from vast datasets,
revolutionizing decision-making processes, fraud detection, and customer
service automation. However, these innovations also introduce new challenges,
particularly in the realm of cybersecurity. Adversarial attacks, such as data
poisoning and evasion attacks, represent critical threats to machine learning
models, exploiting vulnerabilities to manipulate outcomes or compromise
sensitive information. Furthermore, this study highlights the dual-use nature
of AI tools, which can be used by malicious users. To address these challenges,
the paper emphasizes the importance of developing machine learning models with
key characteristics such as security, trust, resilience and robustness. These
features are essential to mitigating risks and ensuring the secure deployment
of AI technologies in banking sectors, where the protection of financial data
is paramount. The findings underscore the urgent need for enhanced
cybersecurity frameworks and continuous improvements in defensive mechanisms.
By exploring both opportunities and risks, this paper aims to guide the
responsible integration of AI in the banking sector, paving the way for
innovation while safeguarding against emerging threats.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [57] [SigN: SIMBox Activity Detection Through Latency Anomalies at the Cellular Edge](https://arxiv.org/abs/2502.01193)
*Anne Josiane Kouam,Aline Carneiro Viana,Philippe Martins,Cedric Adjih,Alain Tchana*

Main category: cs.NI

TL;DR: SigN 是一种新的 SIMBox 检测方法，通过检测延迟异常来识别 SIMBox 活动。


<details>
  <summary>Details</summary>
Motivation: SIMBox 设备通过路由 VoIP 流量，对蜂窝网络构成重大威胁，导致每年高达 31.1 亿美元的欺诈损失，并威胁国家安全。现有检测方法因欺诈技术不断演变而效果受限。

Method: SigN 是一种在蜂窝网络边缘识别 SIMBox 活动的新方法，通过分析蜂窝信令中的网络连接和认证阶段来检测 SIMBox 和标准设备之间的延迟异常。

Result: 实验证明，SIMBox 设备在网络连接的认证阶段会产生比标准设备高出 23 倍的延迟。

Conclusion: SigN 通过在蜂窝网络边缘检测远程 SIM 卡关联来识别 SIMBox 活动，解决了现有检测方法的局限性。该方法通过分析网络连接期间的蜂窝信令来检测 SIMBox 和标准设备之间的延迟异常，特别是网络连接的认证阶段，其延迟比标准设备高出 23 倍。SigN 提供了一种稳健、可扩展且实用的解决方案，可在网络边缘缓解 SIMBox 活动风险。

Abstract: Despite their widespread adoption, cellular networks face growing
vulnerabilities due to their inherent complexity and the integration of
advanced technologies. One of the major threats in this landscape is Voice over
IP (VoIP) to GSM gateways, known as SIMBox devices. These devices use multiple
SIM cards to route VoIP traffic through cellular networks, enabling
international bypass fraud with losses of up to $3.11 billion annually. Beyond
financial impact, SIMBox activity degrades network performance, threatens
national security, and facilitates eavesdropping on communications. Existing
detection methods for SIMBox activity are hindered by evolving fraud techniques
and implementation complexities, limiting their practical adoption in operator
networks.This paper addresses the limitations of current detection methods by
introducing SigN , a novel approach to identifying SIMBox activity at the
cellular edge. The proposed method focuses on detecting remote SIM card
association, a technique used by SIMBox appliances to mimic human mobility
patterns. The method detects latency anomalies between SIMBox and standard
devices by analyzing cellular signaling during network attachment. Extensive
indoor and outdoor experiments demonstrate that SIMBox devices generate
significantly higher attachment latencies, particularly during the
authentication phase, where latency is up to 23 times greater than that of
standard devices. We attribute part of this overhead to immutable factors such
as LTE authentication standards and Internet-based communication protocols.
Therefore, our approach offers a robust, scalable, and practical solution to
mitigate SIMBox activity risks at the network edge.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [58] [Credit Card Fraud Detection Using RoFormer Model With Relative Distance Rotating Encoding](https://arxiv.org/abs/2507.09385)
*Kevin Reyes,Vasco Cortez*

Main category: cs.NE

TL;DR: 通过在RoFormer模型中引入ReDRE，改进了欺诈交易的检测。


<details>
  <summary>Details</summary>
Motivation: 金融系统面临着欺诈检测的重大挑战，特别是对于像Flow Payment这样的支付网关公司。提高交易授权率和降低欺诈率对于用户体验和业务可持续性至关重要，因此需要不断研究和投资新的欺诈检测方法。

Method: 提出了一种名为ReDRE（相对距离旋转编码）的新方法，并将其应用于RoFormer模型，以增强对时间序列数据的特征提取能力，更好地捕捉时间依赖关系和事件关系。

Result: 通过将ReDRE融入RoFormer模型，可以提高时间序列数据在Transformer模型中的特征表征能力，从而提升欺诈检测的效果。

Conclusion: 本文提出了一种新的交易欺诈检测方法，通过将相对距离旋转编码（ReDRE）融入RoFormer模型，以提高欺诈检测的准确性。

Abstract: Fraud detection is one of the most important challenges that financial
systems must address. Detecting fraudulent transactions is critical for payment
gateway companies like Flow Payment, which process millions of transactions
monthly and require robust security measures to mitigate financial risks.
Increasing transaction authorization rates while reducing fraud is essential
for providing a good user experience and building a sustainable business. For
this reason, discovering novel and improved methods to detect fraud requires
continuous research and investment for any company that wants to succeed in
this industry. In this work, we introduced a novel method for detecting
transactional fraud by incorporating the Relative Distance Rotating Encoding
(ReDRE) in the RoFormer model. The incorporation of angle rotation using ReDRE
enhances the characterization of time series data within a Transformer, leading
to improved fraud detection by better capturing temporal dependencies and event
relationships.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [59] [Shill Bidding Prevention in Decentralized Auctions Using Smart Contracts](https://arxiv.org/abs/2506.00282)
*M. A. Bouaicha,G. Destefanis,T. Montanaro,N. Lasla,L. Patrono*

Main category: cs.GT

TL;DR: 在区块链上使用动态处罚来阻止拍卖欺诈。


<details>
  <summary>Details</summary>
Motivation: 在线拍卖中的欺诈行为（如幌骗投标）带来了重大风险。

Method: 提出了一种将动态的、基于行为的处罚应用于区块链智能合约以阻止拍卖欺诈的概念框架，并提出投标人评分（BSS）来评估九种不同的投标行为，以动态调整处罚费用。

Result: 模拟证实了该模型是有效的，动态处罚机制降低了幌骗投标的可盈利性，同时保持了对诚实投标人较低的处罚，并且该系统仅引入了适度的汽油和延迟开销，使交易成本和响应时间在实际使用的可行范围内。

Conclusion: 该方法为无法假定信任的去中心化系统提供了一种实用的、基于行为的欺诈预防方法。

Abstract: In online auctions, fraudulent behaviors such as shill bidding pose
significant risks. This paper presents a conceptual framework that applies
dynamic, behavior-based penalties to deter auction fraud using blockchain smart
contracts. Unlike traditional post-auction detection methods, this approach
prevents manipulation in real-time by introducing an economic disincentive
system where penalty severity scales with suspicious bidding patterns. The
framework employs the proposed Bid Shill Score (BSS) to evaluate nine distinct
bidding behaviors, dynamically adjusting the penalty fees to make fraudulent
activity financially unaffordable while providing fair competition.
  The system is implemented within a decentralized English auction on the
Ethereum blockchain, demonstrating how smart contracts enforce transparent
auction rules without trusted intermediaries. Simulations confirm the
effectiveness of the proposed model: the dynamic penalty mechanism reduces the
profitability of shill bidding while keeping penalties low for honest bidders.
Performance evaluation shows that the system introduces only moderate gas and
latency overhead, keeping transaction costs and response times within practical
bounds for real-world use. The approach provides a practical method for
behaviour-based fraud prevention in decentralised systems where trust cannot be
assumed.

</details>


### [60] [Co-evolutionary Dynamics of Attack and Defence in Cybersecurity](https://arxiv.org/abs/2505.19338)
*Adeela Bashir,Zia Ush Shamszaman,Zhao Song,The Anh Han*

Main category: cs.GT

TL;DR: 本研究利用进化博弈论分析网络攻防动态，发现高防御强度系统更稳定。研究结果与现实数据一致，表明EGT可用于改进网络安全策略和资源分配。


<details>
  <summary>Details</summary>
Motivation: 在不断发展的数字环境中，研究网络攻击与防御的动态至关重要。

Method: 本研究采用进化博弈论（EGT）框架，通过构建攻击者与防御者之间的双群体非对称博弈模型，来研究网络空间攻防的进化动态。模型考虑了成本、潜在收益和成功防御的概率等关键因素，并结合数学分析与数值模拟进行研究。

Result: 研究发现，高防御强度系统具有稳定性且攻击频率低；相反，低防御环境则不稳定且易受攻击。此外，研究确定了五个均衡点，其中“持续防御”和“持续攻击”的策略组合是最有可能的稳定状态，这反映了网络领域攻防双方持续博弈的特点。理论发现与现实世界网络事件数据吻合。

Conclusion: 该分析表明，基于进化博弈论的自适应网络安全策略可以优化资源配置，增强系统弹性，并降低整体网络攻击风险。通过整合真实世界数据，本研究证明了进化博弈论在应对网络威胁演变性以及通过战略规划和主动防御措施实现安全数字生态系统方面的适用性。

Abstract: In the evolving digital landscape, it is crucial to study the dynamics of
cyberattacks and defences. This study uses an Evolutionary Game Theory (EGT)
framework to investigate the evolutionary dynamics of attacks and defences in
cyberspace. We develop a two-population asymmetric game between attacker and
defender to capture the essential factors of costs, potential benefits, and the
probability of successful defences. Through mathematical analysis and numerical
simulations, we find that systems with high defence intensities show stability
with minimal attack frequencies, whereas low-defence environments show
instability, and are vulnerable to attacks. Furthermore, we find five
equilibria, where the strategy pair always defend and attack emerged as the
most likely stable state as cyber domain is characterised by a continuous
battle between defenders and attackers. Our theoretical findings align with
real-world data from past cyber incidents, demonstrating the interdisciplinary
impact, such as fraud detection, risk management and cybersecurity
decision-making. Overall, our analysis suggests that adaptive cybersecurity
strategies based on EGT can improve resource allocation, enhance system
resilience, and reduce the overall risk of cyberattacks. By incorporating
real-world data, this study demonstrates the applicability of EGT in addressing
the evolving nature of cyber threats and the need for secure digital ecosystems
through strategic planning and proactive defence measures.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [61] [Transformer-Based Financial Fraud Detection with Cloud-Optimized Real-Time Streaming](https://arxiv.org/abs/2501.19267)
*Tingting Deng,Shuochen Bi,Jue Xiao*

Main category: cs.CE

TL;DR: 通过利用图自注意力 Transformer 神经网络模块和欺诈预测网络，该模型能有效检测信用卡欺诈交易，在准确率和 AUC 方面均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 金融行业日益互联和依赖数字系统，欺诈检测系统必须不断发展以应对日益增长的威胁。云启用的 Transformer 模型为应对这些挑战提供了变革性的机会。

Method: 利用图自注意力 Transformer 神经网络模块直接从交易网络中挖掘团伙欺诈特征，并结合欺诈预测网络来优化拓扑模式和交易时间模式。

Result: 所提出的模型在所有评估指标上均优于 7 个基线模型，在交易欺诈检测任务中，与基线图注意力神经网络（GAT）相比，平均准确率（AP）提高了 20%，ROC 曲线下面积（AUC）平均提高了 2.7%。

Conclusion: 该模型在信用卡欺诈交易的检测中是有效的。

Abstract: As the financial industry becomes more interconnected and reliant on digital
systems, fraud detection systems must evolve to meet growing threats.
Cloud-enabled Transformer models present a transformative opportunity to
address these challenges. By leveraging the scalability, flexibility, and
advanced AI capabilities of cloud platforms, companies can deploy fraud
detection solutions that adapt to real-time data patterns and proactively
respond to evolving threats. Using the Graph self-attention Transformer neural
network module, we can directly excavate gang fraud features from the
transaction network without constructing complicated feature engineering.
Finally, the fraud prediction network is combined to optimize the topological
pattern and the temporal transaction pattern to realize the high-precision
detection of fraudulent transactions. The results of antifraud experiments on
credit card transaction data show that the proposed model outperforms the 7
baseline models on all evaluation indicators: In the transaction fraud
detection task, the average accuracy (AP) increased by 20% and the area under
the ROC curve (AUC) increased by 2.7% on average compared with the benchmark
graph attention neural network (GAT), which verified the effectiveness of the
proposed model in the detection of credit card fraud transactions.

</details>


### [62] [Optimizing Blockchain Analysis: Tackling Temporality and Scalability with an Incremental Approach with Metropolis-Hastings Random Walks](https://arxiv.org/abs/2501.12491)
*Junliang Luo,Xue Liu*

Main category: cs.CE

TL;DR: 本研究提出了一种针对区块链交易网络的新型增量学习方法，通过优化的随机游走机制，在保持性能的同时降低了计算成本，适用于交易监控和地址分类等场景。


<details>
  <summary>Details</summary>
Motivation: 现有图表示学习方法主要关注交易网络的快照，忽略了其演化特性，并且可能未能充分强调增量学习能力，而这对于处理不断增长的大规模交易网络至关重要。

Method: 采用增量方法进行随机游走节点表示学习，并提出 Metropolis-Hastings 随机游走机制。

Result: 在区块链交易数据集上的实证评估显示，所提出的方法在节点分类任务上具有可比的性能，同时减少了计算开销。

Conclusion: 该研究提出了一种用于区块链交易网络的增量随机游走节点表示学习方法，并结合 Metropolis-Hastings 随机游走机制以提高效率。实验表明，该方法在节点分类任务上表现与现有方法相当，同时显著降低了计算开销。

Abstract: Blockchain technology, with implications in the financial domain, offers data
in the form of large-scale transaction networks. Analyzing transaction networks
facilitates fraud detection, market analysis, and supports government
regulation. Despite many graph representation learning methods for transaction
network analysis, we pinpoint two salient limitations that merit more
investigation. Existing methods predominantly focus on the snapshots of
transaction networks, sidelining the evolving nature of blockchain transaction
networks. Existing methodologies may not sufficiently emphasize efficient,
incremental learning capabilities, which are essential for addressing the
scalability challenges in ever-expanding large-scale transaction networks. To
address these challenges, we employed an incremental approach for random
walk-based node representation learning in transaction networks. Further, we
proposed a Metropolis-Hastings-based random walk mechanism for improved
efficiency. The empirical evaluation conducted on blockchain transaction
datasets reveals comparable performance in node classification tasks while
reducing computational overhead. Potential applications include transaction
network monitoring, the efficient classification of blockchain addresses for
fraud detection or the identification of specialized address types within the
network.

</details>


<div id='stat.CO'></div>

# stat.CO [[Back]](#toc)

### [63] [An Efficient Outlier Detection Algorithm for Data Streaming](https://arxiv.org/abs/2501.01061)
*Rui Hu,Luc,Chen,Yiwei Wang*

Main category: stat.CO

TL;DR: EILOF算法通过只计算新数据点的LOF分数来提高LOF在实时异常检测中的效率和准确性，尤其是在大数据流场景下。


<details>
  <summary>Details</summary>
Motivation: 传统异常检测方法（如LOF）难以处理实时数据，而现有的增量LOF（ILOF）算法在处理大数据流时计算成本高且检测性能会下降。

Method: 提出了一种名为高效增量局部异常值因子（EILOF）的新方法，该方法通过仅计算新数据点的LOF分数而不改变现有数据点的LOF分数来提高LOF算法在在线异常检测中的效率。

Result: EILOF算法在模拟和真实数据集上的测试结果表明，在流式数据量增加的情况下，EILOF的性能优于ILOF。

Conclusion: EILOF算法在处理流式数据时，相比ILOF算法，显著降低了计算成本，并随着数据量的增加系统性地提高了检测准确率。

Abstract: The nature of modern data is increasingly real-time, making outlier detection
crucial in any data-related field, such as finance for fraud detection and
healthcare for monitoring patient vitals. Traditional outlier detection
methods, such as the Local Outlier Factor (LOF) algorithm, struggle with
real-time data due to the need for extensive recalculations with each new data
point, limiting their application in real-time environments. While the
Incremental LOF (ILOF) algorithm has been developed to tackle the challenges of
online anomaly detection, it remains computationally expensive when processing
large streams of data points, and its detection performance may degrade after a
certain threshold of points have streamed in. In this paper, we propose a novel
approach to enhance the efficiency of LOF algorithms for online anomaly
detection, named the Efficient Incremental LOF (EILOF) algorithm. The EILOF
algorithm only computes the LOF scores of new points without altering the LOF
scores of existing data points. Although exact LOF scores have not yet been
computed for the existing points in the new algorithm, datasets often contain
noise, and minor deviations in LOF score calculations do not necessarily
degrade detection performance. In fact, such deviations can sometimes enhance
outlier detection. We systematically tested this approach on both simulated and
real-world datasets, demonstrating that EILOF outperforms ILOF as the volume of
streaming data increases across various scenarios. The EILOF algorithm not only
significantly reduces computational costs, but also systematically improves
detection accuracy when the number of additional points increases compared to
the ILOF algorithm.

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [64] [Detecting Fraud in Financial Networks: A Semi-Supervised GNN Approach with Granger-Causal Explanations](https://arxiv.org/abs/2507.01980)
*Linh Nguyen,Marcel Boersma,Erman Acar*

Main category: q-fin.ST

TL;DR: SAGE-FIN是一种半监督图神经网络方法，用于检测金融欺诈，并提供格兰德因果关系解释。


<details>
  <summary>Details</summary>
Motivation: 由于金融行业欺诈活动造成的巨大经济损失，以及现有机器学习方法在处理稀疏标签数据和模型可解释性方面的挑战，因此需要一种新的方法来有效检测和解释欺诈行为。

Method: SAGE-FIN是一种基于半监督图神经网络（GNN）的方法，并结合了格兰德因果解释，用于金融交易网络。

Result: SAGE-FIN能够基于弱标签或无标签的数据点识别欺诈项目，并提供格兰德因果关系解释，以满足监管要求。

Conclusion: SAGE-FIN在现实世界的金融交易网络（Elliptic++）数据集上得到了有效的验证，并且能够提供基于格兰德因果关系的解释，而无需对网络结构做出任何先验假设。

Abstract: Fraudulent activity in the financial industry costs billions annually.
Detecting fraud, therefore, is an essential yet technically challenging task
that requires carefully analyzing large volumes of data. While machine learning
(ML) approaches seem like a viable solution, applying them successfully is not
so easy due to two main challenges: (1) the sparsely labeled data, which makes
the training of such approaches challenging (with inherent labeling costs), and
(2) lack of explainability for the flagged items posed by the opacity of ML
models, that is often required by business regulations. This article proposes
SAGE-FIN, a semi-supervised graph neural network (GNN) based approach with
Granger causal explanations for Financial Interaction Networks. SAGE-FIN learns
to flag fraudulent items based on weakly labeled (or unlabelled) data points.
To adhere to regulatory requirements, the flagged items are explained by
highlighting related items in the network using Granger causality. We
empirically validate the favorable performance of SAGE-FIN on a real-world
dataset, Bipartite Edge-And-Node Attributed financial network (Elliptic++),
with Granger-causal explanations for the identified fraudulent items without
any prior assumption on the network structure.

</details>


### [65] [EDINET-Bench: Evaluating LLMs on Complex Financial Tasks using Japanese Financial Statements](https://arxiv.org/abs/2506.08762)
*Issa Sugiura,Takashi Ishida,Taro Makino,Chieko Tazuke,Takanori Nakagawa,Kosuke Nakago,David Ha*

Main category: q-fin.ST

TL;DR: 本研究发布了EDINET-Bench，一个包含日本金融数据的开源基准测试集，用于评估LLM在金融任务上的表现。实验证明，即使是先进的LLM在这些任务上也表现不佳，表明需要针对金融领域进行专门优化。


<details>
  <summary>Details</summary>
Motivation: 为了解决日本金融领域缺乏具有挑战性的数据集的问题，阻碍了LLM在这一领域的创新和评估，本研究引入了EDINET-Bench。

Method: EDINET-Bench是通过下载过去10年日本EDINET（电子披露网络）的年报，并自动分配标签来构建的，用于评估LLM在会计欺诈检测、收益预测和行业预测等金融任务上的表现。

Result: EDINET-Bench的实验结果表明，先进的LLM在金融任务上的表现并不理想，仅略优于逻辑回归，凸显了LLM在实际金融应用中的挑战。

Conclusion: EDINET-Bench的实验结果表明，即使是先进的LLM在处理真实的金融任务时也面临巨大挑战，其在欺诈检测和收益预测等任务上的表现仅略优于逻辑回归。这强调了在实际金融应用中，LLM需要领域特定的适应性。

Abstract: Financial analysis presents complex challenges that could leverage large
language model (LLM) capabilities. However, the scarcity of challenging
financial datasets, particularly for Japanese financial data, impedes academic
innovation in financial analytics. As LLMs advance, this lack of accessible
research resources increasingly hinders their development and evaluation in
this specialized domain. To address this gap, we introduce EDINET-Bench, an
open-source Japanese financial benchmark designed to evaluate the performance
of LLMs on challenging financial tasks including accounting fraud detection,
earnings forecasting, and industry prediction. EDINET-Bench is constructed by
downloading annual reports from the past 10 years from Japan's Electronic
Disclosure for Investors' NETwork (EDINET) and automatically assigning labels
corresponding to each evaluation task. Our experiments reveal that even
state-of-the-art LLMs struggle, performing only slightly better than logistic
regression in binary classification for fraud detection and earnings
forecasting. These results highlight significant challenges in applying LLMs to
real-world financial applications and underscore the need for domain-specific
adaptation. Our dataset, benchmark construction code, and evaluation code is
publicly available to facilitate future research in finance with LLMs.

</details>


### [66] [Financial fraud detection system based on improved random forest and gradient boosting machine (GBM)](https://arxiv.org/abs/2502.15822)
*Tianzuo Hu*

Main category: q-fin.ST

TL;DR: 通过结合GBM的优化能力和改进的随机森林（SSRF），提出GBM-SSRF模型，以提高金融欺诈检测的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 针对传统随机森林模型在高计算复杂度和特征选择的局限性，以及GBM模型训练时间长和易过拟合的问题，提出GBM-SSRF模型。

Method: 提出了一种基于改进随机森林（RF）和梯度提升机（GBM）的金融欺诈检测系统，具体来说，该系统引入了一种名为GBM-SSRF（Gradient Boosting Machine with Simplified and Strengthened Random Forest）的新型模型架构，它巧妙地结合了梯度提升机（GBM）强大的优化能力和改进的随机性。

Result: 实验表明，GBM-SSRF模型不仅具有良好的性能，而且具有良好的鲁棒性和泛化能力。

Conclusion: GBM-SSRF模型在金融欺诈检测方面表现出良好的性能、鲁棒性和泛化能力，为金融欺诈检测提供了一个高效且可靠的解决方案。

Abstract: This paper proposes a financial fraud detection system based on improved
Random Forest (RF) and Gradient Boosting Machine (GBM). Specifically, the
system introduces a novel model architecture called GBM-SSRF (Gradient Boosting
Machine with Simplified and Strengthened Random Forest), which cleverly
combines the powerful optimization capabilities of the gradient boosting
machine (GBM) with improved randomization. The computational efficiency and
feature extraction capabilities of the Simplified and Strengthened Random
Forest (SSRF) forest significantly improve the performance of financial fraud
detection. Although the traditional random forest model has good classification
capabilities, it has high computational complexity when faced with large-scale
data and has certain limitations in feature selection. As a commonly used
ensemble learning method, the GBM model has significant advantages in
optimizing performance and handling nonlinear problems. However, GBM takes a
long time to train and is prone to overfitting problems when data samples are
unbalanced. In response to these limitations, this paper optimizes the random
forest based on the structure, reducing the computational complexity and
improving the feature selection ability through the structural simplification
and enhancement of the random forest. In addition, the optimized random forest
is embedded into the GBM framework, and the model can maintain efficiency and
stability with the help of GBM's gradient optimization capability. Experiments
show that the GBM-SSRF model not only has good performance, but also has good
robustness and generalization capabilities, providing an efficient and reliable
solution for financial fraud detection.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [67] [PITCH: AI-assisted Tagging of Deepfake Audio Calls using Challenge-Response](https://arxiv.org/abs/2402.18085)
*Govind Mittal,Arthur Jakobsson,Kelly O. Marshall,Chinmay Hegde,Nasir Memon*

Main category: cs.SD

TL;DR: PITCH通过一系列音频挑战和人机协作，有效检测实时AI语音克隆攻击，提高了身份验证的准确性和安全性。


<details>
  <summary>Details</summary>
Motivation: AI语音克隆技术（尤其是实时深度伪造音频，RTDFs）的兴起加剧了社会工程学攻击，能够实时模仿声音，绕过传统的基于注册的身份验证，对电话身份验证系统构成生存威胁。现有的防御措施无法应对此类攻击，因此需要新的检测方法。

Method: PITCH是一种基于挑战-响应的方法，通过设计一套基于人类听觉系统、语言学和环境因素的音频挑战（共20个），并从中筛选出10个高效挑战，来检测和标记交互式深度伪造音频通话。该方法结合了机器检测和人类评估，并提出了一个结合人类直觉和机器精度的混合系统。

Result: 在机器检测方面，PITCH的挑战将检测能力提升至88.7%的AUROC得分，并识别出10个高效挑战。在人类评估方面，人类评估者在经过筛选的子集上达到了72.6%的准确率，而机器的得分为87.7%。结合人类直觉和机器精度的混合系统将检测准确率提高到84.5%。

Conclusion: PITCH能够作为AI辅助的预筛选器来验证通话，提供一种适应性方法来对抗实时语音克隆攻击，同时保持人类决策的权威性。

Abstract: The rise of AI voice-cloning technology, particularly audio Real-time
Deepfakes (RTDFs), has intensified social engineering attacks by enabling
real-time voice impersonation that bypasses conventional enrollment-based
authentication. This technology represents an existential threat to phone-based
authentication systems, while total identity fraud losses reached $43 billion.
Unlike traditional robocalls, these personalized AI-generated voice attacks
target high-value accounts and circumvent existing defensive measures, creating
an urgent cybersecurity challenge. To address this, we propose PITCH, a robust
challenge-response method to detect and tag interactive deepfake audio calls.
We developed a comprehensive taxonomy of audio challenges based on the human
auditory system, linguistics, and environmental factors, yielding 20
prospective challenges. Testing against leading voice-cloning systems using a
novel dataset (18,600 original and 1.6 million deepfake samples from 100
users), PITCH's challenges enhanced machine detection capabilities to 88.7%
AUROC score, enabling us to identify 10 highly-effective challenges.
  For human evaluation, we filtered a challenging, balanced subset on which
human evaluators independently achieved 72.6% accuracy, while machines scored
87.7%. Recognizing that call environments require human control, we developed a
novel human-AI collaborative system that tags suspicious calls as
"Deepfake-likely." Contrary to prior findings, we discovered that integrating
human intuition with machine precision offers complementary advantages, giving
users maximum control while boosting detection accuracy to 84.5%. This
significant improvement situates PITCH's potential as an AI-assisted
pre-screener for verifying calls, offering an adaptable approach to combat
real-time voice-cloning attacks while maintaining human decision authority.

</details>


### [68] [Beyond Identity: A Generalizable Approach for Deepfake Audio Detection](https://arxiv.org/abs/2505.06766)
*Yasaman Ahmadiadli,Xiao-Ping Zhang,Naimul Khan*

Main category: cs.SD

TL;DR: 由于模型过拟合说话者特征而不是操纵伪影，现有的深度伪造音频检测模型在跨数据集上泛化能力较差。本研究提出了一个身份无关的框架，利用伪影检测模块（ADMs）和动态伪影生成技术来解决这个问题，并在各种数据集上取得了优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度伪造音频检测模型由于模型无意中学习了说话者特定的特征而不是操纵伪影，因此在跨数据集上泛化能力较差。本研究旨在解决身份泄漏问题，以提高模型的泛化能力。

Method: 提出了一种身份无关的音频深度伪造检测框架，利用伪影检测模块（ADMs）来分离时间和频域中的合成伪影，并通过频率域交换、时间域操纵和背景噪声增强等新的动态伪影生成技术来强制学习与数据集无关的特征。

Result: 所提出的 ADM 增强模型在 ASVspoof2019、ADD 2022、FoR 和 In-The-Wild 数据集上进行了广泛的实验，在 ADD 2022、FoR 和 In-The-Wild 数据集上分别取得了 0.230、0.604 和 0.813 的 F1 分数，始终优于基线模型。

Conclusion: 本研究提出的身份无关的音频深度伪造检测框架通过鼓励模型关注伪造特定的伪影而不是过度拟合说话者特征，从而减轻了身份泄漏。实验证明，ADM 增强模型在各种数据集上始终优于基线模型，其中动态频率交换在各种条件下最为有效。这些发现强调了基于伪影的学习在减轻隐式身份泄漏以实现更具可推广性的音频深度伪造检测方面的价值。

Abstract: Deepfake audio presents a growing threat to digital security, due to its
potential for social engineering, fraud, and identity misuse. However, existing
detection models suffer from poor generalization across datasets, due to
implicit identity leakage, where models inadvertently learn speaker-specific
features instead of manipulation artifacts. To the best of our knowledge, this
is the first study to explicitly analyze and address identity leakage in the
audio deepfake detection domain. This work proposes an identity-independent
audio deepfake detection framework that mitigates identity leakage by
encouraging the model to focus on forgery-specific artifacts instead of
overfitting to speaker traits. Our approach leverages Artifact Detection
Modules (ADMs) to isolate synthetic artifacts in both time and frequency
domains, enhancing cross-dataset generalization. We introduce novel dynamic
artifact generation techniques, including frequency domain swaps, time domain
manipulations, and background noise augmentation, to enforce learning of
dataset-invariant features. Extensive experiments conducted on ASVspoof2019,
ADD 2022, FoR, and In-The-Wild datasets demonstrate that the proposed
ADM-enhanced models achieve F1 scores of 0.230 (ADD 2022), 0.604 (FoR), and
0.813 (In-The-Wild), consistently outperforming the baseline. Dynamic Frequency
Swap proves to be the most effective strategy across diverse conditions. These
findings emphasize the value of artifact-based learning in mitigating implicit
identity leakage for more generalizable audio deepfake detection.

</details>


### [69] [Where are we in audio deepfake detection? A systematic analysis over generative and detection models](https://arxiv.org/abs/2410.04324)
*Xiang Li,Pin-Yu Chen,Wenqi Wei*

Main category: cs.SD

TL;DR: 本文介绍了SONAR框架和数据集，用于评估AI语音检测技术。研究发现，基于基础模型的检测器泛化能力更强，跨语言检测效果好，少样本微调能进一步提升性能。这表明提升合成语音的真实性和质量是检测的关键，而非语言本身。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术在语音合成（TTS）和语音转换（VC）领域的快速发展，AI合成语音的质量日益提高，使得区分真实语音和AI生成语音变得更加困难。这可能导致滥用，如身份冒充、欺诈、传播虚假信息和网络诈骗。然而，现有的AI合成语音检测方法未能跟上技术发展的步伐，并且在不同数据集上的泛化能力不足。因此，有必要开发一个全面的框架和基准来评估和改进AI合成语音的检测技术。

Method: 本文提出SONAR（Synthetic AI-Audio Detection Framework and Benchmark）框架，并构建了一个包含9个不同音频合成平台（包括主流TTS提供商和先进TTS模型）的新型评估数据集。SONAR首次实现了对传统和基于基础模型的AI音频检测系统进行统一基准测试。通过大量实验，对现有检测方法的局限性进行了揭示，并评估了基础模型在泛化能力、跨语言能力以及少样本微调方面的表现。

Result: 1. 现有检测方法存在局限性，而基于基础模型的检测系统表现出更强的泛化能力，这可能归因于其模型规模以及预训练数据的质量和规模。
2. 语音基础模型展现出鲁棒的跨语言泛化能力，即使仅使用英语数据进行微调，在多种语言上仍能保持良好的性能。这表明音频深度伪造检测的主要挑战在于合成语音的真实性和质量，而非特定语言的特性。
3. 少样本微调在提升检测模型泛化能力方面是有效且高效的，为开发针对特定实体或个人的定制化检测系统提供了可能。

Conclusion: 现有AI语音检测方法在面对日益增长的AI生成语音时存在局限性且泛化能力不足。本文提出的SONAR框架及其评估基准，通过包含多样化数据源和统一的评估标准，能够全面评估区分AI合成语音的能力。实验证明，基于基础模型的检测系统在泛化能力上表现更优，且在跨语言检测上展现出鲁棒性，这表明合成语音的真实性和质量是关键挑战，而非语言本身。此外，少样本微调技术在提升模型泛化能力方面显示出巨大潜力，可用于定制化检测系统。

Abstract: Recent advances in Text-to-Speech (TTS) and Voice-Conversion (VC) using
generative Artificial Intelligence (AI) technology have made it possible to
generate high-quality and realistic human-like audio. This poses growing
challenges in distinguishing AI-synthesized speech from the genuine human voice
and could raise concerns about misuse for impersonation, fraud, spreading
misinformation, and scams. However, existing detection methods for
AI-synthesized audio have not kept pace and often fail to generalize across
diverse datasets. In this paper, we introduce SONAR, a synthetic AI-Audio
Detection Framework and Benchmark, aiming to provide a comprehensive evaluation
for distinguishing cutting-edge AI-synthesized auditory content. SONAR includes
a novel evaluation dataset sourced from 9 diverse audio synthesis platforms,
including leading TTS providers and state-of-the-art TTS models. It is the
first framework to uniformly benchmark AI-audio detection across both
traditional and foundation model-based detection systems. Through extensive
experiments, (1) we reveal the limitations of existing detection methods and
demonstrate that foundation models exhibit stronger generalization
capabilities, likely due to their model size and the scale and quality of
pretraining data. (2) Speech foundation models demonstrate robust cross-lingual
generalization capabilities, maintaining strong performance across diverse
languages despite being fine-tuned solely on English speech data. This finding
also suggests that the primary challenges in audio deepfake detection are more
closely tied to the realism and quality of synthetic audio rather than
language-specific characteristics. (3) We explore the effectiveness and
efficiency of few-shot fine-tuning in improving generalization, highlighting
its potential for tailored applications, such as personalized detection systems
for specific entities or individuals.

</details>


### [70] [Transferable Adversarial Attacks on Audio Deepfake Detection](https://arxiv.org/abs/2501.11902)
*Muhammad Umar Farooq,Awais Khan,Kutub Uddin,Khalid Mahmood Malik*

Main category: cs.SD

TL;DR: 本研究提出了一种新的基于GAN的攻击方法，揭示了当前音频深度伪造检测系统在对抗性攻击下的严重漏洞，准确率大幅下降，强调了提高其鲁棒性的必要性。


<details>
  <summary>Details</summary>
Motivation: 评估现有音频深度伪造检测系统在面对可迁移对抗性攻击时的鲁棒性，因为这方面的研究尚不充分，但对现实世界的安全至关重要。

Method: 提出了一种基于生成对抗网络的对抗性攻击框架，该框架利用代理模型集和判别器生成可迁移的对抗性样本，并引入自监督音频模型来保证转录和感知完整性，以评估最先进的音频深度伪造检测系统的有效性。

Result: 在白盒、灰盒和黑盒场景下，最先进的音频深度伪造检测系统的准确率分别从98%下降到26%，从92%下降到54%，从94%下降到84%。在“In-the-Wild”和WaveFake数据集上的测试也分别显示准确率从91%下降到46%，从94%下降到67%。

Conclusion: 现有的音频深度伪造检测系统在面对可迁移的对抗性攻击时表现出显著的脆弱性，需要增强其鲁棒性以应对未来的安全威胁。

Abstract: Audio deepfakes pose significant threats, including impersonation, fraud, and
reputation damage. To address these risks, audio deepfake detection (ADD)
techniques have been developed, demonstrating success on benchmarks like
ASVspoof2019. However, their resilience against transferable adversarial
attacks remains largely unexplored. In this paper, we introduce a transferable
GAN-based adversarial attack framework to evaluate the effectiveness of
state-of-the-art (SOTA) ADD systems. By leveraging an ensemble of surrogate ADD
models and a discriminator, the proposed approach generates transferable
adversarial attacks that better reflect real-world scenarios. Unlike previous
methods, the proposed framework incorporates a self-supervised audio model to
ensure transcription and perceptual integrity, resulting in high-quality
adversarial attacks. Experimental results on benchmark dataset reveal that SOTA
ADD systems exhibit significant vulnerabilities, with accuracies dropping from
98% to 26%, 92% to 54%, and 94% to 84% in white-box, gray-box, and black-box
scenarios, respectively. When tested in other data sets, performance drops of
91% to 46%, and 94% to 67% were observed against the In-the-Wild and WaveFake
data sets, respectively. These results highlight the significant
vulnerabilities of existing ADD systems and emphasize the need to enhance their
robustness against advanced adversarial threats to ensure security and
reliability.

</details>


### [71] [AI-Generated Music Detection and its Challenges](https://arxiv.org/abs/2501.10111)
*Darius Afchar,Gabriel Meseguer-Brocal,Romain Hennequin*

Main category: cs.SD

TL;DR: 本研究首次提出了一个准确率高达 99.8% 的 AI-音乐探测器，以应对日益增长的合成音乐威胁，但同时也指出了其在鲁棒性和泛化能力方面的局限性，并为未来的研究方向提供了建议。


<details>
  <summary>Details</summary>
Motivation: 为了应对生成模型新时代下，检测人工生成内容日益增长的重要性，特别是音乐领域。

Method: 通过在真实音频和人工智能重建音频的数据集上训练分类器来实现。

Result: 该探测器达到了令人信服的 99.8% 的准确率，但同时也指出了其在鲁棒性和泛化能力方面的潜在问题。

Conclusion: 本研究首次提出了一个 AI-音乐探测器，可用于监管合成媒体。然而，该探测器在鲁棒性、泛化能力等方面仍有待提高，需要未来的研究来解决这些问题。

Abstract: In the face of a new era of generative models, the detection of artificially
generated content has become a matter of utmost importance. In particular, the
ability to create credible minute-long synthetic music in a few seconds on
user-friendly platforms poses a real threat of fraud on streaming services and
unfair competition to human artists. This paper demonstrates the possibility
(and surprising ease) of training classifiers on datasets comprising real audio
and artificial reconstructions, achieving a convincing accuracy of 99.8%. To
our knowledge, this marks the first publication of a AI-music detector, a tool
that will help in the regulation of synthetic media. Nevertheless, informed by
decades of literature on forgery detection in other fields, we stress that
getting a good test score is not the end of the story. We expose and discuss
several facets that could be problematic with such a deployed detector:
robustness to audio manipulation, generalisation to unseen models. This second
part acts as a position for future research steps in the field and a caveat to
a flourishing market of artificial content checkers.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [72] [Agentic AI Systems Applied to tasks in Financial Services: Modeling and model risk management crews](https://arxiv.org/abs/2502.05439)
*Izunna Okpala,Ashkan Golgoon,Arjun Ravi Kannan*

Main category: cs.AI

TL;DR: 該研究提出了用於金融服務行業的代理工作流程，重點是構建能夠執行建模和模型風險管理任務的代理團隊，並通過數值示例證明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 探索金融服務行業的代理系統工作流程，並構建能夠有效協作以執行複雜建模和模型風險管理（MRM）任務的代理團隊。

Method: 提出了一個包含評估代理和執行特定任務（例如數據探索、特徵工程、模型選擇、訓練、評估和文檔編寫）的代理的建模團隊，以及一個由評估代理和執行 MRM 相關任務（例如合規性檢查、模型複製、概念健全性、結果分析和文檔編寫）的代理組成的 MRM 團隊。

Result: 通過將代理團隊應用於信用卡欺詐檢測、信用卡批准和投資組合信用風險建模數據集，證明了這些團隊在建模和 MRM 任務方面的有效性和魯棒性。

Conclusion: 該研究展示了由具有人類 in the loop 模塊的代理組成的金融服務行業的代理工作流程，以執行複雜的建模和模型風險管理（MRM）任務。

Abstract: The advent of large language models has ushered in a new era of agentic
systems, where artificial intelligence programs exhibit remarkable autonomous
decision-making capabilities across diverse domains. This paper explores
agentic system workflows in the financial services industry. In particular, we
build agentic crews with human-in-the-loop module that can effectively
collaborate to perform complex modeling and model risk management (MRM) tasks.
The modeling crew consists of a judge agent and multiple agents who perform
specific tasks such as exploratory data analysis, feature engineering, model
selection/hyperparameter tuning, model training, model evaluation, and writing
documentation. The MRM crew consists of a judge agent along with specialized
agents who perform tasks such as checking compliance of modeling documentation,
model replication, conceptual soundness, analysis of outcomes, and writing
documentation. We demonstrate the effectiveness and robustness of modeling and
MRM crews by presenting a series of numerical examples applied to credit card
fraud detection, credit card approval, and portfolio credit risk modeling
datasets.

</details>


### [73] [DCOR: Anomaly Detection in Attributed Networks via Dual Contrastive Learning Reconstruction](https://arxiv.org/abs/2412.16788)
*Hossein Rafieizadeh,Hadi Zare,Mohsen Ghassemi Parsa,Hadi Davardoust,Meshkat Shariat Bagheri*

Main category: cs.AI

TL;DR: DCOR是一种新的基于属性网络的方法，它使用图神经网络和对比学习来检测异常。


<details>
  <summary>Details</summary>
Motivation: 早期的大多数工作都解决了图结构数据的复杂性以及预定义的异常，而忽略了数据属性和新兴异常的影响。

Method: DCOR是一种基于属性网络的新颖方法，它将基于重构的异常检测与对比学习相结合。利用图神经网络（GNN）框架，DCOR通过对比原始图和增强图的重构邻接矩阵和特征矩阵来检测细微的异常。

Result: 所获得的结果证明了所提出的方法在属性网络中的有效性。

Conclusion: DCOR在属性网络上显著优于最先进的方法，并且有潜力揭示新的异常模式。

Abstract: Anomaly detection using a network-based approach is one of the most efficient
ways to identify abnormal events such as fraud, security breaches, and system
faults in a variety of applied domains. While most of the earlier works address
the complex nature of graph-structured data and predefined anomalies, the
impact of data attributes and emerging anomalies are often neglected. This
paper introduces DCOR, a novel approach on attributed networks that integrates
reconstruction-based anomaly detection with Contrastive Learning. Utilizing a
Graph Neural Network (GNN) framework, DCOR contrasts the reconstructed
adjacency and feature matrices from both the original and augmented graphs to
detect subtle anomalies. We employed comprehensive experimental studies on
benchmark datasets through standard evaluation measures. The results show that
DCOR significantly outperforms state-of-the-art methods. Obtained results
demonstrate the efficacy of proposed approach in attributed networks with the
potential of uncovering new patterns of anomalies.

</details>


### [74] [AI-based Identity Fraud Detection: A Systematic Review](https://arxiv.org/abs/2501.09239)
*Chuo Jun Zhang,Asif Q. Gill,Bo Liu,Memoona J. Anwar*

Main category: cs.AI

TL;DR: 该研究通过系统性文献回顾，分析了AI驱动的深度伪造技术对身份欺诈的复杂影响，并对现有检测和预防方法进行了分类，为相关领域的研究提供了基础。


<details>
  <summary>Details</summary>
Motivation: 随着数字服务的发展，大量个人身份信息（PII）存储在线上并易受网络攻击，特别是AI驱动的深度伪造技术增加了身份欺诈的复杂性，因此需要审查和理解身份欺诈检测方法、局限性和潜在解决方案。

Method: 通过系统性文献回顾方法，审查了4个主要学术文献数据库中精选的43篇论文。

Result: 研究结果重点介绍了两种身份欺诈的预防和检测方法，并深入探讨了公开的挑战。此外，研究结果被整合为一份基于AI的身份欺诈检测和预防方法的分类，其中包含了关键的见解和趋势。

Conclusion: 本篇论文为研究人员和从业人员提供了一个重要的数字身份欺诈领域的基础知识库，以供进一步研究和开发。

Abstract: With the rapid development of digital services, a large volume of personally
identifiable information (PII) is stored online and is subject to cyberattacks
such as Identity fraud. Most recently, the use of Artificial Intelligence (AI)
enabled deep fake technologies has significantly increased the complexity of
identity fraud. Fraudsters may use these technologies to create highly
sophisticated counterfeit personal identification documents, photos and videos.
These advancements in the identity fraud landscape pose challenges for identity
fraud detection and society at large. There is a pressing need to review and
understand identity fraud detection methods, their limitations and potential
solutions. This research aims to address this important need by using the
well-known systematic literature review method. This paper reviewed a selected
set of 43 papers across 4 major academic literature databases. In particular,
the review results highlight the two types of identity fraud prevention and
detection methods, in-depth and open challenges. The results were also
consolidated into a taxonomy of AI-based identity fraud detection and
prevention methods including key insights and trends. Overall, this paper
provides a foundational knowledge base to researchers and practitioners for
further research and development in this important area of digital identity
fraud.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [75] [On the Efficient Discovery of Maximum $k$-Defective Biclique](https://arxiv.org/abs/2506.16121)
*Donghang Cui,Ronghua Li,Qiangqiang Dai,Hongchao Qin,Guoren Wang*

Main category: cs.DS

TL;DR: 现实世界的图可能包含噪声或不完整的信息，本研究提出了一个名为k-defective biclique的新模型，并开发了一种基于分支定界框架和枢轴技术的算法来解决寻找最大边k-defective biclique问题。该算法在效率和有效性方面优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 现实世界的图可能包含噪声或不完整的信息，导致双图模型中的条件过于严格。为了缓解这个问题，我们关注一个名为k-defective biclique的新放松子图模型，该模型允许与biclique模型相比最多缺少k个边。

Method: 提出了一种基于新颖分支定界框架的算法，并将新颖枢轴技术纳入其中，以解决在 두 부분 그래프에서 최대 엣지 k-결측치 집합을 찾는 NP-난해 문제를 해결합니다.

Result: 算法在10个大型真实数据集上进行了广泛的实验，证明了所提出方法的效率和有效性。

Conclusion: 提出的基于分支定界框架和新颖枢轴技术的算法在效率和有效性方面优于最先进的算法，在各种参数设置下速度提高了1000倍。

Abstract: The problem of identifying the maximum edge biclique in bipartite graphs has
attracted considerable attention in bipartite graph analysis, with numerous
real-world applications such as fraud detection, community detection, and
online recommendation systems. However, real-world graphs may contain noise or
incomplete information, leading to overly restrictive conditions when employing
the biclique model. To mitigate this, we focus on a new relaxed subgraph model,
called the $k$-defective biclique, which allows for up to $k$ missing edges
compared to the biclique model. We investigate the problem of finding the
maximum edge $k$-defective biclique in a bipartite graph, and prove that the
problem is NP-hard. To tackle this computation challenge, we propose a novel
algorithm based on a new branch-and-bound framework, which achieves a
worst-case time complexity of $O(m\alpha_k^n)$, where $\alpha_k < 2$. We
further enhance this framework by incorporating a novel pivoting technique,
reducing the worst-case time complexity to $O(m\beta_k^n)$, where $\beta_k <
\alpha_k$. To improve the efficiency, we develop a series of optimization
techniques, including graph reduction methods, novel upper bounds, and a
heuristic approach. Extensive experiments on 10 large real-world datasets
validate the efficiency and effectiveness of the proposed approaches. The
results indicate that our algorithms consistently outperform state-of-the-art
algorithms, offering up to $1000\times$ speedups across various parameter
settings.

</details>


### [76] [Counting Butterflies over Streaming Bipartite Graphs with Duplicate Edges](https://arxiv.org/abs/2412.11488)
*Lingkai Meng,Long Yuan,Xuemin Lin,Chengjie Li,Kai Wang,Wenjie Zhang*

Main category: cs.DS

TL;DR: DEABC是一种新的二分图蝴蝶计数方法，可处理重复边并提高效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 在流式二分图中有效计数蝴蝶很重要，但现有算法无法处理重复边或效率低下。

Method: DEABC使用基于桶的优先级采样来准确估计蝴蝶的数量，并考虑了重复边。

Result: DEABC在内存使用方面进行了重大改进，同时保持了高准确性，并在实际的流式二分图上优于最先进的算法。

Conclusion: DEABC在准确性和内存效率方面优于现有方法，并实现了更高的吞吐量。

Abstract: Bipartite graphs are commonly used to model relationships between two
distinct entities in real-world applications, such as user-product
interactions, user-movie ratings and collaborations between authors and
publications. A butterfly (a 2x2 bi-clique) is a critical substructure in
bipartite graphs, playing a significant role in tasks like community detection,
fraud detection, and link prediction. As more real-world data is presented in a
streaming format, efficiently counting butterflies in streaming bipartite
graphs has become increasingly important. However, most existing algorithms
typically assume that duplicate edges are absent, which is hard to hold in
real-world graph streams, as a result, they tend to sample edges that appear
multiple times, leading to inaccurate results. The only algorithm designed to
handle duplicate edges is FABLE, but it suffers from significant limitations,
including high variance, substantial time complexity, and memory inefficiency
due to its reliance on a priority queue. To overcome these limitations, we
introduce DEABC (Duplicate-Edge-Aware Butterfly Counting), an innovative method
that uses bucket-based priority sampling to accurately estimate the number of
butterflies, accounting for duplicate edges. Compared to existing methods,
DEABC significantly reduces memory usage by storing only the essential sampled
edge data while maintaining high accuracy. We provide rigorous proofs of the
unbiasedness and variance bounds for DEABC, ensuring they achieve high
accuracy. We compare DEABC with state-of-the-art algorithms on real-world
streaming bipartite graphs. The results show that our DEABC outperforms
existing methods in memory efficiency and accuracy, while also achieving
significantly higher throughput.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [77] [Deepfake Technology Unveiled: The Commoditization of AI and Its Impact on Digital Trust](https://arxiv.org/abs/2506.07363)
*Claudiu Popa,Rex Pallath,Liam Cunningham,Hewad Tahiri,Abiram Kesavarajah,Tao Wu*

Main category: cs.CY

TL;DR: 深度伪造技术因AI发展而普及，降低了制作门槛，但威胁数字信任和安全。本文通过使用Runway、Rope、ElevenLabs等工具演示了其风险，并强调了监管、公众意识和合作的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术的快速发展和易用性提高，深度伪造技术（Deepfake）的普及引发了对数字信任、隐私和安全的一系列担忧。本文旨在揭示深度伪造技术对这些领域的影响，特别是它如何被用于欺诈、传播虚假信息以及破坏多媒体内容的真实性，以引起对该技术及其潜在危害的关注。

Method: 本文通过分析生成式AI技术的发展，特别是语音克隆、换脸和合成媒体创作工具的可及性，探讨了深度伪造技术的扩散。研究使用了Runway、Rope和ElevenLabs等实际工具，通过有限的资源来演示创建逼真深度伪造内容的过程，以此来评估其风险。此外，文章还审视了深度伪造技术衍生的技术和伦理挑战，并提出了缓解和检测的策略。

Result: 研究结果表明，利用Runway、Rope和ElevenLabs等现有工具，即使资源有限，也能轻松制造出高度逼真的深度伪造内容，这证明了该技术对个人和组织构成的严重风险。此外，分析还突显了应对深度伪造技术所带来的技术和伦理挑战的紧迫性。

Conclusion: 深度伪造技术（Deepfake）的日益普及，尤其是在生成式人工智能（AI）的推动下，虽然带来了创新机遇，但也严重威胁到数字信任、个人隐私和信息安全。本文旨在深入分析深度伪造技术，揭示其在欺诈、虚假信息传播以及多媒体真实性侵蚀方面的作用。通过使用Runway、Rope和ElevenLabs等易于获取且成本低廉的工具，我们展示了仅用有限资源即可制造出高度逼真的深度伪造内容，从而凸显了其对个人和组织的潜在风险。最后，文章强调了应对深度伪造技术带来的技术和伦理挑战的重要性，呼吁建立健全的监管框架，提升公众意识，并促进多方合作，以维护数字媒体的信任基础。

Abstract: Deepfake Technology Unveiled: The Commoditization of AI and Its Impact on
Digital Trust. With the increasing accessibility of generative AI, tools for
voice cloning, face-swapping, and synthetic media creation have advanced
significantly, lowering both financial and technical barriers for their use.
While these technologies present innovative opportunities, their rapid growth
raises concerns about trust, privacy, and security. This white paper explores
the implications of deepfake technology, analyzing its role in enabling fraud,
misinformation, and the erosion of authenticity in multimedia. Using
cost-effective, easy to use tools such as Runway, Rope, and ElevenLabs, we
explore how realistic deepfakes can be created with limited resources,
demonstrating the risks posed to individuals and organizations alike. By
analyzing the technical and ethical challenges of deepfake mitigation and
detection, we emphasize the urgent need for regulatory frameworks, public
awareness, and collaborative efforts to maintain trust in digital media.

</details>


### [78] [Advanced Applications of Generative AI in Actuarial Science: Case Studies Beyond ChatGPT](https://arxiv.org/abs/2506.18942)
*Simon Hatzesberger,Iris Nonneman*

Main category: cs.CY

TL;DR: 生成式AI正在彻底改变精算科学，尤其是在保险业，通过提高预测准确性、自动化流程和提供新的数据分析方法。


<details>
  <summary>Details</summary>
Motivation: 本文旨在说明生成式AI（GenAI）对精算科学产生的变革性影响，并通过具体的案例研究来展示其在保险业中的实际应用和潜力。

Method: 本文通过四个已实施的案例研究，展示了生成式AI（GenAI）在精算科学中的应用，包括利用大型语言模型（LLMs）改进索赔成本预测，利用检索增强生成（RAG）自动化市场比较，利用微调的视觉LLMs对车辆损坏进行分类，以及利用多智能体系统自动生成数据报告。

Result: 生成式AI在索赔成本预测、市场比较自动化、车辆损坏分类和数据报告生成方面取得了显著成效，展示了其在保险业中的巨大应用潜力，并指出了潜在的挑战和未来发展方向。

Conclusion: 生成式AI在保险业的广泛应用展示了其变革潜力，尤其是在索赔成本预测、市场比较自动化、车辆损坏分类和数据报告生成方面。尽管面临监管、伦理和技术挑战，但生成式AI有望通过自动化流程和提升洞察力来彻底改变保险行业。

Abstract: This article demonstrates the transformative impact of Generative AI (GenAI)
on actuarial science, illustrated by four implemented case studies. It begins
with a historical overview of AI, tracing its evolution from early neural
networks to modern GenAI technologies. The first case study shows how Large
Language Models (LLMs) improve claims cost prediction by deriving significant
features from unstructured textual data, significantly reducing prediction
errors in the underlying machine learning task. In the second case study, we
explore the automation of market comparisons using the GenAI concept of
Retrieval-Augmented Generation to identify and process relevant information
from documents. A third case study highlights the capabilities of fine-tuned
vision-enabled LLMs in classifying car damage types and extracting contextual
information. The fourth case study presents a multi-agent system that
autonomously analyzes data from a given dataset and generates a corresponding
report detailing the key findings. In addition to these case studies, we
outline further potential applications of GenAI in the insurance industry, such
as the automation of claims processing and fraud detection, and the
verification of document compliance with internal or external policies.
Finally, we discuss challenges and considerations associated with the use of
GenAI, covering regulatory issues, ethical concerns, and technical limitations,
among others.

</details>


### [79] [Scoring the European Citizen in the AI Era](https://arxiv.org/abs/2505.02791)
*Nathan Genicot*

Main category: cs.CY

TL;DR: 欧盟《人工智能法案》禁止社会评分的规定可能会对欧洲现有的评分实践产生实际影响，并可作为《通用数据保护条例》第22条的有力补充，以保护个人免受不成比例的基于人工智能的评分实践的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨了欧盟《人工智能法案》中禁止社会评分的规定可能产生的实际影响，以及该禁令如何作为一项有用的工具来保护个人免受不成比例的基于人工智能的评分实践的影响。

Method: 对欧盟《人工智能法案》中禁止社会评分的规定进行了分析，并将其与现有的欧洲评分实践以及《通用数据保护条例》第22条进行了比较。

Result: 该禁令虽然具有灵活性，但可能对欧洲现有的评分实践产生实际影响，并可作为《通用数据保护条例》第22条的有力补充，以保护个人免受不成比例的基于人工智能的评分实践的影响。

Conclusion: 该禁令是根据《通用数据保护条例》第22条的规定，对个人进行社会评分的有力补充，并可能对基于人工智能的评分实践产生实际影响。

Abstract: Social scoring is one of the AI practices banned by the AI Act. This ban is
explicitly inspired by China, which in 2014 announced its intention to set up a
large-scale government project - the Social Credit System - aiming to rate
every Chinese citizen according to their good behaviour, using digital
technologies and AI. But in Europe, individuals are also scored by public and
private bodies in a variety of contexts, such as assessing creditworthiness,
monitoring employee productivity, detecting social fraud or terrorist risks,
and so on. However, the AI Act does not intend to prohibit these types of
scoring, as they would qualify as 'high-risk AI systems', which are authorised
while subject to various requirements. One might therefore think that the ban
on social scoring will have no practical effect on the scoring practices
already in use in Europe, and that it is merely a vague safeguard in case an
authoritarian power is tempted to set up such a system on European territory.
Contrary to this view, this article argues that the ban has been drafted in a
way that is flexible and therefore likely to make it a useful tool, similar and
complementary to Article 22 of the General Data Protection Regulation, to
protect individuals against certain forms of disproportionate use of AI-based
scoring.

</details>


### [80] [FlowSeries: Anomaly Detection in Financial Transaction Flows](https://arxiv.org/abs/2503.15896)
*Arthur Capozzi,Salvatore Vilella,Dario Moncalvo,Marco Fornasiero,Valeria Ricci,Silvia Ronchiadin,Giancarlo Ruffo*

Main category: cs.CY

TL;DR: WeirdFlows 是一种无需预定义模式或训练集即可检测金融交易欺诈的管道，并能提供可解释性，已在真实的银行交易数据中得到验证。


<details>
  <summary>Details</summary>
Motivation: 在金融犯罪调查过程中，人工智能模型的可解释性以及缺乏标记数据是主要的挑战。网络分析在此背景下是一种有价值的方法。

Method: WeirdFlows 是一个自上而下的搜索管道，用于检测潜在的欺诈交易和不合规的代理。它不需要预先定义的模式或训练集，并且可以解释所发现的异常。

Result: 在对意大利联合圣保罗银行（ISP）银行的数据集（包含 8000 万笔跨境交易）进行评估后，WeirdFlows 被证明在识别可疑交易和行为者方面非常有效，尤其是在欧盟自 2022 年 2 月起实施经济制裁的背景下。

Conclusion: WeirdFlows 管道能够有效处理大型数据集、检测复杂的交易模式，并为正式的反金融犯罪调查提供必要的解释性。

Abstract: In recent years, the digitization and automation of anti-financial crime
(AFC) investigative processes have faced significant challenges, particularly
the need for interpretability of AI model results and the lack of labeled data
for training. Network analysis has emerged as a valuable approach in this
context.
  In this paper, we present WeirdFlows, a top-down search pipeline for
detecting potentially fraudulent transactions and non-compliant agents. In a
transaction network, fraud attempts are often based on complex transaction
patterns that change over time to avoid detection. The WeirdFlows pipeline
requires neither an a priori set of patterns nor a training set. In addition,
by providing elements to explain the anomalies found, it facilitates and
supports the work of an AFC analyst.
  We evaluate WeirdFlows on a dataset from Intesa Sanpaolo (ISP) bank,
comprising 80 million cross-country transactions over 15 months, benchmarking
our implementation of the algorithm. The results, corroborated by ISP AFC
experts, highlight its effectiveness in identifying suspicious transactions and
actors, particularly in the context of the economic sanctions imposed in the EU
after February 2022. This demonstrates \textit{WeirdFlows}' capability to
handle large datasets, detect complex transaction patterns, and provide the
necessary interpretability for formal AFC investigations.

</details>


### [81] [Regulating Ai In Financial Services: Legal Frameworks And Compliance Challenges](https://arxiv.org/abs/2503.14541)
*Shahmar Mirishli*

Main category: cs.CY

TL;DR: 本文分析了金融服务领域人工智能监管的法律框架和合规挑战，强调了适应性政策和跨界合作的必要性，以平衡创新与风险。


<details>
  <summary>Details</summary>
Motivation: 人工智能在金融服务领域的快速应用带来了效率提升，但也引入了算法偏见、数据隐私泄露和自动化决策缺乏透明度等风险，因此需要研究相应的法律框架和合规挑战。

Method: 通过审查现行立法、行业指南和实际用例，并比较欧盟、美国和英国等主要司法管辖区的监管方法，来分析人工智能在金融服务领域的监管。

Result: 现有规则存在差距，需要适应性强、技术中立的政策来促进创新，同时保护消费者权益和市场诚信。同时，文章还强调了人工智能驱动的错误责任、相互关联的人工智能系统带来的系统性风险以及技术驱动的金融排斥的伦理考量。

Conclusion: 该文章提出了一个原则性的监管模式，旨在平衡灵活性与可执行标准，并倡导政策制定者、金融机构和人工智能开发者之间加强合作，以确保金融领域人工智能的安全性、公平性和前瞻性。

Abstract: This article examines the evolving landscape of artificial intelligence (AI)
regulation in financial services, detailing the legal frameworks and compliance
challenges posed by rapid technological adoption. By reviewing current
legislation, industry guidelines, and real-world use cases, it highlights how
AI-driven processes, from fraud detection to algorithmic trading, offer
efficiency gains yet introduce significant risks, including algorithmic bias,
data privacy breaches, and lack of transparency in automated decision-making.
The study compares regulatory approaches across major jurisdictions such as the
European Union, United States, and United Kingdom, identifying both universal
concerns, like the need for explainability and robust data protection, and
region-specific compliance requirements that impact the implementation of
high-risk AI applications. Additionally, it underscores emerging areas of
focus, such as liability for AI-driven errors, systemic risks posed by
interlinked AI systems, and the ethical considerations of technology-driven
financial exclusion. The findings reveal gaps in existing rules and emphasize
the necessity for adaptive, technology-neutral policies capable of fostering
innovation while safeguarding consumer rights and market integrity. The article
concludes by proposing a principled regulatory model that balances flexibility
with enforceable standards, advocating closer collaboration between
policymakers, financial institutions, and AI developers to ensure a secure,
fair, and forward-looking framework for AI in finance.

</details>


### [82] [\textsc{Perseus}: Tracing the Masterminds Behind Cryptocurrency Pump-and-Dump Schemes](https://arxiv.org/abs/2503.01686)
*Honglin Fu,Yebo Feng,Cong Wu,Jiahua Xu*

Main category: cs.CY

TL;DR: 该研究提出了 Perseus 系统，利用 GNN 识别加密货币庞氏骗局的主谋，并在现实部署中取得了显著成效。


<details>
  <summary>Details</summary>
Motivation: 之前的研究主要集中在检测庞氏骗局活动、预测目标加密货币以及分析投资者和社交媒体实体，但未能解决问题的根源——识别和追踪庞氏骗局的主谋。因此，存在一个识别和追踪主谋的关键差距。

Method: Perseus 系统通过收集社交媒体和加密货币市场的实时数据，构建了能够保留信息传播方向和社区结构的、带有时间属性的图。利用图神经网络（GNN）识别庞氏骗局的主谋。

Result: Perseus 系统在现实世界中从 2024 年 2 月 16 日到 10 月 9 日进行部署，成功识别了 438 名在庞氏骗局信息传播网络中效率很高的主谋。与现有的欺诈检测方法相比，Perseus 实现了更高的 F1 分数和精确率，并具有快速的训练和推理速度。

Conclusion: 该研究开发了一个名为 Perseus 的检测系统，用于识别和追踪加密货币庞氏骗局的主谋。 Perseus 通过整合社交媒体和加密货币市场数据，并利用图神经网络（GNN）来识别庞氏骗局的组织者，其在现实世界中的部署成功识别了 438 名主谋，并为监管机构提供了风险解释和监管能力，以缓解加密货币庞氏骗局。

Abstract: Masterminds are entities organizing, coordinating, and orchestrating
cryptocurrency pump-and-dump schemes, a form of trade-based manipulation
undermining market integrity and causing financial losses for unwitting
investors. Previous research detects pump-and-dump activities in the market,
predicts the target cryptocurrency, and examines investors and \ac{osn}
entities. However, these solutions do not address the root cause of the
problem. There is a critical gap in identifying and tracing the masterminds
involved in these schemes. In this research, we develop a detection system
\textsc{Perseus}, which collects real-time data from the \acs{osn} and
cryptocurrency markets. \textsc{Perseus} then constructs temporal attributed
graphs that preserve the direction of information diffusion and the structure
of the community while leveraging \ac{gnn} to identify the masterminds behind
pump-and-dump activities. Our design of \textsc{Perseus} leads to higher F1
scores and precision than the \ac{sota} fraud detection method, achieving fast
training and inferring speeds. Deployed in the real world from February 16 to
October 9 2024, \textsc{Perseus} successfully detects $438$ masterminds who are
efficient in the pump-and-dump information diffusion networks. \textsc{Perseus}
provides regulators with an explanation of the risks of masterminds and
oversight capabilities to mitigate the pump-and-dump schemes of cryptocurrency.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [83] [Protecting Classifiers From Attacks](https://arxiv.org/abs/2004.08705)
*Victor Gallego,Roi Naveiro,Alberto Redondo,David Rios Insua,Fabrizio Ruggeri*

Main category: stat.ML

TL;DR: 该框架能够将统计分类算法增强到可以抵御恶意攻击。


<details>
  <summary>Details</summary>
Motivation: 在恶意软件检测、自动驾驶系统或欺诈检测等多个领域，分类算法容易受到恶意行为者的攻击，这些行为者愿意扰乱实例协变量的值以实现某些目标。

Method: 提出了一种基于近似贝叶斯计算的框架，该框架可在操作期间使用，并在训练阶段使用可扩展的方法。

Result: 提出了一种基于贝叶斯决策理论的框架，该框架使用对抗性风险分析概念来处理攻击者行为方面的不确定性。

Conclusion: 该框架能够将统计分类算法增强到可以抵御恶意攻击。

Abstract: In multiple domains such as malware detection, automated driving systems, or
fraud detection, classification algorithms are susceptible to being attacked by
malicious agents willing to perturb the value of instance covariates to pursue
certain goals. Such problems pertain to the field of adversarial machine
learning and have been mainly dealt with, perhaps implicitly, through
game-theoretic ideas with strong underlying common knowledge assumptions. These
are not realistic in numerous application domains in relation to security and
business competition. We present an alternative Bayesian decision theoretic
framework that accounts for the uncertainty about the attacker's behavior using
adversarial risk analysis concepts. In doing so, we also present core ideas in
adversarial machine learning to a statistical audience. A key ingredient in our
framework is the ability to sample from the distribution of originating
instances given the, possibly attacked, observed ones. We propose an initial
procedure based on approximate Bayesian computation usable during operations;
within it, we simulate the attacker's problem taking into account our
uncertainty about his elements. Large-scale problems require an alternative
scalable approach implementable during the training stage. Globally, we are
able to robustify statistical classification algorithms against malicious
attacks.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [84] [Copy-Move Detection in Optical Microscopy: A Segmentation Network and A Dataset](https://arxiv.org/abs/2412.10258)
*Hao-Chiang Shao,Yuan-Rong Liao,Tse-Yu Tseng,Yen-Liang Chuo,Fong-Yi Lin*

Main category: eess.IV

TL;DR: 本研究提出了一种名为CMSeg-Net的新型网络，通过将复制-移动伪造检测视为图像内协同显著性检测任务，有效解决了生物医学图像中复制-移动伪造区域的检测问题，即使是针对未知的攻击类型和微小的伪造区域也具有良好的检测能力。


<details>
  <summary>Details</summary>
Motivation: 学术欺诈的揭露日益增多，生物医学领域伪造实验图像的检测已成为公众关注的问题。复制-移动目标可能包含背景组织、小的前景对象或两者兼有，这可能超出训练域并受到未知的攻击，导致基于标准对象检测的方法效果不佳。

Method: 提出了一种将检测生物医学复制-移动伪造区域的问题重新表述为图像内协同显著性检测任务的方法，并提出了一种名为CMSeg-Net的复制-移动伪造分割网络。该网络基于多分辨率编码器-解码器架构，并结合了自相关和相关辅助空间注意力模块，能够识别未知的重复区域。

Result: CMSeg-Net能够有效区分复杂显微图像中的小的复制-移动目标和其他相似对象，并在多个数据集上取得了优于现有方法的性能。

Conclusion: CMSeg-Net在FakeParaEgg数据集以及CASIA-CMFD、CoMoFoD和CMF等其他公开的复制-移动检测数据集上，均优于之前的最先进方法。

Abstract: With increasing revelations of academic fraud, detecting forged experimental
images in the biomedical field has become a public concern. The challenge lies
in the fact that copy-move targets can include background tissue, small
foreground objects, or both, which may be out of the training domain and
subject to unseen attacks, rendering standard object-detection-based approaches
less effective. To address this, we reformulate the problem of detecting
biomedical copy-move forgery regions as an intra-image co-saliency detection
task and propose CMSeg-Net, a copy-move forgery segmentation network capable of
identifying unseen duplicated areas. Built on a multi-resolution
encoder-decoder architecture, CMSeg-Net incorporates self-correlation and
correlation-assisted spatial-attention modules to detect intra-image regional
similarities within feature tensors at each observation scale. This design
helps distinguish even small copy-move targets in complex microscopic images
from other similar objects. Furthermore, we created a copy-move forgery dataset
of optical microscopic images, named FakeParaEgg, using open data from the ICIP
2022 Challenge to support CMSeg-Net's development and verify its performance.
Extensive experiments demonstrate that our approach outperforms previous
state-of-the-art methods on the FakeParaEgg dataset and other open copy-move
detection datasets, including CASIA-CMFD, CoMoFoD, and CMF. The FakeParaEgg
dataset, our source code, and the CMF dataset with our manually defined
segmentation ground truths available at
``https://github.com/YoursEver/FakeParaEgg''.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [85] [ADD 2023: Towards Audio Deepfake Detection and Analysis in the Wild](https://arxiv.org/abs/2408.04967)
*Jiangyan Yi,Chu Yuan Zhang,Jianhua Tao,Chenglong Wang,Xinrui Yan,Yong Ren,Hao Gu,Junzuo Zhou*

Main category: eess.AS

TL;DR: ADD 2023 challenge advances audio deepfake detection with new tasks and dataset; paper analyzes top methods and limitations, offering future research directions.


<details>
  <summary>Details</summary>
Motivation: The motivation for this research stems from the increasing prevalence of audio deepfakes and their potential for misuse, necessitating robust detection methods for applications in fraud prevention, audio forensics, and legal evidence. The ADD 2023 challenge was designed to address these real-world scenarios.

Method: The paper details the dataset used in the ADD 2023 challenge, covering fake audio detection, manipulation region localization, and deepfake algorithm recognition. It also analyzes the technical methodologies employed by top-performing participants in each task, identifying shared and distinct approaches.

Result: The paper analyzes the methodologies of top participants in the ADD 2023 challenge, identifying commonalities and differences in their approaches to audio deepfake detection, manipulation region localization, and deepfake algorithm recognition. It also discusses current technical limitations and outlines future research directions.

Conclusion: The ADD 2023 challenge advances audio deepfake detection beyond simple real/fake classification by introducing tasks like identifying manipulated intervals and source attribution, crucial for audio forensics and law enforcement. This paper details the challenge dataset and analyzes the techniques of top participants, highlighting commonalities, differences, and limitations, while also proposing future research directions. The dataset is publicly available.

Abstract: The growing prominence of the field of audio deepfake detection is driven by
its wide range of applications, notably in protecting the public from potential
fraud and other malicious activities, prompting the need for greater attention
and research in this area. The ADD 2023 challenge goes beyond binary real/fake
classification by emulating real-world scenarios, such as the identification of
manipulated intervals in partially fake audio and determining the source
responsible for generating any fake audio, both with real-life implications,
notably in audio forensics, law enforcement, and construction of reliable and
trustworthy evidence. To further foster research in this area, in this article,
we describe the dataset that was used in the fake game, manipulation region
location and deepfake algorithm recognition tracks of the challenge. We also
focus on the analysis of the technical methodologies by the top-performing
participants in each task and note the commonalities and differences in their
approaches. Finally, we discuss the current technical limitations as identified
through the technical analysis, and provide a roadmap for future research
directions. The dataset is available for download at
http://addchallenge.cn/downloadADD2023.

</details>


<div id='q-fin.RM'></div>

# q-fin.RM [[Back]](#toc)

### [86] [Machine Learning based Enterprise Financial Audit Framework and High Risk Identification](https://arxiv.org/abs/2507.06266)
*Tingyu Yuan,Xi Zhang,Xuanjing Chen*

Main category: q-fin.RM

TL;DR: 鉴于全球经济不确定性，本研究提出了一种基于机器学习的AI驱动框架，以提高企业财务审计的效率和准确性。研究评估了SVM、RF和KNN算法，发现随机森林（RF）在识别欺诈和合规异常方面表现最佳（F1分数0.9012），审计频率、过往违规行为、员工工作量和客户评级是关键预测因素。建议采用RF模型并实施实时风险监控。


<details>
  <summary>Details</summary>
Motivation: 鉴于全球经济不确定性，金融审计对于合规和风险缓解至关重要。传统的纯手工审计方法在处理海量数据、复杂的业务结构和不断变化的欺诈手段方面日益受到限制。本研究提出了一种人工智能驱动的企业财务审计和高风险识别框架。

Method: 本研究利用机器学习来提高效率和准确性，并评估了三种算法——支持向量机（SVM）、随机森林（RF）和K-最近邻（KNN）——以构建强大的风险预测模型。通过分层K折交叉验证和使用F1分数、准确率和召回率进行评估，随机森林在识别欺诈和合规异常方面取得了最佳性能，F1分数为0.9012。特征重要性分析显示，审计频率、过往违规行为、员工工作量和客户评级是关键预测指标。

Result: 随机森林（Random Forest）在识别欺诈和合规异常方面表现最佳，其F1分数为0.9012。特征重要性分析显示，审计频率、过往违规行为、员工工作量和客户评级是关键的风险预测因素。

Conclusion: 该研究建议采用随机森林作为核心模型，通过特征工程增强特征，并实施实时风险监控。本研究为在现代企业中使用机器学习进行智能审计和风险管理提供了有价值的见解。

Abstract: In the face of global economic uncertainty, financial auditing has become
essential for regulatory compliance and risk mitigation. Traditional manual
auditing methods are increasingly limited by large data volumes, complex
business structures, and evolving fraud tactics. This study proposes an
AI-driven framework for enterprise financial audits and high-risk
identification, leveraging machine learning to improve efficiency and accuracy.
Using a dataset from the Big Four accounting firms (EY, PwC, Deloitte, KPMG)
from 2020 to 2025, the research examines trends in risk assessment, compliance
violations, and fraud detection. The dataset includes key indicators such as
audit project counts, high-risk cases, fraud instances, compliance breaches,
employee workload, and client satisfaction, capturing both audit behaviors and
AI's impact on operations. To build a robust risk prediction model, three
algorithms - Support Vector Machine (SVM), Random Forest (RF), and K-Nearest
Neighbors (KNN) - are evaluated. SVM uses hyperplane optimization for complex
classification, RF combines decision trees to manage high-dimensional,
nonlinear data with resistance to overfitting, and KNN applies distance-based
learning for flexible performance. Through hierarchical K-fold cross-validation
and evaluation using F1-score, accuracy, and recall, Random Forest achieves the
best performance, with an F1-score of 0.9012, excelling in identifying fraud
and compliance anomalies. Feature importance analysis reveals audit frequency,
past violations, employee workload, and client ratings as key predictors. The
study recommends adopting Random Forest as a core model, enhancing features via
engineering, and implementing real-time risk monitoring. This research
contributes valuable insights into using machine learning for intelligent
auditing and risk management in modern enterprises.

</details>


### [87] [Explainable AI for Fraud Detection: An Attention-Based Ensemble of CNNs, GNNs, and A Confidence-Driven Gating Mechanism](https://arxiv.org/abs/2410.09069)
*Mehdi Hosseini Chagahi,Niloufar Delfan,Saeed Mohammadi Dashtaki,Behzad Moshiri,Md. Jalil Piran*

Main category: q-fin.RM

TL;DR: 提出了一种包含注意力机制和置信度组合层的堆叠式信用卡欺诈检测方法，通过融合CNN、RNN、GNN和LSTM等多种模型，并结合SHAP进行特征重要性分析，实现了高准确率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 电子商务的快速发展和信用卡在在线交易中的广泛使用，使得及时准确地检测信用卡欺诈（CCF）变得尤为重要。欺诈活动不仅给银行和金融机构带来重大的经济损失，还会破坏用户对数字服务的信任。

Method: 提出了一种新的基于堆叠（stacking）的方法，通过添加注意力层和基于置信度的组合层来改进信用卡欺诈检测。其中，注意力层结合了CNN和RNN的软输出（使用DOWA算子）以及GNN和LSTM网络的输出（使用IOWA算子），以捕捉不同的预测信号。基于置信度的组合层则选择不确定性更低的聚合结果输入到元学习器中。此外，使用SHAP解释器识别出区分欺诈与正常交易最重要的十个特征，并将其用于注意力模型。

Result: 实验结果表明，该方法在三个数据集上均取得了高准确率和良好的泛化能力，证明了其在信用卡欺诈检测方面的有效性。

Conclusion: 该方法在三个数据集上实现了高准确率和鲁棒的泛化能力，能够有效检测信用卡欺诈。

Abstract: The rapid expansion of e-commerce and the widespread use of credit cards in
online purchases and financial transactions have significantly heightened the
importance of promptly and accurately detecting credit card fraud (CCF). Not
only do fraudulent activities in financial transactions lead to substantial
monetary losses for banks and financial institutions, but they also undermine
user trust in digital services. This study presents a new stacking-based
approach for CCF detection by adding two extra layers to the usual
classification process: an attention layer and a confidence-based combination
layer. In the attention layer, we combine soft outputs from a convolutional
neural network (CNN) and a recurrent neural network (RNN) using the dependent
ordered weighted averaging (DOWA) operator, and from a graph neural network
(GNN) and a long short-term memory (LSTM) network using the induced ordered
weighted averaging (IOWA) operator. These weighted outputs capture different
predictive signals, increasing the model's accuracy. Next, in the
confidence-based layer, we select whichever aggregate (DOWA or IOWA) shows
lower uncertainty to feed into a meta-learner. To make the model more
explainable, we use shapley additive explanations (SHAP) to identify the top
ten most important features for distinguishing between fraud and normal
transactions. These features are then used in our attention-based model.
Experiments on three datasets show that our method achieves high accuracy and
robust generalization, making it effective for CCF detection.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [88] [QFNN-FFD: Quantum Federated Neural Network for Financial Fraud Detection](https://arxiv.org/abs/2404.02595)
*Nouhaila Innan,Alberto Marchisio,Mohamed Bennai,Muhammad Shafique*

Main category: quant-ph

TL;DR: QFNN-FFD 是一种结合量子机器学习和联邦学习的新型金融欺诈检测框架，具有高精度、高安全性和高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决金融欺诈检测中的数据隐私和效率问题，利用量子计算的强大计算能力和联邦学习的数据隐私保护特性。

Method: 提出了一种结合量子机器学习（QML）和联邦学习（FL）的量子联邦神经网络（QFNN-FFD）框架，用于金融欺诈检测。该框架采用双阶段训练模型，在分布式客户端上进行训练，以提高数据完整性和性能。

Result: QFNN-FFD 实现了超过 95% 的精确率和 80% 的准确率，证明了其高性能、安全性和鲁棒性，能够应对现实世界的应用。

Conclusion: QFNN-FFD 结合了量子机器学习和联邦学习，在金融欺诈检测方面表现出色，提高了准确性、安全性和对噪声的抵抗力，为金融科技树立了新的基准。

Abstract: This study introduces the Quantum Federated Neural Network for Financial
Fraud Detection (QFNN-FFD), a cutting-edge framework merging Quantum Machine
Learning (QML) and quantum computing with Federated Learning (FL) for financial
fraud detection. Using quantum technologies' computational power and the robust
data privacy protections offered by FL, QFNN-FFD emerges as a secure and
efficient method for identifying fraudulent transactions within the financial
sector. Implementing a dual-phase training model across distributed clients
enhances data integrity and enables superior performance metrics, achieving
precision rates consistently above 95%. Additionally, QFNN-FFD demonstrates
exceptional resilience by maintaining an impressive 80% accuracy, highlighting
its robustness and readiness for real-world applications. This combination of
high performance, security, and robustness against noise positions QFNN-FFD as
a transformative advancement in financial technology solutions and establishes
it as a new benchmark for privacy-focused fraud detection systems. This
framework facilitates the broader adoption of secure, quantum-enhanced
financial services and inspires future innovations that could use QML to tackle
complex challenges in other areas requiring high confidentiality and accuracy.

</details>


### [89] [Enhancing Interpretability of Quantum-Assisted Blockchain Clustering via AI Agent-Based Qualitative Analysis](https://arxiv.org/abs/2506.02068)
*Yun-Cheng Tsai,Yen-Ku Liu,Samuel Yen-Chi Chen*

Main category: quant-ph

TL;DR: 本研究提出了一种结合量化评估和AI Agent解释的两阶段框架，以提高量子聚类在区块链分析中的可解释性，并成功识别了QNN模型的单例簇问题，最终确定了三簇的优选配置。


<details>
  <summary>Details</summary>
Motivation: 现有的量子增强聚类模型虽然性能有提升，但可解释性有限，限制了其在金融欺诈检测和区块链治理等敏感领域的应用。本研究旨在解决这一问题。

Method: 本研究提出了一种两阶段分析框架。第一阶段使用经典聚类方法和评估指标（如Silhouette Score, Davies Bouldin Index, Calinski Harabasz Index）来确定最佳簇数和基线划分质量。第二阶段集成AI Agent，生成可读的语义解释，识别簇内特征和簇间关系。

Result: 实验结果表明，虽然完全训练的量子神经网络（QNN）在量化指标上优于随机量子特征（QF），但AI Agent进一步揭示了两种方法的细微差别，特别是暴露了QNN驱动模型中的单例簇现象。两阶段的综合分析结果一致支持三簇配置，证明了本混合方法的实用价值。

Conclusion: 本研究提出的两阶段分析框架，结合了量化聚类评估和AI Agent辅助的定性解释，能够有效提升量子辅助区块链分析的可解释性，为未来自主AI编排的聚类框架奠定了基础。

Abstract: Blockchain transaction data is inherently high dimensional, noisy, and
entangled, posing substantial challenges for traditional clustering algorithms.
While quantum enhanced clustering models have demonstrated promising
performance gains, their interpretability remains limited, restricting their
application in sensitive domains such as financial fraud detection and
blockchain governance. To address this gap, we propose a two stage analysis
framework that synergistically combines quantitative clustering evaluation with
AI Agent assisted qualitative interpretation. In the first stage, we employ
classical clustering methods and evaluation metrics including the Silhouette
Score, Davies Bouldin Index, and Calinski Harabasz Index to determine the
optimal cluster count and baseline partition quality. In the second stage, we
integrate an AI Agent to generate human readable, semantic explanations of
clustering results, identifying intra cluster characteristics and inter cluster
relationships. Our experiments reveal that while fully trained Quantum Neural
Networks (QNN) outperform random Quantum Features (QF) in quantitative metrics,
the AI Agent further uncovers nuanced differences between these methods,
notably exposing the singleton cluster phenomenon in QNN driven models. The
consolidated insights from both stages consistently endorse the three cluster
configuration, demonstrating the practical value of our hybrid approach. This
work advances the interpretability frontier in quantum assisted blockchain
analytics and lays the groundwork for future autonomous AI orchestrated
clustering frameworks.

</details>


### [90] [Hybrid Heuristic Algorithms for Adiabatic Quantum Machine Learning Models](https://arxiv.org/abs/2407.21062)
*Bahram Alidaee,Haibo Wang,Lutfu Sua,Wade Liu*

Main category: quant-ph

TL;DR: 通过结合“r-flip”策略，一种新的混合算法能够比 MSTS 更快、更好地解决 QUBO 问题，并应用于包括交叉对接、供应链管理、机器调度和欺诈检测在内的领域。


<details>
  <summary>Details</summary>
Motivation: 为了缓解量子退火机器学习 (AQML) 训练阶段的计算需求，本文提出了一种新的混合算法。

Method: 提出了一种新颖的混合算法，该算法结合了“r-flip”策略来解决 QUBO 问题，并将其与仅使用模拟退火和多起点塔布搜索 (MSTS) 的方法进行了比较。

Result: r-flip增强混合启发式方法在解决大规模 QUBO 问题时，相比于标准的 MSTS 方法，能够更有效地生成高质量的解决方案，并且在实际可行的时间范围内，计算成本更低。

Conclusion: r-flip增强混合启发式方法在解决大规模 QUBO 问题时，相比于标准的 MSTS 方法，能够更有效地生成高质量的解决方案，并且在实际可行的时间范围内，计算成本更低。

Abstract: Numerous established machine learning models and various neural network
architectures can be restructured as Quadratic Unconstrained Binary
Optimization (QUBO) problems. A significant challenge in Adiabatic Quantum
Machine Learning (AQML) is the computational demand of the training phase. To
mitigate this, approximation techniques inspired by quantum annealing, like
Simulated Annealing and Multiple Start Tabu Search (MSTS), have been employed
to expedite QUBO-based AQML training. This paper introduces a novel hybrid
algorithm that incorporates an "r-flip" strategy. This strategy is aimed at
solving large-scale QUBO problems more effectively, offering better solution
quality and lower computational costs compared to existing MSTS methods. The
r-flip approach has practical applications in diverse fields, including
cross-docking, supply chain management, machine scheduling, and fraud
detection. The paper details extensive computational experiments comparing this
r-flip enhanced hybrid heuristic against a standard MSTS approach. These tests
utilize both standard benchmark problems and three particularly large QUBO
instances. The results indicate that the r-flip enhanced method consistently
produces high-quality solutions efficiently, operating within practical time
constraints.

</details>


### [91] [Toward Practical Quantum Machine Learning: A Novel Hybrid Quantum LSTM for Fraud Detection](https://arxiv.org/abs/2505.00137)
*Rushikesh Ubale,Sujan K. K.,Sangram Deshpande,Gregory T. Byrd*

Main category: quant-ph

TL;DR: 提出了一种混合量子-经典LSTM模型用于欺诈检测，该模型在性能和训练速度上优于传统LSTM。


<details>
  <summary>Details</summary>
Motivation: 为了提高欺诈检测系统的性能和效率，探索利用量子现象（如叠加和纠缠）来增强特征表示和捕捉复杂非线性模式。

Method: 提出了一种新颖的混合量子-经典神经网络架构，该架构将经典的长期短期记忆（LSTM）网络与变分量子电路相结合，并利用参数迁移规则进行混合优化。

Result: 该混合模型在准确率、精确率、召回率和F1分数方面相对于传统的LSTM基线模型取得了有竞争力的改进，并且训练速度显著快于文献中报道的类似架构。

Conclusion: 混合量子-经典技术在提高欺诈检测效率和性能方面展现出巨大潜力。

Abstract: We present a novel hybrid quantum-classical neural network architecture for
fraud detection that integrates a classical Long Short-Term Memory (LSTM)
network with a variational quantum circuit. By leveraging quantum phenomena
such as superposition and entanglement, our model enhances the feature
representation of sequential transaction data, capturing complex non-linear
patterns that are challenging for purely classical models. A comprehensive data
preprocessing pipeline is employed to clean, encode, balance, and normalize a
credit card fraud dataset, ensuring a fair comparison with baseline models.
Notably, our hybrid approach achieves per-epoch training times in the range of
45-65 seconds, which is significantly faster than similar architectures
reported in the literature, where training typically requires several minutes
per epoch. Both classical and quantum gradients are jointly optimized via a
unified backpropagation procedure employing the parameter-shift rule for the
quantum parameters. Experimental evaluations demonstrate competitive
improvements in accuracy, precision, recall, and F1 score relative to a
conventional LSTM baseline. These results underscore the promise of hybrid
quantum-classical techniques in advancing the efficiency and performance of
fraud detection systems.
  Keywords: Hybrid Quantum-Classical Neural Networks, Quantum Computing, Fraud
Detection, Hybrid Quantum LSTM, Variational Quantum Circuit, Parameter-Shift
Rule, Financial Risk Analysis

</details>


### [92] [QFDNN: A Resource-Efficient Variational Quantum Feature Deep Neural Networks for Fraud Detection and Loan Prediction](https://arxiv.org/abs/2504.19632)
*Subham Das,Ashtakala Meghanath,Bikash K. Behera,Shahid Mumtaz,Saif Al-Kuwari,Ahmed Farouk*

Main category: quant-ph

TL;DR: QFDNN是一种新的量子机器学习模型，可以更有效地检测金融欺诈和评估贷款资格，同时对噪声具有更好的抵抗力，并且计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 为了解决经典机器学习模型在处理高维金融数据时遇到的可扩展性、过拟合和高计算成本问题，以及现有量子算法在噪声环境中鲁棒性不足和无法优化精简特征集性能的局限性。

Method: 提出了一种新颖的、资源高效且噪声鲁健的量子模型——量子特征深度神经网络（QFDNN），该模型能够优化特征表示，同时需要更少的量子比特和更简单的变分电路。

Result: QFDNN在信用卡欺诈检测和贷款资格预测数据集上实现了82.2%和74.4%的准确率，同时降低了计算开销。该模型在六种噪声模型下进行了测试，证明了其在各种错误条件下的鲁棒性。

Conclusion: 量子特征深度神经网络（QFDNN）在信用卡欺诈检测和贷款资格预测等金融科技应用中表现出潜力，通过优化特征表示、降低资源消耗和提高对噪声的鲁棒性，增强了金融交易的信任和安全，并支持了可持续性。

Abstract: Social financial technology focuses on trust, sustainability, and social
responsibility, which require advanced technologies to address complex
financial tasks in the digital era. With the rapid growth in online
transactions, automating credit card fraud detection and loan eligibility
prediction has become increasingly challenging. Classical machine learning (ML)
models have been used to solve these challenges; however, these approaches
often encounter scalability, overfitting, and high computational costs due to
complexity and high-dimensional financial data. Quantum computing (QC) and
quantum machine learning (QML) provide a promising solution to efficiently
processing high-dimensional datasets and enabling real-time identification of
subtle fraud patterns. However, existing quantum algorithms lack robustness in
noisy environments and fail to optimize performance with reduced feature sets.
To address these limitations, we propose a quantum feature deep neural network
(QFDNN), a novel, resource efficient, and noise-resilient quantum model that
optimizes feature representation while requiring fewer qubits and simpler
variational circuits. The model is evaluated using credit card fraud detection
and loan eligibility prediction datasets, achieving competitive accuracies of
82.2% and 74.4%, respectively, with reduced computational overhead.
Furthermore, we test QFDNN against six noise models, demonstrating its
robustness across various error conditions. Our findings highlight QFDNN
potential to enhance trust and security in social financial technology by
accurately detecting fraudulent transactions while supporting sustainability
through its resource-efficient design and minimal computational overhead.

</details>


### [93] [Comparative Performance Analysis of Quantum Machine Learning Architectures for Credit Card Fraud Detection](https://arxiv.org/abs/2412.19441)
*Mansour El Alami,Nouhaila Innan,Muhammad Shafique,Mohamed Bennai*

Main category: quant-ph

TL;DR: 研究了 QML 在金融欺诈检测中的应用，发现 VQC 和 SQNN 效果较好，EQNN 效果不佳，并强调了模型配置的重要性。


<details>
  <summary>Details</summary>
Motivation: 金融欺诈日益复杂，需要更有效的检测方法，而量子机器学习（QML）有潜力提高准确性和效率。

Method: 评估了不同量子特征图和 Ansatz 配置对 VQC、SQNN 和 EQNN 三种 QML 分类器在两个非标准化金融欺诈数据集上的性能影响。

Result: VQC 表现出强大的分类能力，F1 分数达到 0.88，SQNN 也取得了有希望的结果，但 EQNN 在处理非标准化数据时遇到困难。

Conclusion: 选择合适的量子特征图和 Ansatz 配置对于基于 QML 的金融欺诈检测至关重要，VQC 在此方面表现出优势，而 EQNN 则面临挑战。

Abstract: As financial fraud becomes increasingly complex, effective detection methods
are essential. Quantum Machine Learning (QML) introduces certain capabilities
that may enhance both accuracy and efficiency in this area. This study examines
how different quantum feature map and ansatz configurations affect the
performance of three QML-based classifiers-the Variational Quantum Classifier
(VQC), the Sampler Quantum Neural Network (SQNN), and the Estimator Quantum
Neural Network (EQNN)-when applied to two non-standardized financial fraud
datasets. Different quantum feature map and ansatz configurations are
evaluated, revealing distinct performance patterns. The VQC consistently
demonstrates strong classification results, achieving an F1 score of 0.88,
while the SQNN also delivers promising outcomes. In contrast, the EQNN
struggles to produce robust results, emphasizing the challenges presented by
non-standardized data. These findings highlight the importance of careful model
configuration in QML-based financial fraud detection. By showing how specific
feature maps and ansatz choices influence predictive success, this work guides
researchers and practitioners in refining QML approaches for complex financial
applications.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [94] [FD4QC: Application of Classical and Quantum-Hybrid Machine Learning for Financial Fraud Detection A Technical Report](https://arxiv.org/abs/2507.19402)
*Matteo Cardaioli,Luca Marangoni,Giada Martini,Francesco Mazzolin,Luca Pajola,Andrea Ferretto Parodi,Alessandra Saitta,Maria Chiara Vernillo*

Main category: cs.LG

TL;DR: 该报告在IBM AML数据集上比较了经典、量子和量子混合机器学习模型在金融欺诈检测中的表现。结果显示，虽然随机森林等经典模型在准确率和F1分数上表现更优，但QSVM等量子模型在精确率和低误报率方面显示出潜力，尽管存在计算开销问题。报告还提出了FD4QC系统架构，并为该领域未来的研究指明了方向。


<details>
  <summary>Details</summary>
Motivation: 随着金融交易的复杂性和交易量的增加，传统的欺诈检测系统面临严峻挑战，需要探索包括量子和量子混合模型在内的新方法。

Method: 1.开发了全面的行为特征工程框架，将原始交易数据转化为丰富的特征集。2.在IBM反洗钱（AML）数据集上实现了并评估了一系列模型，包括逻辑回归、决策树、随机森林、XGBoost等经典基线模型，以及量子支持向量机（QSVM）、变分量子分类器（VQC）和混合量子神经网络（HQNN）等三种经典的量子混合算法架构。3.提出了一个名为FD4QC的实际、API驱动的系统架构，采用“经典优先、量子增强”的理念，并包含稳健的回退机制。

Result: 在当前设置下，经典的基于树的模型（特别是随机森林）在准确率（97.34%）和F1分数（86.95%）方面显著优于量子模型。在量子模型中，QSVM表现出最高的潜力，实现了高精确率（77.15%）和低误报率（1.36%），但召回率较低且计算开销大。

Conclusion: 当前量子机器学习模型在金融欺诈检测任务中表现不如传统的基于树的模型，但QSVM展示了潜力，并指出了未来研究方向。

Abstract: The increasing complexity and volume of financial transactions pose
significant challenges to traditional fraud detection systems. This technical
report investigates and compares the efficacy of classical, quantum, and
quantum-hybrid machine learning models for the binary classification of
fraudulent financial activities.
  As of our methodology, first, we develop a comprehensive behavioural feature
engineering framework to transform raw transactional data into a rich,
descriptive feature set. Second, we implement and evaluate a range of models on
the IBM Anti-Money Laundering (AML) dataset. The classical baseline models
include Logistic Regression, Decision Tree, Random Forest, and XGBoost. These
are compared against three hybrid classic quantum algorithms architectures: a
Quantum Support Vector Machine (QSVM), a Variational Quantum Classifier (VQC),
and a Hybrid Quantum Neural Network (HQNN).
  Furthermore, we propose Fraud Detection for Quantum Computing (FD4QC), a
practical, API-driven system architecture designed for real-world deployment,
featuring a classical-first, quantum-enhanced philosophy with robust fallback
mechanisms.
  Our results demonstrate that classical tree-based models, particularly
\textit{Random Forest}, significantly outperform the quantum counterparts in
the current setup, achieving high accuracy (\(97.34\%\)) and F-measure
(\(86.95\%\)). Among the quantum models, \textbf{QSVM} shows the most promise,
delivering high precision (\(77.15\%\)) and a low false-positive rate
(\(1.36\%\)), albeit with lower recall and significant computational overhead.
  This report provides a benchmark for a real-world financial application,
highlights the current limitations of quantum machine learning in this domain,
and outlines promising directions for future research.

</details>


### [95] [Enhancing supply chain security with automated machine learning](https://arxiv.org/abs/2406.13166)
*Haibo Wang,Lutfu S. Sua,Bahram Alidaee*

Main category: cs.LG

TL;DR: 本研究利用自动化机器学习框架，通过改进的 ML 模型（如 XGBoost 和 LightGBM）显著提高了供应链安全（欺诈检测、预测维护、预测物料短缺）的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 全球供应链的规模和复杂性不断增加，导致了诸如港口等待时间长、材料短缺和通货膨胀等问题，给供应链带来了新的挑战。机器学习方法的应用为应对这些挑战提供了新的途径，因此，本研究旨在应用机器学习技术来增强供应链安全并提高运营效率。

Method: 本研究提出了一种自动化的机器学习框架，应用于供应链安全领域，具体包括欺诈活动检测、预测维护需求和预测物料延迟交货。该框架利用了包括随机森林、XGBoost、LightGBM 和神经网络在内的多种机器学习技术，并通过超参数调优来优化模型性能。

Result: 研究结果表明，在不同数据集上，欺诈检测的准确率为 88%，机器故障预测的准确率为 93.4%，物料延迟交货预测的准确率为 89.3%。通过超参数调整，XGBoost 和 LightGBM 等模型达到了 100% 的精确率，证明了该框架的有效性。

Conclusion: 本研究通过自动化机器学习框架，在提高供应链安全、欺诈活动检测、预测维护需求和预测物料延迟交货方面取得了显著成效。通过超参数调整，XGBoost 和 LightGBM 等监督技术实现了高达 100% 的精确率，整体上提高了供应链的运营效率。

Abstract: The increasing scale and complexity of global supply chains have led to new
challenges spanning various fields, such as supply chain disruptions due to
long waiting lines at the ports, material shortages, and inflation. Coupled
with the size of supply chains and the availability of vast amounts of data,
efforts towards tackling such challenges have led to an increasing interest in
applying machine learning methods in many aspects of supply chains. Unlike
other solutions, ML techniques, including Random Forest, XGBoost, LightGBM, and
Neural Networks, make predictions and approximate optimal solutions faster.
This paper presents an automated ML framework to enhance supply chain security
by detecting fraudulent activities, predicting maintenance needs, and
forecasting material backorders. Using datasets of varying sizes, results show
that fraud detection achieves an 88% accuracy rate using sampling methods,
machine failure prediction reaches 93.4% accuracy, and material backorder
prediction achieves 89.3% accuracy. Hyperparameter tuning significantly
improved the performance of these models, with certain supervised techniques
like XGBoost and LightGBM reaching up to 100% precision. This research
contributes to supply chain security by streamlining data preprocessing,
feature selection, model optimization, and inference deployment, addressing
critical challenges and boosting operational efficiency.

</details>


### [96] [Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection](https://arxiv.org/abs/2507.11997)
*Tairan Huang,Yili Wang*

Main category: cs.LG

TL;DR: MLED是一个新的图欺诈检测框架，它利用大型语言模型（LLM）从文本信息中提取外部知识，并结合图结构信息来提高欺诈检测的准确性。该框架通过类型级和关系级增强器来区分欺诈者和良性实体，并在真实数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的图欺诈检测方法忽略了原始文本信息中丰富的语义线索，并且在处理文本信息方面，虽然LLM表现出强大的能力，但将LLM与图结构进行多模态融合仍然是一个重大挑战。

Method: MLED框架利用LLM从文本信息中提取外部知识来增强图欺诈检测方法。为了整合LLM和图结构信息并增强区分欺诈者的能力，MLED设计了一个多层次的LLM增强框架，包括类型层次增强器和关系层次增强器。

Result: MLED在四个真实数据集上的实验表明，MLED在图欺诈检测方面取得了最先进的性能。

Conclusion: MLED是一个通用的框架，可以应用于现有方法，在图欺诈检测方面取得了最先进的性能。

Abstract: Graph fraud detection has garnered significant attention as Graph Neural
Networks (GNNs) have proven effective in modeling complex relationships within
multimodal data. However, existing graph fraud detection methods typically use
preprocessed node embeddings and predefined graph structures to reveal
fraudsters, which ignore the rich semantic cues contained in raw textual
information. Although Large Language Models (LLMs) exhibit powerful
capabilities in processing textual information, it remains a significant
challenge to perform multimodal fusion of processed textual embeddings with
graph structures. In this paper, we propose a \textbf{M}ulti-level \textbf{L}LM
\textbf{E}nhanced Graph Fraud \textbf{D}etection framework called MLED. In
MLED, we utilize LLMs to extract external knowledge from textual information to
enhance graph fraud detection methods. To integrate LLMs with graph structure
information and enhance the ability to distinguish fraudsters, we design a
multi-level LLM enhanced framework including type-level enhancer and
relation-level enhancer. One is to enhance the difference between the
fraudsters and the benign entities, the other is to enhance the importance of
the fraudsters in different relations. The experiments on four real-world
datasets show that MLED achieves state-of-the-art performance in graph fraud
detection as a generalized framework that can be applied to existing methods.

</details>


### [97] [Harnessing Near-Infrared Spectroscopy and Machine Learning for Traceable Classification of Hanwoo and Holstein Beef](https://arxiv.org/abs/2507.02903)
*AMM Nurul Alam,Abdul Samad,AMM Shamsul Alam,Jahan Ara Monti,Ayesha Muazzam*

Main category: cs.LG

TL;DR: 本研究使用近红外光谱（NIRS）结合机器学习（ML）技术，通过分析牛肉光谱数据，成功区分韩牛和荷斯坦牛，最高准确率达到0.8826，为食品真实性鉴定和打击食品欺诈提供了有效方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决食品真实性、错误标签和掺假问题，本研究旨在评估近红外光谱（NIRS）与先进机器学习（ML）技术相结合在区分韩牛（HNB）和荷斯坦牛（HLB）方面的应用。

Method: 使用便携式近红外光谱仪（NIRS）采集了40个韩牛（HNB）和荷斯坦牛（HLB）的背最长肌样本的近红外光谱数据。通过主成分分析（PCA）进行初步数据分析，随后应用了包括线性判别分析（LDA）、支持向量机（SVM）、逻辑回归（LR）、随机森林、梯度提升（GB）、K-近邻、决策树（DT）、朴素贝叶斯（NB）和神经网络（NN）在内的多种机器学习模型。模型通过超参数调整进行优化，并采用5折交叉验证进行验证。

Result: 主成分分析（PCA）显示出清晰的组间光谱差异，解释了93.72%的总方差。在机器学习模型中，随机森林表现出最高的预测准确性（ROC曲线下面积AUC为0.8826），SVM紧随其后（AUC为0.8747）。GB和NN模型表现令人满意（交叉验证得分为0.752），其中NN模型具有最高的召回率（0.7804）。LR和SVM模型在准确性、精确率和召回率之间取得了良好的平衡。DT和NB模型的预测性能相对较低。

Conclusion: 整合近红外光谱（NIRS）与机器学习（ML）技术为肉类真实性鉴定提供了一种强大可靠的方法，显著有助于检测食品欺诈。

Abstract: This study evaluates the use of Near-Infrared spectroscopy (NIRS) combined
with advanced machine learning (ML) techniques to differentiate Hanwoo beef
(HNB) and Holstein beef (HLB) to address food authenticity, mislabeling, and
adulteration. Rapid and non-invasive spectral data were attained by a portable
NIRS, recording absorbance data within the wavelength range of 700 to 1100 nm.
A total of 40 Longissimus lumborum samples, evenly split between HNB and HLB,
were obtained from a local hypermarket. Data analysis using Principal Component
Analysis (PCA) demonstrated distinct spectral patterns associated with chemical
changes, clearly separating the two beef varieties and accounting for 93.72% of
the total variance. ML models, including Linear Discriminant Analysis (LDA),
Support Vector Machine (SVM), Logistic Regression (LR), Random Forest, Gradient
Boosting (GB), K-Nearest Neighbors, Decision Tree (DT), Naive Bayes (NB), and
Neural Networks (NN), were implemented, optimized through hyperparameter
tuning, and validated by 5-fold cross-validation techniques to enhance model
robustness and prevent overfitting. Random Forest provided the highest
predictive accuracy with a Receiver Operating Characteristic (ROC) Area Under
the Curve (AUC) of 0.8826, closely followed by the SVM model at 0.8747.
Furthermore, GB and NN algorithms exhibited satisfactory performances, with
cross-validation scores of 0.752. Notably, the NN model achieved the highest
recall rate of 0.7804, highlighting its suitability in scenarios requiring
heightened sensitivity. DT and NB exhibited comparatively lower predictive
performance. The LR and SVM models emerged as optimal choices by effectively
balancing high accuracy, precision, and recall. This study confirms that
integrating NIRS with ML techniques offers a powerful and reliable method for
meat authenticity, significantly contributing to detecting food fraud.

</details>


### [98] [Mitigating Message Imbalance in Fraud Detection with Dual-View Graph Representation Learning](https://arxiv.org/abs/2507.06469)
*Yudan Song,Yuecen Wei,Yuhang Lu,Qingyun Sun,Minglai Shao,Li-e Wang,Chunming Hu,Xianxian Li,Xingcheng Fu*

Main category: cs.LG

TL;DR: MimbFD是一种用于欺诈检测的双视角图表示学习方法，解决了信息不平衡和类别不平衡问题，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前的图表示学习方法在欺诈检测中存在局部交互过多、全局拓扑信息传递不平衡以及节点信息被类别不平衡淹没的风险。

Method: 提出了一种新颖的双视角图表示学习方法MimbFD，该方法包含一个拓扑消息可达性模块和一个局部混淆去偏模块。

Result: MimbFD能够缓解欺诈检测中的消息不平衡问题，并展现出优越的性能。

Conclusion: MimbFD在欺诈检测方面表现出色，并在三个公共欺诈数据集上进行了实验验证。

Abstract: Graph representation learning has become a mainstream method for fraud
detection due to its strong expressive power, which focuses on enhancing node
representations through improved neighborhood knowledge capture. However, the
focus on local interactions leads to imbalanced transmission of global
topological information and increased risk of node-specific information being
overwhelmed during aggregation due to the imbalance between fraud and benign
nodes. In this paper, we first summarize the impact of topology and class
imbalance on downstream tasks in GNN-based fraud detection, as the problem of
imbalanced supervisory messages is caused by fraudsters' topological behavior
obfuscation and identity feature concealment. Based on statistical validation,
we propose a novel dual-view graph representation learning method to mitigate
Message imbalance in Fraud Detection(MimbFD). Specifically, we design a
topological message reachability module for high-quality node representation
learning to penetrate fraudsters' camouflage and alleviate insufficient
propagation. Then, we introduce a local confounding debiasing module to adjust
node representations, enhancing the stable association between node
representations and labels to balance the influence of different classes.
Finally, we conducted experiments on three public fraud datasets, and the
results demonstrate that MimbFD exhibits outstanding performance in fraud
detection.

</details>


### [99] [Graph Learning](https://arxiv.org/abs/2507.05636)
*Feng Xia,Ciyuan Peng,Jing Ren,Falih Gozi Febrinanto,Renqiang Luo,Vidya Saikrishna,Shuo Yu,Xiangjie Kong*

Main category: cs.LG

TL;DR: Graph learning, powered by GNNs, is crucial for complex data but faces challenges. This survey details advancements in scalable, dynamic, multimodal, generative, explainable, and responsible graph learning, offering insights into future trends and future trends.


<details>
  <summary>Details</summary>
Motivation: Graph learning is significant due to its ability to model complex, non-Euclidean relationships that traditional machine learning struggles to capture, making it applicable to real-world problems like drug discovery, fraud detection, recommender systems, and scientific reasoning. However, challenges like scalability, generalization, interpretability, and trustworthiness need to be addressed to realize its full potential.

Method: This survey provides a comprehensive introduction to graph learning by reviewing state-of-the-art techniques across key dimensions: scalable, temporal, multimodal, generative, explainable, and responsible graph learning. It also explores ethical considerations and emerging topics, highlighting recent integrations with other AI paradigms and future directions.

Result: The survey reviews state-of-the-art techniques for handling large graphs, dynamic temporal dependencies, heterogeneous data, generating graph samples, and enhancing interpretability. It also explores ethical considerations for responsible deployment and identifies emerging topics and future directions in graph learning.

Conclusion: Graph learning has significantly evolved, driven by GNNs and expanding into areas like scalability, dynamic modeling, multimodal learning, generative AI, XAI, and responsible AI. While it excels at modeling complex relationships, challenges in scalability, generalization, interpretability, and trustworthiness remain. This survey covers key dimensions and emerging topics, serving as a resource for researchers and practitioners.

Abstract: Graph learning has rapidly evolved into a critical subfield of machine
learning and artificial intelligence (AI). Its development began with early
graph-theoretic methods, gaining significant momentum with the advent of graph
neural networks (GNNs). Over the past decade, progress in scalable
architectures, dynamic graph modeling, multimodal learning, generative AI,
explainable AI (XAI), and responsible AI has broadened the applicability of
graph learning to various challenging environments. Graph learning is
significant due to its ability to model complex, non-Euclidean relationships
that traditional machine learning struggles to capture, thus better supporting
real-world applications ranging from drug discovery and fraud detection to
recommender systems and scientific reasoning. However, challenges like
scalability, generalization, heterogeneity, interpretability, and
trustworthiness must be addressed to unlock its full potential. This survey
provides a comprehensive introduction to graph learning, focusing on key
dimensions including scalable, temporal, multimodal, generative, explainable,
and responsible graph learning. We review state-of-the-art techniques for
efficiently handling large-scale graphs, capturing dynamic temporal
dependencies, integrating heterogeneous data modalities, generating novel graph
samples, and enhancing interpretability to foster trust and transparency. We
also explore ethical considerations, such as privacy and fairness, to ensure
responsible deployment of graph learning models. Additionally, we identify and
discuss emerging topics, highlighting recent integration of graph learning and
other AI paradigms and offering insights into future directions. This survey
serves as a valuable resource for researchers and practitioners seeking to
navigate the rapidly evolving landscape of graph learning.

</details>


### [100] [Exploring a Hybrid Deep Learning Approach for Anomaly Detection in Mental Healthcare Provider Billing: Addressing Label Scarcity through Semi-Supervised Anomaly Detection](https://arxiv.org/abs/2507.01924)
*Samirah Bakker,Yao Ma,Seyed Sahand Mohammadi Ziabari*

Main category: cs.LG

TL;DR: 本研究提出了一种结合LSTM、Transformer和伪标签（来自iForest和AE）的混合深度学习方法，用于精神卫生医疗计费中的异常检测。该方法在处理类别不平衡和复杂序列模式方面表现出潜力，并在实际数据上取得了良好的召回率。


<details>
  <summary>Details</summary>
Motivation: 为了解决精神卫生医疗计费中存在的异常和欺诈问题，并应对机器学习方法在处理类别不平衡、标签稀疏和复杂序列模式方面的挑战。

Method: 本研究探索了一种混合深度学习方法，结合了长短期记忆（LSTM）网络和Transformer，并通过Isolation Forests (iForest) 和 Autoencoders (AE) 进行伪标签。

Result: 在声明级别的数据上，iForest LSTM基线达到了最高的召回率（0.963）。在操作级别的数据上，基于iForest的混合模型取得了最高的召回率（0.744），但精度有所降低。

Conclusion: 深度学习和伪标签相结合的方法在处理复杂、不平衡的异常检测问题方面具有潜力。

Abstract: The complexity of mental healthcare billing enables anomalies, including
fraud. While machine learning methods have been applied to anomaly detection,
they often struggle with class imbalance, label scarcity, and complex
sequential patterns. This study explores a hybrid deep learning approach
combining Long Short-Term Memory (LSTM) networks and Transformers, with
pseudo-labeling via Isolation Forests (iForest) and Autoencoders (AE). Prior
work has not evaluated such hybrid models trained on pseudo-labeled data in the
context of healthcare billing. The approach is evaluated on two real-world
billing datasets related to mental healthcare. The iForest LSTM baseline
achieves the highest recall (0.963) on declaration-level data. On the
operation-level data, the hybrid iForest-based model achieves the highest
recall (0.744), though at the cost of lower precision. These findings highlight
the potential of combining pseudo-labeling with hybrid deep learning in
complex, imbalanced anomaly detection settings.

</details>


### [101] [Challenging Gradient Boosted Decision Trees with Tabular Transformers for Fraud Detection at Booking.com](https://arxiv.org/abs/2405.13692)
*Sergei Krutikov,Bulat Khaertdinov,Rodion Kiriukhin,Shubham Agrawal,Mozhdeh Ariannezhad,Kees Jan De Vries*

Main category: cs.LG

TL;DR: Transformer模型通过自监督学习在表格数据欺诈检测任务中超越了GBDT。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer模型在表格数据上的潜力，尤其是在存在选择偏差的欺诈检测场景中，并挑战梯度提升决策树（GBDT）的性能。

Method: 利用自监督学习（SSL）的Transformer模型处理全部可用数据，以学习可转移表征，并进行了大规模预训练和在小型目标数据集上进行微调。

Result: 在离线评估中，所提出的方法在平均精度（AP）得分上显著优于经过精心调优的GBDT模型。在线A/B实验结果证实了Transformer模型在生产环境中优于GBDT，并在业务指标上取得了统计学上的显著改进。

Conclusion: 在生产环境中，基于Transformer的表格模型在欺诈检测任务中表现优于梯度提升决策树（GBDT），并显著改善了业务指标。

Abstract: Transformer-based neural networks, empowered by Self-Supervised Learning
(SSL), have demonstrated unprecedented performance across various domains.
However, related literature suggests that tabular Transformers may struggle to
outperform classical Machine Learning algorithms, such as Gradient Boosted
Decision Trees (GBDT). In this paper, we aim to challenge GBDTs with tabular
Transformers on a typical task faced in e-commerce, namely fraud detection. Our
study is additionally motivated by the problem of selection bias, often
occurring in real-life fraud detection systems. It is caused by the production
system affecting which subset of traffic becomes labeled. This issue is
typically addressed by sampling randomly a small part of the whole production
data, referred to as a Control Group. This subset follows a target distribution
of production data and therefore is usually preferred for training
classification models with standard ML algorithms. Our methodology leverages
the capabilities of Transformers to learn transferable representations using
all available data by means of SSL, giving it an advantage over classical
methods. Furthermore, we conduct large-scale experiments, pre-training tabular
Transformers on vast amounts of data instances and fine-tuning them on smaller
target datasets. The proposed approach outperforms heavily tuned GBDTs by a
considerable margin of the Average Precision (AP) score in offline evaluations.
Finally, we report the results of an online A/B experiment. Experimental
results confirm the superiority of tabular Transformers compared to GBDTs in
production, demonstrated by a statistically significant improvement in our
business metric.

</details>


### [102] [Temporal-Aware Graph Attention Network for Cryptocurrency Transaction Fraud Detection](https://arxiv.org/abs/2506.21382)
*Zhi Zheng,Bochuan Zhou,Yuping Song*

Main category: cs.LG

TL;DR: ATGAT通过时间感知和三元注意力机制增强了图神经网络在加密货币欺诈检测方面的性能，并有效解决了类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 加密货币交易欺诈检测面临日益复杂的交易模式和严重的类别不平衡的双重挑战，传统方法依赖手动特征工程，难以捕捉交易网络中的时间和结构依赖性。

Method: 提出了一种增强的时间感知图注意力网络（ATGAT），包含三个模块：1. 融合多尺度时间差特征和周期位置编码的高级时间嵌入模块；2. 联合优化结构、时间、全局上下文注意力的时间感知三元注意力机制；3. 加权BCE损失以解决类别不平衡问题。

Result: ATGAT在Elliptic++加密货币数据集上实现了0.9130的AUC，相比XGBoost、GCN和GAT分别提高了9.2%、12.0%和10.0%。

Conclusion: ATGAT在Elliptic++加密货币数据集上实现了0.9130的AUC，相比XGBoost、GCN和GAT分别提高了9.2%、12.0%和10.0%，验证了时间感知和三元注意力机制对图神经网络的增强作用，并为金融机构提供了更可靠的欺诈检测工具，其设计原则也可推广到其他时间图异常检测任务。

Abstract: Cryptocurrency transaction fraud detection faces the dual challenges of
increasingly complex transaction patterns and severe class imbalance.
Traditional methods rely on manual feature engineering and struggle to capture
temporal and structural dependencies in transaction networks. This paper
proposes an Augmented Temporal-aware Graph Attention Network (ATGAT) that
enhances detection performance through three modules: (1) designing an advanced
temporal embedding module that fuses multi-scale time difference features with
periodic position encoding; (2) constructing a temporal-aware triple attention
mechanism that jointly optimizes structural, temporal, and global context
attention; (3) employing weighted BCE loss to address class imbalance.
Experiments on the Elliptic++ cryptocurrency dataset demonstrate that ATGAT
achieves an AUC of 0.9130, representing a 9.2% improvement over the best
traditional method XGBoost, 12.0% over GCN, and 10.0% over standard GAT. This
method not only validates the enhancement effect of temporal awareness and
triple attention mechanisms on graph neural networks, but also provides
financial institutions with more reliable fraud detection tools, with its
design principles generalizable to other temporal graph anomaly detection
tasks.

</details>


### [103] [Collaborative Batch Size Optimization for Federated Learning](https://arxiv.org/abs/2506.20511)
*Arno Geimer,Karthick Panner Selvam,Beltran Fiz Pontiveros*

Main category: cs.LG

TL;DR: 通过贪婪随机搜索优化批处理大小以提高联邦学习的训练速度。


<details>
  <summary>Details</summary>
Motivation: 为了在不收集数据集中数据的集中位置的情况下，在从医院的医疗诊断到金融交易中的欺诈检测等各种学科中进行训练模型，本篇论文着重于通过硬件使用优化来改进本地训练过程。

Method: 利用贪婪随机搜索优化本地批处理大小以实现跨所有参与者的最佳训练设置。

Result: 与默认参数设置相比，该方法在提高收敛速度方面表现更好，同时在本地参数优化方面也几乎相当。

Conclusion: 该方法在提高收敛速度方面优于默认参数设置，并且在本地参数优化方面几乎相当。

Abstract: Federated Learning (FL) is a decentralized collaborative Machine Learning
framework for training models without collecting data in a centralized
location. It has seen application across various disciplines, from helping
medical diagnoses in hospitals to detecting fraud in financial transactions. In
this paper, we focus on improving the local training process through hardware
usage optimization. While participants in a federation might share the hardware
they are training on, since there is no information exchange between them,
their training process can be hindered by an improper training configuration.
Taking advantage of the parallel processing inherent to Federated Learning, we
use a greedy randomized search to optimize local batch sizes for the best
training settings across all participants. Our results show that against
default parameter settings, our method improves convergence speed while staying
nearly on par with the case where local parameters are optimized.

</details>


### [104] [Advanced fraud detection using machine learning models: enhancing financial transaction security](https://arxiv.org/abs/2506.10842)
*Nudrat Fariha,Md Nazmuddin Moin Khan,Md Iqbal Hossain,Syed Ali Reza,Joy Chakra Bortty,Kazi Sharmin Sultana,Md Shadidur Islam Jawad,Saniah Safat,Md Abdul Ahad,Maksuda Begum*

Main category: cs.LG

TL;DR: 本研究提出了一种机器学习框架，用于检测信用卡欺诈。该框架通过整合多种数据源、提取关键特征以及应用无监督学习和聚类技术，能够有效识别异常交易。


<details>
  <summary>Details</summary>
Motivation: 数字支付的兴起加速了对智能和可扩展的欺诈检测系统的需求。本研究旨在利用机器学习技术，通过分析信用卡交易数据来检测异常和欺诈行为。

Method: 本研究采用了一种端到端的机器学习方法。首先，通过合并多个数据集来创建统一的分析视图。然后，通过特征工程提取行为信号和时间标记。接着，训练并评估了包括 Isolation Forest、One Class SVM 和深度自动编码器在内的多种无监督模型，并将重建误差排名前1%的样本标记为异常。最后，利用 K-Means 聚类和 DBSCAN 对交易数据进行分段，以识别正常活动和可疑区域。

Result: 研究结果表明，所提出的机器学习框架能够有效地检测信用卡交易中的异常和欺诈行为。无监督模型和聚类技术在分离异常和识别可疑交易方面表现出良好的能力。PCA 可视化说明了模型将异常分离到二维潜在空间的能力。

Conclusion: 本研究提出了一种端到端的、特征丰富的机器学习框架，用于利用真实世界数据检测信用卡交易异常和欺诈。通过合并交易、持卡人、商户和商户类别数据集，并提取行为信号和时间标记，研究人员能够识别潜在的欺诈行为。对无监督模型（Isolation Forest、One Class SVM、深度自动编码器）和聚类技术（K-Means、DBSCAN）的评估表明，这些方法能够有效地分离异常。

Abstract: The rise of digital payments has accelerated the need for intelligent and
scalable systems to detect fraud. This research presents an end-to-end,
feature-rich machine learning framework for detecting credit card transaction
anomalies and fraud using real-world data. The study begins by merging
transactional, cardholder, merchant, and merchant category datasets from a
relational database to create a unified analytical view. Through the feature
engineering process, we extract behavioural signals such as average spending,
deviation from historical patterns, transaction timing irregularities, and
category frequency metrics. These features are enriched with temporal markers
such as hour, day of week, and weekend indicators to expose all latent patterns
that indicate fraudulent behaviours. Exploratory data analysis reveals
contextual transaction trends across all the dataset features. Using the
transactional data, we train and evaluate a range of unsupervised models:
Isolation Forest, One Class SVM, and a deep autoencoder trained to reconstruct
normal behavior. These models flag the top 1% of reconstruction errors as
outliers. PCA visualizations illustrate each models ability to separate
anomalies into a two-dimensional latent space. We further segment the
transaction landscape using K-Means clustering and DBSCAN to identify dense
clusters of normal activity and isolate sparse, suspicious regions.

</details>


### [105] [Structural Alignment Improves Graph Test-Time Adaptation](https://arxiv.org/abs/2502.18334)
*Hans Hao-Hsun Hsu,Shikun Liu,Han Zhao,Pan Li*

Main category: cs.LG

TL;DR: TSA是一种新的图测试时间适应算法，可以在不访问源数据的情况下对齐图结构，从而在分布变化时提高图学习的性能。


<details>
  <summary>Details</summary>
Motivation: 图学习在推荐、欺诈检测和粒子物理等不同领域捕获交互模式方面表现出色。然而，其性能在分布变化下，特别是改变网络连通性的变化下，往往会下降。解决这些变化的现有方法通常需要使用源数据集进行重新训练，而由于计算或隐私限制，这通常是不可行的。

Method: TSA是一种新颖的图测试时间自适应（GTTA）算法，它在推理过程中对齐图结构，而无需访问源数据。TSA采用三种协同策略：不确定性感知邻域加权以适应邻域标签分布变化，基于信噪比的自节点和聚合邻域表示的自适应平衡，以及用于纠正残留标签和特征变化的决策边界细化。

Result: TSA在推理过程中对齐图结构，而无需访问源数据。

Conclusion: TSA在合成和真实世界数据集上的广泛实验证明，其性能持续优于非图TTA方法和最先进的GTTA基线。

Abstract: Graph-based learning excels at capturing interaction patterns in diverse
domains like recommendation, fraud detection, and particle physics. However,
its performance often degrades under distribution shifts, especially those
altering network connectivity. Current methods to address these shifts
typically require retraining with the source dataset, which is often infeasible
due to computational or privacy limitations. We introduce Test-Time Structural
Alignment (TSA), a novel algorithm for Graph Test-Time Adaptation (GTTA) that
aligns graph structures during inference without accessing the source data.
Grounded in a theoretical understanding of graph data distribution shifts, TSA
employs three synergistic strategies: uncertainty-aware neighborhood weighting
to accommodate neighbor label distribution shifts, adaptive balancing of
self-node and aggregated neighborhood representations based on their
signal-to-noise ratio, and decision boundary refinement to correct residual
label and feature shifts. Extensive experiments on synthetic and real-world
datasets demonstrate TSA's consistent outperformance of both non-graph TTA
methods and state-of-the-art GTTA baselines.

</details>


### [106] [Investigating Mask-aware Prototype Learning for Tabular Anomaly Detection](https://arxiv.org/abs/2506.02757)
*Ruiying Lu,Jinhan Liu,Chuan Du,Dandan Guo*

Main category: cs.LG

TL;DR: 提出了一种结合掩码建模和原型学习的新方法，用于表格异常检测，解决了现有方法的表示纠缠和全局相关性建模不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在表格异常检测中存在表示纠缠和缺乏全局相关性建模的问题，影响了异常检测性能。

Method: 通过在数据空间和投影空间中使用掩码建模，并结合原型学习来解决表示纠缠和全局相关性建模缺失的问题。具体来说，模型包括两个部分：编码时，在投影空间内进行掩码建模，学习解耦的正常模式；解码时，并行解码多个掩码表示进行重构，并学习关联原型以提取正常的特征相关性。该方法从分布匹配的角度出发，将投影空间学习和关联原型学习表述为最优传输问题，并利用校准距离来优化异常分数。

Result: 该模型在20个表格基准测试中表现出有效性和可解释性。

Conclusion: 提出的模型在20个表格数据集上进行了定量和定性实验，证明了其有效性和可解释性。

Abstract: Tabular anomaly detection, which aims at identifying deviant samples, has
been crucial in a variety of real-world applications, such as medical disease
identification, financial fraud detection, intrusion monitoring, etc. Although
recent deep learning-based methods have achieved competitive performances,
these methods suffer from representation entanglement and the lack of global
correlation modeling, which hinders anomaly detection performance. To tackle
the problem, we incorporate mask modeling and prototype learning into tabular
anomaly detection. The core idea is to design learnable masks by disentangled
representation learning within a projection space and extracting normal
dependencies as explicit global prototypes. Specifically, the overall model
involves two parts: (i) During encoding, we perform mask modeling in both the
data space and projection space with orthogonal basis vectors for learning
shared disentangled normal patterns; (ii) During decoding, we decode multiple
masked representations in parallel for reconstruction and learn association
prototypes to extract normal characteristic correlations. Our proposal derives
from a distribution-matching perspective, where both projection space learning
and association prototype learning are formulated as optimal transport
problems, and the calibration distances are utilized to refine the anomaly
scores. Quantitative and qualitative experiments on 20 tabular benchmarks
demonstrate the effectiveness and interpretability of our model.

</details>


### [107] [Data Leakage and Deceptive Performance: A Critical Examination of Credit Card Fraud Detection Methodologies](https://arxiv.org/abs/2506.02703)
*Khizar Hayat,Baptiste Magnier*

Main category: cs.LG

TL;DR: Evaluation flaws in credit card fraud detection research can make simple models appear sophisticated. This study demonstrates how data leakage, vague reporting, poor temporal validation, and metric manipulation lead to misleadingly high recall. The findings emphasize the need for methodological rigor over model complexity, with implications for improving machine learning research practices.


<details>
  <summary>Details</summary>
Motivation: The study aims to critically examine the methodological rigor in credit card fraud detection research and reveal how fundamental evaluation flaws can overshadow algorithmic sophistication.

Method: The study involved deliberate experimentation with improper evaluation protocols, including data leakage, vague reporting, inadequate temporal validation, and metric manipulation. A case study using a minimal neural network with data leakage was presented to demonstrate these issues.

Result: Even simple models can achieve deceptively impressive results when basic methodological principles are violated. A minimal neural network with data leakage achieved 99.9% recall despite fundamental evaluation flaws, outperforming more sophisticated methods. The analysis identified four critical issues: data leakage, vague reporting, inadequate temporal validation, and metric manipulation.

Conclusion: Proper evaluation methodology is more important than model complexity in fraud detection research, and methodological rigor must come before architectural sophistication.

Abstract: This study critically examines the methodological rigor in credit card fraud
detection research, revealing how fundamental evaluation flaws can overshadow
algorithmic sophistication. Through deliberate experimentation with improper
evaluation protocols, we demonstrate that even simple models can achieve
deceptively impressive results when basic methodological principles are
violated. Our analysis identifies four critical issues plaguing current
approaches: (1) pervasive data leakage from improper preprocessing sequences,
(2) intentional vagueness in methodological reporting, (3) inadequate temporal
validation for transaction data, and (4) metric manipulation through recall
optimization at precision's expense. We present a case study showing how a
minimal neural network architecture with data leakage outperforms many
sophisticated methods reported in literature, achieving 99.9\% recall despite
fundamental evaluation flaws. These findings underscore that proper evaluation
methodology matters more than model complexity in fraud detection research. The
study serves as a cautionary example of how methodological rigor must precede
architectural sophistication, with implications for improving research
practices across machine learning applications.

</details>


### [108] [CCNETS: A Modular Causal Learning Framework for Pattern Recognition in Imbalanced Datasets](https://arxiv.org/abs/2401.04139)
*Hanbeot Park,Yunjeong Cho,Hoon-Hee Kim*

Main category: cs.LG

TL;DR: CCNETS 通过因果反馈循环将生成、推理和重建整合到一个统一的框架中，以解决类别不平衡问题。它通过 Zoint 机制自适应地融合特征，在信用卡欺诈检测等任务中表现优于基线方法，并提高了在数据有限条件下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 处理类别不平衡是机器学习中的一个核心挑战，特别是在模式识别任务中，必须准确识别罕见但关键的事件（如欺诈交易或医学异常）。传统的生成模型通过数据增强提供潜在的解决方案，但它们通常将生成和分类视为独立的过程，导致分布不匹配和有限的分类器效益。为了解决这些缺点，我们提出了 CCNETS。

Method: CCNETS 是一个模块化学习框架，它在一个统一的因果范式内整合了生成、推理和重建。它由三个合作模块组成：用于潜在特征抽象的解释器，用于标签预测的推理器，以及用于上下文感知数据生成的生产者。这些组件通过因果反馈循环进行交互，其中分类结果指导目标样本合成。一个关键的创新是 Zoint 机制，它能够自适应地融合潜在和可观察的特征，增强语义丰富性，并在不确定的情况下实现稳健的决策。

Result: 在具有极端不平衡（欺诈案例 < 0.2%）的真实世界信用卡欺诈检测数据集上评估了 CCNETS。在三种实验设置下（包括合成训练、增强生成和直接分类器比较），CCNETS 的表现优于基线方法，实现了更高的 F1 分数、精确率和召回率。在 CCNETS 生成的数据上训练的模型在数据有限的条件下也表现出更强的泛化能力。

Conclusion: CCNETS 是一个可扩展、可解释的混合软计算框架，通过因果对齐合成数据和分类器目标，推动了不平衡模式识别的发展，并为稳健、模块化的实际应用学习开辟了新方向。

Abstract: Handling class imbalance remains a central challenge in machine learning,
particularly in pattern recognition tasks where rare but critical events-such
as fraudulent transactions or medical anomalies-must be identified accurately.
Traditional generative models offer a potential remedy through data
augmentation but often treat generation and classification as independent
processes, leading to distribution mismatch and limited classifier benefit. To
address these shortcomings, we propose Causal Cooperative Networks (CCNETS), a
modular learning framework that integrates generation, inference, and
reconstruction within a unified causal paradigm. CCNETS comprises three
cooperative modules: an Explainer for latent feature abstraction, a Reasoner
for label prediction, and a Producer for context-aware data generation. These
components interact through a causal feedback loop, where classification
results guide targeted sample synthesis. A key innovation, the Zoint mechanism,
enables adaptive fusion of latent and observable features, enhancing semantic
richness and enabling robust decision-making under uncertainty. We evaluate
CCNETS on a real-world credit card fraud detection dataset with extreme
imbalance (fraud cases < 0.2%). Across three experimental setups-including
synthetic training, amplified generation, and direct classifier
comparison-CCNETS outperforms baseline methods, achieving higher F1 scores,
precision, and recall. Models trained on CCNETS-generated data also demonstrate
superior generalization under limited data conditions. These results establish
CCNETS as a scalable, interpretable, and hybrid soft computing framework. By
causally aligning synthetic data with classifier objectives, CCNETS advances
imbalanced pattern recognition and opens new directions for robust, modular
learning in real-world applications.

</details>


### [109] [Corporate Fraud Detection in Rich-yet-Noisy Financial Graph](https://arxiv.org/abs/2502.19305)
*Shiqi Wang,Zhibo Zhang,Libing Fang,Cam-Tu Nguyen,Wenzhong Li*

Main category: cs.LG

TL;DR: 在公司欺诈检测中，之前的学习方法未能有效整合公司网络中的丰富交互信息，并且数据中存在大量隐藏的欺诈行为。本文提出了一种名为KeGCN_R的新型图基方法，利用知识图谱嵌入和两阶段学习方法来解决这些问题，并在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 之前的学习方法未能有效整合公司网络中的丰富交互信息，并且数据中存在大量隐藏的欺诈行为，这会引入噪声标签并影响欺诈检测结果。

Method: 提出了一种名为KeGCN_R的新型图基方法，利用知识图谱嵌入来缓解信息过载问题，并通过两阶段学习方法来提高对隐藏欺诈的鲁棒性。

Result: 实验结果证实了交互信息的重要性，并表明KeGCN_R在欺诈检测效果和鲁棒性方面优于其他基线模型。

Conclusion: KeGCN_R在欺诈检测方面优于其他基线模型，并且具有良好的鲁棒性。

Abstract: Corporate fraud detection aims to automatically recognize companies that
conduct wrongful activities such as fraudulent financial statements or illegal
insider trading. Previous learning-based methods fail to effectively integrate
rich interactions in the company network. To close this gap, we collect 18-year
financial records in China to form three graph datasets with fraud labels. We
analyze the characteristics of the financial graphs, highlighting two
pronounced issues: (1) information overload: the dominance of (noisy)
non-company nodes over company nodes hinders the message-passing process in
Graph Convolution Networks (GCN); and (2) hidden fraud: there exists a large
percentage of possible undetected violations in the collected data. The hidden
fraud problem will introduce noisy labels in the training dataset and
compromise fraud detection results. To handle such challenges, we propose a
novel graph-based method, namely, Knowledge-enhanced GCN with Robust Two-stage
Learning (${\rm KeGCN}_{R}$), which leverages Knowledge Graph Embeddings to
mitigate the information overload and effectively learns rich representations.
The proposed model adopts a two-stage learning method to enhance robustness
against hidden frauds. Extensive experimental results not only confirm the
importance of interactions but also show the superiority of ${\rm KeGCN}_{R}$
over a number of strong baselines in terms of fraud detection effectiveness and
robustness.

</details>


### [110] [Evaluating Supervised Learning Models for Fraud Detection: A Comparative Study of Classical and Deep Architectures on Imbalanced Transaction Data](https://arxiv.org/abs/2505.22521)
*Chao Wang,Chuanhao Nie,Yunbo Liu*

Main category: cs.LG

TL;DR: 本研究比较了逻辑回归、随机森林、LightGBM和GRU在欺诈检测任务中的表现，发现集成方法性能更优，GRU在召回率方面表现突出，但准确率较低。模型的选择应根据具体需求而定。


<details>
  <summary>Details</summary>
Motivation: 欺诈检测在金融和电子商务等高风险领域仍然是一项关键任务，因为未经检测的欺诈交易可能导致重大的经济损失。

Method: 本研究系统性地比较了四种监督学习模型——逻辑回归、随机森林、LightGBM和GRU网络——在处理大规模、高度不平衡的在线交易数据集上的性能。

Result: 随机森林和LightGBM等集成方法在整体和特定类别的指标上均表现出优越性能，而逻辑回归则提供了一个可靠且可解释的基准。GRU模型对少数欺诈类别显示出较强的召回率，但以牺牲准确率为代价。

Conclusion: 选择模型应基于欺诈检测系统的特定风险容忍度和运营需求。

Abstract: Fraud detection remains a critical task in high-stakes domains such as
finance and e-commerce, where undetected fraudulent transactions can lead to
significant economic losses. In this study, we systematically compare the
performance of four supervised learning models - Logistic Regression, Random
Forest, Light Gradient Boosting Machine (LightGBM), and a Gated Recurrent Unit
(GRU) network - on a large-scale, highly imbalanced online transaction dataset.
While ensemble methods such as Random Forest and LightGBM demonstrated superior
performance in both overall and class-specific metrics, Logistic Regression
offered a reliable and interpretable baseline. The GRU model showed strong
recall for the minority fraud class, though at the cost of precision,
highlighting a trade-off relevant for real-world deployment. Our evaluation
emphasizes not only weighted averages but also per-class precision, recall, and
F1-scores, providing a nuanced view of each model's effectiveness in detecting
rare but consequential fraudulent activity. The findings underscore the
importance of choosing models based on the specific risk tolerance and
operational needs of fraud detection systems.

</details>


### [111] [Rethinking Contrastive Learning in Graph Anomaly Detection: A Clean-View Perspective](https://arxiv.org/abs/2505.18002)
*Di Jin,Jingyi Cao,Xiaobao Wang,Bingdao Feng,Dongxiao He,Longbiao Wang,Jianwu Dang*

Main category: cs.LG

TL;DR: CVGAD通过识别和移除干扰边来提升图异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有图异常检测方法依赖对比学习，但易受干扰边影响，导致学习到的节点表示不佳，检测效果受损。

Method: 提出CVGAD框架，包含多尺度异常感知模块以识别干扰，及渐进式净化模块以迭代移除干扰边。

Result: 在五个基准数据集上的广泛实验验证了该方法的有效性。

Conclusion: Clean-View Enhanced Graph Anomaly Detection framework (CVGAD)有效，通过多尺度异常感知模块识别干扰源，并用渐进式净化模块迭代移除干扰边，提升了模型性能。

Abstract: Graph anomaly detection aims to identify unusual patterns in graph-based
data, with wide applications in fields such as web security and financial fraud
detection. Existing methods typically rely on contrastive learning, assuming
that a lower similarity between a node and its local subgraph indicates
abnormality. However, these approaches overlook a crucial limitation: the
presence of interfering edges invalidates this assumption, since it introduces
disruptive noise that compromises the contrastive learning process.
Consequently, this limitation impairs the ability to effectively learn
meaningful representations of normal patterns, leading to suboptimal detection
performance. To address this issue, we propose a Clean-View Enhanced Graph
Anomaly Detection framework (CVGAD), which includes a multi-scale anomaly
awareness module to identify key sources of interference in the contrastive
learning process. Moreover, to mitigate bias from the one-step edge removal
process, we introduce a novel progressive purification module. This module
incrementally refines the graph by iteratively identifying and removing
interfering edges, thereby enhancing model performance. Extensive experiments
on five benchmark datasets validate the effectiveness of our approach.

</details>


### [112] [What You Read Isn't What You Hear: Linguistic Sensitivity in Deepfake Speech Detection](https://arxiv.org/abs/2505.17513)
*Binh Nguyen,Shuji Shi,Ryan Ofman,Thai Le*

Main category: cs.LG

TL;DR: 本研究发现，目前的语音反欺骗技术对语言学变化过于敏感，容易被基于文本的攻击绕过。研究人员通过实验证明，即使是小的语言学改动也能显著降低检测准确率，并提出需要改进技术以应对这类攻击。


<details>
  <summary>Details</summary>
Motivation: 随着文本到语音技术的发展，音频欺骗攻击日益增多，但现有语音反欺骗系统主要关注声学层面，忽略了语言学变化的影响，因此有必要研究语言学变化对语音反欺骗检测器的影响。

Method: 本研究通过引入基于文本的对抗性攻击来评估语音反欺骗检测器对语言学变化的敏感性，并进行了广泛的评估和特征归因分析。

Result: 研究发现，即使是微小的语言学扰动也能显著降低检测准确率，攻击成功率在某些开源检测器-声音对上超过60%。一项商业检测准确率从100%下降到32%。通过特征归因分析，发现语言复杂度与模型级别的音频嵌入相似性是导致检测器脆弱性的关键因素。此外，通过复现布拉德·皮特音频深度伪造诈骗案例，证明了基于文本的对抗性攻击可以完全绕过商业检测器。

Conclusion: 现有的语音反欺骗系统主要关注声学层面，忽略了语言学变化的影响。本研究通过引入基于文本的对抗性攻击，揭示了现有语音反欺骗检测器在面对语言学变化时的脆弱性。研究结果表明，即使是微小的语言学扰动也能显著降低检测准确率，并提出需要结合语言学变化来设计更鲁棒的反欺骗系统。

Abstract: Recent advances in text-to-speech technologies have enabled realistic voice
generation, fueling audio-based deepfake attacks such as fraud and
impersonation. While audio anti-spoofing systems are critical for detecting
such threats, prior work has predominantly focused on acoustic-level
perturbations, leaving the impact of linguistic variation largely unexplored.
In this paper, we investigate the linguistic sensitivity of both open-source
and commercial anti-spoofing detectors by introducing transcript-level
adversarial attacks. Our extensive evaluation reveals that even minor
linguistic perturbations can significantly degrade detection accuracy: attack
success rates surpass 60% on several open-source detector-voice pairs, and
notably one commercial detection accuracy drops from 100% on synthetic audio to
just 32%. Through a comprehensive feature attribution analysis, we identify
that both linguistic complexity and model-level audio embedding similarity
contribute strongly to detector vulnerability. We further demonstrate the
real-world risk via a case study replicating the Brad Pitt audio deepfake scam,
using transcript adversarial attacks to completely bypass commercial detectors.
These results highlight the need to move beyond purely acoustic defenses and
account for linguistic variation in the design of robust anti-spoofing systems.
All source code will be publicly available.

</details>


### [113] [Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods](https://arxiv.org/abs/2505.10050)
*Fahad Almalki,Mehedi Masud*

Main category: cs.LG

TL;DR: 该研究提出了一种结合梯度提升模型和XAI技术的欺诈检测框架，实现了高准确率和模型透明度。


<details>
  <summary>Details</summary>
Motivation: 传统的机器学习模型牺牲了模型透明度和可解释性，难以满足监管要求和获得利益相关者的信任。

Method: 该研究提出了一个结合了XGBoost、LightGBM和CatBoost梯度提升模型以及SHAP、LIME、PDP和PFI等可解释人工智能（XAI）技术的欺诈检测框架。

Result: 该模型在IEEE-CIS欺诈检测数据集上取得了99%的准确率和0.99的AUC-ROC得分，优于其他近期方法。

Conclusion: 结合高预测精度和透明可解释性是可能的，这可能为金融欺诈检测带来更合乎道德和更值得信赖的解决方案。

Abstract: Traditional machine learning models often prioritize predictive accuracy,
often at the expense of model transparency and interpretability. The lack of
transparency makes it difficult for organizations to comply with regulatory
requirements and gain stakeholders trust. In this research, we propose a fraud
detection framework that combines a stacking ensemble of well-known gradient
boosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable
artificial intelligence (XAI) techniques are used to enhance the transparency
and interpretability of the model's decisions. We used SHAP (SHapley Additive
Explanations) for feature selection to identify the most important features.
Further efforts were made to explain the model's predictions using Local
Interpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots
(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection
dataset, which includes more than 590,000 real transaction records, was used to
evaluate the proposed model. The model achieved a high performance with an
accuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent
related approaches. These results indicate that combining high prediction
accuracy with transparent interpretability is possible and could lead to a more
ethical and trustworthy solution in financial fraud detection.

</details>


### [114] [Online Isolation Forest](https://arxiv.org/abs/2505.09593)
*Filippo Leveni,Guilherme Weigert Cassales,Bernhard Pfahringer,Albert Bifet,Giacomo Boracchi*

Main category: cs.LG

TL;DR: Online-iForest 是一种高效的在线异常检测方法，适用于流式数据，可与离线方法相媲美。


<details>
  <summary>Details</summary>
Motivation: 离线异常检测方法需要重复访问内存中的数据，并且在流式环境中存在不切实际的假设。现有的在线方法通常也无法解决这些限制，并且需要定期重新训练才能适应在线环境。

Method: 提出了一种名为 Online-iForest 的新颖方法，该方法专为流式条件设计，可以随着数据生成过程随时间演变而进行跟踪。

Result: 实验结果表明，Online-iForest 在效率方面优于所有竞争对手，并且在准确性方面与需要定期重新训练的最先进的离线异常检测技术相媲美。

Conclusion: Online-iForest 是一种新颖的在线异常检测方法，可适应不断变化的数据流，在效率方面优于现有方法。

Abstract: The anomaly detection literature is abundant with offline methods, which
require repeated access to data in memory, and impose impractical assumptions
when applied to a streaming context. Existing online anomaly detection methods
also generally fail to address these constraints, resorting to periodic
retraining to adapt to the online context. We propose Online-iForest, a novel
method explicitly designed for streaming conditions that seamlessly tracks the
data generating process as it evolves over time. Experimental validation on
real-world datasets demonstrated that Online-iForest is on par with online
alternatives and closely rivals state-of-the-art offline anomaly detection
techniques that undergo periodic retraining. Notably, Online-iForest
consistently outperforms all competitors in terms of efficiency, making it a
promising solution in applications where fast identification of anomalies is of
primary importance such as cybersecurity, fraud and fault detection.

</details>


### [115] [Cyber Security Data Science: Machine Learning Methods and their Performance on Imbalanced Datasets](https://arxiv.org/abs/2505.04204)
*Mateo Lopez-Ledezma,Gissel Velarde*

Main category: cs.LG

TL;DR: 网络安全需要自动化，许多应用可视为二元分类。研究评估了几种分类器和不平衡学习技术，发现它们的影响不一，建议针对不同数据集进行测试。


<details>
  <summary>Details</summary>
Motivation: 网络安全至关重要，需要自动化来处理大量日常操作。许多安全应用（如异常检测、欺诈检测、入侵检测、垃圾邮件检测和恶意软件检测）都可以转化为二元分类问题。

Method: 本文评估了随机森林、Light GBM、XGBoost、逻辑回归、决策树和GBDT等单个分类器。此外，还测试了过采样、欠采样、SMOTE和自步集成等采样技术。最后，评估了自步集成及其基础分类器的数量。

Result: 研究发现，不平衡学习技术可能产生积极或消极的影响，应谨慎使用。不同数据集的最佳性能分类器各不相同。

Conclusion: 应在涉及不平衡数据集的新数据集和应用程序中，对单个分类器和不平衡学习技术进行测试。

Abstract: Cybersecurity has become essential worldwide and at all levels, concerning
individuals, institutions, and governments. A basic principle in cybersecurity
is to be always alert. Therefore, automation is imperative in processes where
the volume of daily operations is large. Several cybersecurity applications can
be addressed as binary classification problems, including anomaly detection,
fraud detection, intrusion detection, spam detection, or malware detection. We
present three experiments. In the first experiment, we evaluate single
classifiers including Random Forests, Light Gradient Boosting Machine, eXtreme
Gradient Boosting, Logistic Regression, Decision Tree, and Gradient Boosting
Decision Tree. In the second experiment, we test different sampling techniques
including over-sampling, under-sampling, Synthetic Minority Over-sampling
Technique, and Self-Paced Ensembling. In the last experiment, we evaluate
Self-Paced Ensembling and its number of base classifiers. We found that
imbalance learning techniques had positive and negative effects, as reported in
related studies. Thus, these techniques should be applied with caution.
Besides, we found different best performers for each dataset. Therefore, we
recommend testing single classifiers and imbalance learning techniques for each
new dataset and application involving imbalanced datasets as is the case in
several cyber security applications.

</details>


### [116] [Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content](https://arxiv.org/abs/2505.01008)
*Haoyue Bai,Yiyou Sun,Wei Cheng,Haifeng Chen*

Main category: cs.LG

TL;DR: 一项新的黑盒检测框架，只需API访问，即可通过“破坏与恢复”策略检测AI生成图像，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于生成模型生成的照片级逼真图像的激增，这些图像在人眼看来与真实图像几乎没有区别，这既带来了兴奋也引发了担忧。虽然它们提供了新的创作和商业可能性，但其潜在的滥用，如用于错误信息和欺诈，凸显了对有效检测方法的需求。然而，当前检测方法通常依赖于模型权重或需要广泛的真实图像数据集，这限制了它们在现实世界场景中的可扩展性和实际应用。

Method: 该研究提出了一种新的黑盒检测框架，利用“破坏与恢复”策略。具体而言，该方法会遮蔽图像的一部分，并评估模型重建该部分的能力，以此来衡量图像为模型生成的可能性。对于不支持遮蔽图像输入的黑盒模型，研究还引入了一个成本效益高的代理模型，该模型旨在与目标模型分布对齐，以提高检测能力。

Result: 该框架在八个扩散模型变体数据集上表现出强大的性能，平均精度比基线方法高出4.31%。

Conclusion: 该研究提出了一个新颖的黑盒检测框架，仅需API访问即可，无需模型权重或大型辅助数据集。该框架通过“破坏与恢复”策略，衡量模型重构图像的能力，从而评估图像为模型生成的可能性。对于不支持遮蔽图像输入的黑盒模型，研究还纳入了一个成本效益高的代理模型，以匹配目标模型分布，从而增强检测能力。该框架在八个扩散模型变体数据集上表现出强大的性能，平均精度比基线方法高出4.31%。

Abstract: The recent proliferation of photorealistic images created by generative
models has sparked both excitement and concern, as these images are
increasingly indistinguishable from real ones to the human eye. While offering
new creative and commercial possibilities, the potential for misuse, such as in
misinformation and fraud, highlights the need for effective detection methods.
Current detection approaches often rely on access to model weights or require
extensive collections of real image datasets, limiting their scalability and
practical application in real world scenarios. In this work, we introduce a
novel black box detection framework that requires only API access, sidestepping
the need for model weights or large auxiliary datasets. Our approach leverages
a corrupt and recover strategy: by masking part of an image and assessing the
model ability to reconstruct it, we measure the likelihood that the image was
generated by the model itself. For black-box models that do not support masked
image inputs, we incorporate a cost efficient surrogate model trained to align
with the target model distribution, enhancing detection capability. Our
framework demonstrates strong performance, outperforming baseline methods by
4.31% in mean average precision across eight diffusion model variant datasets.

</details>


### [117] [Addressing Noise and Stochasticity in Fraud Detection for Service Networks](https://arxiv.org/abs/2505.00946)
*Wenxin Zhang,Ding Xu,Xi Xuan,Lei Jiang,Guangzhen Yao,Renda Han,Xiangxiang Lang,Cuicui Luo*

Main category: cs.LG

TL;DR: SGNN-IB通过将图划分为同质和异质子图，并利用信息瓶颈理论和原型学习来提取关键特征和融合信号，从而在社交服务网络中进行欺诈检测，解决了现有方法在信号去噪和频率区分方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于谱图的方法在衍生干净和有区别的图信号方面存在不足，它们忽略了信息传播过程中的噪声，导致滤波能力下降，并且未能区分图信号的频率特定特征，导致信号融合失真。

Method: SGNN-IB将原始图划分为同质和异质子图，以更好地捕捉不同频率的信号。为解决第一个限制，SGNN-IB应用信息瓶颈理论提取编码表示的关键特征。为解决第二个限制，SGNN-IB引入原型学习来实现信号融合，保留信号的频率特定特征。

Result: SGNN-IB在三个真实世界数据集上进行了广泛实验，结果证明其性能优于最先进的欺诈检测方法。

Conclusion: SGNN-IB在三个真实世界数据集上的广泛实验证明，其性能优于最先进的欺诈检测方法。

Abstract: Fraud detection is crucial in social service networks to maintain user trust
and improve service network security. Existing spectral graph-based methods
address this challenge by leveraging different graph filters to capture signals
with different frequencies in service networks. However, most graph
filter-based methods struggle with deriving clean and discriminative graph
signals. On the one hand, they overlook the noise in the information
propagation process, resulting in degradation of filtering ability. On the
other hand, they fail to discriminate the frequency-specific characteristics of
graph signals, leading to distortion of signals fusion. To address these
issues, we develop a novel spectral graph network based on information
bottleneck theory (SGNN-IB) for fraud detection in service networks. SGNN-IB
splits the original graph into homophilic and heterophilic subgraphs to better
capture the signals at different frequencies. For the first limitation, SGNN-IB
applies information bottleneck theory to extract key characteristics of encoded
representations. For the second limitation, SGNN-IB introduces prototype
learning to implement signal fusion, preserving the frequency-specific
characteristics of signals. Extensive experiments on three real-world datasets
demonstrate that SGNN-IB outperforms state-of-the-art fraud detection methods.

</details>


### [118] [Dual-channel Heterophilic Message Passing for Graph Fraud Detection](https://arxiv.org/abs/2504.14205)
*Wenxin Zhang,Jingxing Zhong,Guangzhen Yao,Renda Han,Xiaojian Lin,Zeyu Zhang,Cuicui Luo*

Main category: cs.LG

TL;DR: DHMP框架通过分离同质和异质子图并采用共享权重和定制采样策略来改进欺诈检测，在真实数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于空间图神经网络（GNN）的欺诈检测方法为了适应GNN的同质性偏见，在消息传递中排除了异质性邻居，这可能会破坏原始图拓扑并增加预测的不确定性。

Method: DHMP框架，它包含一个异质性分离模块，将图划分为同质和异质子图，并采用共享权重和定制的采样策略来捕捉不同频率的信号。

Result: DHMP在三个真实世界数据集上的广泛实验证明，其性能优于现有方法。

Conclusion: DHMP通过分离不同频率的信号，在欺诈检测方面优于现有方法，这表明了其在提高欺诈检测准确性方面的潜力。

Abstract: Fraudulent activities have significantly increased across various domains,
such as e-commerce, online review platforms, and social networks, making fraud
detection a critical task. Spatial Graph Neural Networks (GNNs) have been
successfully applied to fraud detection tasks due to their strong inductive
learning capabilities. However, existing spatial GNN-based methods often
enhance the graph structure by excluding heterophilic neighbors during message
passing to align with the homophilic bias of GNNs. Unfortunately, this approach
can disrupt the original graph topology and increase uncertainty in
predictions. To address these limitations, this paper proposes a novel
framework, Dual-channel Heterophilic Message Passing (DHMP), for fraud
detection. DHMP leverages a heterophily separation module to divide the graph
into homophilic and heterophilic subgraphs, mitigating the low-pass inductive
bias of traditional GNNs. It then applies shared weights to capture signals at
different frequencies independently and incorporates a customized sampling
strategy for training. This allows nodes to adaptively balance the
contributions of various signals based on their labels. Extensive experiments
on three real-world datasets demonstrate that DHMP outperforms existing
methods, highlighting the importance of separating signals with different
frequencies for improved fraud detection. The code is available at
https://github.com/shaieesss/DHMP.

</details>


### [119] [ALF: Advertiser Large Foundation Model for Multi-Modal Advertiser Understanding](https://arxiv.org/abs/2504.18785)
*Santosh Rajagopalan,Jonathan Vronsky,Songbai Yan,S. Alireza Golestaneh,Shubhra Chandra,Min Zhou*

Main category: cs.LG

TL;DR: ALF是一个多模态Transformer模型，用于理解广告商行为，通过对比学习和多任务优化来统一广告商表示，并在关键任务中取得最先进的性能，同时降低误报率。


<details>
  <summary>Details</summary>
Motivation: 为了跨文本、图像、视频和结构化数据模态来理解广告商行为和意图。

Method: ALF（Advertiser Large Foundation model）采用多模态Transformer架构，结合对比学习和多任务优化，创建了统一的广告商表示，能够捕捉内容和行为模式。其有效性源于多模态转换、样本间注意力机制、谱归一化投影和校准概率输出的组合。

Result: ALF在生产部署中将误报率降低了90%，同时在滥用检测任务上保持了99.8%的精确率。

Conclusion: ALF在广告欺诈检测、政策违规识别和广告商相似性匹配等关键任务上取得了最先进的性能，并且在生产部署中显著减少了误报率，同时保持了高精度的滥用检测能力。

Abstract: We present ALF (Advertiser Large Foundation model), a multi-modal transformer
architecture for understanding advertiser behavior and intent across text,
image, video and structured data modalities. Through contrastive learning and
multi-task optimization, ALF creates unified advertiser representations that
capture both content and behavioral patterns. Our model achieves
state-of-the-art performance on critical tasks including fraud detection,
policy violation identification, and advertiser similarity matching. In
production deployment, ALF reduces false positives by 90% while maintaining
99.8% precision on abuse detection tasks. The architecture's effectiveness
stems from its novel combination of multi-modal transformations, inter-sample
attention mechanism, spectrally normalized projections, and calibrated
probabilistic outputs.

</details>


### [120] [PTCL: Pseudo-Label Temporal Curriculum Learning for Label-Limited Dynamic Graph](https://arxiv.org/abs/2504.17641)
*Shengtao Zhang,Haokai Zhang,Shiqi Lou,Zicheng Wang,Zinan Zeng,Yilin Wang,Minnan Luo*

Main category: cs.LG

TL;DR: 提出PTCL方法，解决仅有最终标签的动态节点分类问题，并构建FLiD框架。


<details>
  <summary>Details</summary>
Motivation: 解决动态节点分类中标签受限的问题，即在真实场景中难以获取所有时间戳的标签，但最终时间戳的标签相对容易获得。

Method: PTCL（伪标签时间课程学习）方法，包含时间解耦架构（学习时间感知表示）和时间课程学习策略（优先处理接近最终时间戳的伪标签）。

Result: PTCL在真实场景的实验中表现优于其他方法。提出的FLiD框架支持多种模型和数据集，并提供完整的准备、训练和评估流程。

Conclusion: PTCL在仅有最终时间戳标签的情况下，通过伪标签和时间课程学习策略，实现了动态节点分类的优越性能。FLiD框架为标签受限的动态节点分类提供了一个完整的解决方案。

Abstract: Dynamic node classification is critical for modeling evolving systems like
financial transactions and academic collaborations. In such systems,
dynamically capturing node information changes is critical for dynamic node
classification, which usually requires all labels at every timestamp. However,
it is difficult to collect all dynamic labels in real-world scenarios due to
high annotation costs and label uncertainty (e.g., ambiguous or delayed labels
in fraud detection). In contrast, final timestamp labels are easier to obtain
as they rely on complete temporal patterns and are usually maintained as a
unique label for each user in many open platforms, without tracking the history
data. To bridge this gap, we propose PTCL(Pseudo-label Temporal Curriculum
Learning), a pioneering method addressing label-limited dynamic node
classification where only final labels are available. PTCL introduces: (1) a
temporal decoupling architecture separating the backbone (learning time-aware
representations) and decoder (strictly aligned with final labels), which
generate pseudo-labels, and (2) a Temporal Curriculum Learning strategy that
prioritizes pseudo-labels closer to the final timestamp by assigning them
higher weights using an exponentially decaying function. We contribute a new
academic dataset (CoOAG), capturing long-range research interest in dynamic
graph. Experiments across real-world scenarios demonstrate PTCL's consistent
superiority over other methods adapted to this task. Beyond methodology, we
propose a unified framework FLiD (Framework for Label-Limited Dynamic Node
Classification), consisting of a complete preparation workflow, training
pipeline, and evaluation standards, and supporting various models and datasets.
The code can be found at https://github.com/3205914485/FLiD.

</details>


### [121] [Application of Deep Generative Models for Anomaly Detection in Complex Financial Transactions](https://arxiv.org/abs/2504.15491)
*Tengda Tang,Jianhua Yao,Yixian Wang,Qiuwu Sha,Hanrui Feng,Zhen Xu*

Main category: cs.LG

TL;DR: 提出一种基于GAN和VAE的算法，用于检测海量支付流量中的可疑行为，实验证明其在检测稀有欺诈行为方面效果显著。


<details>
  <summary>Details</summary>
Motivation: 为了在海量支付流量中检测可疑行为（如潜在欺诈和洗钱行为），并提高检测稀有欺诈行为的准确性。

Method: 提出一种结合生成对抗网络（GAN）和变分自编码器（VAE）的算法，利用GAN生成模拟的正常支付流量数据，并通过判别器识别异常模式；利用VAE对支付流量的潜在分布进行建模，以提高生成数据的真实性，从而提升检测精度。

Result: 实验结果表明，所提出的方法在各种评估指标上，尤其在检测稀有欺诈行为方面，显著优于传统的机器学习算法和其他深度学习模型，并有效识别了不同交易模式。

Conclusion: 该方法在处理复杂金融数据方面具有优势，尤其在检测稀有欺诈行为方面，显著优于传统机器学习算法和其他深度学习模型。

Abstract: This study proposes an algorithm for detecting suspicious behaviors in large
payment flows based on deep generative models. By combining Generative
Adversarial Networks (GAN) and Variational Autoencoders (VAE), the algorithm is
designed to detect abnormal behaviors in financial transactions. First, the GAN
is used to generate simulated data that approximates normal payment flows. The
discriminator identifies anomalous patterns in transactions, enabling the
detection of potential fraud and money laundering behaviors. Second, a VAE is
introduced to model the latent distribution of payment flows, ensuring that the
generated data more closely resembles real transaction features, thus improving
the model's detection accuracy. The method optimizes the generative
capabilities of both GAN and VAE, ensuring that the model can effectively
capture suspicious behaviors even in sparse data conditions. Experimental
results show that the proposed method significantly outperforms traditional
machine learning algorithms and other deep learning models across various
evaluation metrics, especially in detecting rare fraudulent behaviors.
Furthermore, this study provides a detailed comparison of performance in
recognizing different transaction patterns (such as normal, money laundering,
and fraud) in large payment flows, validating the advantages of generative
models in handling complex financial data.

</details>


### [122] [Federated Spectral Graph Transformers Meet Neural Ordinary Differential Equations for Non-IID Graphs](https://arxiv.org/abs/2504.11808)
*Kishan Gurumurthy,Himanshu Pal,Charu Sharma*

Main category: cs.LG

TL;DR: 我们提出了一种新颖的联邦图神经网络（GNN）方法，结合了神经网络常微分方程（ODE），以解决隐私问题和处理非独立同分布（non-IID）数据，并在同质和异质图上均取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界中由于隐私、法规和商业竞争等问题，难以将大量图数据集中用于GNN训练的挑战，并填补联邦学习在GNN领域研究不足的空白。

Method: 提出了一种基于谱图神经网络（GNNs）并结合神经网络常微分方程（ODE）的联邦学习新方法，以更好地捕捉信息。

Result: 该方法有效处理了非独立同分布（non-IID）数据，性能与仅在IID数据上运行的现有方法相当，并在非独立同分布异质图上取得了显著改进，在同质图上也表现更优。

Conclusion: 本研究展示了联邦学习在各种具有挑战性的图设置中的潜力，特别是在处理非独立同分布（non-IID）异质图方面取得了显著改进，同时在同质图上也达到了更好的性能。

Abstract: Graph Neural Network (GNN) research is rapidly advancing due to GNNs'
capacity to learn distributed representations from graph-structured data.
However, centralizing large volumes of real-world graph data for GNN training
is often impractical due to privacy concerns, regulatory restrictions, and
commercial competition. Federated learning (FL), a distributed learning
paradigm, offers a solution by preserving data privacy with collaborative model
training. Despite progress in training huge vision and language models,
federated learning for GNNs remains underexplored. To address this challenge,
we present a novel method for federated learning on GNNs based on spectral GNNs
equipped with neural ordinary differential equations (ODE) for better
information capture, showing promising results across both homophilic and
heterophilic graphs. Our approach effectively handles non-Independent and
Identically Distributed (non-IID) data, while also achieving performance
comparable to existing methods that only operate on IID data. It is designed to
be privacy-preserving and bandwidth-optimized, making it suitable for
real-world applications such as social network analysis, recommendation
systems, and fraud detection, which often involve complex, non-IID, and
heterophilic graph structures. Our results in the area of federated learning on
non-IID heterophilic graphs demonstrate significant improvements, while also
achieving better performance on homophilic graphs. This work highlights the
potential of federated learning in diverse and challenging graph settings.
Open-source code available on GitHub
(https://github.com/SpringWiz11/Fed-GNODEFormer).

</details>


### [123] [Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks Against GNN-Based Fraud Detectors](https://arxiv.org/abs/2412.18370)
*Jinhyeok Choi,Heehyeon Kim,Joyce Jiyoung Whang*

Main category: cs.LG

TL;DR: 本研究提出了一种名为MonTi的新型攻击模型，用于欺骗基于图神经网络（GNN）的欺诈检测系统。研究发现，欺诈团伙可以通过协同攻击来逃避检测，MonTi模型能够通过同时生成攻击节点的属性和边，并自适应地调整攻击策略，有效地实现这一目标，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管图神经网络（GNNs）在欺诈检测方面表现出色，但针对GNN的攻击及其风险研究不足。随着欺诈行为日益团伙化，有必要研究欺诈团伙如何通过协同伪装来规避GNN检测，从而为GNN欺诈检测器提供更强的鲁棒性。

Method: 提出了一种名为MonTi的基于Transformer的多目标一次性图注入攻击模型。该模型通过Transformer编码器同时生成所有攻击节点的属性和边，以更有效地捕捉属性和边之间的相互依赖关系。此外，MonTi能够自适应地为每个攻击节点分配度预算，以探索涉及目标、候选和攻击节点的多样化注入结构，克服了现有方法固定所有攻击节点度预算的局限性。

Result: MonTi在五个真实世界图上的实验结果表明，其在多目标图注入攻击方面优于现有的最先进方法，能够有效地使欺诈节点被错误分类为良性节点。

Conclusion: 本研究提出了MonTi模型，一种基于Transformer的多目标一次性图注入攻击模型，用于针对基于GNN的欺诈检测器。MonTi通过同时生成攻击节点的属性和边来有效捕捉它们之间的相互依赖关系，并能自适应地分配每个攻击节点的度预算，以探索多样化的注入结构。实验证明，MonTi在五个真实世界图上的表现优于现有的图注入攻击方法。

Abstract: Graph neural networks (GNNs) have emerged as an effective tool for fraud
detection, identifying fraudulent users, and uncovering malicious behaviors.
However, attacks against GNN-based fraud detectors and their risks have rarely
been studied, thereby leaving potential threats unaddressed. Recent findings
suggest that frauds are increasingly organized as gangs or groups. In this
work, we design attack scenarios where fraud gangs aim to make their fraud
nodes misclassified as benign by camouflaging their illicit activities in
collusion. Based on these scenarios, we study adversarial attacks against
GNN-based fraud detectors by simulating attacks of fraud gangs in three
real-world fraud cases: spam reviews, fake news, and medical insurance frauds.
We define these attacks as multi-target graph injection attacks and propose
MonTi, a transformer-based Multi-target one-Time graph injection attack model.
MonTi simultaneously generates attributes and edges of all attack nodes with a
transformer encoder, capturing interdependencies between attributes and edges
more effectively than most existing graph injection attack methods that
generate these elements sequentially. Additionally, MonTi adaptively allocates
the degree budget for each attack node to explore diverse injection structures
involving target, candidate, and attack nodes, unlike existing methods that fix
the degree budget across all attack nodes. Experiments show that MonTi
outperforms the state-of-the-art graph injection attack methods on five
real-world graphs.

</details>


### [124] [ROSFD: Robust Online Streaming Fraud Detection with Resilience to Concept Drift in Data Streams](https://arxiv.org/abs/2504.10229)
*Vivek Yelleti*

Main category: cs.LG

TL;DR: 针对流式数据的欺诈检测需求，提出ROSFD框架，通过离线初始化和实时适应（使用DDM、EDDM、ADWIN等漂移检测器）来解决延迟、可扩展性和概念漂移问题。使用ADWIN的ROSFD和自适应随机森林模型取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 传统的批量处理方法难以捕捉欺诈活动的快速演变模式，而连续生成的流式数据（如在线交易和数字交互）需要及时的欺诈检测。因此，处理流式数据对于有效的欺诈检测至关重要，需要解决延迟、可扩展性和概念漂移等挑战。

Method: 提出了一种名为ROSFD（鲁棒在线流式欺诈检测）的框架，该框架包含两个阶段：1. 离线模型初始化：使用增量学习原理在离线环境中构建模型以解决“冷启动”问题。2. 实时模型适应：利用漂移检测算法（DDM、EDDM、ADWIN）来识别数据流中的概念漂移，并据此对模型进行增量训练。这种“仅在需要时训练”的策略减少了重新训练的次数，同时对AUC（受试者工作特征曲线下面积）的影响不大。

Result: ROSFD框架，特别是使用ADWIN作为漂移检测方法的ROSFD框架，在流式数据欺诈检测方面表现出最佳性能。自适应随机森林模型在大多数数据集上始终优于其他模型，实现了最高的AUC。

Conclusion: ROSFD框架，特别是使用ADWIN作为漂移检测方法的ROSFD框架，在流式数据欺诈检测方面表现出最佳性能。自适应随机森林模型在大多数数据集上始终优于其他模型，实现了最高的AUC。

Abstract: Continuous generation of streaming data from diverse sources, such as online
transactions and digital interactions, necessitates timely fraud detection.
Traditional batch processing methods often struggle to capture the rapidly
evolving patterns of fraudulent activities. This paper highlights the critical
importance of processing streaming data for effective fraud detection. To
address the inherent challenges of latency, scalability, and concept drift in
streaming environments, we propose a robust online streaming fraud detection
(ROSFD) framework. Our proposed framework comprises two key stages: (i) Stage
One: Offline Model Initialization. In this initial stage, a model is built in
offline settings using incremental learning principles to overcome the
"cold-start" problem. (ii) Stage Two: Real-time Model Adaptation. In this
dynamic stage, drift detection algorithms (viz.,, DDM, EDDM, and ADWIN) are
employed to identify concept drift in the incoming data stream and
incrementally train the model accordingly. This "train-only-when-required"
strategy drastically reduces the number of retrains needed without
significantly impacting the area under the receiver operating characteristic
curve (AUC). Overall, ROSFD utilizing ADWIN as the drift detection method
demonstrated the best performance among the employed methods. In terms of model
efficacy, Adaptive Random Forest consistently outperformed other models,
achieving the highest AUC in four out of five datasets.

</details>


### [125] [Detecting Credit Card Fraud via Heterogeneous Graph Neural Networks with Graph Attention](https://arxiv.org/abs/2504.08183)
*Qiuwu Sha,Tengda Tang,Xinyu Du,Jie Liu,Yixian Wang,Yuan Sheng*

Main category: cs.LG

TL;DR: 该研究提出了一种基于异构图神经网络（HGNN）的信用卡欺诈检测方法，通过构建包含用户、商户和交易的异构图，并结合图注意力机制和时间衰减机制，有效提升了欺诈检测能力。该方法在IEEE-CIS欺诈检测数据集上取得了优于现有GNN模型的性能，并在处理欺诈样本稀疏性方面采用了SMOTE和代价敏感学习。未来研究将探索动态图神经网络和强化学习以增强实时适应性。


<details>
  <summary>Details</summary>
Motivation: 为了解决复杂交易网络中的信用卡欺诈问题，并克服传统依赖数值特征的机器学习方法的局限性。

Method: 提出了一种基于异构图神经网络（HGNN）的信用卡欺诈检测方法。该方法构建了包含用户、商户和交易等多种节点类型的异构交易图，利用图神经网络捕捉高阶交易关系。通过引入图注意力机制动态分配不同交易关系权重，并结合时间衰减机制增强对时间相关欺诈模式的敏感性。为解决欺诈样本稀疏问题，采用了SMOTE过采样和代价敏感学习。

Result: 实验结果表明，所提出的HGNN方法在IEEE-CIS欺诈检测数据集上，相比GCN、GAT和GraphSAGE等现有GNN模型，在准确率和OC-ROC方面均表现更优。

Conclusion: 该研究提出的基于异构图神经网络（HGNN）的信用卡欺诈检测方法，在IEEE-CIS欺诈检测数据集上，相较于GCN、GAT和GraphSAGE等现有GNN模型，在准确率和OC-ROC方面均取得了显著提升，证明了其有效性。

Abstract: This study proposes a credit card fraud detection method based on
Heterogeneous Graph Neural Network (HGNN) to address fraud in complex
transaction networks. Unlike traditional machine learning methods that rely
solely on numerical features of transaction records, this approach constructs
heterogeneous transaction graphs. These graphs incorporate multiple node types,
including users, merchants, and transactions. By leveraging graph neural
networks, the model captures higher-order transaction relationships. A Graph
Attention Mechanism is employed to dynamically assign weights to different
transaction relationships. Additionally, a Temporal Decay Mechanism is
integrated to enhance the model's sensitivity to time-related fraud patterns.
To address the scarcity of fraudulent transaction samples, this study applies
SMOTE oversampling and Cost-sensitive Learning. These techniques strengthen the
model's ability to identify fraudulent transactions. Experimental results
demonstrate that the proposed method outperforms existing GNN models, including
GCN, GAT, and GraphSAGE, on the IEEE-CIS Fraud Detection dataset. The model
achieves notable improvements in both accuracy and OC-ROC. Future research may
explore the integration of dynamic graph neural networks and reinforcement
learning. Such advancements could enhance the real-time adaptability of fraud
detection systems and provide more intelligent solutions for financial risk
control.

</details>


### [126] [UMGAD: Unsupervised Multiplex Graph Anomaly Detection](https://arxiv.org/abs/2411.12556)
*Xiang Li,Jianpeng Qi,Zhongying Zhao,Guanjie Zheng,Lei Cao,Junyu Dong,Yanwei Yu*

Main category: cs.LG

TL;DR: UMGAD是一种新颖的无监督多图异常检测方法，通过多关系关联、图掩码自动编码器和对比学习来处理多类型交互图中的异常检测和无监督阈值选择问题，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的图异常检测（GAD）方法在多类型交互图方面存在局限性，并且在无监督场景下选择异常分数阈值是一个挑战。为了解决这些问题，提出了一种新的无监督多图异常检测方法UMGAD。

Method: UMGAD方法首先学习多关系关联，然后通过图掩码自动编码器（GMAE）捕获节点属性和结构重建中的异常信息。接着，生成属性级和子图级增强视图图，并通过GMAE进行属性和结构重建。最后，通过原始视图和增强视图图之间的对比学习来优化节点属性和结构特征。

Result: UMGAD在检测多类型交互图中的异常方面表现出色，并且提出了一种新的异常分数阈值选择策略，使其在无监督场景下不依赖于真实标签信息。

Conclusion: UMGAD在六个数据集上的广泛实验表明，其性能显著优于最先进的方法，在所有数据集的AUC方面平均提高了12.25%，在Macro-F1方面平均提高了11.29%。

Abstract: Graph anomaly detection (GAD) is a critical task in graph machine learning,
with the primary objective of identifying anomalous nodes that deviate
significantly from the majority. This task is widely applied in various
real-world scenarios, including fraud detection and social network analysis.
However, existing GAD methods still face two major challenges: (1) They are
often limited to detecting anomalies in single-type interaction graphs and
struggle with multiple interaction types in multiplex heterogeneous graphs. (2)
In unsupervised scenarios, selecting appropriate anomaly score thresholds
remains a significant challenge for accurate anomaly detection. To address the
above challenges, we propose a novel Unsupervised Multiplex Graph Anomaly
Detection method, named UMGAD. We first learn multi-relational correlations
among nodes in multiplex heterogeneous graphs and capture anomaly information
during node attribute and structure reconstruction through graph-masked
autoencoder (GMAE). Then, to further extract abnormal information, we generate
attribute-level and subgraph-level augmented-view graphs, respectively, and
perform attribute and structure reconstruction through GMAE. Finally, we learn
to optimize node attributes and structural features through contrastive
learning between original-view and augmented-view graphs to improve the model's
ability to capture anomalies. Meanwhile, we propose a new anomaly score
threshold selection strategy, which allows the model to be independent of
ground truth information in real unsupervised scenarios. Extensive experiments
on six datasets show that our UMGAD significantly outperforms state-of-the-art
methods, achieving average improvements of 12.25% in AUC and 11.29% in Macro-F1
across all datasets.

</details>


### [127] [Addressing Class Imbalance with Probabilistic Graphical Models and Variational Inference](https://arxiv.org/abs/2504.05758)
*Yujia Lou,Jie Liu,Yuan Sheng,Jiawei Wang,Yiwei Zhang,Yaokun Ren*

Main category: cs.LG

TL;DR: 提出基于DPGMs的不平衡分类新方法，通过变分推断、类别感知权重和对抗学习生成少数类样本，在信用卡欺诈检测等任务中提升少数类识别率并降低误报率，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统不平衡数据分类方法在处理少数类样本时存在学习能力不足的问题，容易导致分类偏差。本研究旨在解决这一核心挑战。

Method: 本研究提出了一种基于深度概率图模型（DPGMs）的不平衡数据分类方法。该方法引入变分推断优化概率模型以解决类别不平衡导致的分类偏差，使模型能自适应调整少数类的表示能力。同时，结合了类别感知权重调整策略以增强分类器对少数类的敏感性。此外，还融合了对抗学习机制在潜在空间生成少数类样本，以更好地刻画高维特征空间中的类别边界。

Result: 实验结果表明，本研究提出的方法在Kaggle“信用卡欺诈检测”数据集上，与GANs、BRF、XGBoost-Cost Sensitive、SAAD、HAN等多种先进不平衡分类方法相比，在AUC、Precision、Recall和F1-score指标上均取得了最优性能，有效提升了少数类的识别率并降低了误报率。

Conclusion: 本研究提出的基于深度概率图模型（DPGMs）的不平衡数据分类方法，在处理少数类样本学习能力不足的问题上取得了显著成效，并在AUC、Precision、Recall和F1-score等关键指标上优于多种先进方法，有效提高了少数类识别率并降低了误报率。该方法在金融欺诈检测、医疗诊断和异常检测等不平衡分类任务中具有广泛的应用前景。

Abstract: This study proposes a method for imbalanced data classification based on deep
probabilistic graphical models (DPGMs) to solve the problem that traditional
methods have insufficient learning ability for minority class samples. To
address the classification bias caused by class imbalance, we introduce
variational inference optimization probability modeling, which enables the
model to adaptively adjust the representation ability of minority classes and
combines the class-aware weight adjustment strategy to enhance the classifier's
sensitivity to minority classes. In addition, we combine the adversarial
learning mechanism to generate minority class samples in the latent space so
that the model can better characterize the category boundary in the
high-dimensional feature space. The experiment is evaluated on the Kaggle
"Credit Card Fraud Detection" dataset and compared with a variety of advanced
imbalanced classification methods (such as GAN-based sampling, BRF,
XGBoost-Cost Sensitive, SAAD, HAN). The results show that the method in this
study has achieved the best performance in AUC, Precision, Recall and F1-score
indicators, effectively improving the recognition rate of minority classes and
reducing the false alarm rate. This method can be widely used in imbalanced
classification tasks such as financial fraud detection, medical diagnosis, and
anomaly detection, providing a new solution for related research.

</details>


### [128] [Incremental Outlier Detection Modelling Using Streaming Analytics in Finance & Health Care](https://arxiv.org/abs/2305.09907)
*Vivek Yelleti,Ch Priyanka*

Main category: cs.LG

TL;DR: 本文提出了一种混合框架，结合了传统方法和增量学习，以应对实时数据流的挑战。通过在金融和医疗领域对八种异常检测模型进行评估，发现增量学习方法能显著提升模型性能，特别是在不平衡数据集上。其中，IForest ASD 模型表现尤为出色。


<details>
  <summary>Details</summary>
Motivation: 在实时数据时代，传统方法难以跟上流数据环境的动态性质。

Method: 本文提出了一个混合框架：第一阶段采用传统方法，一次性构建模型并在实时环境中进行评估；第二阶段采用增量学习方法，随着新数据的到来持续重新训练模型，使其能够适应并保持最新。为了实现这些框架，研究采用了包括单类支持向量机 (OCSVM)、Isolation Forest 动态滑动窗口方法 (IForest ASD)、精确风暴 (ES)、角度异常检测 (ABOD)、局部异常因子 (LOF)、Kitsunes 在线算法 (KitNet) 和 K-最近邻保形密度与距离 (KNN CAD) 在内的 8 种不同的最先进的异常检测模型。

Result: 在金融和医疗预测任务（包括信用卡欺诈检测、客户流失预测、以太坊欺诈检测、心脏中风预测和糖尿病预测）上评估了所提出的框架。结果表明，增量学习框架显著提高了性能，尤其是在高度不平衡的数据集上。

Conclusion: 增量学习框架在处理高度不平衡数据集时显著提高了性能，其中 Isolation Forest ASD 模型在各种数据集上表现出卓越的有效性，持续位列最佳性能模型前三名。

Abstract: In the era of real-time data, traditional methods often struggle to keep pace
with the dynamic nature of streaming environments. In this paper, we proposed a
hybrid framework where in (i) stage-I follows a traditional approach where the
model is built once and evaluated in a real-time environment, and (ii) stage-II
employs an incremental learning approach where the model is continuously
retrained as new data arrives, enabling it to adapt and stay up to date. To
implement these frameworks, we employed 8 distinct state-of-the-art outlier
detection models, including one-class support vector machine (OCSVM), isolation
forest adaptive sliding window approach (IForest ASD), exact storm (ES),
angle-based outlier detection (ABOD), local outlier factor (LOF), Kitsunes
online algorithm (KitNet), and K-nearest neighbour conformal density and
distance based (KNN CAD). We evaluated the performance of these models across
seven financial and healthcare prediction tasks, including credit card fraud
detection, churn prediction, Ethereum fraud detection, heart stroke prediction,
and diabetes prediction. The results indicate that our proposed incremental
learning framework significantly improves performance, particularly on highly
imbalanced datasets. Among all models, the IForest ASD model consistently
ranked among the top three best-performing models, demonstrating superior
effectiveness across various datasets.

</details>


### [129] [Enhancing Customer Contact Efficiency with Graph Neural Networks in Credit Card Fraud Detection Workflow](https://arxiv.org/abs/2504.02275)
*Menghao Huo,Kuan Lu,Qiang Zhu,Zhenrui Chen*

Main category: cs.LG

TL;DR: RGCN 框架通过利用交易数据的关系结构，在信用卡欺诈检测方面取得了更好的效果，减少了误报。


<details>
  <summary>Details</summary>
Motivation: 解决现有信用卡欺诈检测系统误报率高，导致用户体验不佳和客户信任度下降的问题。

Method: 提出了一种结合关系图卷积网络（RGCN）的欺诈检测框架，以提高欺诈交易识别的准确性和效率。

Result: 通过利用交易数据的关系结构，该模型在保持高检测性能的同时，减少了对客户直接确认的需求，并通过 IBM 信用卡交易数据集的实验进行了评估。

Conclusion: 该研究提出的 RGCN 框架通过利用交易数据的关系结构，在提高欺诈检测准确性和效率方面取得了成功，同时减少了对客户确认的依赖。

Abstract: Credit card fraud has been a persistent issue since the last century, causing
significant financial losses to the industry. The most effective way to prevent
fraud is by contacting customers to verify suspicious transactions. However,
while these systems are designed to detect fraudulent activity, they often
mistakenly flag legitimate transactions, leading to unnecessary declines that
disrupt the user experience and erode customer trust. Frequent false positives
can frustrate customers, resulting in dissatisfaction, increased complaints,
and a diminished sense of security. To address these limitations, we propose a
fraud detection framework incorporating Relational Graph Convolutional Networks
(RGCN) to enhance the accuracy and efficiency of identifying fraudulent
transactions. By leveraging the relational structure of transaction data, our
model reduces the need for direct customer confirmation while maintaining high
detection performance. Our experiments are conducted using the IBM credit card
transaction dataset to evaluate the effectiveness of this approach.

</details>


### [130] [Advances in Continual Graph Learning for Anti-Money Laundering Systems: A Comprehensive Review](https://arxiv.org/abs/2503.24259)
*Bruno Deprez,Wei Wei,Wouter Verbeke,Bart Baesens,Kevin Mets,Tim Verdonck*

Main category: cs.LG

TL;DR: 本篇综述评估了用于反洗钱（AML）的国家级持续图学习方法，并展示了持续学习在提高模型适应性和鲁棒性方面的优势。


<details>
  <summary>Details</summary>
Motivation: 由于洗钱者不断调整其策略以逃避检测，因此需要对模型进行持续的微调。然而，传统的机器学习模型在用新数据微调时会发生灾难性遗忘。持续学习方法可以通过允许模型在保留先验知识的同时整合新信息来解决此问题，从而增强当前的 AML 实践。

Method: 对基于重放、基于正则化和基于架构的策略进行了分类，并在合成和真实世界的 AML 数据集上进行了详细的实验评估。

Result: 持续学习提高了模型在面对极端类别不平衡和不断变化的欺诈模式时的适应性和鲁棒性。

Conclusion: 本篇综述评估了用于反洗钱（AML）的国家级持续图学习方法。

Abstract: Financial institutions are required by regulation to report suspicious
financial transactions related to money laundering. Therefore, they need to
constantly monitor vast amounts of incoming and outgoing transactions. A
particular challenge in detecting money laundering is that money launderers
continuously adapt their tactics to evade detection. Hence, detection methods
need constant fine-tuning. Traditional machine learning models suffer from
catastrophic forgetting when fine-tuning the model on new data, thereby
limiting their effectiveness in dynamic environments. Continual learning
methods may address this issue and enhance current anti-money laundering (AML)
practices, by allowing models to incorporate new information while retaining
prior knowledge. Research on continual graph learning for AML, however, is
still scarce. In this review, we critically evaluate state-of-the-art continual
graph learning approaches for AML applications. We categorise methods into
replay-based, regularization-based, and architecture-based strategies within
the graph neural network (GNN) framework, and we provide in-depth experimental
evaluations on both synthetic and real-world AML data sets that showcase the
effect of the different hyperparameters. Our analysis demonstrates that
continual learning improves model adaptability and robustness in the face of
extreme class imbalances and evolving fraud patterns. Finally, we outline key
challenges and propose directions for future research.

</details>


### [131] [A Data Balancing and Ensemble Learning Approach for Credit Card Fraud Detection](https://arxiv.org/abs/2503.21160)
*Yuhan Wang*

Main category: cs.LG

TL;DR: 本研究提出了一种结合SMOTE-KMEANS和集成机器学习模型的新方法，用于信用卡欺诈检测，取得了比传统模型更高的准确率（AUC为0.96），并探讨了过采样技术对分类器性能的影响。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在通过结合SMOTE-KMEANS技术和集成机器学习模型来改进信用ka卡欺诈的识别方法，以提高欺诈交易的检测效率和准确性。

Method: 本研究提出了一种创新的信用ka卡欺诈识别方法，该方法结合了SMOTE-KMEANS技术和集成机器学习模型。

Result: 提出的模型与逻辑回归、决策树、随机森林和支持向量机等传统模型进行了基准测试。结果显示，结合SMOTE-KMEANS算法后，所提出的模型达到了0.96的AUC，表现出优越的性能，显著提高了欺诈检测能力，并保持了高精度和召回率。

Conclusion: 研究结果表明，所提出的结合SMOTE-KMEANS算法和集成机器学习模型的方法在处理不平衡数据集的分类任务方面表现稳健且有效，能够显著提高欺诈交易的检测能力，同时保持高精度和召回率。未来研究将进一步优化SMOTE-KMEANS方法并将其整合到现有的欺诈检测系统中。

Abstract: This research introduces an innovative method for identifying credit card
fraud by combining the SMOTE-KMEANS technique with an ensemble machine learning
model. The proposed model was benchmarked against traditional models such as
logistic regression, decision trees, random forests, and support vector
machines. Performance was evaluated using metrics, including accuracy, recall,
and area under the curve (AUC). The results demonstrated that the proposed
model achieved superior performance, with an AUC of 0.96 when combined with the
SMOTE-KMEANS algorithm. This indicates a significant improvement in detecting
fraudulent transactions while maintaining high precision and recall. The study
also explores the application of different oversampling techniques to enhance
the performance of various classifiers. The findings suggest that the proposed
method is robust and effective for classification tasks on balanced datasets.
Future research directions include further optimization of the SMOTE-KMEANS
approach and its integration into existing fraud detection systems to enhance
financial security and consumer protection.

</details>


### [132] [Unsupervised Detection of Fraudulent Transactions in E-commerce Using Contrastive Learning](https://arxiv.org/abs/2503.18841)
*Xuan Li,Yuting Peng,Xiaoxuan Sun,Yifei Duan,Zhou Fang,Tengda Tang*

Main category: cs.LG

TL;DR: 本研究提出了一种基于SimCLR的无监督欺诈检测方法，通过对比学习有效识别电子商务欺诈行为，并在实验中超越了传统无监督方法。


<details>
  <summary>Details</summary>
Motivation: 传统监督学习方法在欺诈检测中需要大量标注数据，而这些数据难以获取，并且欺诈行为的不断演变降低了传统方法的适应性和有效性。为了解决这个问题，本研究提出了一种无监督学习方法。

Method: 本研究提出了一种基于SimCLR的无监督电子商务欺诈检测算法，利用对比学习框架在无标签环境下学习交易数据的底层表示，从而有效检测欺诈行为。

Result: 实验结果表明，所提出的基于SimCLR的无监督算法在准确率、精确率、召回率和F1分数方面优于K-means、Isolation Forest和Autoencoders等传统无监督方法，证明了其强大的欺诈检测能力。

Conclusion: 该研究提出了一个基于SimCLR的无监督电子商务欺诈检测算法，并在eBay数据集上进行了实验验证。结果表明，与K-means、Isolation Forest和Autoencoders等传统无监督方法相比，该算法在准确率、精确率、召回率和F1分数方面均表现更优，展现出强大的欺诈检测能力。该方法在电子商务平台安全方面具有广阔的应用前景，能够提高检测准确性和鲁棒性。未来，该模型有望与实时监控系统集成，为电子商务平台提供更高效的安全保障。

Abstract: With the rapid development of e-commerce, e-commerce platforms are facing an
increasing number of fraud threats. Effectively identifying and preventing
these fraudulent activities has become a critical research problem. Traditional
fraud detection methods typically rely on supervised learning, which requires
large amounts of labeled data. However, such data is often difficult to obtain,
and the continuous evolution of fraudulent activities further reduces the
adaptability and effectiveness of traditional methods. To address this issue,
this study proposes an unsupervised e-commerce fraud detection algorithm based
on SimCLR. The algorithm leverages the contrastive learning framework to
effectively detect fraud by learning the underlying representations of
transaction data in an unlabeled setting. Experimental results on the eBay
platform dataset show that the proposed algorithm outperforms traditional
unsupervised methods such as K-means, Isolation Forest, and Autoencoders in
terms of accuracy, precision, recall, and F1 score, demonstrating strong fraud
detection capabilities. The results confirm that the SimCLR-based unsupervised
fraud detection method has broad application prospects in e-commerce platform
security, improving both detection accuracy and robustness. In the future, with
the increasing scale and diversity of datasets, the model's performance will
continue to improve, and it could be integrated with real-time monitoring
systems to provide more efficient security for e-commerce platforms.

</details>


### [133] [Enhance GNNs with Reliable Confidence Estimation via Adversarial Calibration Learning](https://arxiv.org/abs/2503.18235)
*Yilong Wang,Jiahao Zhang,Tianxiang Zhao,Suhang Wang*

Main category: cs.LG

TL;DR: GNN校准方法在不同节点组上泛化能力差，AdvCali框架通过对抗性训练和Group ECE损失自适应提升节点组校准，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络（GNN）校准方法虽然能改善整体校准，但往往难以在具有不同度级别、类别和局部结构的节点组之间泛化，甚至可能导致校准性能下降，这在高风险应用中会引发对GNN可靠性的担忧。

Method: 提出了一种名为AdvCali的新颖框架，该框架利用对抗性训练来自动识别校准不良的节点组，并采用可微分的Group Expected Calibration Error（ECE）损失项来优化这些组内的置信度估计。

Result: 实验证明，AdvCali框架不仅能改善全局校准，还能显著增强按特征相似性、拓扑结构和连通性定义的节点组内的校准性能，并且在实际场景中表现出有效性。

Conclusion: AdvCali框架通过利用对抗性训练和可微分的Group Expected Calibration Error（ECE）损失项，能够自适应地提升不同节点组的校准性能，并在全局校准和节点分组校准方面均优于现有方法。

Abstract: Despite their impressive predictive performance, GNNs often exhibit poor
confidence calibration, i.e., their predicted confidence scores do not
accurately reflect true correctness likelihood. This issue raises concerns
about their reliability in high-stakes domains such as fraud detection, and
risk assessment, where well-calibrated predictions are essential for
decision-making. To ensure trustworthy predictions, several GNN calibration
methods are proposed. Though they can improve global calibration, our
experiments reveal that they often fail to generalize across different node
groups, leading to inaccurate confidence in node groups with different degree
levels, classes, and local structures. In certain cases, they even degrade
calibration compared to the original uncalibrated GNN. To address this
challenge, we propose a novel AdvCali framework that adaptively enhances
calibration across different node groups. Our method leverages adversarial
training to automatically identify mis-calibrated node groups and applies a
differentiable Group Expected Calibration Error (ECE) loss term to refine
confidence estimation within these groups. This allows the model to dynamically
adjust its calibration strategy without relying on dataset-specific prior
knowledge about miscalibrated subgroups. Extensive experiments on real-world
datasets demonstrate that our approach not only improves global calibration but
also significantly enhances calibration within groups defined by feature
similarity, topology, and connectivity, outperforming previous methods and
demonstrating its effectiveness in practical scenarios.

</details>


### [134] [TeMP-TraG: Edge-based Temporal Message Passing in Transaction Graphs](https://arxiv.org/abs/2503.16901)
*Steve Gounoue,Ashutosh Sao,Simon Gottschalk*

Main category: cs.LG

TL;DR: TeMP-TraG 是一种新的图神经网络，可提高检测金融犯罪的交易图分析能力。


<details>
  <summary>Details</summary>
Motivation: 为了应对交易图（包括丰富的边特征、多图结构和时间动态）在节点和边分类中检测金融犯罪（如洗钱和欺诈）所带来的独特挑战。

Method: 提出了一种名为 TeMP-TraG 的新颖图神经网络机制，该机制将时间动态整合到消息传递中，并优先聚合近期交易的消息。

Result: TeMP-TraG 在四个最先进的图神经网络上平均提高了 6.19% 的性能，证明了其在利用交易图打击金融犯罪方面的有效性。

Conclusion: TeMP-TraG 是一种先进的图神经网络机制，通过整合时间动态和优先考虑近期交易，在检测金融犯罪方面取得了显著进展。

Abstract: Transaction graphs, which represent financial and trade transactions between
entities such as bank accounts and companies, can reveal patterns indicative of
financial crimes like money laundering and fraud. However, effective detection
of such cases requires node and edge classification methods capable of
addressing the unique challenges of transaction graphs, including rich edge
features, multigraph structures and temporal dynamics. To tackle these
challenges, we propose TeMP-TraG, a novel graph neural network mechanism that
incorporates temporal dynamics into message passing. TeMP-TraG prioritises more
recent transactions when aggregating node messages, enabling better detection
of time-sensitive patterns. We demonstrate that TeMP-TraG improves four
state-of-the-art graph neural networks by 6.19% on average. Our results
highlight TeMP-TraG as an advancement in leveraging transaction graphs to
combat financial crime.

</details>


### [135] [A Label-Free Heterophily-Guided Approach for Unsupervised Graph Fraud Detection](https://arxiv.org/abs/2502.13308)
*Junjun Pan,Yixin Liu,Xin Zheng,Yizhen Zheng,Alan Wee-Chung Liew,Fuyi Li,Shirui Pan*

Main category: cs.LG

TL;DR: HUGE是一种用于无监督图欺诈检测（GFD）的新方法，通过其异质性估计模块（包含新的HALO度量）和基于对齐的欺诈检测模块（具有排序损失和非对称对齐损失），有效地处理了标签稀疏性和复杂异质性模式的挑战，并在实验中表现出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管现有的监督图欺诈检测（GFD）方法表现出有希望的性能，但它们对标签的依赖限制了它们在无监督场景中的应用。此外，在没有标签的情况下准确捕捉复杂多样的异质性模式带来了进一步的挑战。

Method: HUGE包含两个关键组件：一个异质性估计模块和一个基于对齐的欺诈检测模块。异质性估计模块设计了一种新的无标签异质性度量HALO，它捕捉了GFD的关键图属性，并能从节点属性中估计异质性。基于对齐的欺诈检测模块开发了一个联合MLP-GNN架构，并结合了排序损失和非对称对齐损失。排序损失将预测的欺诈分数与HALO的相对顺序对齐，通过比较非邻近节点之间的异质性来提供额外的鲁棒性保证。非对称对齐损失有效地利用了结构信息，同时减轻了GNN的特征平滑效应。

Result: HUGE在6个数据集上的广泛实验表明，其性能显著优于现有方法，证明了其有效性和鲁棒性。

Conclusion: HUGE在6个数据集上的广泛实验表明，其性能显著优于现有方法，证明了其有效性和鲁棒性。

Abstract: Graph fraud detection (GFD) has rapidly advanced in protecting online
services by identifying malicious fraudsters. Recent supervised GFD research
highlights that heterophilic connections between fraudsters and users can
greatly impact detection performance, since fraudsters tend to camouflage
themselves by building more connections to benign users. Despite the promising
performance of supervised GFD methods, the reliance on labels limits their
applications to unsupervised scenarios; Additionally, accurately capturing
complex and diverse heterophily patterns without labels poses a further
challenge. To fill the gap, we propose a Heterophily-guided Unsupervised Graph
fraud dEtection approach (HUGE) for unsupervised GFD, which contains two
essential components: a heterophily estimation module and an alignment-based
fraud detection module. In the heterophily estimation module, we design a novel
label-free heterophily metric called HALO, which captures the critical graph
properties for GFD, enabling its outstanding ability to estimate heterophily
from node attributes. In the alignment-based fraud detection module, we develop
a joint MLP-GNN architecture with ranking loss and asymmetric alignment loss.
The ranking loss aligns the predicted fraud score with the relative order of
HALO, providing an extra robustness guarantee by comparing heterophily among
non-adjacent nodes. Moreover, the asymmetric alignment loss effectively
utilizes structural information while alleviating the feature-smooth effects of
GNNs. Extensive experiments on 6 datasets demonstrate that HUGE significantly
outperforms competitors, showcasing its effectiveness and robustness.

</details>


### [136] [Scam Detection for Ethereum Smart Contracts: Leveraging Graph Representation Learning for Secure Blockchain](https://arxiv.org/abs/2412.12370)
*Yihong Jin,Ze Yang,Xinhe Xu*

Main category: cs.LG

TL;DR: 本研究利用图表示学习技术来检测以太坊智能合约中的欺诈交易。通过将交易数据表示为图并应用机器学习模型，研究旨在提高检测的准确性和可靠性。结果表明，MLP 模型在处理样本不平衡问题时优于 GCN 模型。


<details>
  <summary>Details</summary>
Motivation: 当前以太坊智能合约的攻击增多，严重影响了金融和信誉。现有的反欺诈检测技术（包括代码解析或手动特征提取）仍然存在一些缺点，尽管可以获得一些泛化性或适应性。

Method: 本研究提出使用图表示学习技术来寻找交易模式和区分恶意交易合约，即将以太坊交易数据表示为图，然后使用先进的机器学习技术获得可靠和准确的结果。考虑到样本不平衡问题，我们采用了SMOTE-ENN方法，并测试了几种模型。

Result: 在测试的 several models 中，MLP 的表现优于 GCN，但确切效果取决于其实际应用。

Conclusion: 本研究为以太坊生态系统的信任和安全开辟了更多可能性。

Abstract: As more and more attacks have been detected on Ethereum smart contracts, it
has seriously affected finance and credibility. Current anti-fraud detection
techniques, including code parsing or manual feature extraction, still have
some shortcomings, although some generalization or adaptability can be
obtained. In the face of this situation, this paper proposes to use graphical
representation learning technology to find transaction patterns and distinguish
malicious transaction contracts, that is, to represent Ethereum transaction
data as graphs, and then use advanced ML technology to obtain reliable and
accurate results. Taking into account the sample imbalance, we treated with
SMOTE-ENN and tested several models, in which MLP performed better than GCN,
but the exact effect depends on its field trials. Our research opens up more
possibilities for trust and security in the Ethereum ecosystem.

</details>


### [137] [Deep Learning Advancements in Anomaly Detection: A Comprehensive Survey](https://arxiv.org/abs/2503.13195)
*Haoqi Huang,Ping Wang,Jianhua Pei,Jiacheng Wang,Shahen Alexanian,Dusit Niyato*

Main category: cs.LG

TL;DR: 本次调查全面回顾了 180 多项关于利用深度学习进行异常检测的研究，重点介绍了基于重建和预测的方法以及混合方法。它还讨论了开放性问题和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 数据来自不同来源的快速扩展使得异常检测（AD）在识别可能预示系统故障、安全漏洞或欺诈的意外观察结果方面变得越来越重要。随着数据集变得越来越复杂和高维，传统的检测方法在有效捕获复杂模式方面遇到了困难。深度学习的进步使异常检测方法更加强大和适应性更强，提高了它们处理高维和非结构化数据的能力。

Method: 本调查对 180 多项最新研究进行了全面的回顾，重点关注基于深度学习的异常检测技术。我们将这些方法分为基于重建和基于预测的方法，并探讨了传统方法与深度学习方法的集成。

Result: 对基于深度学习的异常检测技术进行了分类和分析，重点是它们在模拟复杂数据分布方面的有效性。此外，还探讨了传统和深度学习方法的一体化，并强调了混合方法如何将传统技术的解释性与深度学习的灵活性相结合，以提高检测准确性和模型透明度。

Conclusion: 本次调查为现有文献中的空白提供了桥梁，并为寻求利用深度学习增强异常检测技术的研究人员和从业人员提供了宝贵的资源。

Abstract: The rapid expansion of data from diverse sources has made anomaly detection
(AD) increasingly essential for identifying unexpected observations that may
signal system failures, security breaches, or fraud. As datasets become more
complex and high-dimensional, traditional detection methods struggle to
effectively capture intricate patterns. Advances in deep learning have made AD
methods more powerful and adaptable, improving their ability to handle
high-dimensional and unstructured data. This survey provides a comprehensive
review of over 180 recent studies, focusing on deep learning-based AD
techniques. We categorize and analyze these methods into reconstruction-based
and prediction-based approaches, highlighting their effectiveness in modeling
complex data distributions. Additionally, we explore the integration of
traditional and deep learning methods, highlighting how hybrid approaches
combine the interpretability of traditional techniques with the flexibility of
deep learning to enhance detection accuracy and model transparency. Finally, we
identify open issues and propose future research directions to advance the
field of AD. This review bridges gaps in existing literature and serves as a
valuable resource for researchers and practitioners seeking to enhance AD
techniques using deep learning.

</details>


### [138] [Unsupervised Graph Anomaly Detection via Multi-Hypersphere Heterophilic Graph Learning](https://arxiv.org/abs/2503.12037)
*Hang Ni,Jindong Han,Nengjun Zhu,Hao Liu*

Main category: cs.LG

TL;DR: 提出了一种名为多超球异质图学习（MHetGL）的框架，用于无监督图异常检测，解决了现有方法忽视局部图上下文和未能学习区分性嵌入的问题，并在实验中表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有的基于GNN的方法遵循同质性原理，未能学习到区分性嵌入，并且忽视了局部图上下文的异常模式，导致性能不佳。

Method: 提出了一种名为多超球异质图学习（MHetGL）的框架，该框架包含异质图编码（HGE）模块和多超球学习（MHL）模块，用于无监督图异常检测。HGE模块旨在学习潜在异常值的可区分表示，而MHL模块旨在通过结合全局和局部两种视角来增强对上下文相关异常值的检测能力。

Result: MHetGL outperforms 14 baselines on ten real-world datasets.

Conclusion: MHetGL在十个真实世界的数据集上表现优于14个基线模型

Abstract: Graph Anomaly Detection (GAD) plays a vital role in various data mining
applications such as e-commerce fraud prevention and malicious user detection.
Recently, Graph Neural Network (GNN) based approach has demonstrated great
effectiveness in GAD by first encoding graph data into low-dimensional
representations and then identifying anomalies under the guidance of supervised
or unsupervised signals. However, existing GNN-based approaches implicitly
follow the homophily principle (i.e., the "like attracts like" phenomenon) and
fail to learn discriminative embedding for anomalies that connect vast normal
nodes. Moreover, such approaches identify anomalies in a unified global
perspective but overlook diversified abnormal patterns conditioned on local
graph context, leading to suboptimal performance. To overcome the
aforementioned limitations, in this paper, we propose a Multi-hypersphere
Heterophilic Graph Learning (MHetGL) framework for unsupervised GAD.
Specifically, we first devise a Heterophilic Graph Encoding (HGE) module to
learn distinguishable representations for potential anomalies by purifying and
augmenting their neighborhood in a fully unsupervised manner. Then, we propose
a Multi-Hypersphere Learning (MHL) module to enhance the detection capability
for context-dependent anomalies by jointly incorporating critical patterns from
both global and local perspectives. Extensive experiments on ten real-world
datasets show that MHetGL outperforms 14 baselines. Our code is publicly
available at https://github.com/KennyNH/MHetGL.

</details>


### [139] [Financial Fraud Detection with Entropy Computing](https://arxiv.org/abs/2503.11273)
*Babak Emami,Wesley Dyk,David Haycraft,Carrie Spear,Lac Nguyen,Nicholas Chancellor*

Main category: cs.LG

TL;DR: CVQBoost 是一种新的量子计算分类算法，在欺诈检测方面比 XGBoost 更快、更具可扩展性，准确性相当。


<details>
  <summary>Details</summary>
Motivation: 介绍一种新的分类算法 CVQBoost，并将其与 XGBoost 在欺诈检测任务上进行性能基准测试，特别关注运行时和可扩展性。

Method: CVQBoost 算法，该算法利用了 Quantum Computing Inc. 的熵量子计算（EQC）范式，并在 Dirac-3 硬件上运行。

Result: CVQBoost 在 Dirac-3 硬件上运行，在准确性（AUC）方面与 XGBoost 相当，但训练时间显著减少，尤其是在数据集规模和特征复杂度增加时。它在大规模合成数据集（100 万到 7000 万个样本）上表现出良好的可扩展性。

Conclusion: CVQBoost 是一种有前途的分类算法，在处理高维机器学习应用（如欺诈检测）方面，与传统的梯度提升方法相比，具有卓越的可扩展性和效率。

Abstract: We introduce CVQBoost, a novel classification algorithm that leverages early
hardware implementing Quantum Computing Inc's Entropy Quantum Computing (EQC)
paradigm, Dirac-3 [Nguyen et. al. arXiv:2407.04512]. We apply CVQBoost to a
fraud detection test case and benchmark its performance against XGBoost, a
widely utilized ML method. Running on Dirac-3, CVQBoost demonstrates a
significant runtime advantage over XGBoost, which we evaluate on
high-performance hardware comprising up to 48 CPUs and four NVIDIA L4 GPUs
using the RAPIDS AI framework. Our results show that CVQBoost maintains
competitive accuracy (measured by AUC) while significantly reducing training
time, particularly as dataset size and feature complexity increase. To assess
scalability, we extend our study to large synthetic datasets ranging from 1M to
70M samples, demonstrating that CVQBoost on Dirac-3 is well-suited for
large-scale classification tasks. These findings position CVQBoost as a
promising alternative to gradient boosting methods, offering superior
scalability and efficiency for high-dimensional ML applications such as fraud
detection.

</details>


### [140] [Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions](https://arxiv.org/abs/2503.10058)
*Jiani Fan,Lwin Khin Shar,Ruichen Zhang,Ziyao Liu,Wenzhuo Yang,Dusit Niyato,Bomin Mao,Kwok-Yan Lam*

Main category: cs.LG

TL;DR: 本文综述了深度学习在反洗钱中的应用，并提出了一个利用机器学习、反洗钱规则和账户画像的新框架，以解决数据稀缺问题并提高欺诈检测能力。


<details>
  <summary>Details</summary>
Motivation: 随着移动支付和智能物联网设备的普及，金融科技领域的反洗钱（AML）调查面临日益严峻的挑战。交易模式的复杂性和不可预测性增加了误报率，而现有的AML机器学习方法在处理大规模、异构的交易数据以及应对数据隐私和可用性限制方面存在不足。特别是，对具有巨大潜力的深度学习技术的研究尚不深入。

Method: 本研究通过文献综述，深入探讨了深度学习技术在反洗钱领域的应用和相关挑战。此外，我们提出了一个创新的框架，该框架运用最小特权原则，整合了机器学习技术，明确了反洗钱的危险信号，并通过账户画像提供预测的背景信息。

Result: 本论文对深度学习在反洗钱领域的应用进行了全面的回顾，并提出了一个旨在克服数据稀疏性挑战的新颖框架，通过整合机器学习、反洗钱危险信号和账户画像来提高欺诈检测的有效性。

Conclusion: 本论文全面回顾了深度学习在反洗钱（AML）领域的应用及其挑战，并提出了一个结合机器学习、反洗钱危险信号以及账户画像的新颖框架，以在数据可用性受限的情况下实现有效的欺诈检测。

Abstract: Money laundering is a financial crime that obscures the origin of illicit
funds, necessitating the development and enforcement of anti-money laundering
(AML) policies by governments and organizations. The proliferation of mobile
payment platforms and smart IoT devices has significantly complicated AML
investigations. As payment networks become more interconnected, there is an
increasing need for efficient real-time detection to process large volumes of
transaction data on heterogeneous payment systems by different operators such
as digital currencies, cryptocurrencies and account-based payments. Most of
these mobile payment networks are supported by connected devices, many of which
are considered loT devices in the FinTech space that constantly generate data.
Furthermore, the growing complexity and unpredictability of transaction
patterns across these networks contribute to a higher incidence of false
positives. While machine learning solutions have the potential to enhance
detection efficiency, their application in AML faces unique challenges, such as
addressing privacy concerns tied to sensitive financial data and managing the
real-world constraint of limited data availability due to data regulations.
Existing surveys in the AML literature broadly review machine learning
approaches for money laundering detection, but they often lack an in-depth
exploration of advanced deep learning techniques - an emerging field with
significant potential. To address this gap, this paper conducts a comprehensive
review of deep learning solutions and the challenges associated with their use
in AML. Additionally, we propose a novel framework that applies the
least-privilege principle by integrating machine learning techniques, codifying
AML red flags, and employing account profiling to provide context for
predictions and enable effective fraud detection under limited data
availability....

</details>


### [141] [Evidential Uncertainty Probes for Graph Neural Networks](https://arxiv.org/abs/2503.08097)
*Linlin Yu,Kangshuo Li,Pritom Kumar Saha,Yifei Lou,Feng Chen*

Main category: cs.LG

TL;DR: 提出了一种即插即用的EPN框架，可以与预训练模型结合使用，无需重新训练，通过MLP提取证据，并结合EPN-reg正则化技术，能够准确高效地量化不确定性。


<details>
  <summary>Details</summary>
Motivation: 在药物发现和金融欺诈检测等高风险应用中，准确量化随机不确定性和认知不确定性至关重要，而现有的EGNN模型需要修改网络架构和重新训练，无法利用预训练模型。

Method: 提出了一种即插即用的框架EPN，通过轻量级MLP头从学习到的表示中提取证据，无需对预训练模型进行修改或重新训练，并引入了基于证据的正则化技术EPN-reg来增强对认知不确定性的估计。

Result: 实验证明，EPN-reg在准确性和效率方面达到了最先进的不确定性量化性能。

Conclusion: 提出的EPN-reg框架能够准确且高效地进行不确定性量化，适用于实际部署。

Abstract: Accurate quantification of both aleatoric and epistemic uncertainties is
essential when deploying Graph Neural Networks (GNNs) in high-stakes
applications such as drug discovery and financial fraud detection, where
reliable predictions are critical. Although Evidential Deep Learning (EDL)
efficiently quantifies uncertainty using a Dirichlet distribution over
predictive probabilities, existing EDL-based GNN (EGNN) models require
modifications to the network architecture and retraining, failing to take
advantage of pre-trained models. We propose a plug-and-play framework for
uncertainty quantification in GNNs that works with pre-trained models without
the need for retraining. Our Evidential Probing Network (EPN) uses a
lightweight Multi-Layer-Perceptron (MLP) head to extract evidence from learned
representations, allowing efficient integration with various GNN architectures.
We further introduce evidence-based regularization techniques, referred to as
EPN-reg, to enhance the estimation of epistemic uncertainty with theoretical
justifications. Extensive experiments demonstrate that the proposed EPN-reg
achieves state-of-the-art performance in accurate and efficient uncertainty
quantification, making it suitable for real-world deployment.

</details>


### [142] [Enhancing Fairness in Unsupervised Graph Anomaly Detection through Disentanglement](https://arxiv.org/abs/2406.00987)
*Wenjing Chang,Kay Liu,Philip S. Yu,Jianjun Yu*

Main category: cs.LG

TL;DR: DEFEND 是一个新颖的、基于解纠缠的公平感知图异常检测框架，它通过解纠缠 GNN 表示、基于重建的异常检测以及约束重建误差与敏感属性之间的相关性来解决 GAD 中的公平性问题，并在真实数据集上取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的图异常检测方法在很大程度上忽略了公平性问题，可能导致歧视性决策偏向某些基于敏感属性（如性别、宗教、种族等）的人口统计群体，这在现实世界的应用中受到社会和伦理的限制。本研究旨在解决这一关键问题，首次尝试将公平性与效用相结合，以解决图异常检测的决策问题。

Method: DEFEND 框架通过以下方式集成公平性与效用：1. 在 GNN 中引入解纠缠，以捕获信息性但与敏感属性无关的节点表示，从而有效减少图表示学习中固有的社会偏见。2. 采用基于重建的异常检测方法，仅关注节点属性而不考虑图结构，以减轻评估异常节点时的歧视性偏见。3. 约束重建误差与预测的敏感属性之间的相关性，以应对输入与敏感属性之间的固有联系。

Result: DEFEND 在真实世界数据集上的实证评估表明，其在图异常检测方面表现有效，并显著提高了公平性，优于最先进的基线。

Conclusion: DEFEND 在图异常检测方面表现有效，并显著提高了公平性，优于最先进的基线。

Abstract: Graph anomaly detection (GAD) is increasingly crucial in various
applications, ranging from financial fraud detection to fake news detection.
However, current GAD methods largely overlook the fairness problem, which might
result in discriminatory decisions skewed toward certain demographic groups
defined on sensitive attributes (e.g., gender, religion, ethnicity, etc.). This
greatly limits the applicability of these methods in real-world scenarios in
light of societal and ethical restrictions. To address this critical gap, we
make the first attempt to integrate fairness with utility in GAD
decision-making. Specifically, we devise a novel DisEntangle-based
FairnEss-aware aNomaly Detection framework on the attributed graph, named
DEFEND. DEFEND first introduces disentanglement in GNNs to capture informative
yet sensitive-irrelevant node representations, effectively reducing societal
bias inherent in graph representation learning. Besides, to alleviate
discriminatory bias in evaluating anomalous nodes, DEFEND adopts a
reconstruction-based anomaly detection, which concentrates solely on node
attributes without incorporating any graph structure. Additionally, given the
inherent association between input and sensitive attributes, DEFEND constrains
the correlation between the reconstruction error and the predicted sensitive
attributes. Our empirical evaluations on real-world datasets reveal that DEFEND
performs effectively in GAD and significantly enhances fairness compared to
state-of-the-art baselines. To foster reproducibility, our code is available at
https://github.com/AhaChang/DEFEND.

</details>


### [143] [Effective High-order Graph Representation Learning for Credit Card Fraud Detection](https://arxiv.org/abs/2503.01556)
*Yao Zou,Dawei Cheng*

Main category: cs.LG

TL;DR: HOGRL is a novel model that effectively detects credit card fraud by learning pure representations from high-order transaction graphs, overcoming the limitations of existing GNN models in identifying disguised multi-hop transactions.


<details>
  <summary>Details</summary>
Motivation: Existing graph neural network (GNN) models struggle with learning features of camouflaged, indirect multi-hop transactions due to over-smoothing issues, presenting a challenge in detecting disguised relationships.

Method: HOGRL learns different orders of pure representations directly from high-order transaction graphs by constructing high-order transaction graphs and learning pure representations of each order. It utilizes a mixture-of-expert attention mechanism to determine the importance of different orders for optimizing fraud detection.

Result: HOGRL achieves significant improvements compared with state-of-the-art fraud detection baselines in both open source and real-world datasets.

Conclusion: HOGRL's superior performance proves its effectiveness in addressing high-order fraud camouflage criminals.

Abstract: Credit card fraud imposes significant costs on both cardholders and issuing
banks. Fraudsters often disguise their crimes, such as using legitimate
transactions through several benign users to bypass anti-fraud detection.
Existing graph neural network (GNN) models struggle with learning features of
camouflaged, indirect multi-hop transactions due to their inherent
over-smoothing issues in deep multi-layer aggregation, presenting a major
challenge in detecting disguised relationships. Therefore, in this paper, we
propose a novel High-order Graph Representation Learning model (HOGRL) to avoid
incorporating excessive noise during the multi-layer aggregation process. In
particular, HOGRL learns different orders of \emph{pure} representations
directly from high-order transaction graphs. We realize this goal by
effectively constructing high-order transaction graphs first and then learning
the \emph{pure} representations of each order so that the model could identify
fraudsters' multi-hop indirect transactions via multi-layer \emph{pure} feature
learning. In addition, we introduce a mixture-of-expert attention mechanism to
automatically determine the importance of different orders for jointly
optimizing fraud detection performance. We conduct extensive experiments in
both the open source and real-world datasets, the result demonstrates the
significant improvements of our proposed HOGRL compared with state-of-the-art
fraud detection baselines. HOGRL's superior performance also proves its
effectiveness in addressing high-order fraud camouflage criminals.

</details>


### [144] [A Survey on Diffusion Models for Anomaly Detection](https://arxiv.org/abs/2501.11430)
*Jing Liu,Zhenchao Ma,Zepu Wang,Chenxuanyin Zou,Jiayang Ren,Zehua Wang,Liang Song,Bo Hu,Yang Liu,Victor C. M. Leung*

Main category: cs.LG

TL;DR: Diffusion models are great for anomaly detection (DMAD). This survey covers DMAD methods, challenges, and future work.


<details>
  <summary>Details</summary>
Motivation: To provide a comprehensive review of recent advances in diffusion models for anomaly detection (DMAD), given their growing potential in various domains.

Method: This paper surveys recent advances in diffusion models for anomaly detection (DMAD). It covers fundamental concepts of AD and DMs, analyzes classic DM architectures (DDPMs, DDIMs, Score SDEs), categorizes DMAD methods (reconstruction-based, density-based, hybrid), explores applications across data modalities (image, time series, video, multimodal), and discusses challenges and future research directions.

Result: The survey provides a detailed examination of DMAD methods, tasks, challenges, and future research directions, offering a valuable resource for researchers in the field. A collection of papers and resources is available at https://github.com/fdjingliu/DMAD.

Conclusion: Diffusion models (DMs) are a powerful tool for anomaly detection (AD), especially in complex, high-dimensional data. This survey categorizes DMAD methods into reconstruction-based, density-based, and hybrid approaches, and discusses challenges like efficiency and interpretability, alongside future directions such as edge-cloud collaboration and LLM integration.

Abstract: Diffusion models (DMs) have emerged as a powerful class of generative AI
models, showing remarkable potential in anomaly detection (AD) tasks across
various domains, such as cybersecurity, fraud detection, healthcare, and
manufacturing. The intersection of these two fields, termed diffusion models
for anomaly detection (DMAD), offers promising solutions for identifying
deviations in increasingly complex and high-dimensional data. In this survey,
we review recent advances in DMAD research. We begin by presenting the
fundamental concepts of AD and DMs, followed by a comprehensive analysis of
classic DM architectures including DDPMs, DDIMs, and Score SDEs. We further
categorize existing DMAD methods into reconstruction-based, density-based, and
hybrid approaches, providing detailed examinations of their methodological
innovations. We also explore the diverse tasks across different data
modalities, encompassing image, time series, video, and multimodal data
analysis. Furthermore, we discuss critical challenges and emerging research
directions, including computational efficiency, model interpretability,
robustness enhancement, edge-cloud collaboration, and integration with large
language models. The collection of DMAD research papers and resources is
available at https://github.com/fdjingliu/DMAD.

</details>


### [145] [Using Machine Learning to Detect Fraudulent SMSs in Chichewa](https://arxiv.org/abs/2502.16947)
*Amelia Taylor,Amoss Robert*

Main category: cs.LG

TL;DR: 该研究首次发布了奇切瓦语短信欺诈检测数据集，并使用随机森林和逻辑回归模型进行了实验。结果显示，模型在奇切瓦语数据集上准确率超过96%，但在翻译后的数据集上准确率有所下降，凸显了语言特定模型和数据预处理的重要性。


<details>
  <summary>Details</summary>
Motivation: 全球范围内对短信欺诈的担忧日益增加，而现有的机器学习模型大多基于英语数据集。该研究旨在填补空白，介绍首个用于奇切瓦语短信欺诈检测的数据集，并探索开发奇切瓦语机器学习分类模型的可行性。

Method: 创建了三个数据集：一个包含奇切瓦语短信的小型数据集（通过一手研究收集），经过标签保留文本转换进行扩增，然后通过人工翻译和机器翻译分别翻译成英语。使用随机森林和逻辑回归算法对奇切瓦语和翻译后的数据集进行了机器学习分类实验。

Result: 随机森林和逻辑回归模型在奇切瓦语数据集上均达到了超过96%的准确率。然而，在将模型应用于翻译后的数据集时，性能有所下降，这表明了数据预处理的重要性以及依赖机器翻译文本进行模型训练的挑战。

Conclusion: 研究结果强调了开发针对特定语言（如奇切瓦语）的短信欺诈检测模型的重要性，以优化准确性和性能。它还强调了在跨语言自然语言处理任务中，数据预处理，特别是依赖英语特定工具进行数据预处理的挑战和影响。

Abstract: SMS enabled fraud is of great concern globally. Building classifiers based on
machine learning for SMS fraud requires the use of suitable datasets for model
training and validation. Most research has centred on the use of datasets of
SMSs in English. This paper introduces a first dataset for SMS fraud detection
in Chichewa, a major language in Africa, and reports on experiments with
machine learning algorithms for classifying SMSs in Chichewa as fraud or
non-fraud. We answer the broader research question of how feasible it is to
develop machine learning classification models for Chichewa SMSs. To do that,
we created three datasets. A small dataset of SMS in Chichewa was collected
through primary research from a segment of the young population. We applied a
label-preserving text transformations to increase its size. The enlarged
dataset was translated into English using two approaches: human translation and
machine translation. The Chichewa and the translated datasets were subjected to
machine classification using random forest and logistic regression. Our
findings indicate that both models achieved a promising accuracy of over 96% on
the Chichewa dataset. There was a drop in performance when moving from the
Chichewa to the translated dataset. This highlights the importance of data
preprocessing, especially in multilingual or cross-lingual NLP tasks, and shows
the challenges of relying on machine-translated text for training machine
learning models. Our results underscore the importance of developing language
specific models for SMS fraud detection to optimise accuracy and performance.
Since most machine learning models require data preprocessing, it is essential
to investigate the impact of the reliance on English-specific tools for data
preprocessing.

</details>


### [146] [ML-Driven Approaches to Combat Medicare Fraud: Advances in Class Imbalance Solutions, Feature Engineering, Adaptive Learning, and Business Impact](https://arxiv.org/abs/2502.15898)
*Dorsa Farahmandazad,Kasra Danesh*

Main category: cs.LG

TL;DR: 本研究使用机器学习方法（特别是随机森林）来检测Medicare欺诈，结果显示随机森林模型准确率高达98.8%，有效解决了数据不平衡等问题，为改进医疗欺诈检测提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 为了应对Medicare欺诈给医疗系统造成的巨大经济损失和对合法受益人医疗质量的影响，本研究旨在利用机器学习技术提升Medicare欺诈检测能力，解决类别不平衡、高维数据和欺诈模式变化等关键问题。

Method: 本研究采用包括随机森林、KNN、LDA、决策树和AdaBoost在内的五种机器学习模型，并结合了SMOTE过采样、特征选择和代码聚合等数据预处理技术，以应对Medicare欺诈检测中的类别不平衡、高维数据和欺诈模式演变等挑战。

Result: 随机森林模型表现最佳，训练准确率为99.2%，验证准确率为98.8%，F1分数达到98.4%。决策树模型也表现良好，验证准确率为96.3%。KNN和AdaBoost模型的验证准确率分别为79.2%和81.1%，而LDA模型的验证准确率仅为63.3%，且召回率较低（16.6%）。

Conclusion: 机器学习在识别Medicare欺诈方面具有巨大潜力，特别是随机森林模型表现出色，能够有效应对数据不平衡、高维性和不断变化的欺诈模式。未来的研究应侧重于提高模型的可解释性和性能，以构建可扩展、可靠的欺诈检测系统。

Abstract: Medicare fraud poses a substantial challenge to healthcare systems, resulting
in significant financial losses and undermining the quality of care provided to
legitimate beneficiaries. This study investigates the use of machine learning
(ML) to enhance Medicare fraud detection, addressing key challenges such as
class imbalance, high-dimensional data, and evolving fraud patterns. A dataset
comprising inpatient claims, outpatient claims, and beneficiary details was
used to train and evaluate five ML models: Random Forest, KNN, LDA, Decision
Tree, and AdaBoost. Data preprocessing techniques included resampling SMOTE
method to address the class imbalance, feature selection for dimensionality
reduction, and aggregation of diagnostic and procedural codes. Random Forest
emerged as the best-performing model, achieving a training accuracy of 99.2%
and validation accuracy of 98.8%, and F1-score (98.4%). The Decision Tree also
performed well, achieving a validation accuracy of 96.3%. KNN and AdaBoost
demonstrated moderate performance, with validation accuracies of 79.2% and
81.1%, respectively, while LDA struggled with a validation accuracy of 63.3%
and a low recall of 16.6%. The results highlight the importance of advanced
resampling techniques, feature engineering, and adaptive learning in detecting
Medicare fraud effectively. This study underscores the potential of machine
learning in addressing the complexities of fraud detection. Future work should
explore explainable AI and hybrid models to improve interpretability and
performance, ensuring scalable and reliable fraud detection systems that
protect healthcare resources and beneficiaries.

</details>


### [147] [Cluster Aware Graph Anomaly Detection](https://arxiv.org/abs/2409.09770)
*Lecheng Zheng,John R. Birge,Haiyue Wu,Yifang Zhang,Jingrui He*

Main category: cs.LG

TL;DR: CARE是一种新的多视图图异常检测方法，通过结合伪标签和相似性引导损失来解决数据异构性和标签缺失问题，并在多个数据集上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有无监督图异常检测方法难以处理多视图异构性、缺乏标签信息、高维度以及复杂多视图图。

Method: CARE通过在图的邻接矩阵中添加伪标签（软成员资格分配）来捕获局部和全局节点亲和力，并引入了相似性引导损失来缓解伪标签的潜在偏差。理论上，该损失是对比学习损失的变体，并与图谱聚类相关。

Result: 实验结果表明，CARE在Amazon和YelpChi等多个数据集上表现优于现有方法。

Conclusion: CARE在Amazon数据集上AUPRC超过第二名39%，在YelpChi数据集上AUROC超过第二名18.7%，证明了其有效性和效率。

Abstract: Graph anomaly detection has gained significant attention across various
domains, particularly in critical applications like fraud detection in
e-commerce platforms and insider threat detection in cybersecurity. Usually,
these data are composed of multiple types (e.g., user information and
transaction records for financial data), thus exhibiting view heterogeneity.
However, in the era of big data, the heterogeneity of views and the lack of
label information pose substantial challenges to traditional approaches.
Existing unsupervised graph anomaly detection methods often struggle with
high-dimensionality issues, rely on strong assumptions about graph structures
or fail to handle complex multi-view graphs. To address these challenges, we
propose a cluster aware multi-view graph anomaly detection method, called CARE.
Our approach captures both local and global node affinities by augmenting the
graph's adjacency matrix with the pseudo-label (i.e., soft membership
assignments) without any strong assumption about the graph. To mitigate
potential biases from the pseudo-label, we introduce a similarity-guided loss.
Theoretically, we show that the proposed similarity-guided loss is a variant of
contrastive learning loss, and we present how this loss alleviates the bias
introduced by pseudo-label with the connection to graph spectral clustering.
Experimental results on several datasets demonstrate the effectiveness and
efficiency of our proposed framework. Specifically, CARE outperforms the
second-best competitors by more than 39% on the Amazon dataset with respect to
AUPRC and 18.7% on the YelpChi dataset with respect to AUROC. The code of our
method is available at the GitHub link:
https://github.com/zhenglecheng/CARE-demo.

</details>


### [148] [Maximum Mean Discrepancy on Exponential Windows for Online Change Detection](https://arxiv.org/abs/2205.12706)
*Florian Kalinke,Marco Heyden,Georg Gntuni,Edouard Fouché,Klemens Böhm*

Main category: cs.LG

TL;DR: MMDEW是一种高效的变化检测算法，结合了MMD和指数窗口，运行时间为多对数，内存复杂度为对数，并在基准数据流上表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 在数据流分析中，变化检测至关重要，并且有许多应用，例如预测性维护、欺诈检测或医学领域。通过假设检验将数据流中的观测分布进行比较是一种原则性的变化检测方法。MMD（最大均值差异）是一种概率分布空间的（半）度量，在核丰富域上提供了强大的非参数双样本检验。

Method: 提出了一种名为MMDEW（Maximum Mean Discrepancy on Exponential Windows）的新型变化检测算法，该算法结合了MMD的优点和基于指数窗口的高效计算。

Result: MMDEW算法具有多对数运行时间和对数内存复杂度。

Conclusion: MMDEW算法在基准数据流上表现优于现有技术。

Abstract: Detecting changes is of fundamental importance when analyzing data streams
and has many applications, e.g., in predictive maintenance, fraud detection, or
medicine. A principled approach to detect changes is to compare the
distributions of observations within the stream to each other via hypothesis
testing. Maximum mean discrepancy (MMD), a (semi-)metric on the space of
probability distributions, provides powerful non-parametric two-sample tests on
kernel-enriched domains. In particular, MMD is able to detect any disparity
between distributions under mild conditions. However, classical MMD estimators
suffer from a quadratic runtime complexity, which renders their direct use for
change detection in data streams impractical. In this article, we propose a new
change detection algorithm, called Maximum Mean Discrepancy on Exponential
Windows (MMDEW), that combines the benefits of MMD with an efficient
computation based on exponential windows. We prove that MMDEW enjoys
polylogarithmic runtime and logarithmic memory complexity and show empirically
that it outperforms the state of the art on benchmark data streams.

</details>


### [149] [RAGFormer: Learning Semantic Attributes and Topological Structure for Fraud Detection](https://arxiv.org/abs/2402.17472)
*Haolin Li,Shuyang Jiang,Lifeng Zhang,Siyuan Du,Guangnan Ye,Hongfeng Chai*

Main category: cs.LG

TL;DR: RAGFormer 框架通过结合语义和拓扑特征来改进欺诈检测，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的欺诈检测方法主要只关注图的一个方面（拓扑结构或节点属性），但实证研究表明这两种特征都独立有效且近乎正交，因此无法充分捕捉欺诈图的全面特征。

Method: 提出了一种名为 RAGFormer 的新颖框架，该框架包含一个利用 Transformer 学习语义特征和节点交互的语义编码器，以及一个学习拓扑特征和节点交互的关系感知 GNN 拓扑编码器。这两个编码器的输出通过一个注意力融合模块进行结合，以同时利用这两种正交的特征进行预测。

Result: RAGFormer 在两个公开数据集上实现了最先进的性能，并在工业信用卡欺诈检测数据集上取得了显著的改进，证明了其在实际应用中的有效性。

Conclusion: RAGFormer 框架通过同时嵌入语义和拓扑特征，能够有效地捕捉欺诈图的全面特征，并在公开数据集和工业信用卡欺诈检测数据集中取得了最先进的性能，验证了其在实际业务场景中的适用性。

Abstract: Fraud detection remains a challenging task due to the complex and deceptive
nature of fraudulent activities. Current approaches primarily concentrate on
learning only one perspective of the graph: either the topological structure of
the graph or the attributes of individual nodes. However, we conduct empirical
studies to reveal that these two types of features, while nearly orthogonal,
are each independently effective. As a result, previous methods can not fully
capture the comprehensive characteristics of the fraud graph. To address this
dilemma, we present a novel framework called Relation-Aware GNN with
transFormer~(RAGFormer) which simultaneously embeds both semantic and
topological features into a target node. The simple yet effective network
consists of a semantic encoder, a topology encoder, and an attention fusion
module. The semantic encoder utilizes Transformer to learn semantic features
and node interactions across different relations. We introduce Relation-Aware
GNN as the topology encoder to learn topological features and node interactions
within each relation. These two complementary features are interleaved through
an attention fusion module to support prediction by both orthogonal features.
Extensive experiments on two popular public datasets demonstrate that RAGFormer
achieves state-of-the-art performance. The significant improvement of RAGFormer
in an industrial credit card fraud detection dataset further validates the
applicability of our method in real-world business scenarios.

</details>


### [150] [ASTM :Autonomous Smart Traffic Management System Using Artificial Intelligence CNN and LSTM](https://arxiv.org/abs/2410.10929)
*Christofel Rio Goenawan*

Main category: cs.LG

TL;DR: 本研究提出了一种基于 AI 的自动智能交通管理系统，通过 YOLO V5 和 RNN-LSTM 技术，将交通流量提高了 50%，并将车辆通行延迟降低了 70%。


<details>
  <summary>Details</summary>
Motivation: 为了在现代社会提高交通效率和减少交通拥堵，本研究旨在利用人工智能（AI）技术改进自动智能交通管理（ASTM）系统，以提升交通流量和降低拥堵率。

Method: 本研究提出了一种结合 YOLO V5 卷积神经网络进行车辆检测和 RNN-LSTM 模型进行未来12小时车辆数量预测的自动智能交通管理（STM）系统。该系统通过人工智能调控交通周期长度，以优化交通流量。

Result: 研究结果表明，与未使用 STM 的情况相比，所提出的 ASTM 系统将交通管理拥堵流率提高了 50%（从每分钟约 15 辆车提高到 21 辆车），并将交通管理车辆通行延迟降低了 70%（从每辆车约 12 秒降低到 5 秒）。RNN-LSTM 模型的预测误差（MSE）为 4.521 辆车，均方根误差（RMSE）为 2.232 辆车。

Conclusion: 该研究提出的自动智能交通管理（ASTM）系统通过利用 YOLO V5 和 RNN-LSTM 等人工智能技术，显著提高了交通流量（50%）并降低了车辆通行延迟（70%），证明了 AI 在改善城市交通系统方面的潜力。

Abstract: In the modern world, the development of Artificial Intelligence (AI) has
contributed to improvements in various areas, including automation, computer
vision, fraud detection, and more. AI can be leveraged to enhance the
efficiency of Autonomous Smart Traffic Management (ASTM) systems and reduce
traffic congestion rates. This paper presents an Autonomous Smart Traffic
Management (STM) system that uses AI to improve traffic flow rates. The system
employs the YOLO V5 Convolutional Neural Network to detect vehicles in traffic
management images. Additionally, it predicts the number of vehicles for the
next 12 hours using a Recurrent Neural Network with Long Short-Term Memory
(RNN-LSTM). The Smart Traffic Management Cycle Length Analysis manages the
traffic cycle length based on these vehicle predictions, aided by AI. From the
results of the RNN-LSTM model for predicting vehicle numbers over the next 12
hours, we observe that the model predicts traffic with a Mean Squared Error
(MSE) of 4.521 vehicles and a Root Mean Squared Error (RMSE) of 2.232 vehicles.
After simulating the STM system in the CARLA simulation environment, we found
that the Traffic Management Congestion Flow Rate with ASTM (21 vehicles per
minute) is 50\% higher than the rate without STM (around 15 vehicles per
minute). Additionally, the Traffic Management Vehicle Pass Delay with STM (5
seconds per vehicle) is 70\% lower than without STM (around 12 seconds per
vehicle). These results demonstrate that the STM system using AI can increase
traffic flow by 50\% and reduce vehicle pass delays by 70\%.

</details>


### [151] [A Structured Reasoning Framework for Unbalanced Data Classification Using Probabilistic Models](https://arxiv.org/abs/2502.03386)
*Junliang Du,Shiyu Dou,Bohuan Yang,Jiacheng Hu,Tai An*

Main category: cs.LG

TL;DR: 本研究提出了一种马尔可夫网络模型，通过结合联合概率分布、条件依赖、边际概率估计、加权损失优化、正则化约束和结构化推理，有效解决了类别不平衡数据导致的分类偏差和少数类识别能力不足的问题。实验证明，该模型在金融风控等领域具有广泛的应用前景。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型在处理类别不平衡数据时存在分类偏差和少数类识别能力不足的问题。本研究旨在通过构建马尔可夫网络模型来解决这些挑战。

Method: 本研究构建了一个马尔可夫网络模型，通过联合概率分布和条件依赖实现对类别不平衡数据的全局建模和推理优化。采用了边际概率估计和加权损失优化策略，并结合正则化约束和结构化推理方法来提升模型的泛化能力和鲁棒性。

Result: 实验结果显示，马尔可夫网络模型在加权准确率、F1分数和AUC-ROC等指标上显著优于逻辑回归、支持向量机、随机森林和XGBoost等传统分类模型，证明了其在类别不平衡数据场景下的优越性能和应用潜力。

Conclusion: 马尔可夫网络模型在处理类别不平衡数据方面表现出色，能够有效解决传统模型中存在的分类偏差和少数类识别能力不足的问题。通过联合概率分布和条件依赖构建，该模型实现了样本类别的全局建模和推理优化。实验结果表明，与逻辑回归、支持向量机、随机森林和XGBoost等传统模型相比，马尔可夫网络在加权准确率、F1分数和AUC-ROC等指标上表现更优，证明了其在类别不平衡数据场景下的决策能力和适用性。

Abstract: This paper studies a Markov network model for unbalanced data, aiming to
solve the problems of classification bias and insufficient minority class
recognition ability of traditional machine learning models in environments with
uneven class distribution. By constructing joint probability distribution and
conditional dependency, the model can achieve global modeling and reasoning
optimization of sample categories. The study introduced marginal probability
estimation and weighted loss optimization strategies, combined with
regularization constraints and structured reasoning methods, effectively
improving the generalization ability and robustness of the model. In the
experimental stage, a real credit card fraud detection dataset was selected and
compared with models such as logistic regression, support vector machine,
random forest and XGBoost. The experimental results show that the Markov
network performs well in indicators such as weighted accuracy, F1 score, and
AUC-ROC, significantly outperforming traditional classification models,
demonstrating its strong decision-making ability and applicability in
unbalanced data scenarios. Future research can focus on efficient model
training, structural optimization, and deep learning integration in large-scale
unbalanced data environments and promote its wide application in practical
applications such as financial risk control, medical diagnosis, and intelligent
monitoring.

</details>


### [152] [FRAUD-RLA: A new reinforcement learning adversarial attack against credit card fraud detection](https://arxiv.org/abs/2502.02290)
*Daniele Lunghi,Yannick Molinghen,Alkis Simitsis,Tom Lenaerts,Gianluca Bontempi*

Main category: cs.LG

TL;DR: A new adversarial attack called FRAUD-RLA, using reinforcement learning, is proposed for credit card fraud detection. It is effective and requires less knowledge than existing methods.


<details>
  <summary>Details</summary>
Motivation: Adversarial attacks are a significant threat to data-driven systems, but the issue of credit card fraud detection has been largely overlooked. This paper addresses this gap by proposing a new threat model and a new adversarial attack.

Method: We design a new adversarial attack for credit card fraud detection, called FRAUD-RLA, employing reinforcement learning to bypass classifiers. FRAUD-RLA maximizes the attacker's reward by optimizing the exploration-exploitation tradeoff and requires less knowledge than competitors.

Result: Our experiments show that FRAUD-RLA is effective, even considering the severe limitations imposed by our threat model.

Conclusion: FRAUD-RLA is effective against two fraud detection systems on three heterogeneous datasets, even under severe limitations.

Abstract: Adversarial attacks pose a significant threat to data-driven systems, and
researchers have spent considerable resources studying them. Despite its
economic relevance, this trend largely overlooked the issue of credit card
fraud detection. To address this gap, we propose a new threat model that
demonstrates the limitations of existing attacks and highlights the necessity
to investigate new approaches. We then design a new adversarial attack for
credit card fraud detection, employing reinforcement learning to bypass
classifiers. This attack, called FRAUD-RLA, is designed to maximize the
attacker's reward by optimizing the exploration-exploitation tradeoff and
working with significantly less required knowledge than competitors. Our
experiments, conducted on three different heterogeneous datasets and against
two fraud detection systems, indicate that FRAUD-RLA is effective, even
considering the severe limitations imposed by our threat model.

</details>


### [153] [Real-Time Anomaly Detection with Synthetic Anomaly Monitoring (SAM)](https://arxiv.org/abs/2501.18417)
*Emanuele Luzio,Moacir Antonelli Ponti*

Main category: cs.LG

TL;DR: SAM is an innovative anomaly detection approach using synthetic control methods, showing robust performance across various datasets compared to existing models.


<details>
  <summary>Details</summary>
Motivation: Anomaly detection is essential for identifying rare and significant events across diverse domains such as finance, cybersecurity, and network monitoring.

Method: SAM models normal behavior by treating each feature as a control unit and identifies anomalies as deviations within this causal framework, applying synthetic control methods from causal inference.

Result: Extensive experiments comparing SAM with Isolation Forest, Local Outlier Factor (LOF), k-Nearest Neighbors (kNN), and One-Class Support Vector Machine (SVM) across five diverse datasets show that SAM consistently delivers robust performance.

Conclusion: SAM consistently delivers robust performance, highlighting its potential as a powerful tool for real-time anomaly detection in dynamic and complex environments.

Abstract: Anomaly detection is essential for identifying rare and significant events
across diverse domains such as finance, cybersecurity, and network monitoring.
This paper presents Synthetic Anomaly Monitoring (SAM), an innovative approach
that applies synthetic control methods from causal inference to improve both
the accuracy and interpretability of anomaly detection processes. By modeling
normal behavior through the treatment of each feature as a control unit, SAM
identifies anomalies as deviations within this causal framework. We conducted
extensive experiments comparing SAM with established benchmark models,
including Isolation Forest, Local Outlier Factor (LOF), k-Nearest Neighbors
(kNN), and One-Class Support Vector Machine (SVM), across five diverse
datasets, including Credit Card Fraud, HTTP Dataset CSIC 2010, and KDD Cup
1999, among others. Our results demonstrate that SAM consistently delivers
robust performance, highlighting its potential as a powerful tool for real-time
anomaly detection in dynamic and complex environments.

</details>


### [154] [Using Causality for Enhanced Prediction of Web Traffic Time Series](https://arxiv.org/abs/2502.00612)
*Chang Tian,Mingzhe Xing,Zenglin Shi,Matthew B. Blaschko,Yinliang Yue,Marie-Francine Moens*

Main category: cs.LG

TL;DR: 该研究提出了一种名为CCMPlus的神经网路模块，用于提取网络服务间的因果关系特征，以提高流量预测的准确性。实验证明，该方法在真实数据集上优于现有技术，证实了利用因果关系进行预测的有效性。


<details>
  <summary>Details</summary>
Motivation: 网络服务流量预测具有重要的社会价值，可应用于动态资源扩展、负载均衡、系统异常检测等多种实际场景。然而，网络服务流量的预测因其频繁剧烈的波动和异构的用户行为而变得充满挑战。现有方法多集中于时间序列本身，忽略了服务间的因果关系。

Method: 提出了一种名为CCMPlus的神经网路模块，用于提取跨服务的因果关系特征，并能与现有时间序列模型集成以提升预测性能。理论上证明了该模块生成的因果相关矩阵能够捕捉服务间的因果关系。

Result: 在微软Azure、阿里巴巴集团和蚂蚁集团的真实数据集上进行的实证研究表明，所提出的方法在服务流量时间序列预测的均方误差（MSE）和平均绝对误差（MAE）方面优于最先进的方法。

Conclusion: 研究结果表明，利用因果关系可以显著提高服务流量预测的准确性，并且提出的CCMPlus模块能够有效提取服务间的因果关系特征，能够无缝集成到现有时间序列模型中，一致性地提升预测性能。

Abstract: Predicting web service traffic has significant social value, as it can be
applied to various practical scenarios, including but not limited to dynamic
resource scaling, load balancing, system anomaly detection, service-level
agreement compliance, and fraud detection. Web service traffic is characterized
by frequent and drastic fluctuations over time and are influenced by
heterogeneous web user behaviors, making accurate prediction a challenging
task. Previous research has extensively explored statistical approaches, and
neural networks to mine features from preceding service traffic time series for
prediction. However, these methods have largely overlooked the causal
relationships between services. Drawing inspiration from causality in
ecological systems, we empirically recognize the causal relationships between
web services. To leverage these relationships for improved web service traffic
prediction, we propose an effective neural network module, CCMPlus, designed to
extract causal relationship features across services. This module can be
seamlessly integrated with existing time series models to consistently enhance
the performance of web service traffic predictions. We theoretically justify
that the causal correlation matrix generated by the CCMPlus module captures
causal relationships among services. Empirical results on real-world datasets
from Microsoft Azure, Alibaba Group, and Ant Group confirm that our method
surpasses state-of-the-art approaches in Mean Squared Error (MSE) and Mean
Absolute Error (MAE) for predicting service traffic time series. These findings
highlight the efficacy of leveraging causal relationships for improved
predictions.

</details>


### [155] [Year-over-Year Developments in Financial Fraud Detection via Deep Learning: A Systematic Literature Review](https://arxiv.org/abs/2502.00201)
*Yisong Chen,Chuqing Zhao,Yixin Xu,Chuanhao Nie*

Main category: cs.LG

TL;DR: 本综述系统性地回顾了深度学习在金融欺诈检测中的进展，分析了57项研究，评估了不同模型的有效性，并讨论了数据隐私、特征工程、不平衡数据集、模型可解释性、道德考量以及区块链和主成分分析等机遇与挑战。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在系统性地回顾深度学习技术在金融欺诈检测领域的进展，这是一个金融部门的关键问题。

Method: 采用Kitchenham系统文献综述方法，分析了2019年至2024年间发表的57项研究。

Result: 评估了精确率、召回率、F1分数和AUC-ROC等性能指标，并探讨了数据隐私框架、特征工程和数据预处理的进展。研究强调了不平衡数据集、模型可解释性和道德考量等挑战，以及自动化和隐私保护技术（如区块链整合和主成分分析）的机会。

Conclusion: 本综述强调了在金融欺诈检测领域，深度学习模型（如卷积神经网络、长短期记忆网络和Transformer）在信用卡交易、保险索赔和财务报表审计等领域的有效性。研究考察了数据隐私框架、特征工程和数据预处理的进展，并讨论了诸如不平衡数据集、模型可解释性和区块链整合等挑战与机遇。

Abstract: This paper systematically reviews advancements in deep learning (DL)
techniques for financial fraud detection, a critical issue in the financial
sector. Using the Kitchenham systematic literature review approach, 57 studies
published between 2019 and 2024 were analyzed. The review highlights the
effectiveness of various deep learning models such as Convolutional Neural
Networks, Long Short-Term Memory, and transformers across domains such as
credit card transactions, insurance claims, and financial statement audits.
Performance metrics such as precision, recall, F1-score, and AUC-ROC were
evaluated. Key themes explored include the impact of data privacy frameworks
and advancements in feature engineering and data preprocessing. The study
emphasizes challenges such as imbalanced datasets, model interpretability, and
ethical considerations, alongside opportunities for automation and
privacy-preserving techniques such as blockchain integration and Principal
Component Analysis. By examining trends over the past five years, this review
identifies critical gaps and promising directions for advancing DL applications
in financial fraud detection, offering actionable insights for researchers and
practitioners.

</details>


### [156] [GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction](https://arxiv.org/abs/2306.01951)
*Amit Roy,Juan Shu,Jia Li,Carl Yang,Olivier Elshocht,Jeroen Smeets,Pan Li*

Main category: cs.LG

TL;DR: GAD-NR是一种新的图异常检测方法，通过邻域重建来识别异常节点，相比现有方法在检测准确率和异常类型覆盖面方面均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图自编码器（GAE）的图异常检测（GAD）方法主要针对直接链接重建进行优化，导致在潜在空间中节点聚集，因此擅长检测集群型结构异常，但难以处理不符合集群的复杂结构异常。

Method: 提出了一种名为GAD-NR的新型图自编码器（GAE）变体，该模型通过邻域重建来检测图异常。GAD-NR旨在根据节点的表征重建其整个邻域，包括局部结构、节点属性和邻居属性，并通过比较异常节点和正常节点之间的邻域重建损失来识别异常。

Result: GAD-NR在六个真实世界数据集上进行了广泛的实验，结果显示其在AUC方面比现有最先进的竞争方法有显著改进（最高可达30%）。此外，与其他方法相比，GAD-NR在检测所有三种类型的异常方面表现出色，而现有方法仅能检测其中一到两种。

Conclusion: GAD-NR通过重建节点邻域（包括局部结构、节点属性和邻居属性）来检测图中的异常节点，在六个真实世界数据集上的实验结果表明，其在AUC方面比现有方法有显著提高（最高可达30%），并且能够检测所有三种类型的异常，而现有方法仅能检测其中一到两种。

Abstract: Graph Anomaly Detection (GAD) is a technique used to identify abnormal nodes
within graphs, finding applications in network security, fraud detection,
social media spam detection, and various other domains. A common method for GAD
is Graph Auto-Encoders (GAEs), which encode graph data into node
representations and identify anomalies by assessing the reconstruction quality
of the graphs based on these representations. However, existing GAE models are
primarily optimized for direct link reconstruction, resulting in nodes
connected in the graph being clustered in the latent space. As a result, they
excel at detecting cluster-type structural anomalies but struggle with more
complex structural anomalies that do not conform to clusters. To address this
limitation, we propose a novel solution called GAD-NR, a new variant of GAE
that incorporates neighborhood reconstruction for graph anomaly detection.
GAD-NR aims to reconstruct the entire neighborhood of a node, encompassing the
local structure, self-attributes, and neighbor attributes, based on the
corresponding node representation. By comparing the neighborhood reconstruction
loss between anomalous nodes and normal nodes, GAD-NR can effectively detect
any anomalies. Extensive experimentation conducted on six real-world datasets
validates the effectiveness of GAD-NR, showcasing significant improvements (by
up to 30% in AUC) over state-of-the-art competitors. The source code for GAD-NR
is openly available. Importantly, the comparative analysis reveals that the
existing methods perform well only in detecting one or two types of anomalies
out of the three types studied. In contrast, GAD-NR excels at detecting all
three types of anomalies across the datasets, demonstrating its comprehensive
anomaly detection capabilities.

</details>


### [157] [SCFCRC: Simultaneously Counteract Feature Camouflage and Relation Camouflage for Fraud Detection](https://arxiv.org/abs/2501.12430)
*Xiaocheng Zhang,Zhuangzhuang Ye,GuoPing Zhao,Jianing Wang,Xiaohong Su*

Main category: cs.LG

TL;DR: SCFCRC 是一种基于 Transformer 的欺诈检测器，它通过同时对抗特征伪装和关系伪装来提高欺诈检测性能。它包含一个特征伪装过滤器和一个关系伪装精炼器，并使用对比学习和混合专家（MoE）网络来提高特征质量和减轻关系伪装的影响。


<details>
  <summary>Details</summary>
Motivation: 欺诈者经常与许多良性用户互动，伪装他们的特征或关系来隐藏自己。大多数现有工作仅专注于特征伪装或关系伪装，或将特征学习与关系学习分离，以避免两种伪装相互影响。然而，这无意中忽略了源自特征或关系的有价值信息，这些信息可以相互增强它们的对抗性伪装策略。为了弥补这一差距，我们提出了 SCFCRC，一种基于 Transformer 的欺诈检测器。

Method: SCFCRC 使用两个组件：特征伪装过滤器和关系伪装精炼器。特征伪装过滤器利用标签传播生成的伪标签来训练过滤器，并使用结合了实例级和原型级的对比学习来提高特征质量。关系伪装精炼器使用混合专家（MoE）网络将多关系图分解为多个子结构，并逐个攻破它们，以减轻关系伪装对检测性能造成的损害。此外，我们还引入了一种用于 MoE 的正则化方法来增强模型的鲁棒性。

Result: 实验证明，SCFCRC 在两个欺诈检测基准数据集上均优于最先进的基线。

Conclusion: SCFCRC 通过同时对抗特征伪装和关系伪装，在两个欺诈检测基准数据集上的广泛实验证明，我们的方法优于最先进的基线。

Abstract: In fraud detection, fraudsters often interact with many benign users,
camouflaging their features or relations to hide themselves. Most existing work
concentrates solely on either feature camouflage or relation camouflage, or
decoupling feature learning and relation learning to avoid the two camouflage
from affecting each other. However, this inadvertently neglects the valuable
information derived from features or relations, which could mutually enhance
their adversarial camouflage strategies. In response to this gap, we propose
SCFCRC, a Transformer-based fraud detector that Simultaneously Counteract
Feature Camouflage and Relation Camouflage. SCFCRC consists of two components:
Feature Camouflage Filter and Relation Camouflage Refiner. The feature
camouflage filter utilizes pseudo labels generated through label propagation to
train the filter and uses contrastive learning that combines instance-wise and
prototype-wise to improve the quality of features. The relation camouflage
refiner uses Mixture-of-Experts(MoE) network to disassemble the multi-relations
graph into multiple substructures and divide and conquer them to mitigate the
degradation of detection performance caused by relation camouflage.
Furthermore, we introduce a regularization method for MoE to enhance the
robustness of the model. Extensive experiments on two fraud detection benchmark
datasets demonstrate that our method outperforms state-of-the-art baselines.

</details>


### [158] [Attention is All You Need Until You Need Retention](https://arxiv.org/abs/2501.09166)
*M. Murat Yaslioglu*

Main category: cs.LG

TL;DR: 提出了一种新颖的Transformer留存层，通过持久内存模块实现增量学习和适应性，模仿了人类社交学习过程。


<details>
  <summary>Details</summary>
Motivation: Transformer架构缺乏内在的留存能力，这限制了它们在需要动态适应性方面的能力，因为它们仅依赖于固定的预训练权重和短暂的上下文窗口，而无法像人类认知一样编码和动态回忆符号模板。

Method: 通过整合记忆注意力机制和情景缓冲区来管理记忆可扩展性、减轻过拟合并确保有效召回。

Result: 所提出的留存层包含一个持久的内存模块，能够进行实时数据填充、动态召回和引导式输出生成，从而使模型能够跨会话存储、更新和重用观察到的模式，从而实现增量学习，并弥合静态预训练与动态、上下文敏感适应之间的差距。

Conclusion: 该留存层增强架构通过模拟人类学习的关键方面，促进了更流畅、更具响应性的AI范式，为需要持续适应的领域扩展了传统Transformer的功能，并为动态、会话感知模型铺平了道路。

Abstract: This work introduces a novel Retention Layer mechanism for Transformer based
architectures, addressing their inherent lack of intrinsic retention
capabilities. Unlike human cognition, which can encode and dynamically recall
symbolic templates, Generative Pretrained Transformers rely solely on fixed
pretrained weights and ephemeral context windows, limiting their adaptability.
The proposed Retention Layer incorporates a persistent memory module capable of
real time data population, dynamic recall, and guided output generation. This
enhancement allows models to store, update, and reuse observed patterns across
sessions, enabling incremental learning and bridging the gap between static
pretraining and dynamic, context sensitive adaptation. The Retention Layer
design parallels social learning processes, encompassing attention, retention,
reproduction, and motivation stages. Technically, it integrates a memory
attention mechanism and episodic buffers to manage memory scalability, mitigate
overfitting, and ensure efficient recall. Applications span adaptive personal
assistants, real time fraud detection, autonomous robotics, content moderation,
and healthcare diagnostics. In each domain, the retention mechanism enables
systems to learn incrementally, personalize outputs, and respond to evolving
real world challenges effectively. By emulating key aspects of human learning,
this retention enhanced architecture fosters a more fluid and responsive AI
paradigm, paving the way for dynamic, session aware models that extend the
capabilities of traditional Transformers into domains requiring continual
adaptation.

</details>


### [159] [Detection of AI Deepfake and Fraud in Online Payments Using GAN-Based Models](https://arxiv.org/abs/2501.07033)
*Zong Ke,Shicheng Zhou,Yining Zhou,Chia Hong Chang,Rong Zhang*

Main category: cs.LG

TL;DR: 本研究利用生成对抗网络（GAN）技术，开发了一种新的模型来检测在线支付中的深度伪造和欺诈行为，实现了超过95%的准确率，从而增强了支付安全。


<details>
  <summary>Details</summary>
Motivation: 随着深度伪造技术的日益普及，可能在在线交易中增加欺诈的可能性，而传统的安全系统难以识别这些复杂的欺诈形式。本研究旨在通过利用GAN技术来增强在线支付安全，识别支付图像中的伪造行为。

Method: 本研究提出并实现了一种新颖的生成对抗网络（GAN）模型，专门用于检测在线支付图像中的细微伪造。模型在包含真实支付图像和使用StyleGAN、DeepFake等先进GAN架构生成的深度伪造图像的数据集上进行了训练。

Result: 实验结果表明，所提出的GAN模型能够准确地区分合法交易和深度伪造，实现了超过95%的高检测率，有效提升了支付系统对抗AI驱动欺诈的能力。

Conclusion: 本研究提出了一种基于生成对抗网络的新模型，用于检测在线支付系统中的AI深度伪造和欺诈活动，显著提高了支付系统的鲁棒性。该模型在区分真实交易和深度伪造方面表现出色，检测率超过95%，为金融服务领域的欺诈检测提供了新的思路。

Abstract: This study explores the use of Generative Adversarial Networks (GANs) to
detect AI deepfakes and fraudulent activities in online payment systems. With
the growing prevalence of deepfake technology, which can manipulate facial
features in images and videos, the potential for fraud in online transactions
has escalated. Traditional security systems struggle to identify these
sophisticated forms of fraud. This research proposes a novel GAN-based model
that enhances online payment security by identifying subtle manipulations in
payment images. The model is trained on a dataset consisting of real-world
online payment images and deepfake images generated using advanced GAN
architectures, such as StyleGAN and DeepFake. The results demonstrate that the
proposed model can accurately distinguish between legitimate transactions and
deepfakes, achieving a high detection rate above 95%. This approach
significantly improves the robustness of payment systems against AI-driven
fraud. The paper contributes to the growing field of digital security, offering
insights into the application of GANs for fraud detection in financial
services. Keywords- Payment Security, Image Recognition, Generative Adversarial
Networks, AI Deepfake, Fraudulent Activities

</details>


### [160] [Semi-supervised Credit Card Fraud Detection via Attribute-Driven Graph Representation](https://arxiv.org/abs/2412.18287)
*Sheng Xiang,Mingzhi Zhu,Dawei Cheng,Enxia Li,Ruihui Zhao,Yi Ouyang,Ling Chen,Yefeng Zheng*

Main category: cs.LG

TL;DR: 提出了一种基于半监督图神经网络（GTAN）的信用欺诈检测方法，通过构建时间交易图和利用门控时间注意力网络学习交易表示，并在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 当前方法主要依赖标记数据，但标记数据仅占交易记录的一小部分，导致大量未标记数据中的特征未能得到充分利用。

Method: 利用交易记录构建时间交易图，并通过门控时间注意力网络（GTAN）在节点间传递消息来学习交易表示，并通过风险传播对欺诈模式进行建模。

Result: 所提出的GTAN模型在三个欺诈检测数据集上均优于其他最先进的基线，并且在仅有少量标记数据的情况下表现出出色的欺诈检测性能。

Conclusion: 所提出的GTAN模型在三个欺诈检测数据集上均优于其他最先进的基线，并且在仅有少量标记数据的情况下表现出出色的欺诈检测性能。

Abstract: Credit card fraud incurs a considerable cost for both cardholders and issuing
banks. Contemporary methods apply machine learning-based classifiers to detect
fraudulent behavior from labeled transaction records. But labeled data are
usually a small proportion of billions of real transactions due to expensive
labeling costs, which implies that they do not well exploit many natural
features from unlabeled data. Therefore, we propose a semi-supervised graph
neural network for fraud detection. Specifically, we leverage transaction
records to construct a temporal transaction graph, which is composed of
temporal transactions (nodes) and interactions (edges) among them. Then we pass
messages among the nodes through a Gated Temporal Attention Network (GTAN) to
learn the transaction representation. We further model the fraud patterns
through risk propagation among transactions. The extensive experiments are
conducted on a real-world transaction dataset and two publicly available fraud
detection datasets. The result shows that our proposed method, namely GTAN,
outperforms other state-of-the-art baselines on three fraud detection datasets.
Semi-supervised experiments demonstrate the excellent fraud detection
performance of our model with only a tiny proportion of labeled data.

</details>


### [161] [Enhancing Ethereum Fraud Detection via Generative and Contrastive Self-supervision](https://arxiv.org/abs/2408.00641)
*Chenxiang Jin,Jiajun Zhou,Chenxuan Xie,Shanqing Yu,Qi Xuan,Xiaoniu Yang*

Main category: cs.LG

TL;DR: Meta-IFD框架通过双重自监督学习（生成式和对比式）来增强以太坊欺诈检测，解决了数据不平衡和行为模式区分的挑战，并在真实数据集上证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 以太坊上猖獗的欺诈活动阻碍了区块链生态的健康发展，亟需加强监管。然而，账户交互频率和交互类型在以太坊交易环境中的多种不平衡性给数据挖掘式欺诈检测研究带来了严峻挑战。

Method: 提出元交互概念以细化交互行为，并基于此提出名为Meta-IFD的双重自监督增强以太坊欺诈检测框架。该框架引入生成式自监督机制增强账户交互特征，并引入对比式自监督机制区分行为模式，通过多视角交互特征学习来表征账户行为并挖掘潜在欺诈风险。

Result: 通过在真实以太坊数据集上的大量实验证明了Meta-IFD框架在检测庞氏骗局和网络钓鱼诈骗等常见以太坊欺诈行为方面的有效性和优越性。此外，生成模块有效缓解了以太坊数据中的交互分布不平衡问题，而对比模块显著增强了框架区分不同行为模式的能力。

Conclusion: Meta-IFD框架在检测以太坊欺诈行为方面表现出有效性和优越性，并且可以缓解数据不平衡问题并提高区分不同行为模式的能力。

Abstract: The rampant fraudulent activities on Ethereum hinder the healthy development
of the blockchain ecosystem, necessitating the reinforcement of regulations.
However, multiple imbalances involving account interaction frequencies and
interaction types in the Ethereum transaction environment pose significant
challenges to data mining-based fraud detection research. To address this, we
first propose the concept of meta-interactions to refine interaction behaviors
in Ethereum, and based on this, we present a dual self-supervision enhanced
Ethereum fraud detection framework, named Meta-IFD. This framework initially
introduces a generative self-supervision mechanism to augment the interaction
features of accounts, followed by a contrastive self-supervision mechanism to
differentiate various behavior patterns, and ultimately characterizes the
behavioral representations of accounts and mines potential fraud risks through
multi-view interaction feature learning. Extensive experiments on real Ethereum
datasets demonstrate the effectiveness and superiority of our framework in
detecting common Ethereum fraud behaviors such as Ponzi schemes and phishing
scams. Additionally, the generative module can effectively alleviate the
interaction distribution imbalance in Ethereum data, while the contrastive
module significantly enhances the framework's ability to distinguish different
behavior patterns. The source code will be available in
https://github.com/GISec-Team/Meta-IFD.

</details>


### [162] [Backdoor attacks on DNN and GBDT -- A Case Study from the insurance domain](https://arxiv.org/abs/2412.08366)
*Robin Kühlem,Daniel Otten,Daniel Ludwig,Anselm Hudde,Alexander Rosenbaum,Andreas Mauthe*

Main category: cs.LG

TL;DR: 后门攻击对保险领域的GBDT和DNN模型构成威胁，攻击效果与数据相关，需警惕。


<details>
  <summary>Details</summary>
Motivation: 评估机器学习模型（特别是GBDT和DNN）在保险领域中的鲁棒性，并研究后门攻击的影响，特别是在异质性表格数据上的表现。

Method: 训练了两个GBDT模型和两个DNN模型，并在两个不同的保险领域表格数据集上执行了预测和欺诈检测任务，通过添加包含特定模式的样本来实施后门攻击。

Result: 后门攻击在某些数据集上取得了高成功率，即使只添加了少量受污染的样本。然而，攻击效果在不同数据集上存在差异，在某些数据集上效果显著，而在另一些数据集上效果不佳。

Conclusion: 梯度提升决策树（GBDT）和深度神经网络（DNN）模型在保险领域的应用面临被攻击的风险，后门攻击可以利用少量样本成功地操纵模型，但攻击效果受到数据集异质性的影响，需要对该风险进行评估。

Abstract: Machine learning (ML) will likely play a large role in many processes in the
future, also for insurance companies. However, ML models are at risk of being
attacked and manipulated. In this work, the robustness of Gradient Boosted
Decision Tree (GBDT) models and Deep Neural Networks (DNN) within an insurance
context will be evaluated. Therefore, two GBDT models and two DNNs are trained
on two different tabular datasets from an insurance context. Past research in
this domain mainly used homogenous data and there are comparably few insights
regarding heterogenous tabular data. The ML tasks performed on the datasets are
claim prediction (regression) and fraud detection (binary classification). For
the backdoor attacks different samples containing a specific pattern were
crafted and added to the training data. It is shown, that this type of attack
can be highly successful, even with a few added samples. The backdoor attacks
worked well on the models trained on one dataset but poorly on the models
trained on the other. In real-world scenarios the attacker will have to face
several obstacles but as attacks can work with very few added samples this risk
should be evaluated.

</details>


### [163] [PyOD 2: A Python Library for Outlier Detection with LLM-powered Model Selection](https://arxiv.org/abs/2412.12154)
*Sihan Chen,Zhuangzhuang Qian,Wingchun Siu,Xingcan Hu,Jiaqi Li,Shawn Li,Yuehan Qin,Tiankai Yang,Zhuo Xiao,Wanghao Ye,Yichi Zhang,Yushun Dong,Yue Zhao*

Main category: cs.LG

TL;DR: PyOD 2.0 库通过整合最新的深度学习模型和引入大语言模型驱动的自动化模型选择，改进了异常检测的易用性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 PyOD 库在深度学习模型覆盖不足、跨框架（PyTorch 和 TensorFlow）实现不一致以及缺乏自动化模型选择功能方面存在局限，给非专业用户带来了使用上的困难。

Method: 本文介绍了 PyOD 2.0，这是一个集成了 12 种最先进的深度学习模型（统一在 PyTorch 框架下）并引入了基于大语言模型的自动化异常检测模型选择流程的库。

Result: PyOD 2.0 成功地将 12 种最新的深度学习模型整合到一个统一的 PyTorch 框架中，并实现了基于大语言模型的自动化模型选择，支持总计 45 种算法。这极大地简化了异常检测的工作流程，提高了在各种数据集上的鲁棒性和性能。

Conclusion: PyOD 2 通过集成最新的深度学习模型并引入基于大语言模型的自动化模型选择流程，解决了现有 PyOD 库在深度学习模型覆盖、框架兼容性和自动化方面的不足，从而简化了异常检测工作流，提高了模型性能和易用性，为异常检测的研究和工业应用树立了新的标杆。

Abstract: Outlier detection (OD), also known as anomaly detection, is a critical
machine learning (ML) task with applications in fraud detection, network
intrusion detection, clickstream analysis, recommendation systems, and social
network moderation. Among open-source libraries for outlier detection, the
Python Outlier Detection (PyOD) library is the most widely adopted, with over
8,500 GitHub stars, 25 million downloads, and diverse industry usage. However,
PyOD currently faces three limitations: (1) insufficient coverage of modern
deep learning algorithms, (2) fragmented implementations across PyTorch and
TensorFlow, and (3) no automated model selection, making it hard for
non-experts.
  To address these issues, we present PyOD Version 2 (PyOD 2), which integrates
12 state-of-the-art deep learning models into a unified PyTorch framework and
introduces a large language model (LLM)-based pipeline for automated OD model
selection. These improvements simplify OD workflows, provide access to 45
algorithms, and deliver robust performance on various datasets. In this paper,
we demonstrate how PyOD 2 streamlines the deployment and automation of OD
models and sets a new standard in both research and industry. PyOD 2 is
accessible at
[https://github.com/yzhao062/pyod](https://github.com/yzhao062/pyod). This
study aligns with the Web Mining and Content Analysis track, addressing topics
such as the robustness of Web mining methods and the quality of
algorithmically-generated Web data.

</details>


### [164] [Impact of Sampling Techniques and Data Leakage on XGBoost Performance in Credit Card Fraud Detection](https://arxiv.org/abs/2412.07437)
*Siyaxolisa Kabane*

Main category: cs.LG

TL;DR: 信用卡欺诈检测中使用XGBoost时，在拆分前应用采样技术会导致数据泄露，虚高模型性能；仅在训练集上应用采样技术（拆分后）的模型虽然性能稍低，但结果更可靠。


<details>
  <summary>Details</summary>
Motivation: 信用卡欺诈检测是一个关键的金融安全挑战，而XGBoost等机器学习模型在识别欺诈交易方面表现强大。然而，信用卡交易数据固有的类别不平衡问题给模型性能带来了巨大挑战。尽管采样技术常用于解决类别不平衡问题，但有时在训练集和测试集划分之前就应用了这些技术，这可能导致数据泄露，影响评估的准确性。

Method: 本研究采用XGBoost模型，并比较了三种不同场景下处理类别不平衡问题对模型性能的影响：1. 不进行任何不平衡处理；2. 在训练集和测试集划分后，仅对训练集应用采样技术；3. 在训练集和测试集划分前应用采样技术。研究使用了Kaggle上包含284,807笔信用卡交易的数据集，其中欺诈案例占0.172%。

Result: 研究发现，在拆分前应用采样技术可能导致性能指标虚高，这主要是由于数据泄露问题。而仅在训练集上应用采样技术（拆分后）的模型，虽然结果略低于拆分前采样的方法，但能更好地保证评估过程的有效性，并且结果更为可靠。

Conclusion: 研究结果表明，虽然欠采样和过采样等方法可以提升XGBoost在信用卡欺诈检测中的性能，但应用的时机对结果的可靠性有很大影响。在训练集划分之前应用采样技术可能会导致数据泄露，从而虚高模型性能。令人惊讶的是，仅在训练集上应用采样技术（在训练集和测试集划分之后）的模型，其性能虽然低于在拆分前应用采样技术的方法，但却能更好地保持评估过程的完整性，并提供了更可靠的结果。

Abstract: Credit card fraud detection remains a critical challenge in financial
security, with machine learning models like XGBoost(eXtreme gradient boosting)
emerging as powerful tools for identifying fraudulent transactions. However,
the inherent class imbalance in credit card transaction datasets poses
significant challenges for model performance. Although sampling techniques are
commonly used to address this imbalance, their implementation sometimes
precedes the train-test split, potentially introducing data leakage.
  This study presents a comparative analysis of XGBoost's performance in credit
card fraud detection under three scenarios: Firstly without any imbalance
handling techniques, secondly with sampling techniques applied only to the
training set after the train-test split, and third with sampling techniques
applied before the train-test split. We utilized a dataset from Kaggle of
284,807 credit card transactions, containing 0.172\% fraudulent cases, to
evaluate these approaches.
  Our findings show that although sampling strategies enhance model
performance, the reliability of results is greatly impacted by when they are
applied. Due to a data leakage issue that frequently occurs in machine learning
models during the sampling phase, XGBoost models trained on data where sampling
was applied prior to the train-test split may have displayed artificially
inflated performance metrics. Surprisingly, models trained with sampling
techniques applied solely to the training set demonstrated significantly lower
results than those with pre-split sampling, all the while preserving the
integrity of the evaluation process.

</details>


### [165] [SimMLP: Training MLPs on Graphs without Supervision](https://arxiv.org/abs/2402.08918)
*Zehong Wang,Zheyuan Zhang,Chuxu Zhang,Yanfang Ye*

Main category: cs.LG

TL;DR: SimMLP框架通过自监督学习将GNN的结构信息融入MLP，实现了与GNN相当的性能，尤其擅长处理未见节点的问题，并在多项图学习任务中超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决GNNs在延迟敏感应用（如实时金融欺诈检测）中依赖邻域聚合带来的推理挑战，以及现有知识蒸馏方法在处理未见节点时未能充分利用结构信息的问题，研究提出了SimMLP框架。

Method: SimMLP框架通过自监督学习方法，将图的结构信息整合到MLPs中。具体而言，它通过对齐图上下文感知GNNs的表征和邻域依赖性无关的MLPs的表征来实现这一目标。该框架利用互信息和归纳偏差进行理论分析，证明了其与GNNs的等价性，突出了其在结构学习方面的能力。

Result: SimMLP在20个基准数据集上进行了广泛的实验，涵盖了节点分类、链接预测和图分类任务。实验结果表明，SimMLP在处理未见节点（如归纳式和冷启动节点分类）的场景下，其性能优于最先进的基线方法，充分展示了其强大的结构学习能力。

Conclusion: SimMLP是一种创新的自监督学习框架，旨在将图神经网络（GNNs）的结构信息有效注入到多层感知机（MLPs）中。通过对齐图上下文感知GNNs和不依赖邻域的MLPs的表征，SimMLP实现了在最优情况下的等价性，克服了传统MLP在处理图数据时的结构信息提取不足的问题。实验证明，SimMLP在节点分类、链接预测和图分类等多种任务上，尤其是在处理未见节点（如归纳式和冷启动节点分类）的场景下，表现优于现有技术。

Abstract: Graph Neural Networks (GNNs) have demonstrated their effectiveness in various
graph learning tasks, yet their reliance on neighborhood aggregation during
inference poses challenges for deployment in latency-sensitive applications,
such as real-time financial fraud detection. To address this limitation, recent
studies have proposed distilling knowledge from teacher GNNs into student
Multi-Layer Perceptrons (MLPs) trained on node content, aiming to accelerate
inference. However, these approaches often inadequately explore structural
information when inferring unseen nodes. To this end, we introduce SimMLP, a
Self-supervised framework for learning MLPs on graphs, designed to fully
integrate rich structural information into MLPs. Notably, SimMLP is the first
MLP-learning method that can achieve equivalence to GNNs in the optimal case.
The key idea is to employ self-supervised learning to align the representations
encoded by graph context-aware GNNs and neighborhood dependency-free MLPs,
thereby fully integrating the structural information into MLPs. We provide a
comprehensive theoretical analysis, demonstrating the equivalence between
SimMLP and GNNs based on mutual information and inductive bias, highlighting
SimMLP's advanced structural learning capabilities. Additionally, we conduct
extensive experiments on 20 benchmark datasets, covering node classification,
link prediction, and graph classification, to showcase SimMLP's superiority
over state-of-the-art baselines, particularly in scenarios involving unseen
nodes (e.g., inductive and cold-start node classification) where structural
insights are crucial. Our codes are available at:
https://github.com/Zehong-Wang/SimMLP.

</details>


### [166] [Training MLPs on Graphs without Supervision](https://arxiv.org/abs/2412.03864)
*Zehong Wang,Zheyuan Zhang,Chuxu Zhang,Yanfang Ye*

Main category: cs.LG

TL;DR: SimMLP是一种将图结构信息融入MLP的新型自监督学习框架，实现了与GNN的理论等价性，并在多种图学习任务中超越现有技术，尤其擅长处理未见节点。


<details>
  <summary>Details</summary>
Motivation: 现有的GNN蒸馏方法在推理未见节点时未能充分利用结构信息，导致部署延迟和性能受限，尤其在金融欺诈检测等实时应用中。SimMLP旨在解决此问题。

Method: 提出SimMLP框架，利用自监督学习对图上下文感知GNN和不依赖邻域的MLP进行表示对齐，从而将结构信息完全整合到MLP中。

Result: 在20个基准数据集的节点分类、链接预测和图分类任务上，SimMLP均优于现有方法，特别是在归纳学习和冷启动节点分类等需要丰富结构信息的场景下。

Conclusion: SimMLP通过自监督学习将图的结构信息融入MLP，实现了与GNN在理论上的等价性，并在多个图学习任务中展现出优越性能，尤其在处理未见节点时效果显著。

Abstract: Graph Neural Networks (GNNs) have demonstrated their effectiveness in various
graph learning tasks, yet their reliance on neighborhood aggregation during
inference poses challenges for deployment in latency-sensitive applications,
such as real-time financial fraud detection. To address this limitation, recent
studies have proposed distilling knowledge from teacher GNNs into student
Multi-Layer Perceptrons (MLPs) trained on node content, aiming to accelerate
inference. However, these approaches often inadequately explore structural
information when inferring unseen nodes. To this end, we introduce SimMLP, a
Self-supervised framework for learning MLPs on graphs, designed to fully
integrate rich structural information into MLPs. Notably, SimMLP is the first
MLP-learning method that can achieve equivalence to GNNs in the optimal case.
The key idea is to employ self-supervised learning to align the representations
encoded by graph context-aware GNNs and neighborhood dependency-free MLPs,
thereby fully integrating the structural information into MLPs. We provide a
comprehensive theoretical analysis, demonstrating the equivalence between
SimMLP and GNNs based on mutual information and inductive bias, highlighting
SimMLP's advanced structural learning capabilities. Additionally, we conduct
extensive experiments on 20 benchmark datasets, covering node classification,
link prediction, and graph classification, to showcase SimMLP's superiority
over state-of-the-art baselines, particularly in scenarios involving unseen
nodes (e.g., inductive and cold-start node classification) where structural
insights are crucial. Our codes are available at:
https://github.com/Zehong-Wang/SimMLP.

</details>


### [167] [Multi-task CNN Behavioral Embedding Model For Transaction Fraud Detection](https://arxiv.org/abs/2411.19457)
*Bo Qu,Zhurong Wang,Minghao Gu,Daisuke Yagi,Yang Zhao,Yinan Shan,Frank Zahradnik*

Main category: cs.LG

TL;DR: 本研究提出了一种新的多任务CNN模型，用于电子商务欺诈检测，解决了现有方法的效率和领域知识整合问题。该模型采用独特的CNN设计和多任务学习，在真实数据上表现优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度学习方法在平衡建模能力、效率和整合领域知识方面存在的挑战，以应对电子商务领域日益增长的交易欺诈检测需求。

Method: 提出了一种单层CNN设计，采用多范围卷积核，并在CNN中集成位置编码以引入序列顺序信号，同时实现了多任务学习，随机分配标签权重，无需手动调整。

Result: 所提出的单层CNN设计，采用多范围卷积核，其可扩展性和领域归纳偏置优于LSTM和Transformer模型。将位置编码与CNN集成，增强了序列顺序信号，提升了整体性能。多任务学习和随机分配的标签权重消除了手动调整的需要。在真实世界数据上的测试表明，该模型能增强下游交易模型的性能。

Conclusion: 所提出的多任务CNN行为嵌入模型在交易欺诈检测方面表现出增强的性能，并且与Transformer时间序列（TST）模型相比具有可比的竞争力。

Abstract: The burgeoning e-Commerce sector requires advanced solutions for the
detection of transaction fraud. With an increasing risk of financial
information theft and account takeovers, deep learning methods have become
integral to the embedding of behavior sequence data in fraud detection.
However, these methods often struggle to balance modeling capabilities and
efficiency and incorporate domain knowledge. To address these issues, we
introduce the multitask CNN behavioral Embedding Model for Transaction Fraud
Detection. Our contributions include 1) introducing a single-layer CNN design
featuring multirange kernels which outperform LSTM and Transformer models in
terms of scalability and domain-focused inductive bias, and 2) the integration
of positional encoding with CNN to introduce sequence-order signals enhancing
overall performance, and 3) implementing multitask learning with randomly
assigned label weights, thus removing the need for manual tuning. Testing on
real-world data reveals our model's enhanced performance of downstream
transaction models and comparable competitiveness with the Transformer Time
Series (TST) model.

</details>


### [168] [CaT-GNN: Enhancing Credit Card Fraud Detection via Causal Temporal Graph Neural Networks](https://arxiv.org/abs/2402.14708)
*Yifan Duan,Guibin Zhang,Shilong Wang,Xiaojiang Peng,Wang Ziqi,Junyuan Mao,Hao Wu,Xinke Jiang,Kun Wang*

Main category: cs.LG

TL;DR: CaT-GNN 是一种用于信用欺诈检测的新型方法，它利用因果不变学习来提高 GNN 在识别欺诈行为时的鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 信用欺诈对经济构成重大威胁。虽然基于图神经网络 (GNN) 的欺诈检测方法表现良好，但它们通常会忽略节点局部结构对其预测的因果影响。

Method: 提出了一种名为 CaT-GNN 的新型信用欺诈检测方法，该方法利用因果不变学习来揭示交易数据中的固有相关性。它将问题分解为发现和干预阶段，识别因果节点，并应用因果混合策略来提高模型的鲁棒性和可解释性。CaT-GNN 由因果检查器（利用时间注意力机制中的注意力权重识别因果节点和环境节点）和因果干预器（基于节点集对环境节点进行因果混合增强）组成。

Result: 在三个数据集（包括一个私有金融数据集和两个公共数据集）上进行了评估，CaT-GNN 的表现优于现有的最先进方法。

Conclusion: 该研究强调了将因果推理与图神经网络相结合以提高金融交易欺诈检测能力。CaT-GNN 在三个数据集上的表现优于现有最先进的方法。

Abstract: Credit card fraud poses a significant threat to the economy. While Graph
Neural Network (GNN)-based fraud detection methods perform well, they often
overlook the causal effect of a node's local structure on predictions. This
paper introduces a novel method for credit card fraud detection, the
\textbf{\underline{Ca}}usal \textbf{\underline{T}}emporal
\textbf{\underline{G}}raph \textbf{\underline{N}}eural \textbf{N}etwork
(CaT-GNN), which leverages causal invariant learning to reveal inherent
correlations within transaction data. By decomposing the problem into discovery
and intervention phases, CaT-GNN identifies causal nodes within the transaction
graph and applies a causal mixup strategy to enhance the model's robustness and
interpretability. CaT-GNN consists of two key components: Causal-Inspector and
Causal-Intervener. The Causal-Inspector utilizes attention weights in the
temporal attention mechanism to identify causal and environment nodes without
introducing additional parameters. Subsequently, the Causal-Intervener performs
a causal mixup enhancement on environment nodes based on the set of nodes.
Evaluated on three datasets, including a private financial dataset and two
public datasets, CaT-GNN demonstrates superior performance over existing
state-of-the-art methods. Our findings highlight the potential of integrating
causal reasoning with graph neural networks to improve fraud detection
capabilities in financial transactions.

</details>


### [169] [TASER: Temporal Adaptive Sampling for Fast and Accurate Dynamic Graph Representation Learning](https://arxiv.org/abs/2402.05396)
*Gangda Deng,Hongkuan Zhou,Hanqing Zeng,Yinglong Xia,Christopher Leung,Jianbo Li,Rajgopal Kannan,Viktor Prasanna*

Main category: cs.LG

TL;DR: TASER 是一种新颖的时间自适应采样方法，可提高 TGNN 的准确性和效率，解决了现有 TGNN 去噪技术中的噪声和开销问题。


<details>
  <summary>Details</summary>
Motivation: 现有的 TGNN 去噪技术没有考虑到每个节点多样化和动态的噪声模式，并且在迷你批次生成中存在开销过大的问题。本文认为，快速准确的 TGNN 的解决方案在于时间自适应采样。

Method: TASER 提出了一种自适应采样方法，该方法根据训练动态和过去交互的上下文、结构和时间属性来调整其迷你批次选择和时间邻居选择。为了减轻迷你批次生成的瓶颈，TASER 采用了一个纯粹基于 GPU 的时间邻居查找器和一个专用的 GPU 功能缓存。

Result: TASER 在平均准确率（MRR）方面超越了相应的基线 2.3%，同时在训练时间上实现了平均 5.1 倍的加速。

Conclusion: TASER 通过在五个流行数据集上使用两个最先进的主干 TGNN 进行评估，在平均准确率（MRR）方面超越了相应的基线 2.3%，同时在训练时间上实现了平均 5.1 倍的加速。

Abstract: Recently, Temporal Graph Neural Networks (TGNNs) have demonstrated
state-of-the-art performance in various high-impact applications, including
fraud detection and content recommendation. Despite the success of TGNNs, they
are prone to the prevalent noise found in real-world dynamic graphs like
time-deprecated links and skewed interaction distribution. The noise causes two
critical issues that significantly compromise the accuracy of TGNNs: (1) models
are supervised by inferior interactions, and (2) noisy input induces high
variance in the aggregated messages. However, current TGNN denoising techniques
do not consider the diverse and dynamic noise pattern of each node. In
addition, they also suffer from the excessive mini-batch generation overheads
caused by traversing more neighbors. We believe the remedy for fast and
accurate TGNNs lies in temporal adaptive sampling. In this work, we propose
TASER, the first adaptive sampling method for TGNNs optimized for accuracy,
efficiency, and scalability. TASER adapts its mini-batch selection based on
training dynamics and temporal neighbor selection based on the contextual,
structural, and temporal properties of past interactions. To alleviate the
bottleneck in mini-batch generation, TASER implements a pure GPU-based temporal
neighbor finder and a dedicated GPU feature cache. We evaluate the performance
of TASER using two state-of-the-art backbone TGNNs. On five popular datasets,
TASER outperforms the corresponding baselines by an average of 2.3% in Mean
Reciprocal Rank (MRR) while achieving an average of 5.1x speedup in training
time.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [170] [Microservices and Real-Time Processing in Retail IT: A Review of Open-Source Toolchains and Deployment Strategies](https://arxiv.org/abs/2506.09938)
*Aaditaa Vashisht,Rekha B S*

Main category: cs.SE

TL;DR: 该研究回顾了 Kafka、Spring Boot、MongoDB 和 Kubernetes 等技术在现代零售和金融系统中的应用，强调了它们在提高实时处理、可扩展性和弹性的方面的作用，并为行业实践者和教育工作者提供了见解。


<details>
  <summary>Details</summary>
Motivation: 随着数字化转型的快速发展，零售业越来越依赖实时、可扩展和有弹性的系统来管理金融交易、分析客户行为和简化订单处理。本文献综述旨在探讨现代事件驱动和微服务架构如何重塑零售和金融系统。

Method: 本研究通过系统性地回顾近年来的学术出版物、技术白皮书和行业报告，探讨了现代事件驱动和微服务架构（特别是利用 Apache Kafka、Spring Boot、MongoDB 和 Kubernetes 的架构）如何改变零售和金融系统。

Result: 研究结果表明，Kafka 和 Spring Boot 等技术在构建支持实时分析和欺诈检测的低延迟、事件驱动应用程序方面发挥着关键作用，而部署在 Kubernetes 上的 MongoDB 可确保库存和交易系统的容错能力和高可用性。Kubernetes 在自动化微服务的部署和扩展方面也发挥着至关重要的作用。

Conclusion: 该研究综合了学术出版物、技术白皮书和行业报告，重点关注了支持实时分析、欺诈检测、库存和交易系统的现代事件驱动和微服务架构。它强调了 Kafka、Spring Boot、MongoDB 和 Kubernetes 在构建低延迟、可扩展和有弹性的零售和金融系统中的作用，特别是 Kubernetes 在自动化部署和扩展微服务方面的作用。

Abstract: With the rapid pace of digital transformation, the retail industry is
increasingly depending on real-time, scalable, and resilient systems to manage
financial transactions, analyze customer behavior, and streamline order
processing. This literature review explores how modern event-driven and
microservices-based architectures, particularly those leveraging Apache Kafka,
Spring Boot, MongoDB, and Kubernetes are transforming retail and financial
systems. By systematically reviewing academic publications, technical white
papers, and industry reports from recent years, this study synthesizes key
themes and implementation strategies. The analysis reveals that technologies
like Kafka and Spring Boot are instrumental in building low-latency,
event-driven applications that support real-time analytics and fraud detection,
while MongoDB, when deployed on Kubernetes, ensures fault tolerance and high
availability in inventory and transaction systems. Kubernetes itself plays a
crucial role in automating deployment and scaling of microservices. These
findings provide valuable insights for industry practitioners aiming to design
scalable infrastructures, identify research opportunities in hybrid deployment
models, and offer educators a foundation to integrate modern system
architectures into professional and technical communication training.

</details>


### [171] [AgentDroid: A Multi-Agent Framework for Detecting Fraudulent Android Applications](https://arxiv.org/abs/2503.12163)
*Ruwei Pan,Hongyu Zhang,Zhonghao Jiang,Ran Hou*

Main category: cs.SE

TL;DR: AgentDroid是一个利用多模态分析和基于GPT-4o的多智能体系统来检测Android欺诈应用程序的新框架，相比现有方法提高了检测准确性。


<details>
  <summary>Details</summary>
Motivation: 随着欺诈性Android应用程序（如虚假和恶意应用程序）的日益普及，以高准确性和适应性检测它们至关重要。

Method: AgentDroid使用多模态分析和多智能体系统（基于GPT-4o）来检测Android欺诈应用程序。它处理应用程序数据，提取多模态数据，并由具有专门角色的LLM智能体进行分析和协作。

Result: 实验结果表明，基于GPT-4o的多智能体框架在包含各种类别欺诈和合法应用程序的数据集上，实现了91.7%的准确率和91.68%的F1分数，证明了其比基线方法更高的检测准确性。

Conclusion: AgentDroid框架在Android欺诈应用程序检测方面取得了91.7%的准确率和91.68%的F1分数，优于基线方法。

Abstract: With the increasing prevalence of fraudulent Android applications such as
fake and malicious applications, it is crucial to detect them with high
accuracy and adaptability. This paper introduces AgentDroid, a novel framework
for Android fraudulent application detection based on multi-modal analysis and
multi-agent systems. AgentDroid overcomes the limitations of traditional
detection methods such as the inability to handle multimodal data and high
false alarm rates. It processes Android applications and extracts a series of
multi-modal data for analysis. Multiple LLM-based agents with specialized roles
analyze the relevant data and collaborate to detect complex fraud effectively.
We constructed a dataset containing various categories of fraudulent
applications and legitimate applications and validated our framework on this
dataset. Experimental results indicate that our multi-agent framework based on
GPT-4o achieves an accuracy of 91.7% and an F1-Score of 91.68%, showing
improved detection accuracy over the baseline methods.

</details>


### [172] [Improved Detection and Diagnosis of Faults in Deep Neural Networks Using Hierarchical and Explainable Classification](https://arxiv.org/abs/2501.12560)
*Sigma Jahan,Mehil B Shah,Parvez Mahbub,Mohammad Masudur Rahman*

Main category: cs.SE

TL;DR: DEFault 是一种新的技术，可以检测和诊断 DNN 程序中的故障。它结合了动态和静态分析，并利用分层分类和可解释的 AI 方法来提高准确性和根本原因分析。


<details>
  <summary>Details</summary>
Motivation: DNN 系统通常由于其固有的复杂性和底层模型固有的随机性而存在可靠性问题。现有的检测 DNN 程序故障的技术，要么受限于它们支持的故障类型（例如，超参数或层），要么受限于它们使用的信息类型（例如，动态或静态），因此可能无法全面检测和诊断故障。

Method: DEFault 首先在模型训练期间捕获动态（即运行时）特征，并利用分层分类方法来检测文献中的所有主要故障类别。然后，它从 DNN 程序中捕获静态特征（例如，层类型），并利用可解释的 AI 方法（例如，SHAP）来缩小故障的根本原因。

Result: DEFault 在~14.5K DNN 程序的大型、多样化数据集上进行训练和评估，并通过 52 个真实世界故障 DNN 程序的基准数据集进行验证。该方法在检测真实世界的故障 DNN 程序方面实现了~94% 的召回率，在诊断故障根本原因方面实现了~63% 的召回率，比最先进的技术性能高出 3.92% - 11.54%。

Conclusion: DEFault 有潜力通过有效检测和诊断故障来显著提高 DNN 程序的可靠性。

Abstract: Deep Neural Networks (DNN) have found numerous applications in various
domains, including fraud detection, medical diagnosis, facial recognition, and
autonomous driving. However, DNN-based systems often suffer from reliability
issues due to their inherent complexity and the stochastic nature of their
underlying models. Unfortunately, existing techniques to detect faults in DNN
programs are either limited by the types of faults (e.g., hyperparameter or
layer) they support or the kind of information (e.g., dynamic or static) they
use. As a result, they might fall short of comprehensively detecting and
diagnosing the faults. In this paper, we present DEFault (Detect and Explain
Fault) -- a novel technique to detect and diagnose faults in DNN programs. It
first captures dynamic (i.e., runtime) features during model training and
leverages a hierarchical classification approach to detect all major fault
categories from the literature. Then, it captures static features (e.g., layer
types) from DNN programs and leverages explainable AI methods (e.g., SHAP) to
narrow down the root cause of the fault. We train and evaluate DEFault on a
large, diverse dataset of ~14.5K DNN programs and further validate our
technique using a benchmark dataset of 52 real-life faulty DNN programs. Our
approach achieves ~94% recall in detecting real-world faulty DNN programs and
~63% recall in diagnosing the root causes of the faults, demonstrating 3.92% -
11.54% higher performance than that of state-of-the-art techniques. Thus,
DEFault has the potential to significantly improve the reliability of DNN
programs by effectively detecting and diagnosing the faults.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [173] [Dupin: A Parallel Framework for Densest Subgraph Discovery in Fraud Detection on Massive Graphs (Technical Report)](https://arxiv.org/abs/2504.09311)
*Jiaxin Jiang,Siyuan Yao,Yuchen Li,Qiange Wang,Bingsheng He,Min Chen*

Main category: cs.DB

TL;DR: Dupin 是一个为万亿规模图设计的并行处理框架，可高效执行 DSD，在欺诈检测方面速度和准确性均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的 DSD 方法在生产系统中存在可扩展性挑战，因为它们主要是顺序执行的，无法处理大规模交易网络，并导致检测延迟显著。

Method: Dupin 是一个新颖的并行处理框架，利用剥离过程的独特属性，支持可扩展的密集子图发现 (DSD) 处理，并提供易于使用的 API 来自定义 DSD 目标。

Result: Dupin 在万亿规模图上的表现优于其他 DSD 方法，性能提高高达 100 倍，将欺诈预防能力从 45% 提高到 94.5%，并将密度误差从 30% 降低到 5% 以下。

Conclusion: Dupin 在处理万亿级图时，通过利用剥离过程的独特属性，并提供理论保证，在检测质量和效率方面表现出色，用户友好的 API 可实现灵活的自定义，确保了对各种欺诈检测场景的鲁棒适应性。在实际应用中，Dupin 的有效性得到了证实，与传统方法相比，性能提高了 100 倍，将欺诈交易的预防能力从 45% 提高到 94.5%，并将密度误差从 30% 降低到 5% 以下。

Abstract: Detecting fraudulent activities in financial and e-commerce transaction
networks is crucial. One effective method for this is Densest Subgraph
Discovery (DSD). However, deploying DSD methods in production systems faces
substantial scalability challenges due to the predominantly sequential nature
of existing methods, which impedes their ability to handle large-scale
transaction networks and results in significant detection delays. To address
these challenges, we introduce Dupin, a novel parallel processing framework
designed for efficient DSD processing in billion-scale graphs. Dupin is powered
by a processing engine that exploits the unique properties of the peeling
process, with theoretical guarantees on detection quality and efficiency. Dupin
provides userfriendly APIs for flexible customization of DSD objectives and
ensures robust adaptability to diverse fraud detection scenarios. Empirical
evaluations demonstrate that Dupin consistently outperforms several existing
DSD methods, achieving performance improvements of up to 100 times compared to
traditional approaches. On billion-scale graphs, Dupin demonstrates the
potential to enhance the prevention of fraudulent transactions from 45% to
94.5% and reduces density error from 30% to below 5%, as supported by our
experimental results. These findings highlight the effectiveness of Dupin in
real-world applications, ensuring both speed and accuracy in fraud detection.

</details>


### [174] [FeatInsight: An Online ML Feature Management System on 4Paradigm Sage-Studio Platform](https://arxiv.org/abs/2504.00786)
*Xin Tong,Xuanhe Zhou,Bingsheng He,Guoliang Li,Zirui Tang,Wei Zhou,Fan Wu,Mian Lu,Yuqiang Chen*

Main category: cs.DB

TL;DR: FeatInsight is a system for managing the entire online ML feature lifecycle, addressing challenges of scale, performance, and rapid updates. It has been widely deployed, demonstrating improvements in efficiency and performance for applications like product recommendation and fraud detection.


<details>
  <summary>Details</summary>
Motivation: Managing online ML features is challenging due to large-scale data, the need for high-performance computation of interdependent features, and the requirement for rapid updates to accommodate real-time data changes. Feature management is essential for online ML applications and can be a performance bottleneck.

Method: FeatInsight is a system that supports the entire feature lifecycle, including design, storage, visualization, computation, verification, and lineage management, using OpenMLDB as the execution engine.

Result: Demonstrates how FeatInsight enhances feature design efficiency (e.g., for online product recommendation) and improves feature computation performance (e.g., for online fraud detection).

Conclusion: FeatInsight has been deployed in over 100 real-world scenarios, handling up to a trillion-dimensional feature space and enabling millisecond-level feature updates, enhancing efficiency and performance in online ML applications.

Abstract: Feature management is essential for many online machine learning applications
and can often become the performance bottleneck (e.g., taking up to 70% of the
overall latency in sales prediction service). Improper feature configurations
(e.g., introducing too many irrelevant features) can severely undermine the
model's generalization capabilities. However, managing online ML features is
challenging due to (1) large-scale, complex raw data (e.g., the 2018 PHM
dataset contains 17 tables and dozens to hundreds of columns), (2) the need for
high-performance, consistent computation of interdependent features with
complex patterns, and (3) the requirement for rapid updates and deployments to
accommodate real-time data changes. In this demo, we present FeatInsight, a
system that supports the entire feature lifecycle, including feature design,
storage, visualization, computation, verification, and lineage management.
FeatInsight (with OpenMLDB as the execution engine) has been deployed in over
100 real-world scenarios on 4Paradigm's Sage Studio platform, handling up to a
trillion-dimensional feature space and enabling millisecond-level feature
updates. We demonstrate how FeatInsight enhances feature design efficiency
(e.g., for online product recommendation) and improve feature computation
performance (e.g., for online fraud detection). The code is available at
https://github.com/4paradigm/FeatInsight.

</details>


### [175] [Graph Data Management and Graph Machine Learning: Synergies and Opportunities](https://arxiv.org/abs/2502.00529)
*Arijit Khan,Xiangyu Ke,Yinghui Wu*

Main category: cs.DB

TL;DR: 本调查全面概述了图数据管理和图机器学习之间的协同作用，强调了它们在整个图数据科学和机器学习管道中的相互促进作用，并讨论了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 鉴于机器学习（尤其是深度学习）在图应用中的普及，从化学信息学（药物发现）和生物信息学（蛋白质相互作用预测）到基于知识图谱的查询应答、欺诈检测和社交网络分析，本调查旨在全面概述图数据管理和图机器学习之间的协同作用。

Method: 通过重点介绍两个关键方面来阐述协同作用：1. 图数据管理如何增强图机器学习（例如，通过图数据清理、可扩展图嵌入、高效图基向量数据管理、鲁棒图神经网络、用户友好的可解释性方法来提高图神经网络性能）；2. 图机器学习如何反过来帮助图数据管理（例如，在知识图谱查询应答和各种数据科学任务中的应用）。

Result: 本调查提供了图数据管理与图机器学习之间协同作用的全面概述，并讨论了相关公开问题和关键研究方向。

Conclusion: 本调查全面概述了图数据管理和图机器学习之间的协同作用，说明了它们如何在整个图数据科学和机器学习管道中相互交织和相互加强。

Abstract: The ubiquity of machine learning, particularly deep learning, applied to
graphs is evident in applications ranging from cheminformatics (drug discovery)
and bioinformatics (protein interaction prediction) to knowledge graph-based
query answering, fraud detection, and social network analysis. Concurrently,
graph data management deals with the research and development of effective,
efficient, scalable, robust, and user-friendly systems and algorithms for
storing, processing, and analyzing vast quantities of heterogeneous and complex
graph data. Our survey provides a comprehensive overview of the synergies
between graph data management and graph machine learning, illustrating how they
intertwine and mutually reinforce each other across the entire spectrum of the
graph data science and machine learning pipeline. Specifically, the survey
highlights two crucial aspects: (1) How graph data management enhances graph
machine learning, including contributions such as improved graph neural network
performance through graph data cleaning, scalable graph embedding, efficient
graph-based vector data management, robust graph neural networks, user-friendly
explainability methods; and (2) how graph machine learning, in turn, aids in
graph data management, with a focus on applications like query answering over
knowledge graphs and various data science tasks. We discuss pertinent open
problems and delineate crucial research directions.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [176] [Human-Centred AI in FinTech: Developing a User Experience (UX) Research Point of View (PoV) Playbook](https://arxiv.org/abs/2506.15325)
*Festus Adedoyin,Huseyin Dogan*

Main category: cs.HC

TL;DR: 本研究阐述了以人为本的人工智能（HCAI）如何通过个性化金融服务、机器人咨询和增强的风险管理来革新金融行业，并强调了用户体验研究（UXR）在确保技术成功应用中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨人工智能（AI）如何在金融行业促进更具个性化和适应性的金融产品和服务的开发，特别关注以人为本的人工智能（HCAI）的作用。

Method: 本研究通过分析当代研究和行业进展，探讨了以人为本的人工智能（HCAI）在金融行业的应用实例。

Result: 研究结果表明，HCAI驱动的数据分析、机器学习和自然语言处理能够帮助金融机构深入了解客户需求，从而创建满足个人消费者需求的定制化金融解决方案，提升用户体验和满意度。此外，AI驱动的机器人咨询服务能提供定制化的投资建议和投资组合管理，并且AI在增强欺诈检测、风险评估和法规遵从方面也发挥着重要作用，从而促进了更安全、更具适应性的金融环境。

Conclusion: 该研究强调了以人为本的人工智能（HCAI）对金融行业的深远影响，并为金融机构利用这些技术提供了战略框架。通过纳入用户体验研究（UXR）的视角，金融机构可以确保人工智能驱动的解决方案符合用户需求和业务目标。

Abstract: Advancements in Artificial Intelligence (AI) have significantly transformed
the financial industry, enabling the development of more personalised and
adaptable financial products and services. This research paper explores various
instances where Human-Centred AI (HCAI) has facilitated these advancements,
drawing from contemporary studies and industry progress. The paper examines how
the application of HCAI-powered data analytics, machine learning, and natural
language processing enables financial institutions to gain a deeper
understanding of their customers' unique needs, preferences, and behavioural
patterns. This, in turn, allows for the creation of tailored financial
solutions that address individual consumer requirements, ultimately enhancing
overall user experience and satisfaction. Additionally, the study highlights
the integration of AI-powered robo-advisory services, which offer customised
investment recommendations and portfolio management tailored to diverse risk
profiles and investment goals. Moreover, the paper underscores the role of AI
in strengthening fraud detection, risk assessment, and regulatory compliance,
leading to a more secure and adaptable financial landscape. The findings of
this research demonstrate the substantial impact of Human-Centred AI on the
financial industry, offering a strategic framework for financial institutions
to leverage these technologies. By incorporating a User Experience Research
(UXR) Point of View (PoV), financial institutions can ensure that AI-driven
solutions align with user needs and business objectives.

</details>


### [177] [StructVizor: Interactive Profiling of Semi-Structured Textual Data](https://arxiv.org/abs/2503.06500)
*Yanwei Huang,Yan Miao,Di Weng,Adam Perer,Yingcai Wu*

Main category: cs.HC

TL;DR: StructVizor 帮助用户对半结构化文本数据进行可视化分析和重塑。


<details>
  <summary>Details</summary>
Motivation: 现有的数据剖析技术主要关注结构化数据，而大量的半结构化文本数据需要繁琐的手动剖析。本文提出StructVizor，旨在解决半结构化文本数据解析和结构可视化，以及高效的数据重塑操作。

Method: StructVizor通过自动数据解析和结构挖掘，实现数据结构模式的可视化分析，并结合新颖的交互方式支持基于配置文件的重塑。

Result: StructVizor能够可视化半结构化文本数据的结构模式，并支持基于配置文件的重塑操作。用户研究表明该系统易于使用，并能有效支持探索性数据分析和重塑任务。

Conclusion: StructVizor是一个用户友好的系统，通过自动解析和结构挖掘，实现了半结构化文本数据的可视化分析和基于配置文件的重塑，并在用户研究中得到了验证。

Abstract: Data profiling plays a critical role in understanding the structure of
complex datasets and supporting numerous downstream tasks, such as social media
analytics and financial fraud detection. While existing research predominantly
focuses on structured data formats, a substantial portion of semi-structured
textual data still requires ad-hoc and arduous manual profiling to extract and
comprehend its internal structures. In this work, we propose StructVizor, an
interactive profiling system that facilitates sensemaking and transformation of
semi-structured textual data. Our tool mainly addresses two challenges: a)
extracting and visualizing the diverse structural patterns within data, such as
how information is organized or related, and b) enabling users to efficiently
perform various wrangling operations on textual data. Through automatic data
parsing and structure mining, StructVizor enables visual analytics of
structural patterns, while incorporating novel interactions to enable
profile-based data wrangling. A comparative user study involving 12
participants demonstrates the system's usability and its effectiveness in
supporting exploratory data analysis and transformation tasks.

</details>


### [178] ["Auntie, Please Don't Fall for Those Smooth Talkers": How Chinese Younger Family Members Safeguard Seniors from Online Fraud](https://arxiv.org/abs/2501.10803)
*Yue Deng,Changyang He,Yixin Zou,Bo Li*

Main category: cs.HC

TL;DR: 本研究发现，在中国，年轻家庭成员通过识别欺诈、提供保护和教育来帮助老年人防范在线欺诈，但同时也面临挑战。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在填补关于家庭如何保护老年人免受在线欺诈的研究空白，因为老年人是网络欺诈的重点目标，而家庭在其中扮演着至关重要的角色。

Method: 本研究采用归纳主题分析法，分析了小红书上124个帖子和16,872条评论，以探索中国针对老年人的在线欺诈的家庭支持生态系统。

Result: 研究识别出一种从家庭视角出发的针对老年人的在线欺诈分类，年轻家庭成员在识别异常收费等老年人难以察觉的欺诈方面作用显著。他们承担了预防、识别、劝阻、挽回损失和教育等多种保护角色，但也面临老年人拒绝帮助和巨大的精神经济压力等挑战。最终，研究提出了一个概念框架来描述家庭支持在针对老年人的欺诈中的作用。

Conclusion: 本研究通过对小红书上124个帖子和16,872条评论进行归纳主题分析，探讨了中国针对老年人的在线欺诈的家庭支持生态系统。研究结果表明，年轻家庭成员在识别老年人难以察觉的欺诈（如异常收费）方面发挥着关键作用，并承担着预防、识别、劝阻、追回损失和教育等多重保护角色。同时，他们也面临着老年人拒绝帮助和巨大的精神经济压力等挑战。研究提出了一个概念框架来描述家庭在老年人欺诈防护中的支持作用，并为研究人员和从业者提供了考虑更广泛的利益相关者生态系统和文化方面的启示。

Abstract: Online fraud substantially harms individuals and seniors are
disproportionately targeted. While family is crucial for seniors, little
research has empirically examined how they protect seniors against fraud. To
address this gap, we employed an inductive thematic analysis of 124 posts and
16,872 comments on RedNote (Xiaohongshu), exploring the family support
ecosystem for senior-targeted online fraud in China. We develop a taxonomy of
senior-targeted online fraud from a familial perspective, revealing younger
members often spot frauds hard for seniors to detect, such as unusual charges.
Younger family members fulfill multiple safeguarding roles, including
preventative measures, fraud identification, fraud persuasion, loss recovery,
and education. They also encounter numerous challenges, such as seniors'
refusal of help and considerable mental and financial stress. Drawing on these,
we develop a conceptual framework to characterize family support in
senior-targeted fraud, and outline implications for researchers and
practitioners to consider the broader stakeholder ecosystem and cultural
aspects.

</details>


### [179] [PonziLens+: Visualizing Bytecode Actions for Smart Ponzi Scheme Identification](https://arxiv.org/abs/2412.18470)
*Xiaolin Wen,Tai D. Nguyen,Shaolun Ruan,Qiaomu Shen,Jun Sun,Feida Zhu,Yong Wang*

Main category: cs.HC

TL;DR: 提出PonziLens+可视化分析方法，有效识别智能合约庞氏骗局。


<details>
  <summary>Details</summary>
Motivation: 现有检测智能合约庞氏骗局的方法缺乏可靠性和透明度，且难以适应各种庞氏骗局。

Method: 提取智能合约字节码中的语义动作，并利用PonziLens+可视化分析这些行为以识别庞氏骗局特征。

Result: PonziLens+通过三个可视化模块直观展示智能合约行为，突出欺诈特征，能够帮助投资者和审计员有效识别智能合约庞氏骗局。

Conclusion: 该研究提出了PonziLens+，一种用于识别智能合约庞氏骗局的可视化分析方法，并通过案例研究和用户访谈证明了其有效性和可用性。

Abstract: With the prevalence of smart contracts, smart Ponzi schemes have become a
common fraud on blockchain and have caused significant financial loss to
cryptocurrency investors in the past few years. Despite the critical importance
of detecting smart Ponzi schemes, a reliable and transparent identification
approach adaptive to various smart Ponzi schemes is still missing. To fill the
research gap, we first extract semantic-meaningful actions to represent the
execution behaviors specified in smart contract bytecodes, which are derived
from a literature review and in-depth interviews with domain experts. We then
propose PonziLens+, a novel visual analytic approach that provides an intuitive
and reliable analysis of Ponzi-scheme-related features within these execution
behaviors. PonziLens+ has three visualization modules that intuitively reveal
all potential behaviors of a smart contract, highlighting fraudulent features
across three levels of detail. It can help smart contract investors and
auditors achieve confident identification of any smart Ponzi schemes. We
conducted two case studies and in-depth user interviews with 12 domain experts
and common investors to evaluate PonziLens+. The results demonstrate the
effectiveness and usability of PonziLens+ in achieving an effective
identification of smart Ponzi schemes.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [180] [Is Your LLM-Based Multi-Agent a Reliable Real-World Planner? Exploring Fraud Detection in Travel Planning](https://arxiv.org/abs/2505.16557)
*Junchi Yao,Jianhua Xu,Tianyu Xin,Ziyi Wang,Shenzhe Zhu,Shu Yang,Di Wang*

Main category: cs.MA

TL;DR: WandaPlan 是一个评估环境，用于评估基于大语言模型的规划系统在面对欺诈信息时的风险。研究发现现有系统过于关注效率而忽略了数据真实性，并提出了集成反欺诈代理的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的自主和协作任务执行框架，依赖的现实世界数据（如点评网站和社交媒体）易受欺诈信息（如虚假点评或误导性描述）的影响，可能导致经济损失和用户体验受损。因此，有必要评估此类规划系统在真实应用中的风险。

Method: 在包含欺诈内容的真实世界数据中，评估了现有框架在虚假信息欺诈、团队协调多人欺诈和级别升级多轮欺诈这三种欺诈情况下的表现。此外，还验证了 WandaPlan 的通用性，能够评估真实世界开源规划框架的风险。

Result: 现有框架在优先考虑任务效率而非数据真实性方面存在明显弱点。WandaPlan 能够评估真实世界开源规划框架的风险。

Conclusion: 通过集成反欺诈代理，可以为可靠的规划提供解决方案，以减轻欺诈风险。

Abstract: The rise of Large Language Model-based Multi-Agent Planning has leveraged
advanced frameworks to enable autonomous and collaborative task execution. Some
systems rely on platforms like review sites and social media, which are prone
to fraudulent information, such as fake reviews or misleading descriptions.
This reliance poses risks, potentially causing financial losses and harming
user experiences. To evaluate the risk of planning systems in real-world
applications, we introduce \textbf{WandaPlan}, an evaluation environment
mirroring real-world data and injected with deceptive content. We assess system
performance across three fraud cases: Misinformation Fraud, Team-Coordinated
Multi-Person Fraud, and Level-Escalating Multi-Round Fraud. We reveal
significant weaknesses in existing frameworks that prioritize task efficiency
over data authenticity. At the same time, we validate WandaPlan's
generalizability, capable of assessing the risks of real-world open-source
planning frameworks. To mitigate the risk of fraud, we propose integrating an
anti-fraud agent, providing a solution for reliable planning.

</details>


### [181] [Free Agent in Agent-Based Mixture-of-Experts Generative AI Framework](https://arxiv.org/abs/2501.17903)
*Jung-Hua Liu*

Main category: cs.MA

TL;DR: RLFA是一种受棒球启发的算法，用于替换多代理系统中的低效代理，以提高整体性能和适应性。


<details>
  <summary>Details</summary>
Motivation: 许多多代理系统虽然会将任务分配给专门的、自主的代理，但往往缺乏实时替换或重新分配表现不佳代理的机制。

Method: RLFA算法借鉴了美国职业棒球大联盟的自由球员模式，让每个代理内部使用混合专家（MoE）方法，通过门控函数指导将传入任务委托给专门的子模型。

Result: RLFA算法能够及时替换检测准确率低于预设阈值且持续表现不佳的代理，并测试新代理的试用期模式，以确保持续的准确性、更快地适应新兴威胁，并最大限度地减少对正在进行的操作的干扰。

Conclusion: RLFA算法通过引入基于奖励的机制，能够实时检测、移除表现不佳的代理，并无缝接入更强大的代理，从而确保持续的准确性、更快地适应新兴威胁，并最大限度地减少对正在进行的操作的干扰。通过不断更新代理“阵容”，该系统促进了多代理生成式AI环境中持续的改进和更具韧性的协作。

Abstract: Multi-agent systems commonly distribute tasks among specialized, autonomous
agents, yet they often lack mechanisms to replace or reassign underperforming
agents in real time. Inspired by the free-agency model of Major League
Baseball, the Reinforcement Learning Free Agent (RLFA) algorithm introduces a
reward-based mechanism to detect and remove agents exhibiting persistent
underperformance and seamlessly insert more capable ones. Each agent internally
uses a mixture-of-experts (MoE) approach, delegating incoming tasks to
specialized sub-models under the guidance of a gating function. A primary use
case is fraud detection, where RLFA promptly swaps out an agent whose detection
accuracy dips below a preset threshold. A new agent is tested in a probationary
mode, and upon demonstrating superior performance, fully replaces the
underperformer. This dynamic, free-agency cycle ensures sustained accuracy,
quicker adaptation to emerging threats, and minimal disruption to ongoing
operations. By continually refreshing its roster of agents, the system fosters
ongoing improvements and more resilient collaboration in multi-agent Generative
AI environments.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [182] [Proof-of-Behavior: Behavior-Driven Consensus for Trustworthy Decentralized Finance](https://arxiv.org/abs/2506.22171)
*Ailiya Borjigin,Wei Zhou,Cong He*

Main category: cs.DC

TL;DR: PoB is a new consensus model that measures validator trustworthiness by scoring actions and adapting weights, significantly reducing fraud and improving fairness in DeFi with minimal throughput impact.


<details>
  <summary>Details</summary>
Motivation: Current blockchain protocols lack validator trustworthiness measurement, leading to subtle misconduct, especially in DeFi. PoB addresses this by ensuring consensus is linked to verifiable conduct.

Method: PoB consensus model: (i) assigns a layered utility score to each action covering motivation and outcome, (ii) adapts validator weights using recent scores, and (iii) applies decentralized verification with proportional slashing. The reward design is incentive-compatible, yielding a Nash equilibrium where honest behavior maximizes long-run payoffs.

Result: PoB cuts fraud acceptance by over 90%, demotes malicious validators within two rounds, and improves proposer fairness over standard PoS, with a throughput overhead of no more than 5%.

Conclusion: PoB 提供了一个可扩展、友好且合规的区块链治理基础，适用于金融应用，通过将共识影响力与可验证的信任行为联系起来。

Abstract: Current blockchain protocols (e.g., Proof-of-Work and Proof-of-Stake) secure
the ledger yet cannot measure validator trustworthiness, allowing subtle
misconduct that is especially damaging in decentralized-finance (DeFi)
settings. We introduce Proof-of-Behavior (PoB), a consensus model that (i)
gives each action a layered utility score -- covering motivation and outcome,
(ii) adapts validator weights using recent scores, and (iii) applies
decentralized verification with proportional slashing. The reward design is
incentive-compatible, yielding a Nash equilibrium in which honest behavior
maximizes long-run pay-offs. Simulated DeFi experiments (loan-fraud detection,
reputation-weighted validation) show that PoB cuts fraud acceptance by more
than 90%, demotes malicious validators within two rounds, and improves proposer
fairness versus standard PoS, all with no more than a 5% throughput overhead.
By linking consensus influence to verifiably trustworthy conduct, PoB offers a
scalable, regulation-friendly foundation for secure and fair blockchain
governance in financial applications.

</details>


### [183] [Big Data-Driven Fraud Detection Using Machine Learning and Real-Time Stream Processing](https://arxiv.org/abs/2506.02008)
*Chen Liu,Hengyu Tang,Zhixiao Yang,Ke Zhou,Sangwhan Cha*

Main category: cs.DC

TL;DR: 该研究利用大数据和机器学习技术，构建了一个高精度的金融欺诈和洗钱检测系统。


<details>
  <summary>Details</summary>
Motivation: 在数字金融时代，金融机构需要有效检测欺诈交易和洗钱。

Method: 本研究提出了一种利用Apache Kafka、Flink、Spark以及AWS S3和RDS等大数据工具和机器学习模型来检测欺诈交易和洗钱的方法。研究人员使用合成数据集训练了逻辑回归、决策树和随机森林等二元分类模型，并通过工程化特征进行评估。

Result: 所提出的系统在检测金融欺诈和洗钱方面表现出超过99%的分类准确率。

Conclusion: 利用大数据架构和机器学习模型可以有效地检测金融欺诈和洗钱活动。

Abstract: In the age of digital finance, detecting fraudulent transactions and money
laundering is critical for financial institutions. This paper presents a
scalable and efficient solution using Big Data tools and machine learning
models. We utilize realtime data streaming platforms like Apache Kafka and
Flink, distributed processing frameworks such as Apache Spark, and cloud
storage services AWS S3 and RDS. A synthetic dataset representing real-world
Anti-Money Laundering (AML) challenges is employed to build a binary
classification model. Logistic Regression, Decision Tree, and Random Forest are
trained and evaluated using engineered features. Our system demonstrates over
99% classification accuracy, illustrating the power of combining Big Data
architectures with machine learning to tackle fraud.

</details>


### [184] [Design, Implementation and Practical Energy-Efficiency Evaluation of a Blockchain Based Academic Credential Verification System for Low-Power Nodes](https://arxiv.org/abs/2410.20605)
*Gabriel Fernández-Blanco,Iván Froiz-Míguez,Paula Fraga-Lamas,Tiago M. Fernández-Caramés*

Main category: cs.DC

TL;DR: 本研究提出了一种基于以太坊区块链和 IPFS 的去中心化解决方案，用于验证学术记录，并评估了 PoA 协议的环保性和性能。


<details>
  <summary>Details</summary>
Motivation: 教育系统管理大量文书工作，容易导致人为错误、滥用或欺诈，例如伪造文凭、证书或其他凭证，这会损害证书和学术机构的信誉，给社会带来重大成本。

Method: 本研究提出了一种利用以太坊区块链和 IPFS 去中心化存储系统来记录和验证学术记录的解决方案，并评估了其在性能和能源效率方面的表现，同时将其与传统的 PoW 共识协议和新的 PoA 协议进行了比较。

Result: 研究结果表明，PoA 协议比传统的 PoW 协议更环保，CPU 负载更低。此外，研究还发现，虽然可以使用树莓派等低功耗设备实现区块链节点，但响应延迟会增加。以太坊 gas limit 对区块链网络的性能有显著影响。

Conclusion: 该提议的解决方案通过在以太坊区块链和基于 IPFS 的去中心化存储系统上部署智能合约来记录和验证学术记录，旨在解决教育系统中因伪造文凭、证书或其他凭证而产生的欺诈问题。与传统的 PoW 共识协议相比，PoA 协议在性能和能源效率方面表现出更好的环保性和更低的 CPU 负载。

Abstract: The educational system manages extensive documentation and paperwork, which
can lead to human errors and sometimes abuse or fraud, such as the
falsification of diplomas, certificates or other credentials. In fact, in the
last years, multiple cases of fraud have been detected, which have a
significant cost to society, since they harm the trustworthiness of
certificates and academic institutions. To tackle such an issue, this article
proposes a solution aimed at recording and verifying academic records through a
decentralized application that is supported by a smart contract deployed in the
Ethereum blockchain and by a decentralized storage system based on
Inter-Planetary File System (IPFS). The proposed solution is evaluated in terms
of performance and energy-efficiency, comparing the results obtained with a
traditional Proof-of-Work (PoW) consensus protocol and the new
Proof-of-Authority (PoA) protocol. The results shown in this paper indicate
that the latter is clearly greener and demands less CPU load. Moreover, this
article compares the performance of a traditional computer and two SBCs (a
Raspberry Pi 4 and an Orange Pi One), showing that is possible to make use of
the latter low-power devices to implement blockchain nodes but at the cost of
higher response latency. Furthermore, the impact of Ethereum gas limit is
evaluated, demonstrating its significant influence on the blockchain network
performance. Thus, this article provides guidelines, useful practical
evaluations and key findings that will help the next generation of green
blockchain developers and researchers.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [185] [Blockchain Data Analytics: A Scoping Literature Review and Directions for Future Research](https://arxiv.org/abs/2505.04403)
*Marcel Bühlmann,Hans-Georg Fill,Simon Curty*

Main category: cs.ET

TL;DR: 一篇关于区块链数据分析的综述，分析了466篇文献，发现非法活动检测和金融分析是研究热点，而商业智能应用则有待发展。


<details>
  <summary>Details</summary>
Motivation: 随着区块链技术的广泛应用和数据的快速增长，对高级数据分析技术的需求日益增加，但目前缺乏对区块链数据分析的全面综述，本研究旨在填补这一空白。

Method: 通过系统的文献综述方法，分析了466篇相关出版物，并将它们归纳为六个主要的研究主题：非法活动检测、数据管理、金融分析、用户分析、社区检测和挖矿分析。

Result: 研究发现，目前对区块链数据分析的研究集中在非法活动检测和金融应用，而用于商业智能的整体性应用则探索不足。

Conclusion: 本篇综述系统地梳理了区块链数据分析的研究现状，发现了在非法活动检测和金融应用方面的研究较多，而全面的商业智能应用则有待深入挖掘，并为该领域未来的研究方向提供了建议。

Abstract: Blockchain technology has rapidly expanded beyond its original use in
cryptocurrencies to a broad range of applications, creating vast amounts of
immutable, decentralized data. As blockchain adoption grows, so does the need
for advanced data analytics techniques to extract insights for business
intelligence, fraud detection, financial analysis and many more. While previous
research has examined specific aspects of blockchain data analytics, such as
transaction patterns, illegal activity detection, and data management, there
remains a lack of comprehensive reviews that explore the full scope of
blockchain data analytics. This study addresses this gap through a scoping
literature review, systematically mapping the existing research landscape,
identifying key topics, and highlighting emerging trends. Using established
methodologies for literature reviews, we analyze 466 publications, clustering
them into six major research themes: illegal activity detection, data
management, financial analysis, user analysis, community detection, and mining
analysis. Our findings reveal a strong focus on detecting illicit activities
and financial applications, while holistic business intelligence use cases
remain underexplored. This review provides a structured overview of blockchain
data analytics, identifying research gaps and proposing future directions to
enhance the fields impact.

</details>


### [186] [Brain-Inspired Quantum Neural Architectures for Pattern Recognition: Integrating QSNN and QLSTM](https://arxiv.org/abs/2505.01735)
*Eva Andrés,Manuel Pegalajar Cuéllar,Gabriel Navarro*

Main category: cs.ET

TL;DR: 一种结合QSNN和QLSTM的新型量子模型，模仿人脑来检测信用卡欺诈。


<details>
  <summary>Details</summary>
Motivation: 利用深度学习和量子计算的最新进展，开发一种能模仿人脑功能、用于检测信用卡欺诈等异常的新型模型。

Method: 该模型结合了量子脉冲神经网络（QSNN）和量子长短期记忆（QLSTM）架构，分为两个阶段：第一阶段提取低级信息（类似于下丘脑），第二阶段处理信息并捕获相关模式（类似于海马体）。

Result: 文章将该模型与包括量子神经网络（QNN）在内的其他量子模型及其对应的经典模型进行了比较。

Conclusion: 该模型在检测信用卡欺诈方面表现出了前景，并与现有模型进行了比较。

Abstract: Recent advances in the fields of deep learning and quantum computing have
paved the way for innovative developments in artificial intelligence. In this
manuscript, we leverage these cutting-edge technologies to introduce a novel
model that emulates the intricate functioning of the human brain, designed
specifically for the detection of anomalies such as fraud in credit card
transactions. Leveraging the synergies of Quantum Spiking Neural Networks
(QSNN) and Quantum Long Short-Term Memory (QLSTM) architectures, our approach
is developed in two distinct stages, closely mirroring the information
processing mechanisms found in the brain's sensory and memory systems. In the
initial stage, similar to the brain's hypothalamus, we extract low-level
information from the data, emulating sensory data processing patterns. In the
subsequent stage, resembling the hippocampus, we process this information at a
higher level, capturing and memorizing correlated patterns. We will compare
this model with other quantum models such as Quantum Neural Networks among
others and their corresponding classical models.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [187] [Network Analytics for Anti-Money Laundering -- A Systematic Literature Review and Experimental Evaluation](https://arxiv.org/abs/2405.19383)
*Bruno Deprez,Toon Vanderschueren,Bart Baesens,Tim Verdonck,Wouter Verbeke*

Main category: cs.SI

TL;DR: 本文对反洗钱（AML）领域中的网络分析研究进行了全面的文献综述和方法比较，强调了深度学习的兴起以及在使用GNN和合成数据时需要注意的问题，并提供了一个开源框架以促进标准化研究。


<details>
  <summary>Details</summary>
Motivation: 为了有效打击洗钱活动，利用网络信息进行分析，但现有研究存在碎片化、缺乏全面概述的问题，导致对方法的理解和比较检测能力有限。

Method: 本文进行了广泛且独特的文献回顾，基于Web of Science和Scopus上的97篇论文，并遵循最近提出的欺诈分析框架进行分类。此外，本文提出了一个全面的框架，用于在标准化的设置中评估和比较主要方法的性能，并对手动特征工程、随机游走方法和深度学习方法在两个公开数据集上进行了比较。

Result: 通过对97篇文献的分析，发现大多数研究依赖于专家规则和手动特征，而深度学习方法日益受到重视。在对手动特征工程、随机游走和深度学习方法在两个公共数据集上的比较中，发现网络分析能提升预测能力，但使用GNN需注意类别不平衡和网络拓扑问题，合成数据可能导致结果过于乐观。

Conclusion: 大多数研究依赖于基于专家规则和手动特征的方法，但深度学习方法正获得关注。网络分析可提高预测能力，但在处理类别不平衡和网络拓扑时需谨慎使用图神经网络（GNN）。同时，应注意合成数据可能导致过于乐观的结果。

Abstract: Money laundering presents a pervasive challenge, burdening society by
financing illegal activities. The use of network information is increasingly
being explored to effectively combat money laundering, given it involves
connected parties. This led to a surge in research on network analytics for
anti-money laundering (AML). The literature is, however, fragmented and a
comprehensive overview of existing work is missing. This results in limited
understanding of the methods to apply and their comparative detection power.
This paper presents an extensive and unique literature review, based on 97
papers from Web of Science and Scopus, resulting in a taxonomy following a
recently proposed fraud analytics framework. We conclude that most research
relies on expert-based rules and manual features, while deep learning methods
have been gaining traction. This paper also presents a comprehensive framework
to evaluate and compare the performance of prominent methods in a standardized
setup. We compare manual feature engineering, random walk-based, and deep
learning methods on two publicly available data sets. We conclude that (1)
network analytics increases the predictive power, but caution is needed when
applying GNNs in the face of class imbalance and network topology, and that (2)
care should be taken with synthetic data as this can give overly optimistic
results. The open-source implementation facilitates researchers and
practitioners to extend this work on proprietary data, promoting a standardised
approach for the analysis and evaluation of network analytics for AML.

</details>


### [188] [Temporal Motifs for Financial Networks: A Study on Mercari, JPMC, and Venmo Platforms](https://arxiv.org/abs/2301.07791)
*Penghang Liu,Bahadir Altun,Rupam Acharyya,Robert E. Tillman,Shunya Kimura,Naoki Masuda,Ahmet Erdem Sarıyüce*

Main category: cs.SI

TL;DR: 本研究利用时间局部图模型分析金融交易网络，在欺诈检测和友谊预测等任务中取得优于基线方法的成果，并揭示了金融与社交关系的相互作用。


<details>
  <summary>Details</summary>
Motivation: 理解金融交易网络中的动态关系对于欺诈检测等应用至关重要。然而，传统的图分析方法往往忽略了交易的时间顺序和重复性。时间局部图模型（temporal motifs）通过捕捉节点在短时间内的交互模式，为金融交易网络的分析提供了新的视角和工具。

Method: 本研究提出了使用时间局部图模型来分析金融交易网络，并将其应用于实际数据集，包括Mercari、J.P. Morgan Chase生成的合成网络以及Venmo用户网络。在Mercari和J.P. Morgan Chase网络上，研究人员将该模型应用于欺诈检测问题，并与包括LINE和node2vec在内的基线方法进行了比较。在Venmo网络上，研究人员进行了友谊预测、商家识别和时间周期分析等任务，并使用了Jaccard和Adamic-Adar等通用启发式方法进行比较。

Result: 在Mercari和J.P. Morgan Chase网络上，时间局部图模型在欺诈检测任务上表现优于基线方法，并且运行时性能也具有优势。在Venmo网络上，时间局部图模型在友谊预测任务上优于Jaccard和Adamic-Adar等通用启发式方法，并能准确识别商家。此外，研究还观察到稀有时间局部图模型（如时间周期）中存在有趣的模式。

Conclusion: 研究结果表明，时间局部图模型在金融交易网络分析中优于其他基线方法，并且在实际应用中具有良好的运行时性能。此外，该研究还揭示了金融关系与社交关系之间的相互作用，并在友谊预测、商家识别和时间周期分析任务中取得了有意义的成果。

Abstract: Understanding the dynamics of financial transactions among people is critical
for various applications such as fraud detection. One important aspect of
financial transaction networks is temporality. The order and repetition of
transactions can offer new insights when considered within the graph structure.
Temporal motifs, defined as a set of nodes that interact with each other in a
short time period, are a promising tool in this context. In this work, we study
three unique temporal financial networks: transactions in Mercari, an online
marketplace, payments in a synthetic network generated by J.P. Morgan Chase,
and payments and friendships among Venmo users. We consider the fraud detection
problem on the Mercari and J.P. Morgan Chase networks, for which the ground
truth is available. We show that temporal motifs offer superior performance to
several baselines, including a previous method that considers simple graph
features and two node embedding techniques (LINE and node2vec), while being
practical in terms of runtime performance. For the Venmo network, we
investigate the interplay between financial and social relations on three
tasks: friendship prediction, vendor identification, and analysis of temporal
cycles. For friendship prediction, temporal motifs yield better results than
general heuristics, such as Jaccard and Adamic-Adar measures. We are also able
to identify vendors with high accuracy and observe interesting patterns in rare
motifs, such as temporal cycles. We believe that the analysis, datasets, and
lessons from this work will be beneficial for future research on financial
transaction networks.

</details>


### [189] [GARG-AML against Smurfing: A Scalable and Interpretable Graph-Based Framework for Anti-Money Laundering](https://arxiv.org/abs/2506.04292)
*Bruno Deprez,Bart Baesens,Tim Verdonck,Wouter Verbeke*

Main category: cs.SI

TL;DR: GARG-AML是一种新的基于图的方法，用于通过量化洗钱风险来检测洗钱。它比现有方法更有效、更透明，并且可以集成到现有的反洗钱流程中。


<details>
  <summary>Details</summary>
Motivation: 洗钱是一个重大的挑战，估计占全球GDP的2%-5%。为了规避监管机构对金融机构施加的严格控制，出现了一种名为“smurfing”的洗钱方式，即将大额交易分解成小额。然而，近期的研究主要集中在黑盒网络嵌入方法上，这阻碍了它们在商业中的应用。

Method: GARG-AML是一种新颖的基于图的方法，通过源自每个节点在网络中二阶交易网络的结构导出的单一可解释指标来量化洗钱风险。它将GARG-AML分数计算与不同的基于树的方法相结合，并结合了节点邻居的分数。

Result: GARG-AML 在计算效率、检测能力和透明度之间取得了有效的平衡，可以集成到现有的反洗钱流程中。实验评估表明，GARG-AML 优于当前的洗钱检测方法。

Conclusion: GARG-AML通过结合GARG-AML分数计算、基于树的方法以及邻居节点得分，增强了其能力，并在大规模合成和开源网络上进行了实验评估，结果表明其优于当前最先进的洗钱检测方法。该研究强调了利用二阶邻域的邻接矩阵和基本网络属性在推进欺诈检测方面的潜力。

Abstract: Money laundering poses a significant challenge as it is estimated to account
for 2%-5% of the global GDP. This has compelled regulators to impose stringent
controls on financial institutions. One prominent laundering method for evading
these controls, called smurfing, involves breaking up large transactions into
smaller amounts. Given the complexity of smurfing schemes, which involve
multiple transactions distributed among diverse parties, network analytics has
become an important anti-money laundering tool. However, recent advances have
focused predominantly on black-box network embedding methods, which has
hindered their adoption in businesses. In this paper, we introduce GARG-AML, a
novel graph-based method that quantifies smurfing risk through a single
interpretable metric derived from the structure of the second-order transaction
network of each individual node in the network. Unlike traditional methods,
GARG-AML strikes an effective balance among computational efficiency, detection
power and transparency, which enables its integration into existing AML
workflows. To enhance its capabilities, we combine the GARG-AML score
calculation with different tree-based methods and also incorporate the scores
of the node's neighbours. An experimental evaluation on large-scale synthetic
and open-source networks demonstrate that the GARG-AML outperforms the current
state-of-the-art smurfing detection methods. By leveraging only the adjacency
matrix of the second-order neighbourhood and basic network features, this work
highlights the potential of fundamental network properties towards advancing
fraud detection.

</details>


### [190] [Methodology for Identifying Social Groups within a Transactional Graph](https://arxiv.org/abs/2502.07694)
*Maxence Morin,Baptiste Hemery,Fabrice Jeanne,Estelle Pawlowski-Cherrier*

Main category: cs.SI

TL;DR: A new framework is presented to better identify user groups in social network transaction data by looking at context and structure, improving on older methods.


<details>
  <summary>Details</summary>
Motivation: Social network analysis is crucial for organizations to leverage data from user interactions for purposes like service personalization or fraud detection. Traditional methods struggle to accurately identify specific user groups.

Method: The framework focuses on the contextual and structural nuances that define user groups within transactional graphs.

Result: The paper introduces a novel framework designed to identify groups of users within transactional graphs by focusing on contextual and structural nuances, addressing limitations of traditional methods like community detection and graph matching in accurately identifying specific groups of users.  The effectiveness and specific outcomes of this framework are not detailed in the abstract but it is presented as an improvement over existing techniques.

Conclusion: The paper introduces a novel framework for identifying user groups in transactional graphs, focusing on contextual and structural nuances.

Abstract: Social network analysis is pivotal for organizations aiming to leverage the
vast amounts of data generated from user interactions on social media and other
digital platforms. These interactions often reveal complex social structures,
such as tightly-knit groups based on common interests, which are crucial for
enhancing service personalization or fraud detection. Traditional methods like
community detection and graph matching, while useful, often fall short of
accurately identifying specific groups of users. This paper introduces a novel
framework specifically designed to identify groups of users within
transactional graphs by focusing on the contextual and structural nuances that
define these groups.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [191] [Abnormal component analysis](https://arxiv.org/abs/2312.16139)
*Romain Valla,Pavlo Mozharovskyi,Florence d'Alché-Buc*

Main category: stat.ME

TL;DR: ACA是一种用于异常检测的新型统计工具，它利用数据深度来识别和解释异常值，并在模拟和真实数据研究中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前异常检测领域的方法大多是无监督的，并且像PCA这样的探索性方法不够稳健，导致对异常值的解释研究不足。

Method: ACA是一种利用数据深度作为得分来探索异常值的新型统计工具，搜索能最佳可视化和解释异常值的低维数据表示。

Result: ACA生成的低维数据表示比现有方法能更好地分离异常值群，并提供了一种可解释的线性变量解释。

Conclusion: ACA方法在异常分析方面优于现有文献中的方法，并提供了可解释的异常原因。

Abstract: At the crossway of machine learning and data analysis, anomaly detection aims
at identifying observations that exhibit abnormal behaviour. Be it measurement
errors, disease development, severe weather, production quality default(s)
(items) or failed equipment, financial frauds or crisis events, their on-time
identification and isolation constitute an important task in almost any area of
industry and science. While a substantial body of literature is devoted to
detection of anomalies, little attention is payed to their explanation. This is
the case mostly due to intrinsically non-supervised nature of the task and
non-robustness of the exploratory methods like principal component analysis
(PCA).
  We introduce a new statistical tool dedicated for exploratory analysis of
abnormal observations using data depth as a score. Abnormal component analysis
(shortly ACA) is a method that searches a low-dimensional data representation
that best visualises and explains anomalies. This low-dimensional
representation not only allows to distinguish groups of anomalies better than
the methods of the state of the art, but as well provides a -- linear in
variables and thus easily interpretable -- explanation for anomalies. In a
comparative simulation and real-data study, ACA also proves advantageous for
anomaly analysis with respect to methods present in the literature.

</details>


### [192] [Community detection in multi-layer networks by regularized debiased spectral clustering](https://arxiv.org/abs/2409.07956)
*Huan Qing*

Main category: stat.ME

TL;DR: 本研究提出了一种用于多层网络社区检测的新方法RDSoS，并引入了SoS-modularity来评估社区质量，在多层网络分析和各种实际应用中均表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有正则化谱聚类方法在多层网络社区检测方面的不足，并探索其在多层网络分析中的潜力。

Method: 提出了一种名为RDSoS的新方法，该方法基于新颖的正则化拉普拉斯矩阵，对去偏平方邻接矩阵之和进行正则化，以检测多层网络中的社区。

Result: RDSoS方法在多层随机区块模型及其度校正版本中具有一致性。实验结果表明，RDSoS方法对正则化参数不敏感，性能优于现有技术，并能揭示真实网络的分类属性。此外，SoS-modularity比跨层的Newman-Girvan模度平均值更准确地评估社区质量。

Conclusion: 该研究提出了RDSoS方法，并在一系列应用中展示了其优越性，同时提出SoS-modularity作为一种更准确的社区划分质量评估指标。

Abstract: Community detection is a crucial problem in the analysis of multi-layer
networks. While regularized spectral clustering methods using the classical
regularized Laplacian matrix have shown great potential in handling sparse
single-layer networks, to our knowledge, their potential in multi-layer network
community detection remains unexplored. To address this gap, in this work, we
introduce a new method, called regularized debiased sum of squared adjacency
matrices (RDSoS), to detect communities in multi-layer networks. RDSoS is
developed based on a novel regularized Laplacian matrix that regularizes the
debiased sum of squared adjacency matrices. In contrast, the classical
regularized Laplacian matrix typically regularizes the adjacency matrix of a
single-layer network. Therefore, at a high level, our regularized Laplacian
matrix extends the classical one to multi layer networks. We establish the
consistency property of RDSoS under the multi-layer stochastic block model
(MLSBM) and further extend RDSoS and its theoretical results to the
degree-corrected version of the MLSBM model. Additionally, we introduce a sum
of squared adjacency matrices modularity (SoS-modularity) to measure the
quality of community partitions in multi-layer networks and estimate the number
of communities by maximizing this metric. Our methods offer promising
applications for predicting gene functions, improving recommender systems,
detecting medical insurance fraud, and facilitating link prediction.
Experimental results demonstrate that our methods exhibit insensitivity to the
selection of the regularizer, generally outperform state-of-the-art techniques,
uncover the assortative property of real networks, and that our SoS-modularity
provides a more accurate assessment of community quality compared to the
average of the Newman-Girvan modularity across layers.

</details>


### [193] [New User Event Prediction Through the Lens of Causal Inference](https://arxiv.org/abs/2407.05625)
*Henry Shaowu Yuchi,Shixiang Zhu,Li Dong,Yigit M. Arisoy,Matthew C. Spencer*

Main category: stat.ME

TL;DR: 提出了一种用于新用户（具有有限历史且无需了解用户类别）的离散事件预测框架，通过将用户事件历史视为“处理”并使用逆倾向得分（IPS）对每个事件进行重新加权来解决用户类别作为混淆因素的问题，并在模拟和真实世界数据（Netflix、亚马逊）上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常将用户分配到基于行为的类别中，并单独分析每个类别。然而，这种方法需要大量数据才能充分理解用户行为，给那些历史数据有限的新用户带来了建模挑战。

Method: 将用户事件历史视为“处理”，用户类别视为关键混淆因素，将预测问题构建为反事实结果估计，并使用逆倾向得分（IPS）对每个事件进行重新加权。

Result: 通过数值模拟研究和两个真实世界应用（包括 Netflix 评分预测和亚马逊客服的卖家联系预测）证明了所提出框架的改进性能。

Conclusion: 为数据量有限的新用户提出了一种新颖的离散事件预测框架，无需了解用户类别，将用户事件历史视为“处理”，用户类别视为关键混淆因素，将预测问题构建为反事实结果估计，并使用逆倾向得分对每个事件进行重新加权。

Abstract: Modeling and analysis for event series generated by users of heterogeneous
behavioral patterns are closely involved in our daily lives, including credit
card fraud detection, online platform user recommendation, and social network
analysis. The most commonly adopted approach to this task is to assign users to
behavior-based categories and analyze each of them separately. However, this
requires extensive data to fully understand the user behavior, presenting
challenges in modeling newcomers without significant historical knowledge. In
this work, we propose a novel discrete event prediction framework for new users
with limited history, without needing to know the user's category. We treat the
user event history as the "treatment" for future events and the user category
as the key confounder. Thus, the prediction problem can be framed as
counterfactual outcome estimation, where each event is re-weighted by its
inverse propensity score. We demonstrate the improved performance of the
proposed framework with a numerical simulation study and two real-world
applications, including Netflix rating prediction and seller contact prediction
for customer support at Amazon.

</details>
