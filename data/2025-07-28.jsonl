{"id": "2507.19402", "title": "FD4QC: Application of Classical and Quantum-Hybrid Machine Learning for Financial Fraud Detection A Technical Report", "url": "https://arxiv.org/abs/2507.19402", "pdf": "https://arxiv.org/pdf/2507.19402", "abs": "https://arxiv.org/abs/2507.19402", "authors": ["Matteo Cardaioli", "Luca Marangoni", "Giada Martini", "Francesco Mazzolin", "Luca Pajola", "Andrea Ferretto Parodi", "Alessandra Saitta", "Maria Chiara Vernillo"], "categories": ["cs.LG", "cs.CE"], "comment": "This is a technical report", "summary": "The increasing complexity and volume of financial transactions pose\nsignificant challenges to traditional fraud detection systems. This technical\nreport investigates and compares the efficacy of classical, quantum, and\nquantum-hybrid machine learning models for the binary classification of\nfraudulent financial activities.\n  As of our methodology, first, we develop a comprehensive behavioural feature\nengineering framework to transform raw transactional data into a rich,\ndescriptive feature set. Second, we implement and evaluate a range of models on\nthe IBM Anti-Money Laundering (AML) dataset. The classical baseline models\ninclude Logistic Regression, Decision Tree, Random Forest, and XGBoost. These\nare compared against three hybrid classic quantum algorithms architectures: a\nQuantum Support Vector Machine (QSVM), a Variational Quantum Classifier (VQC),\nand a Hybrid Quantum Neural Network (HQNN).\n  Furthermore, we propose Fraud Detection for Quantum Computing (FD4QC), a\npractical, API-driven system architecture designed for real-world deployment,\nfeaturing a classical-first, quantum-enhanced philosophy with robust fallback\nmechanisms.\n  Our results demonstrate that classical tree-based models, particularly\n\\textit{Random Forest}, significantly outperform the quantum counterparts in\nthe current setup, achieving high accuracy (\\(97.34\\%\\)) and F-measure\n(\\(86.95\\%\\)). Among the quantum models, \\textbf{QSVM} shows the most promise,\ndelivering high precision (\\(77.15\\%\\)) and a low false-positive rate\n(\\(1.36\\%\\)), albeit with lower recall and significant computational overhead.\n  This report provides a benchmark for a real-world financial application,\nhighlights the current limitations of quantum machine learning in this domain,\nand outlines promising directions for future research."}
{"id": "2406.13166", "title": "Enhancing supply chain security with automated machine learning", "url": "https://arxiv.org/abs/2406.13166", "pdf": "https://arxiv.org/pdf/2406.13166", "abs": "https://arxiv.org/abs/2406.13166", "authors": ["Haibo Wang", "Lutfu S. Sua", "Bahram Alidaee"], "categories": ["cs.LG", "econ.GN", "math.OC", "q-fin.EC"], "comment": "36 pages", "summary": "The increasing scale and complexity of global supply chains have led to new\nchallenges spanning various fields, such as supply chain disruptions due to\nlong waiting lines at the ports, material shortages, and inflation. Coupled\nwith the size of supply chains and the availability of vast amounts of data,\nefforts towards tackling such challenges have led to an increasing interest in\napplying machine learning methods in many aspects of supply chains. Unlike\nother solutions, ML techniques, including Random Forest, XGBoost, LightGBM, and\nNeural Networks, make predictions and approximate optimal solutions faster.\nThis paper presents an automated ML framework to enhance supply chain security\nby detecting fraudulent activities, predicting maintenance needs, and\nforecasting material backorders. Using datasets of varying sizes, results show\nthat fraud detection achieves an 88% accuracy rate using sampling methods,\nmachine failure prediction reaches 93.4% accuracy, and material backorder\nprediction achieves 89.3% accuracy. Hyperparameter tuning significantly\nimproved the performance of these models, with certain supervised techniques\nlike XGBoost and LightGBM reaching up to 100% precision. This research\ncontributes to supply chain security by streamlining data preprocessing,\nfeature selection, model optimization, and inference deployment, addressing\ncritical challenges and boosting operational efficiency."}
{"id": "2405.19383", "title": "Network Analytics for Anti-Money Laundering -- A Systematic Literature Review and Experimental Evaluation", "url": "https://arxiv.org/abs/2405.19383", "pdf": "https://arxiv.org/pdf/2405.19383", "abs": "https://arxiv.org/abs/2405.19383", "authors": ["Bruno Deprez", "Toon Vanderschueren", "Bart Baesens", "Tim Verdonck", "Wouter Verbeke"], "categories": ["cs.SI", "cs.LG"], "comment": null, "summary": "Money laundering presents a pervasive challenge, burdening society by\nfinancing illegal activities. The use of network information is increasingly\nbeing explored to effectively combat money laundering, given it involves\nconnected parties. This led to a surge in research on network analytics for\nanti-money laundering (AML). The literature is, however, fragmented and a\ncomprehensive overview of existing work is missing. This results in limited\nunderstanding of the methods to apply and their comparative detection power.\nThis paper presents an extensive and unique literature review, based on 97\npapers from Web of Science and Scopus, resulting in a taxonomy following a\nrecently proposed fraud analytics framework. We conclude that most research\nrelies on expert-based rules and manual features, while deep learning methods\nhave been gaining traction. This paper also presents a comprehensive framework\nto evaluate and compare the performance of prominent methods in a standardized\nsetup. We compare manual feature engineering, random walk-based, and deep\nlearning methods on two publicly available data sets. We conclude that (1)\nnetwork analytics increases the predictive power, but caution is needed when\napplying GNNs in the face of class imbalance and network topology, and that (2)\ncare should be taken with synthetic data as this can give overly optimistic\nresults. The open-source implementation facilitates researchers and\npractitioners to extend this work on proprietary data, promoting a standardised\napproach for the analysis and evaluation of network analytics for AML."}
{"id": "2507.12295", "title": "Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding", "url": "https://arxiv.org/abs/2507.12295", "pdf": "https://arxiv.org/pdf/2507.12295", "abs": "https://arxiv.org/abs/2507.12295", "authors": ["Feng Xiao", "Jicong Fan"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Text anomaly detection is a critical task in natural language processing\n(NLP), with applications spanning fraud detection, misinformation\nidentification, spam detection and content moderation, etc. Despite significant\nadvances in large language models (LLMs) and anomaly detection algorithms, the\nabsence of standardized and comprehensive benchmarks for evaluating the\nexisting anomaly detection methods on text data limits rigorous comparison and\ndevelopment of innovative approaches. This work performs a comprehensive\nempirical study and introduces a benchmark for text anomaly detection,\nleveraging embeddings from diverse pre-trained language models across a wide\narray of text datasets. Our work systematically evaluates the effectiveness of\nembedding-based text anomaly detection by incorporating (1) early language\nmodels (GloVe, BERT); (2) multiple LLMs (LLaMa-2, LLama-3, Mistral, OpenAI\n(small, ada, large)); (3) multi-domain text datasets (news, social media,\nscientific publications); (4) comprehensive evaluation metrics (AUROC, AUPRC).\nOur experiments reveal a critical empirical insight: embedding quality\nsignificantly governs anomaly detection efficacy, and deep learning-based\napproaches demonstrate no performance advantage over conventional shallow\nalgorithms (e.g., KNN, Isolation Forest) when leveraging LLM-derived\nembeddings.In addition, we observe strongly low-rank characteristics in\ncross-model performance matrices, which enables an efficient strategy for rapid\nmodel evaluation (or embedding evaluation) and selection in practical\napplications. Furthermore, by open-sourcing our benchmark toolkit that includes\nall embeddings from different models and code at\nhttps://github.com/jicongfan/Text-Anomaly-Detection-Benchmark, this work\nprovides a foundation for future research in robust and scalable text anomaly\ndetection systems."}
{"id": "2507.11997", "title": "Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection", "url": "https://arxiv.org/abs/2507.11997", "pdf": "https://arxiv.org/pdf/2507.11997", "abs": "https://arxiv.org/abs/2507.11997", "authors": ["Tairan Huang", "Yili Wang"], "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph fraud detection has garnered significant attention as Graph Neural\nNetworks (GNNs) have proven effective in modeling complex relationships within\nmultimodal data. However, existing graph fraud detection methods typically use\npreprocessed node embeddings and predefined graph structures to reveal\nfraudsters, which ignore the rich semantic cues contained in raw textual\ninformation. Although Large Language Models (LLMs) exhibit powerful\ncapabilities in processing textual information, it remains a significant\nchallenge to perform multimodal fusion of processed textual embeddings with\ngraph structures. In this paper, we propose a \\textbf{M}ulti-level \\textbf{L}LM\n\\textbf{E}nhanced Graph Fraud \\textbf{D}etection framework called MLED. In\nMLED, we utilize LLMs to extract external knowledge from textual information to\nenhance graph fraud detection methods. To integrate LLMs with graph structure\ninformation and enhance the ability to distinguish fraudsters, we design a\nmulti-level LLM enhanced framework including type-level enhancer and\nrelation-level enhancer. One is to enhance the difference between the\nfraudsters and the benign entities, the other is to enhance the importance of\nthe fraudsters in different relations. The experiments on four real-world\ndatasets show that MLED achieves state-of-the-art performance in graph fraud\ndetection as a generalized framework that can be applied to existing methods."}
{"id": "2506.07363", "title": "Deepfake Technology Unveiled: The Commoditization of AI and Its Impact on Digital Trust", "url": "https://arxiv.org/abs/2506.07363", "pdf": "https://arxiv.org/pdf/2506.07363", "abs": "https://arxiv.org/abs/2506.07363", "authors": ["Claudiu Popa", "Rex Pallath", "Liam Cunningham", "Hewad Tahiri", "Abiram Kesavarajah", "Tao Wu"], "categories": ["cs.CY", "cs.AI", "I.2.m"], "comment": "12 pages, 13 figures", "summary": "Deepfake Technology Unveiled: The Commoditization of AI and Its Impact on\nDigital Trust. With the increasing accessibility of generative AI, tools for\nvoice cloning, face-swapping, and synthetic media creation have advanced\nsignificantly, lowering both financial and technical barriers for their use.\nWhile these technologies present innovative opportunities, their rapid growth\nraises concerns about trust, privacy, and security. This white paper explores\nthe implications of deepfake technology, analyzing its role in enabling fraud,\nmisinformation, and the erosion of authenticity in multimedia. Using\ncost-effective, easy to use tools such as Runway, Rope, and ElevenLabs, we\nexplore how realistic deepfakes can be created with limited resources,\ndemonstrating the risks posed to individuals and organizations alike. By\nanalyzing the technical and ethical challenges of deepfake mitigation and\ndetection, we emphasize the urgent need for regulatory frameworks, public\nawareness, and collaborative efforts to maintain trust in digital media."}
{"id": "2404.02595", "title": "QFNN-FFD: Quantum Federated Neural Network for Financial Fraud Detection", "url": "https://arxiv.org/abs/2404.02595", "pdf": "https://arxiv.org/pdf/2404.02595", "abs": "https://arxiv.org/abs/2404.02595", "authors": ["Nouhaila Innan", "Alberto Marchisio", "Mohamed Bennai", "Muhammad Shafique"], "categories": ["quant-ph", "cs.LG", "q-fin.RM"], "comment": "9 pages, 8 figures. Accepted at QSW 2025", "summary": "This study introduces the Quantum Federated Neural Network for Financial\nFraud Detection (QFNN-FFD), a cutting-edge framework merging Quantum Machine\nLearning (QML) and quantum computing with Federated Learning (FL) for financial\nfraud detection. Using quantum technologies' computational power and the robust\ndata privacy protections offered by FL, QFNN-FFD emerges as a secure and\nefficient method for identifying fraudulent transactions within the financial\nsector. Implementing a dual-phase training model across distributed clients\nenhances data integrity and enables superior performance metrics, achieving\nprecision rates consistently above 95%. Additionally, QFNN-FFD demonstrates\nexceptional resilience by maintaining an impressive 80% accuracy, highlighting\nits robustness and readiness for real-world applications. This combination of\nhigh performance, security, and robustness against noise positions QFNN-FFD as\na transformative advancement in financial technology solutions and establishes\nit as a new benchmark for privacy-focused fraud detection systems. This\nframework facilitates the broader adoption of secure, quantum-enhanced\nfinancial services and inspires future innovations that could use QML to tackle\ncomplex challenges in other areas requiring high confidentiality and accuracy."}
{"id": "2507.09385", "title": "Credit Card Fraud Detection Using RoFormer Model With Relative Distance Rotating Encoding", "url": "https://arxiv.org/abs/2507.09385", "pdf": "https://arxiv.org/pdf/2507.09385", "abs": "https://arxiv.org/abs/2507.09385", "authors": ["Kevin Reyes", "Vasco Cortez"], "categories": ["cs.NE", "cs.LG"], "comment": "2025 IEEE Conference on Artificial Intelligence (CAI)", "summary": "Fraud detection is one of the most important challenges that financial\nsystems must address. Detecting fraudulent transactions is critical for payment\ngateway companies like Flow Payment, which process millions of transactions\nmonthly and require robust security measures to mitigate financial risks.\nIncreasing transaction authorization rates while reducing fraud is essential\nfor providing a good user experience and building a sustainable business. For\nthis reason, discovering novel and improved methods to detect fraud requires\ncontinuous research and investment for any company that wants to succeed in\nthis industry. In this work, we introduced a novel method for detecting\ntransactional fraud by incorporating the Relative Distance Rotating Encoding\n(ReDRE) in the RoFormer model. The incorporation of angle rotation using ReDRE\nenhances the characterization of time series data within a Transformer, leading\nto improved fraud detection by better capturing temporal dependencies and event\nrelationships."}
{"id": "2507.08917", "title": "Detecting Deepfake Talking Heads from Facial Biometric Anomalies", "url": "https://arxiv.org/abs/2507.08917", "pdf": "https://arxiv.org/pdf/2507.08917", "abs": "https://arxiv.org/abs/2507.08917", "authors": ["Justin D. Norman", "Hany Farid"], "categories": ["cs.CV"], "comment": "10 pages, 3 figures, 3 tables", "summary": "The combination of highly realistic voice cloning, along with visually\ncompelling avatar, face-swap, or lip-sync deepfake video generation, makes it\nrelatively easy to create a video of anyone saying anything. Today, such\ndeepfake impersonations are often used to power frauds, scams, and political\ndisinformation. We propose a novel forensic machine learning technique for the\ndetection of deepfake video impersonations that leverages unnatural patterns in\nfacial biometrics. We evaluate this technique across a large dataset of\ndeepfake techniques and impersonations, as well as assess its reliability to\nvideo laundering and its generalization to previously unseen video deepfake\ngenerators."}
{"id": "2301.07791", "title": "Temporal Motifs for Financial Networks: A Study on Mercari, JPMC, and Venmo Platforms", "url": "https://arxiv.org/abs/2301.07791", "pdf": "https://arxiv.org/pdf/2301.07791", "abs": "https://arxiv.org/abs/2301.07791", "authors": ["Penghang Liu", "Bahadir Altun", "Rupam Acharyya", "Robert E. Tillman", "Shunya Kimura", "Naoki Masuda", "Ahmet Erdem Sarıyüce"], "categories": ["cs.SI", "cs.AI"], "comment": "To appear at ASONAM 2025", "summary": "Understanding the dynamics of financial transactions among people is critical\nfor various applications such as fraud detection. One important aspect of\nfinancial transaction networks is temporality. The order and repetition of\ntransactions can offer new insights when considered within the graph structure.\nTemporal motifs, defined as a set of nodes that interact with each other in a\nshort time period, are a promising tool in this context. In this work, we study\nthree unique temporal financial networks: transactions in Mercari, an online\nmarketplace, payments in a synthetic network generated by J.P. Morgan Chase,\nand payments and friendships among Venmo users. We consider the fraud detection\nproblem on the Mercari and J.P. Morgan Chase networks, for which the ground\ntruth is available. We show that temporal motifs offer superior performance to\nseveral baselines, including a previous method that considers simple graph\nfeatures and two node embedding techniques (LINE and node2vec), while being\npractical in terms of runtime performance. For the Venmo network, we\ninvestigate the interplay between financial and social relations on three\ntasks: friendship prediction, vendor identification, and analysis of temporal\ncycles. For friendship prediction, temporal motifs yield better results than\ngeneral heuristics, such as Jaccard and Adamic-Adar measures. We are also able\nto identify vendors with high accuracy and observe interesting patterns in rare\nmotifs, such as temporal cycles. We believe that the analysis, datasets, and\nlessons from this work will be beneficial for future research on financial\ntransaction networks."}
{"id": "2507.02903", "title": "Harnessing Near-Infrared Spectroscopy and Machine Learning for Traceable Classification of Hanwoo and Holstein Beef", "url": "https://arxiv.org/abs/2507.02903", "pdf": "https://arxiv.org/pdf/2507.02903", "abs": "https://arxiv.org/abs/2507.02903", "authors": ["AMM Nurul Alam", "Abdul Samad", "AMM Shamsul Alam", "Jahan Ara Monti", "Ayesha Muazzam"], "categories": ["cs.LG"], "comment": "We need to withdraw the present manuscript to make some major\n  revisions to avoid potential conflict with relevant paper from other research", "summary": "This study evaluates the use of Near-Infrared spectroscopy (NIRS) combined\nwith advanced machine learning (ML) techniques to differentiate Hanwoo beef\n(HNB) and Holstein beef (HLB) to address food authenticity, mislabeling, and\nadulteration. Rapid and non-invasive spectral data were attained by a portable\nNIRS, recording absorbance data within the wavelength range of 700 to 1100 nm.\nA total of 40 Longissimus lumborum samples, evenly split between HNB and HLB,\nwere obtained from a local hypermarket. Data analysis using Principal Component\nAnalysis (PCA) demonstrated distinct spectral patterns associated with chemical\nchanges, clearly separating the two beef varieties and accounting for 93.72% of\nthe total variance. ML models, including Linear Discriminant Analysis (LDA),\nSupport Vector Machine (SVM), Logistic Regression (LR), Random Forest, Gradient\nBoosting (GB), K-Nearest Neighbors, Decision Tree (DT), Naive Bayes (NB), and\nNeural Networks (NN), were implemented, optimized through hyperparameter\ntuning, and validated by 5-fold cross-validation techniques to enhance model\nrobustness and prevent overfitting. Random Forest provided the highest\npredictive accuracy with a Receiver Operating Characteristic (ROC) Area Under\nthe Curve (AUC) of 0.8826, closely followed by the SVM model at 0.8747.\nFurthermore, GB and NN algorithms exhibited satisfactory performances, with\ncross-validation scores of 0.752. Notably, the NN model achieved the highest\nrecall rate of 0.7804, highlighting its suitability in scenarios requiring\nheightened sensitivity. DT and NB exhibited comparatively lower predictive\nperformance. The LR and SVM models emerged as optimal choices by effectively\nbalancing high accuracy, precision, and recall. This study confirms that\nintegrating NIRS with ML techniques offers a powerful and reliable method for\nmeat authenticity, significantly contributing to detecting food fraud."}
{"id": "2004.08705", "title": "Protecting Classifiers From Attacks", "url": "https://arxiv.org/abs/2004.08705", "pdf": "https://arxiv.org/pdf/2004.08705", "abs": "https://arxiv.org/abs/2004.08705", "authors": ["Victor Gallego", "Roi Naveiro", "Alberto Redondo", "David Rios Insua", "Fabrizio Ruggeri"], "categories": ["stat.ML", "cs.CR", "cs.LG", "stat.CO"], "comment": "Published in Statistical Science:\n  https://projecteuclid.org/journals/statistical-science/volume-39/issue-3/Protecting-Classifiers-from-Attacks/10.1214/24-STS922.full", "summary": "In multiple domains such as malware detection, automated driving systems, or\nfraud detection, classification algorithms are susceptible to being attacked by\nmalicious agents willing to perturb the value of instance covariates to pursue\ncertain goals. Such problems pertain to the field of adversarial machine\nlearning and have been mainly dealt with, perhaps implicitly, through\ngame-theoretic ideas with strong underlying common knowledge assumptions. These\nare not realistic in numerous application domains in relation to security and\nbusiness competition. We present an alternative Bayesian decision theoretic\nframework that accounts for the uncertainty about the attacker's behavior using\nadversarial risk analysis concepts. In doing so, we also present core ideas in\nadversarial machine learning to a statistical audience. A key ingredient in our\nframework is the ability to sample from the distribution of originating\ninstances given the, possibly attacked, observed ones. We propose an initial\nprocedure based on approximate Bayesian computation usable during operations;\nwithin it, we simulate the attacker's problem taking into account our\nuncertainty about his elements. Large-scale problems require an alternative\nscalable approach implementable during the training stage. Globally, we are\nable to robustify statistical classification algorithms against malicious\nattacks."}
{"id": "2507.06469", "title": "Mitigating Message Imbalance in Fraud Detection with Dual-View Graph Representation Learning", "url": "https://arxiv.org/abs/2507.06469", "pdf": "https://arxiv.org/pdf/2507.06469", "abs": "https://arxiv.org/abs/2507.06469", "authors": ["Yudan Song", "Yuecen Wei", "Yuhang Lu", "Qingyun Sun", "Minglai Shao", "Li-e Wang", "Chunming Hu", "Xianxian Li", "Xingcheng Fu"], "categories": ["cs.LG", "cs.SI"], "comment": null, "summary": "Graph representation learning has become a mainstream method for fraud\ndetection due to its strong expressive power, which focuses on enhancing node\nrepresentations through improved neighborhood knowledge capture. However, the\nfocus on local interactions leads to imbalanced transmission of global\ntopological information and increased risk of node-specific information being\noverwhelmed during aggregation due to the imbalance between fraud and benign\nnodes. In this paper, we first summarize the impact of topology and class\nimbalance on downstream tasks in GNN-based fraud detection, as the problem of\nimbalanced supervisory messages is caused by fraudsters' topological behavior\nobfuscation and identity feature concealment. Based on statistical validation,\nwe propose a novel dual-view graph representation learning method to mitigate\nMessage imbalance in Fraud Detection(MimbFD). Specifically, we design a\ntopological message reachability module for high-quality node representation\nlearning to penetrate fraudsters' camouflage and alleviate insufficient\npropagation. Then, we introduce a local confounding debiasing module to adjust\nnode representations, enhancing the stable association between node\nrepresentations and labels to balance the influence of different classes.\nFinally, we conducted experiments on three public fraud datasets, and the\nresults demonstrate that MimbFD exhibits outstanding performance in fraud\ndetection."}
{"id": "2507.05636", "title": "Graph Learning", "url": "https://arxiv.org/abs/2507.05636", "pdf": "https://arxiv.org/pdf/2507.05636", "abs": "https://arxiv.org/abs/2507.05636", "authors": ["Feng Xia", "Ciyuan Peng", "Jing Ren", "Falih Gozi Febrinanto", "Renqiang Luo", "Vidya Saikrishna", "Shuo Yu", "Xiangjie Kong"], "categories": ["cs.LG", "cs.AI", "68T09, 68R10", "I.2.6; G.2.2; E.1"], "comment": "178 pages", "summary": "Graph learning has rapidly evolved into a critical subfield of machine\nlearning and artificial intelligence (AI). Its development began with early\ngraph-theoretic methods, gaining significant momentum with the advent of graph\nneural networks (GNNs). Over the past decade, progress in scalable\narchitectures, dynamic graph modeling, multimodal learning, generative AI,\nexplainable AI (XAI), and responsible AI has broadened the applicability of\ngraph learning to various challenging environments. Graph learning is\nsignificant due to its ability to model complex, non-Euclidean relationships\nthat traditional machine learning struggles to capture, thus better supporting\nreal-world applications ranging from drug discovery and fraud detection to\nrecommender systems and scientific reasoning. However, challenges like\nscalability, generalization, heterogeneity, interpretability, and\ntrustworthiness must be addressed to unlock its full potential. This survey\nprovides a comprehensive introduction to graph learning, focusing on key\ndimensions including scalable, temporal, multimodal, generative, explainable,\nand responsible graph learning. We review state-of-the-art techniques for\nefficiently handling large-scale graphs, capturing dynamic temporal\ndependencies, integrating heterogeneous data modalities, generating novel graph\nsamples, and enhancing interpretability to foster trust and transparency. We\nalso explore ethical considerations, such as privacy and fairness, to ensure\nresponsible deployment of graph learning models. Additionally, we identify and\ndiscuss emerging topics, highlighting recent integration of graph learning and\nother AI paradigms and offering insights into future directions. This survey\nserves as a valuable resource for researchers and practitioners seeking to\nnavigate the rapidly evolving landscape of graph learning."}
{"id": "2507.06266", "title": "Machine Learning based Enterprise Financial Audit Framework and High Risk Identification", "url": "https://arxiv.org/abs/2507.06266", "pdf": "https://arxiv.org/pdf/2507.06266", "abs": "https://arxiv.org/abs/2507.06266", "authors": ["Tingyu Yuan", "Xi Zhang", "Xuanjing Chen"], "categories": ["q-fin.RM", "cs.AI", "cs.LG", "stat.AP"], "comment": null, "summary": "In the face of global economic uncertainty, financial auditing has become\nessential for regulatory compliance and risk mitigation. Traditional manual\nauditing methods are increasingly limited by large data volumes, complex\nbusiness structures, and evolving fraud tactics. This study proposes an\nAI-driven framework for enterprise financial audits and high-risk\nidentification, leveraging machine learning to improve efficiency and accuracy.\nUsing a dataset from the Big Four accounting firms (EY, PwC, Deloitte, KPMG)\nfrom 2020 to 2025, the research examines trends in risk assessment, compliance\nviolations, and fraud detection. The dataset includes key indicators such as\naudit project counts, high-risk cases, fraud instances, compliance breaches,\nemployee workload, and client satisfaction, capturing both audit behaviors and\nAI's impact on operations. To build a robust risk prediction model, three\nalgorithms - Support Vector Machine (SVM), Random Forest (RF), and K-Nearest\nNeighbors (KNN) - are evaluated. SVM uses hyperplane optimization for complex\nclassification, RF combines decision trees to manage high-dimensional,\nnonlinear data with resistance to overfitting, and KNN applies distance-based\nlearning for flexible performance. Through hierarchical K-fold cross-validation\nand evaluation using F1-score, accuracy, and recall, Random Forest achieves the\nbest performance, with an F1-score of 0.9012, excelling in identifying fraud\nand compliance anomalies. Feature importance analysis reveals audit frequency,\npast violations, employee workload, and client ratings as key predictors. The\nstudy recommends adopting Random Forest as a core model, enhancing features via\nengineering, and implementing real-time risk monitoring. This research\ncontributes valuable insights into using machine learning for intelligent\nauditing and risk management in modern enterprises."}
{"id": "2507.04061", "title": "Consistent and Invariant Generalization Learning for Short-video Misinformation Detection", "url": "https://arxiv.org/abs/2507.04061", "pdf": "https://arxiv.org/pdf/2507.04061", "abs": "https://arxiv.org/abs/2507.04061", "authors": ["Hanghui Guo", "Weijie Shi", "Mengze Li", "Juncheng Li", "Hao Chen", "Yue Cui", "Jiajie Xu", "Jia Zhu", "Jiawei Shen", "Zhangze Chen", "Sirui Han"], "categories": ["cs.CV", "cs.MM"], "comment": "Accepted to ACM MM 2025,15 pages, 16figures", "summary": "Short-video misinformation detection has attracted wide attention in the\nmulti-modal domain, aiming to accurately identify the misinformation in the\nvideo format accompanied by the corresponding audio. Despite significant\nadvancements, current models in this field, trained on particular domains\n(source domains), often exhibit unsatisfactory performance on unseen domains\n(target domains) due to domain gaps. To effectively realize such domain\ngeneralization on the short-video misinformation detection task, we propose\ndeep insights into the characteristics of different domains: (1) The detection\non various domains may mainly rely on different modalities (i.e., mainly\nfocusing on videos or audios). To enhance domain generalization, it is crucial\nto achieve optimal model performance on all modalities simultaneously. (2) For\nsome domains focusing on cross-modal joint fraud, a comprehensive analysis\nrelying on cross-modal fusion is necessary. However, domain biases located in\neach modality (especially in each frame of videos) will be accumulated in this\nfusion process, which may seriously damage the final identification of\nmisinformation. To address these issues, we propose a new DOmain generalization\nmodel via ConsisTency and invariance learning for shORt-video misinformation\ndetection (named DOCTOR), which contains two characteristic modules: (1) We\ninvolve the cross-modal feature interpolation to map multiple modalities into a\nshared space and the interpolation distillation to synchronize multi-modal\nlearning; (2) We design the diffusion model to add noise to retain core\nfeatures of multi modal and enhance domain invariant features through\ncross-modal guided denoising. Extensive experiments demonstrate the\neffectiveness of our proposed DOCTOR model. Our code is public available at\nhttps://github.com/ghh1125/DOCTOR."}
{"id": "2507.01924", "title": "Exploring a Hybrid Deep Learning Approach for Anomaly Detection in Mental Healthcare Provider Billing: Addressing Label Scarcity through Semi-Supervised Anomaly Detection", "url": "https://arxiv.org/abs/2507.01924", "pdf": "https://arxiv.org/pdf/2507.01924", "abs": "https://arxiv.org/abs/2507.01924", "authors": ["Samirah Bakker", "Yao Ma", "Seyed Sahand Mohammadi Ziabari"], "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The complexity of mental healthcare billing enables anomalies, including\nfraud. While machine learning methods have been applied to anomaly detection,\nthey often struggle with class imbalance, label scarcity, and complex\nsequential patterns. This study explores a hybrid deep learning approach\ncombining Long Short-Term Memory (LSTM) networks and Transformers, with\npseudo-labeling via Isolation Forests (iForest) and Autoencoders (AE). Prior\nwork has not evaluated such hybrid models trained on pseudo-labeled data in the\ncontext of healthcare billing. The approach is evaluated on two real-world\nbilling datasets related to mental healthcare. The iForest LSTM baseline\nachieves the highest recall (0.963) on declaration-level data. On the\noperation-level data, the hybrid iForest-based model achieves the highest\nrecall (0.744), though at the cost of lower precision. These findings highlight\nthe potential of combining pseudo-labeling with hybrid deep learning in\ncomplex, imbalanced anomaly detection settings."}
{"id": "2507.00827", "title": "A Technique for the Detection of PDF Tampering or Forgery", "url": "https://arxiv.org/abs/2507.00827", "pdf": "https://arxiv.org/pdf/2507.00827", "abs": "https://arxiv.org/abs/2507.00827", "authors": ["Gabriel Grobler", "Sheunesu Makura", "Hein Venter"], "categories": ["cs.CR"], "comment": "19 Pages, 5 figures, published in Online Proceedings of the South\n  African Institute of Computer Scientists and Information Technologists 2024\n  Conference, ISSN 2959-8877", "summary": "Tampering or forgery of digital documents has become widespread, most\ncommonly through altering images without any malicious intent such as enhancing\nthe overall appearance of the image. However, there are occasions when\ntampering of digital documents can have negative consequences, such as\nfinancial fraud and reputational damage. Tampering can occur through altering a\ndigital document's text or editing an image's pixels. Many techniques have been\ndeveloped to detect whether changes have been made to a document. Most of these\ntechniques rely on generating hashes or watermarking the document. These\ntechniques, however, have limitations in that they cannot detect alterations to\nportable document format (PDF) signatures or other non-visual aspects, such as\nmetadata. This paper presents a new technique that can be used to detect\ntampering within a PDF document by utilizing the PDF document's file page\nobjects. The technique employs a prototype that can detect changes to a PDF\ndocument, such as changes made to the text, images, or metadata of the said\nfile."}
{"id": "2507.00096", "title": "AI-Governed Agent Architecture for Web-Trustworthy Tokenization of Alternative Assets", "url": "https://arxiv.org/abs/2507.00096", "pdf": "https://arxiv.org/pdf/2507.00096", "abs": "https://arxiv.org/abs/2507.00096", "authors": ["Ailiya Borjigin", "Wei Zhou", "Cong He"], "categories": ["cs.CR", "cs.AI"], "comment": "8 Pages, 1 figure", "summary": "Alternative Assets tokenization is transforming non-traditional financial\ninstruments are represented and traded on the web. However, ensuring\ntrustworthiness in web-based tokenized ecosystems poses significant challenges,\nfrom verifying off-chain asset data to enforcing regulatory compliance. This\npaper proposes an AI-governed agent architecture that integrates intelligent\nagents with blockchain to achieve web-trustworthy tokenization of alternative\nassets. In the proposed architecture, autonomous agents orchestrate the\ntokenization process (asset verification, valuation, compliance checking, and\nlifecycle management), while an AI-driven governance layer monitors agent\nbehavior and enforces trust through adaptive policies and cryptoeconomic\nincentives. We demonstrate that this approach enhances transparency, security,\nand compliance in asset tokenization, addressing key concerns around data\nauthenticity and fraud. A case study on tokenizing real estate assets\nillustrates how the architecture mitigates risks (e.g., fraudulent listings and\nmoney laundering) through real-time AI anomaly detection and on-chain\nenforcement. Our evaluation and analysis suggest that combining AI governance\nwith multi-agent systems and blockchain can significantly bolster trust in\ntokenized asset ecosystems. This work offers a novel framework for trustworthy\nasset tokenization on the web and provides insights for practitioners aiming to\ndeploy secure, compliant tokenization platforms."}
{"id": "2405.13692", "title": "Challenging Gradient Boosted Decision Trees with Tabular Transformers for Fraud Detection at Booking.com", "url": "https://arxiv.org/abs/2405.13692", "pdf": "https://arxiv.org/pdf/2405.13692", "abs": "https://arxiv.org/abs/2405.13692", "authors": ["Sergei Krutikov", "Bulat Khaertdinov", "Rodion Kiriukhin", "Shubham Agrawal", "Mozhdeh Ariannezhad", "Kees Jan De Vries"], "categories": ["cs.LG"], "comment": "Submitted to CIKM'25, Applied Research track", "summary": "Transformer-based neural networks, empowered by Self-Supervised Learning\n(SSL), have demonstrated unprecedented performance across various domains.\nHowever, related literature suggests that tabular Transformers may struggle to\noutperform classical Machine Learning algorithms, such as Gradient Boosted\nDecision Trees (GBDT). In this paper, we aim to challenge GBDTs with tabular\nTransformers on a typical task faced in e-commerce, namely fraud detection. Our\nstudy is additionally motivated by the problem of selection bias, often\noccurring in real-life fraud detection systems. It is caused by the production\nsystem affecting which subset of traffic becomes labeled. This issue is\ntypically addressed by sampling randomly a small part of the whole production\ndata, referred to as a Control Group. This subset follows a target distribution\nof production data and therefore is usually preferred for training\nclassification models with standard ML algorithms. Our methodology leverages\nthe capabilities of Transformers to learn transferable representations using\nall available data by means of SSL, giving it an advantage over classical\nmethods. Furthermore, we conduct large-scale experiments, pre-training tabular\nTransformers on vast amounts of data instances and fine-tuning them on smaller\ntarget datasets. The proposed approach outperforms heavily tuned GBDTs by a\nconsiderable margin of the Average Precision (AP) score in offline evaluations.\nFinally, we report the results of an online A/B experiment. Experimental\nresults confirm the superiority of tabular Transformers compared to GBDTs in\nproduction, demonstrated by a statistically significant improvement in our\nbusiness metric."}
{"id": "2506.22171", "title": "Proof-of-Behavior: Behavior-Driven Consensus for Trustworthy Decentralized Finance", "url": "https://arxiv.org/abs/2506.22171", "pdf": "https://arxiv.org/pdf/2506.22171", "abs": "https://arxiv.org/abs/2506.22171", "authors": ["Ailiya Borjigin", "Wei Zhou", "Cong He"], "categories": ["cs.DC"], "comment": "8 pages, submitted to WI IAT 2025", "summary": "Current blockchain protocols (e.g., Proof-of-Work and Proof-of-Stake) secure\nthe ledger yet cannot measure validator trustworthiness, allowing subtle\nmisconduct that is especially damaging in decentralized-finance (DeFi)\nsettings. We introduce Proof-of-Behavior (PoB), a consensus model that (i)\ngives each action a layered utility score -- covering motivation and outcome,\n(ii) adapts validator weights using recent scores, and (iii) applies\ndecentralized verification with proportional slashing. The reward design is\nincentive-compatible, yielding a Nash equilibrium in which honest behavior\nmaximizes long-run pay-offs. Simulated DeFi experiments (loan-fraud detection,\nreputation-weighted validation) show that PoB cuts fraud acceptance by more\nthan 90%, demotes malicious validators within two rounds, and improves proposer\nfairness versus standard PoS, all with no more than a 5% throughput overhead.\nBy linking consensus influence to verifiably trustworthy conduct, PoB offers a\nscalable, regulation-friendly foundation for secure and fair blockchain\ngovernance in financial applications."}
{"id": "2506.21443", "title": "Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection", "url": "https://arxiv.org/abs/2506.21443", "pdf": "https://arxiv.org/pdf/2506.21443", "abs": "https://arxiv.org/abs/2506.21443", "authors": ["Ali Şenol", "Garima Agrawal", "Huan Liu"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Detecting deceptive conversations on dynamic platforms is increasingly\ndifficult due to evolving language patterns and Concept Drift (CD)-i.e.,\nsemantic or topical shifts that alter the context or intent of interactions\nover time. These shifts can obscure malicious intent or mimic normal dialogue,\nmaking accurate classification challenging. While Large Language Models (LLMs)\nshow strong performance in natural language tasks, they often struggle with\ncontextual ambiguity and hallucinations in risk-sensitive scenarios. To address\nthese challenges, we present a Domain Knowledge (DK)-Enhanced LLM framework\nthat integrates pretrained LLMs with structured, task-specific insights to\nperform fraud and concept drift detection. The proposed architecture consists\nof three main components: (1) a DK-LLM module to detect fake or deceptive\nconversations; (2) a drift detection unit (OCDD) to determine whether a\nsemantic shift has occurred; and (3) a second DK-LLM module to classify the\ndrift as either benign or fraudulent. We first validate the value of domain\nknowledge using a fake review dataset and then apply our full framework to\nSEConvo, a multiturn dialogue dataset that includes various types of fraud and\nspam attacks. Results show that our system detects fake conversations with high\naccuracy and effectively classifies the nature of drift. Guided by structured\nprompts, the LLaMA-based implementation achieves 98% classification accuracy.\nComparative studies against zero-shot baselines demonstrate that incorporating\ndomain knowledge and drift awareness significantly improves performance,\ninterpretability, and robustness in high-stakes NLP applications."}
{"id": "2506.21382", "title": "Temporal-Aware Graph Attention Network for Cryptocurrency Transaction Fraud Detection", "url": "https://arxiv.org/abs/2506.21382", "pdf": "https://arxiv.org/pdf/2506.21382", "abs": "https://arxiv.org/abs/2506.21382", "authors": ["Zhi Zheng", "Bochuan Zhou", "Yuping Song"], "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Cryptocurrency transaction fraud detection faces the dual challenges of\nincreasingly complex transaction patterns and severe class imbalance.\nTraditional methods rely on manual feature engineering and struggle to capture\ntemporal and structural dependencies in transaction networks. This paper\nproposes an Augmented Temporal-aware Graph Attention Network (ATGAT) that\nenhances detection performance through three modules: (1) designing an advanced\ntemporal embedding module that fuses multi-scale time difference features with\nperiodic position encoding; (2) constructing a temporal-aware triple attention\nmechanism that jointly optimizes structural, temporal, and global context\nattention; (3) employing weighted BCE loss to address class imbalance.\nExperiments on the Elliptic++ cryptocurrency dataset demonstrate that ATGAT\nachieves an AUC of 0.9130, representing a 9.2% improvement over the best\ntraditional method XGBoost, 12.0% over GCN, and 10.0% over standard GAT. This\nmethod not only validates the enhancement effect of temporal awareness and\ntriple attention mechanisms on graph neural networks, but also provides\nfinancial institutions with more reliable fraud detection tools, with its\ndesign principles generalizable to other temporal graph anomaly detection\ntasks."}
{"id": "2506.20511", "title": "Collaborative Batch Size Optimization for Federated Learning", "url": "https://arxiv.org/abs/2506.20511", "pdf": "https://arxiv.org/pdf/2506.20511", "abs": "https://arxiv.org/abs/2506.20511", "authors": ["Arno Geimer", "Karthick Panner Selvam", "Beltran Fiz Pontiveros"], "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Federated Learning (FL) is a decentralized collaborative Machine Learning\nframework for training models without collecting data in a centralized\nlocation. It has seen application across various disciplines, from helping\nmedical diagnoses in hospitals to detecting fraud in financial transactions. In\nthis paper, we focus on improving the local training process through hardware\nusage optimization. While participants in a federation might share the hardware\nthey are training on, since there is no information exchange between them,\ntheir training process can be hindered by an improper training configuration.\nTaking advantage of the parallel processing inherent to Federated Learning, we\nuse a greedy randomized search to optimize local batch sizes for the best\ntraining settings across all participants. Our results show that against\ndefault parameter settings, our method improves convergence speed while staying\nnearly on par with the case where local parameters are optimized."}
{"id": "2507.01980", "title": "Detecting Fraud in Financial Networks: A Semi-Supervised GNN Approach with Granger-Causal Explanations", "url": "https://arxiv.org/abs/2507.01980", "pdf": "https://arxiv.org/pdf/2507.01980", "abs": "https://arxiv.org/abs/2507.01980", "authors": ["Linh Nguyen", "Marcel Boersma", "Erman Acar"], "categories": ["q-fin.ST", "cs.LG", "stat.ML"], "comment": null, "summary": "Fraudulent activity in the financial industry costs billions annually.\nDetecting fraud, therefore, is an essential yet technically challenging task\nthat requires carefully analyzing large volumes of data. While machine learning\n(ML) approaches seem like a viable solution, applying them successfully is not\nso easy due to two main challenges: (1) the sparsely labeled data, which makes\nthe training of such approaches challenging (with inherent labeling costs), and\n(2) lack of explainability for the flagged items posed by the opacity of ML\nmodels, that is often required by business regulations. This article proposes\nSAGE-FIN, a semi-supervised graph neural network (GNN) based approach with\nGranger causal explanations for Financial Interaction Networks. SAGE-FIN learns\nto flag fraudulent items based on weakly labeled (or unlabelled) data points.\nTo adhere to regulatory requirements, the flagged items are explained by\nhighlighting related items in the network using Granger causality. We\nempirically validate the favorable performance of SAGE-FIN on a real-world\ndataset, Bipartite Edge-And-Node Attributed financial network (Elliptic++),\nwith Granger-causal explanations for the identified fraudulent items without\nany prior assumption on the network structure."}
{"id": "2506.18787", "title": "3D Arena: An Open Platform for Generative 3D Evaluation", "url": "https://arxiv.org/abs/2506.18787", "pdf": "https://arxiv.org/pdf/2506.18787", "abs": "https://arxiv.org/abs/2506.18787", "authors": ["Dylan Ebert"], "categories": ["cs.CV"], "comment": "9 pages, 2 figures", "summary": "Evaluating Generative 3D models remains challenging due to misalignment\nbetween automated metrics and human perception of quality. Current benchmarks\nrely on image-based metrics that ignore 3D structure or geometric measures that\nfail to capture perceptual appeal and real-world utility. To address this gap,\nwe present 3D Arena, an open platform for evaluating image-to-3D generation\nmodels through large-scale human preference collection using pairwise\ncomparisons.\n  Since launching in June 2024, the platform has collected 123,243 votes from\n8,096 users across 19 state-of-the-art models, establishing the largest human\npreference evaluation for Generative 3D. We contribute the iso3d dataset of 100\nevaluation prompts and demonstrate quality control achieving 99.75% user\nauthenticity through statistical fraud detection. Our ELO-based ranking system\nprovides reliable model assessment, with the platform becoming an established\nevaluation resource.\n  Through analysis of this preference data, we present insights into human\npreference patterns. Our findings reveal preferences for visual presentation\nfeatures, with Gaussian splat outputs achieving a 16.6 ELO advantage over\nmeshes and textured models receiving a 144.1 ELO advantage over untextured\nmodels. We provide recommendations for improving evaluation methods, including\nmulti-criteria assessment, task-oriented evaluation, and format-aware\ncomparison. The platform's community engagement establishes 3D Arena as a\nbenchmark for the field while advancing understanding of human-centered\nevaluation in Generative 3D."}
{"id": "2506.18942", "title": "Advanced Applications of Generative AI in Actuarial Science: Case Studies Beyond ChatGPT", "url": "https://arxiv.org/abs/2506.18942", "pdf": "https://arxiv.org/pdf/2506.18942", "abs": "https://arxiv.org/abs/2506.18942", "authors": ["Simon Hatzesberger", "Iris Nonneman"], "categories": ["cs.CY", "q-fin.RM"], "comment": null, "summary": "This article demonstrates the transformative impact of Generative AI (GenAI)\non actuarial science, illustrated by four implemented case studies. It begins\nwith a historical overview of AI, tracing its evolution from early neural\nnetworks to modern GenAI technologies. The first case study shows how Large\nLanguage Models (LLMs) improve claims cost prediction by deriving significant\nfeatures from unstructured textual data, significantly reducing prediction\nerrors in the underlying machine learning task. In the second case study, we\nexplore the automation of market comparisons using the GenAI concept of\nRetrieval-Augmented Generation to identify and process relevant information\nfrom documents. A third case study highlights the capabilities of fine-tuned\nvision-enabled LLMs in classifying car damage types and extracting contextual\ninformation. The fourth case study presents a multi-agent system that\nautonomously analyzes data from a given dataset and generates a corresponding\nreport detailing the key findings. In addition to these case studies, we\noutline further potential applications of GenAI in the insurance industry, such\nas the automation of claims processing and fraud detection, and the\nverification of document compliance with internal or external policies.\nFinally, we discuss challenges and considerations associated with the use of\nGenAI, covering regulatory issues, ethical concerns, and technical limitations,\namong others."}
{"id": "2506.19871", "title": "An Attack Method for Medical Insurance Claim Fraud Detection based on Generative Adversarial Network", "url": "https://arxiv.org/abs/2506.19871", "pdf": "https://arxiv.org/pdf/2506.19871", "abs": "https://arxiv.org/abs/2506.19871", "authors": ["Yining Pang", "Chenghan Li"], "categories": ["cs.CR", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2405.12076 by other authors", "summary": "Insurance fraud detection represents a pivotal advancement in modern\ninsurance service, providing intelligent and digitalized monitoring to enhance\nmanagement and prevent fraud. It is crucial for ensuring the security and\nefficiency of insurance systems. Although AI and machine learning algorithms\nhave demonstrated strong performance in detecting fraudulent claims, the\nabsence of standardized defense mechanisms renders current systems vulnerable\nto emerging adversarial threats. In this paper, we propose a GAN-based approach\nto conduct adversarial attacks on fraud detection systems. Our results indicate\nthat an attacker, without knowledge of the training data or internal model\ndetails, can generate fraudulent cases that are classified as legitimate with a\n99\\% attack success rate (ASR). By subtly modifying real insurance records and\nclaims, adversaries can significantly increase the fraud risk, potentially\nbypassing compromised detection systems. These findings underscore the urgent\nneed to enhance the robustness of insurance fraud detection models against\nadversarial manipulation, thereby ensuring the stability and reliability of\ndifferent insurance systems."}
{"id": "2506.19870", "title": "Secure Energy Transactions Using Blockchain Leveraging AI for Fraud Detection and Energy Market Stability", "url": "https://arxiv.org/abs/2506.19870", "pdf": "https://arxiv.org/pdf/2506.19870", "abs": "https://arxiv.org/abs/2506.19870", "authors": ["Md Asif Ul Hoq Khan", "MD Zahedul Islam", "Istiaq Ahmed", "Md Masud Karim Rabbi", "Farhana Rahman Anonna", "MD Abdul Fahim Zeeshan", "Mehedi Hasan Ridoy", "Bivash Ranjan Chowdhury", "Md Nazmul Shakir Rabbi", "GM Alamin Sadnan"], "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Peer-to-peer trading and the move to decentralized grids have reshaped the\nenergy markets in the United States. Notwithstanding, such developments lead to\nnew challenges, mainly regarding the safety and authenticity of energy trade.\nThis study aimed to develop and build a secure, intelligent, and efficient\nenergy transaction system for the decentralized US energy market. This research\ninterlinks the technological prowess of blockchain and artificial intelligence\n(AI) in a novel way to solve long-standing challenges in the distributed energy\nmarket, specifically those of security, fraudulent behavior detection, and\nmarket reliability. The dataset for this research is comprised of more than 1.2\nmillion anonymized energy transaction records from a simulated peer-to-peer\n(P2P) energy exchange network emulating real-life blockchain-based American\nmicrogrids, including those tested by LO3 Energy and Grid+ Labs. Each record\ncontains detailed fields of transaction identifier, timestamp, energy volume\n(kWh), transaction type (buy/sell), unit price, prosumer/consumer identifier\n(hashed for privacy), smart meter readings, geolocation regions, and settlement\nconfirmation status. The dataset also includes system-calculated behavior\nmetrics of transaction rate, variability of energy production, and historical\npricing patterns. The system architecture proposed involves the integration of\ntwo layers, namely a blockchain layer and artificial intelligence (AI) layer,\neach playing a unique but complementary function in energy transaction securing\nand market intelligence improvement. The machine learning models used in this\nresearch were specifically chosen for their established high performance in\nclassification tasks, specifically in the identification of energy transaction\nfraud in decentralized markets."}
{"id": "2506.16121", "title": "On the Efficient Discovery of Maximum $k$-Defective Biclique", "url": "https://arxiv.org/abs/2506.16121", "pdf": "https://arxiv.org/pdf/2506.16121", "abs": "https://arxiv.org/abs/2506.16121", "authors": ["Donghang Cui", "Ronghua Li", "Qiangqiang Dai", "Hongchao Qin", "Guoren Wang"], "categories": ["cs.DS"], "comment": null, "summary": "The problem of identifying the maximum edge biclique in bipartite graphs has\nattracted considerable attention in bipartite graph analysis, with numerous\nreal-world applications such as fraud detection, community detection, and\nonline recommendation systems. However, real-world graphs may contain noise or\nincomplete information, leading to overly restrictive conditions when employing\nthe biclique model. To mitigate this, we focus on a new relaxed subgraph model,\ncalled the $k$-defective biclique, which allows for up to $k$ missing edges\ncompared to the biclique model. We investigate the problem of finding the\nmaximum edge $k$-defective biclique in a bipartite graph, and prove that the\nproblem is NP-hard. To tackle this computation challenge, we propose a novel\nalgorithm based on a new branch-and-bound framework, which achieves a\nworst-case time complexity of $O(m\\alpha_k^n)$, where $\\alpha_k < 2$. We\nfurther enhance this framework by incorporating a novel pivoting technique,\nreducing the worst-case time complexity to $O(m\\beta_k^n)$, where $\\beta_k <\n\\alpha_k$. To improve the efficiency, we develop a series of optimization\ntechniques, including graph reduction methods, novel upper bounds, and a\nheuristic approach. Extensive experiments on 10 large real-world datasets\nvalidate the efficiency and effectiveness of the proposed approaches. The\nresults indicate that our algorithms consistently outperform state-of-the-art\nalgorithms, offering up to $1000\\times$ speedups across various parameter\nsettings."}
{"id": "2506.15325", "title": "Human-Centred AI in FinTech: Developing a User Experience (UX) Research Point of View (PoV) Playbook", "url": "https://arxiv.org/abs/2506.15325", "pdf": "https://arxiv.org/pdf/2506.15325", "abs": "https://arxiv.org/abs/2506.15325", "authors": ["Festus Adedoyin", "Huseyin Dogan"], "categories": ["cs.HC"], "comment": null, "summary": "Advancements in Artificial Intelligence (AI) have significantly transformed\nthe financial industry, enabling the development of more personalised and\nadaptable financial products and services. This research paper explores various\ninstances where Human-Centred AI (HCAI) has facilitated these advancements,\ndrawing from contemporary studies and industry progress. The paper examines how\nthe application of HCAI-powered data analytics, machine learning, and natural\nlanguage processing enables financial institutions to gain a deeper\nunderstanding of their customers' unique needs, preferences, and behavioural\npatterns. This, in turn, allows for the creation of tailored financial\nsolutions that address individual consumer requirements, ultimately enhancing\noverall user experience and satisfaction. Additionally, the study highlights\nthe integration of AI-powered robo-advisory services, which offer customised\ninvestment recommendations and portfolio management tailored to diverse risk\nprofiles and investment goals. Moreover, the paper underscores the role of AI\nin strengthening fraud detection, risk assessment, and regulatory compliance,\nleading to a more secure and adaptable financial landscape. The findings of\nthis research demonstrate the substantial impact of Human-Centred AI on the\nfinancial industry, offering a strategic framework for financial institutions\nto leverage these technologies. By incorporating a User Experience Research\n(UXR) Point of View (PoV), financial institutions can ensure that AI-driven\nsolutions align with user needs and business objectives."}
{"id": "2505.16557", "title": "Is Your LLM-Based Multi-Agent a Reliable Real-World Planner? Exploring Fraud Detection in Travel Planning", "url": "https://arxiv.org/abs/2505.16557", "pdf": "https://arxiv.org/pdf/2505.16557", "abs": "https://arxiv.org/abs/2505.16557", "authors": ["Junchi Yao", "Jianhua Xu", "Tianyu Xin", "Ziyi Wang", "Shenzhe Zhu", "Shu Yang", "Di Wang"], "categories": ["cs.MA"], "comment": "Accepted by ICML 2025 Workshop MAS", "summary": "The rise of Large Language Model-based Multi-Agent Planning has leveraged\nadvanced frameworks to enable autonomous and collaborative task execution. Some\nsystems rely on platforms like review sites and social media, which are prone\nto fraudulent information, such as fake reviews or misleading descriptions.\nThis reliance poses risks, potentially causing financial losses and harming\nuser experiences. To evaluate the risk of planning systems in real-world\napplications, we introduce \\textbf{WandaPlan}, an evaluation environment\nmirroring real-world data and injected with deceptive content. We assess system\nperformance across three fraud cases: Misinformation Fraud, Team-Coordinated\nMulti-Person Fraud, and Level-Escalating Multi-Round Fraud. We reveal\nsignificant weaknesses in existing frameworks that prioritize task efficiency\nover data authenticity. At the same time, we validate WandaPlan's\ngeneralizability, capable of assessing the risks of real-world open-source\nplanning frameworks. To mitigate the risk of fraud, we propose integrating an\nanti-fraud agent, providing a solution for reliable planning."}
{"id": "2506.11635", "title": "FAA Framework: A Large Language Model-Based Approach for Credit Card Fraud Investigations", "url": "https://arxiv.org/abs/2506.11635", "pdf": "https://arxiv.org/pdf/2506.11635", "abs": "https://arxiv.org/abs/2506.11635", "authors": ["Shaun Shuster", "Eyal Zaloof", "Asaf Shabtai", "Rami Puzis"], "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The continuous growth of the e-commerce industry attracts fraudsters who\nexploit stolen credit card details. Companies often investigate suspicious\ntransactions in order to retain customer trust and address gaps in their fraud\ndetection systems. However, analysts are overwhelmed with an enormous number of\nalerts from credit card transaction monitoring systems. Each alert\ninvestigation requires from the fraud analysts careful attention, specialized\nknowledge, and precise documentation of the outcomes, leading to alert fatigue.\nTo address this, we propose a fraud analyst assistant (FAA) framework, which\nemploys multi-modal large language models (LLMs) to automate credit card fraud\ninvestigations and generate explanatory reports. The FAA framework leverages\nthe reasoning, code execution, and vision capabilities of LLMs to conduct\nplanning, evidence collection, and analysis in each investigation step. A\ncomprehensive empirical evaluation of 500 credit card fraud investigations\ndemonstrates that the FAA framework produces reliable and efficient\ninvestigations comprising seven steps on average. Thus we found that the FAA\nframework can automate large parts of the workload and help reduce the\nchallenges faced by fraud analysts."}
{"id": "2506.10842", "title": "Advanced fraud detection using machine learning models: enhancing financial transaction security", "url": "https://arxiv.org/abs/2506.10842", "pdf": "https://arxiv.org/pdf/2506.10842", "abs": "https://arxiv.org/abs/2506.10842", "authors": ["Nudrat Fariha", "Md Nazmuddin Moin Khan", "Md Iqbal Hossain", "Syed Ali Reza", "Joy Chakra Bortty", "Kazi Sharmin Sultana", "Md Shadidur Islam Jawad", "Saniah Safat", "Md Abdul Ahad", "Maksuda Begum"], "categories": ["cs.LG"], "comment": null, "summary": "The rise of digital payments has accelerated the need for intelligent and\nscalable systems to detect fraud. This research presents an end-to-end,\nfeature-rich machine learning framework for detecting credit card transaction\nanomalies and fraud using real-world data. The study begins by merging\ntransactional, cardholder, merchant, and merchant category datasets from a\nrelational database to create a unified analytical view. Through the feature\nengineering process, we extract behavioural signals such as average spending,\ndeviation from historical patterns, transaction timing irregularities, and\ncategory frequency metrics. These features are enriched with temporal markers\nsuch as hour, day of week, and weekend indicators to expose all latent patterns\nthat indicate fraudulent behaviours. Exploratory data analysis reveals\ncontextual transaction trends across all the dataset features. Using the\ntransactional data, we train and evaluate a range of unsupervised models:\nIsolation Forest, One Class SVM, and a deep autoencoder trained to reconstruct\nnormal behavior. These models flag the top 1% of reconstruction errors as\noutliers. PCA visualizations illustrate each models ability to separate\nanomalies into a two-dimensional latent space. We further segment the\ntransaction landscape using K-Means clustering and DBSCAN to identify dense\nclusters of normal activity and isolate sparse, suspicious regions."}
{"id": "2506.09938", "title": "Microservices and Real-Time Processing in Retail IT: A Review of Open-Source Toolchains and Deployment Strategies", "url": "https://arxiv.org/abs/2506.09938", "pdf": "https://arxiv.org/pdf/2506.09938", "abs": "https://arxiv.org/abs/2506.09938", "authors": ["Aaditaa Vashisht", "Rekha B S"], "categories": ["cs.SE", "cs.DB"], "comment": null, "summary": "With the rapid pace of digital transformation, the retail industry is\nincreasingly depending on real-time, scalable, and resilient systems to manage\nfinancial transactions, analyze customer behavior, and streamline order\nprocessing. This literature review explores how modern event-driven and\nmicroservices-based architectures, particularly those leveraging Apache Kafka,\nSpring Boot, MongoDB, and Kubernetes are transforming retail and financial\nsystems. By systematically reviewing academic publications, technical white\npapers, and industry reports from recent years, this study synthesizes key\nthemes and implementation strategies. The analysis reveals that technologies\nlike Kafka and Spring Boot are instrumental in building low-latency,\nevent-driven applications that support real-time analytics and fraud detection,\nwhile MongoDB, when deployed on Kubernetes, ensures fault tolerance and high\navailability in inventory and transaction systems. Kubernetes itself plays a\ncrucial role in automating deployment and scaling of microservices. These\nfindings provide valuable insights for industry practitioners aiming to design\nscalable infrastructures, identify research opportunities in hybrid deployment\nmodels, and offer educators a foundation to integrate modern system\narchitectures into professional and technical communication training."}
{"id": "2506.12088", "title": "Risks & Benefits of LLMs & GenAI for Platform Integrity, Healthcare Diagnostics, Cybersecurity, Privacy & AI Safety: A Comprehensive Survey, Roadmap & Implementation Blueprint", "url": "https://arxiv.org/abs/2506.12088", "pdf": "https://arxiv.org/pdf/2506.12088", "abs": "https://arxiv.org/abs/2506.12088", "authors": ["Kiarash Ahi"], "categories": ["cs.CR", "cs.CY"], "comment": null, "summary": "Large Language Models (LLMs) and generative AI (GenAI) systems such as\nChatGPT, Claude, Gemini, LLaMA, and Copilot, developed by OpenAI, Anthropic,\nGoogle, Meta, and Microsoft are reshaping digital platforms and app ecosystems\nwhile introducing key challenges in cybersecurity, privacy, and platform\nintegrity. Our analysis shows alarming trends: LLM-assisted malware is\nprojected to rise from 2% in 2021 to 50% by 2025; AI-generated Google reviews\ngrew from 1.2% in 2021 to 12.21% in 2023, with an expected 30% by 2025; AI scam\nreports surged 456%; and misinformation sites increased over 1500%, with a\n50-60% increase in deepfakes in 2024. Concurrently, as LLMs have facilitated\ncode development, mobile app submissions grew from 1.8 million in 2020 to 3.0\nmillion in 2024, with 3.6 million expected by 2025. To address AI threats,\nplatforms from app stores like Google Play and Apple to developer hubs like\nGitHub Copilot, and social platforms like TikTok and Facebook, to marketplaces\nlike Amazon are deploying AI and LLM-based defenses. This highlights the dual\nnature of these technologies as both the source of new threats and the\nessential tool for their mitigation. Integrating LLMs into clinical diagnostics\nalso raises concerns about accuracy, bias, and safety, needing strong\ngovernance. Drawing on a comprehensive analysis of 455 references, this paper\npresents a survey of LLM and GenAI risks. We propose a strategic roadmap and\noperational blueprint integrating policy auditing (CCPA, GDPR), fraud\ndetection, and compliance automation, and an advanced LLM-DA stack with modular\ncomponents including multi LLM routing, agentic memory, and governance layers\nto enhance platform integrity. We also provide actionable insights,\ncross-functional best practices, and real-world case studies. These\ncontributions offer paths to scalable trust, safety, and responsible innovation\nacross digital platforms."}
{"id": "2506.08762", "title": "EDINET-Bench: Evaluating LLMs on Complex Financial Tasks using Japanese Financial Statements", "url": "https://arxiv.org/abs/2506.08762", "pdf": "https://arxiv.org/pdf/2506.08762", "abs": "https://arxiv.org/abs/2506.08762", "authors": ["Issa Sugiura", "Takashi Ishida", "Taro Makino", "Chieko Tazuke", "Takanori Nakagawa", "Kosuke Nakago", "David Ha"], "categories": ["q-fin.ST", "cs.CE", "cs.CL", "cs.LG"], "comment": null, "summary": "Financial analysis presents complex challenges that could leverage large\nlanguage model (LLM) capabilities. However, the scarcity of challenging\nfinancial datasets, particularly for Japanese financial data, impedes academic\ninnovation in financial analytics. As LLMs advance, this lack of accessible\nresearch resources increasingly hinders their development and evaluation in\nthis specialized domain. To address this gap, we introduce EDINET-Bench, an\nopen-source Japanese financial benchmark designed to evaluate the performance\nof LLMs on challenging financial tasks including accounting fraud detection,\nearnings forecasting, and industry prediction. EDINET-Bench is constructed by\ndownloading annual reports from the past 10 years from Japan's Electronic\nDisclosure for Investors' NETwork (EDINET) and automatically assigning labels\ncorresponding to each evaluation task. Our experiments reveal that even\nstate-of-the-art LLMs struggle, performing only slightly better than logistic\nregression in binary classification for fraud detection and earnings\nforecasting. These results highlight significant challenges in applying LLMs to\nreal-world financial applications and underscore the need for domain-specific\nadaptation. Our dataset, benchmark construction code, and evaluation code is\npublicly available to facilitate future research in finance with LLMs."}
{"id": "2506.03988", "title": "RAID: A Dataset for Testing the Adversarial Robustness of AI-Generated Image Detectors", "url": "https://arxiv.org/abs/2506.03988", "pdf": "https://arxiv.org/pdf/2506.03988", "abs": "https://arxiv.org/abs/2506.03988", "authors": ["Hicham Eddoubi", "Jonas Ricker", "Federico Cocchi", "Lorenzo Baraldi", "Angelo Sotgiu", "Maura Pintor", "Marcella Cornia", "Lorenzo Baraldi", "Asja Fischer", "Rita Cucchiara", "Battista Biggio"], "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "AI-generated images have reached a quality level at which humans are\nincapable of reliably distinguishing them from real images. To counteract the\ninherent risk of fraud and disinformation, the detection of AI-generated images\nis a pressing challenge and an active research topic. While many of the\npresented methods claim to achieve high detection accuracy, they are usually\nevaluated under idealized conditions. In particular, the adversarial robustness\nis often neglected, potentially due to a lack of awareness or the substantial\neffort required to conduct a comprehensive robustness analysis. In this work,\nwe tackle this problem by providing a simpler means to assess the robustness of\nAI-generated image detectors. We present RAID (Robust evaluation of\nAI-generated image Detectors), a dataset of 72k diverse and highly transferable\nadversarial examples. The dataset is created by running attacks against an\nensemble of seven state-of-the-art detectors and images generated by four\ndifferent text-to-image models. Extensive experiments show that our methodology\ngenerates adversarial images that transfer with a high success rate to unseen\ndetectors, which can be used to quickly provide an approximate yet still\nreliable estimate of a detector's adversarial robustness. Our findings indicate\nthat current state-of-the-art AI-generated image detectors can be easily\ndeceived by adversarial examples, highlighting the critical need for the\ndevelopment of more robust methods. We release our dataset at\nhttps://huggingface.co/datasets/aimagelab/RAID and evaluation code at\nhttps://github.com/pralab/RAID."}
{"id": "2506.05740", "title": "FIST: A Structured Threat Modeling Framework for Fraud Incidents", "url": "https://arxiv.org/abs/2506.05740", "pdf": "https://arxiv.org/pdf/2506.05740", "abs": "https://arxiv.org/abs/2506.05740", "authors": ["Yu-Chen Dai", "Lu-An Chen", "Sy-Jye Her", "Yu-Xian Jiang"], "categories": ["cs.CR"], "comment": null, "summary": "Fraudulent activities are rapidly evolving, employing increasingly diverse\nand sophisticated methods that pose serious threats to individuals,\norganizations, and society. This paper proposes the FIST Framework (Fraud\nIncident Structured Threat Framework), an innovative structured threat modeling\nmethodology specifically designed for fraud scenarios. Inspired by MITRE\nATT\\&CK and DISARM, FIST systematically incorporates social engineering\ntactics, stage-based behavioral decomposition, and detailed attack technique\nmapping into a reusable knowledge base. FIST aims to enhance the efficiency of\nfraud detection and the standardization of threat intelligence sharing,\npromoting collaboration and a unified language across organizations and\nsectors. The framework integrates interdisciplinary insights from\ncybersecurity, criminology, and behavioral science, addressing both technical\nvectors and psychological manipulation mechanisms in fraud. This approach\nenables fine-grained analysis of fraud incidents, supporting automated\ndetection, quantitative risk assessment, and standardized incident reporting.\nThe effectiveness of the framework is further validated through real-world case\nstudies, demonstrating its value in bridging academic research and practical\napplications, and laying the foundation for an intelligence-driven anti-fraud\necosystem. To the best of our knowledge, FIST is the first systematic,\nopen-source fraud threat modeling framework that unifies both technical and\npsychological aspects, and is made freely available to foster collaboration\nbetween academia and industry."}
{"id": "2312.16139", "title": "Abnormal component analysis", "url": "https://arxiv.org/abs/2312.16139", "pdf": "https://arxiv.org/pdf/2312.16139", "abs": "https://arxiv.org/abs/2312.16139", "authors": ["Romain Valla", "Pavlo Mozharovskyi", "Florence d'Alché-Buc"], "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "At the crossway of machine learning and data analysis, anomaly detection aims\nat identifying observations that exhibit abnormal behaviour. Be it measurement\nerrors, disease development, severe weather, production quality default(s)\n(items) or failed equipment, financial frauds or crisis events, their on-time\nidentification and isolation constitute an important task in almost any area of\nindustry and science. While a substantial body of literature is devoted to\ndetection of anomalies, little attention is payed to their explanation. This is\nthe case mostly due to intrinsically non-supervised nature of the task and\nnon-robustness of the exploratory methods like principal component analysis\n(PCA).\n  We introduce a new statistical tool dedicated for exploratory analysis of\nabnormal observations using data depth as a score. Abnormal component analysis\n(shortly ACA) is a method that searches a low-dimensional data representation\nthat best visualises and explains anomalies. This low-dimensional\nrepresentation not only allows to distinguish groups of anomalies better than\nthe methods of the state of the art, but as well provides a -- linear in\nvariables and thus easily interpretable -- explanation for anomalies. In a\ncomparative simulation and real-data study, ACA also proves advantageous for\nanomaly analysis with respect to methods present in the literature."}
{"id": "2502.00837", "title": "Explainability in Practice: A Survey of Explainable NLP Across Various Domains", "url": "https://arxiv.org/abs/2502.00837", "pdf": "https://arxiv.org/pdf/2502.00837", "abs": "https://arxiv.org/abs/2502.00837", "authors": ["Hadi Mohammadi", "Ayoub Bagheri", "Anastasia Giachanou", "Daniel L. Oberski"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Natural Language Processing (NLP) has become a cornerstone in many critical\nsectors, including healthcare, finance, and customer relationship management.\nThis is especially true with the development and use of advanced models such as\nGPT-based architectures and BERT, which are widely used in decision-making\nprocesses. However, the black-box nature of these advanced NLP models has\ncreated an urgent need for transparency and explainability. This review\nexplores explainable NLP (XNLP) with a focus on its practical deployment and\nreal-world applications, examining its implementation and the challenges faced\nin domain-specific contexts. The paper underscores the importance of\nexplainability in NLP and provides a comprehensive perspective on how XNLP can\nbe designed to meet the unique demands of various sectors, from healthcare's\nneed for clear insights to finance's emphasis on fraud detection and risk\nassessment. Additionally, this review aims to bridge the knowledge gap in XNLP\nliterature by offering a domain-specific exploration and discussing\nunderrepresented areas such as real-world applicability, metric evaluation, and\nthe role of human interaction in model assessment. The paper concludes by\nsuggesting future research directions that could enhance the understanding and\nbroader application of XNLP."}
{"id": "2502.18334", "title": "Structural Alignment Improves Graph Test-Time Adaptation", "url": "https://arxiv.org/abs/2502.18334", "pdf": "https://arxiv.org/pdf/2502.18334", "abs": "https://arxiv.org/abs/2502.18334", "authors": ["Hans Hao-Hsun Hsu", "Shikun Liu", "Han Zhao", "Pan Li"], "categories": ["cs.LG"], "comment": null, "summary": "Graph-based learning excels at capturing interaction patterns in diverse\ndomains like recommendation, fraud detection, and particle physics. However,\nits performance often degrades under distribution shifts, especially those\naltering network connectivity. Current methods to address these shifts\ntypically require retraining with the source dataset, which is often infeasible\ndue to computational or privacy limitations. We introduce Test-Time Structural\nAlignment (TSA), a novel algorithm for Graph Test-Time Adaptation (GTTA) that\naligns graph structures during inference without accessing the source data.\nGrounded in a theoretical understanding of graph data distribution shifts, TSA\nemploys three synergistic strategies: uncertainty-aware neighborhood weighting\nto accommodate neighbor label distribution shifts, adaptive balancing of\nself-node and aggregated neighborhood representations based on their\nsignal-to-noise ratio, and decision boundary refinement to correct residual\nlabel and feature shifts. Extensive experiments on synthetic and real-world\ndatasets demonstrate TSA's consistent outperformance of both non-graph TTA\nmethods and state-of-the-art GTTA baselines."}
{"id": "2506.04292", "title": "GARG-AML against Smurfing: A Scalable and Interpretable Graph-Based Framework for Anti-Money Laundering", "url": "https://arxiv.org/abs/2506.04292", "pdf": "https://arxiv.org/pdf/2506.04292", "abs": "https://arxiv.org/abs/2506.04292", "authors": ["Bruno Deprez", "Bart Baesens", "Tim Verdonck", "Wouter Verbeke"], "categories": ["cs.SI", "cs.LG", "stat.AP"], "comment": null, "summary": "Money laundering poses a significant challenge as it is estimated to account\nfor 2%-5% of the global GDP. This has compelled regulators to impose stringent\ncontrols on financial institutions. One prominent laundering method for evading\nthese controls, called smurfing, involves breaking up large transactions into\nsmaller amounts. Given the complexity of smurfing schemes, which involve\nmultiple transactions distributed among diverse parties, network analytics has\nbecome an important anti-money laundering tool. However, recent advances have\nfocused predominantly on black-box network embedding methods, which has\nhindered their adoption in businesses. In this paper, we introduce GARG-AML, a\nnovel graph-based method that quantifies smurfing risk through a single\ninterpretable metric derived from the structure of the second-order transaction\nnetwork of each individual node in the network. Unlike traditional methods,\nGARG-AML strikes an effective balance among computational efficiency, detection\npower and transparency, which enables its integration into existing AML\nworkflows. To enhance its capabilities, we combine the GARG-AML score\ncalculation with different tree-based methods and also incorporate the scores\nof the node's neighbours. An experimental evaluation on large-scale synthetic\nand open-source networks demonstrate that the GARG-AML outperforms the current\nstate-of-the-art smurfing detection methods. By leveraging only the adjacency\nmatrix of the second-order neighbourhood and basic network features, this work\nhighlights the potential of fundamental network properties towards advancing\nfraud detection."}
{"id": "2506.02757", "title": "Investigating Mask-aware Prototype Learning for Tabular Anomaly Detection", "url": "https://arxiv.org/abs/2506.02757", "pdf": "https://arxiv.org/pdf/2506.02757", "abs": "https://arxiv.org/abs/2506.02757", "authors": ["Ruiying Lu", "Jinhan Liu", "Chuan Du", "Dandan Guo"], "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 11 figures", "summary": "Tabular anomaly detection, which aims at identifying deviant samples, has\nbeen crucial in a variety of real-world applications, such as medical disease\nidentification, financial fraud detection, intrusion monitoring, etc. Although\nrecent deep learning-based methods have achieved competitive performances,\nthese methods suffer from representation entanglement and the lack of global\ncorrelation modeling, which hinders anomaly detection performance. To tackle\nthe problem, we incorporate mask modeling and prototype learning into tabular\nanomaly detection. The core idea is to design learnable masks by disentangled\nrepresentation learning within a projection space and extracting normal\ndependencies as explicit global prototypes. Specifically, the overall model\ninvolves two parts: (i) During encoding, we perform mask modeling in both the\ndata space and projection space with orthogonal basis vectors for learning\nshared disentangled normal patterns; (ii) During decoding, we decode multiple\nmasked representations in parallel for reconstruction and learn association\nprototypes to extract normal characteristic correlations. Our proposal derives\nfrom a distribution-matching perspective, where both projection space learning\nand association prototype learning are formulated as optimal transport\nproblems, and the calibration distances are utilized to refine the anomaly\nscores. Quantitative and qualitative experiments on 20 tabular benchmarks\ndemonstrate the effectiveness and interpretability of our model."}
{"id": "2506.02703", "title": "Data Leakage and Deceptive Performance: A Critical Examination of Credit Card Fraud Detection Methodologies", "url": "https://arxiv.org/abs/2506.02703", "pdf": "https://arxiv.org/pdf/2506.02703", "abs": "https://arxiv.org/abs/2506.02703", "authors": ["Khizar Hayat", "Baptiste Magnier"], "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": null, "summary": "This study critically examines the methodological rigor in credit card fraud\ndetection research, revealing how fundamental evaluation flaws can overshadow\nalgorithmic sophistication. Through deliberate experimentation with improper\nevaluation protocols, we demonstrate that even simple models can achieve\ndeceptively impressive results when basic methodological principles are\nviolated. Our analysis identifies four critical issues plaguing current\napproaches: (1) pervasive data leakage from improper preprocessing sequences,\n(2) intentional vagueness in methodological reporting, (3) inadequate temporal\nvalidation for transaction data, and (4) metric manipulation through recall\noptimization at precision's expense. We present a case study showing how a\nminimal neural network architecture with data leakage outperforms many\nsophisticated methods reported in literature, achieving 99.9\\% recall despite\nfundamental evaluation flaws. These findings underscore that proper evaluation\nmethodology matters more than model complexity in fraud detection research. The\nstudy serves as a cautionary example of how methodological rigor must precede\narchitectural sophistication, with implications for improving research\npractices across machine learning applications."}
{"id": "2506.02068", "title": "Enhancing Interpretability of Quantum-Assisted Blockchain Clustering via AI Agent-Based Qualitative Analysis", "url": "https://arxiv.org/abs/2506.02068", "pdf": "https://arxiv.org/pdf/2506.02068", "abs": "https://arxiv.org/abs/2506.02068", "authors": ["Yun-Cheng Tsai", "Yen-Ku Liu", "Samuel Yen-Chi Chen"], "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Blockchain transaction data is inherently high dimensional, noisy, and\nentangled, posing substantial challenges for traditional clustering algorithms.\nWhile quantum enhanced clustering models have demonstrated promising\nperformance gains, their interpretability remains limited, restricting their\napplication in sensitive domains such as financial fraud detection and\nblockchain governance. To address this gap, we propose a two stage analysis\nframework that synergistically combines quantitative clustering evaluation with\nAI Agent assisted qualitative interpretation. In the first stage, we employ\nclassical clustering methods and evaluation metrics including the Silhouette\nScore, Davies Bouldin Index, and Calinski Harabasz Index to determine the\noptimal cluster count and baseline partition quality. In the second stage, we\nintegrate an AI Agent to generate human readable, semantic explanations of\nclustering results, identifying intra cluster characteristics and inter cluster\nrelationships. Our experiments reveal that while fully trained Quantum Neural\nNetworks (QNN) outperform random Quantum Features (QF) in quantitative metrics,\nthe AI Agent further uncovers nuanced differences between these methods,\nnotably exposing the singleton cluster phenomenon in QNN driven models. The\nconsolidated insights from both stages consistently endorse the three cluster\nconfiguration, demonstrating the practical value of our hybrid approach. This\nwork advances the interpretability frontier in quantum assisted blockchain\nanalytics and lays the groundwork for future autonomous AI orchestrated\nclustering frameworks."}
{"id": "2506.00719", "title": "Browser Fingerprinting Using WebAssembly", "url": "https://arxiv.org/abs/2506.00719", "pdf": "https://arxiv.org/pdf/2506.00719", "abs": "https://arxiv.org/abs/2506.00719", "authors": ["Mordechai Guri", "Dor Fibert"], "categories": ["cs.CR"], "comment": null, "summary": "Web client fingerprinting has become a widely used technique for uniquely\nidentifying users, browsers, operating systems, and devices with high accuracy.\nWhile it is beneficial for applications such as fraud detection and\npersonalized experiences, it also raises privacy concerns by enabling\npersistent tracking and detailed user profiling. This paper introduces an\nadvanced fingerprinting method using WebAssembly (Wasm) - a low-level\nprogramming language that offers near-native execution speed in modern web\nbrowsers. With broad support across major browsers and growing adoption,\nWebAssembly provides a strong foundation for developing more effective\nfingerprinting methods.\n  In this work, we present a new approach that leverages WebAssembly's\ncomputational capabilities to identify returning devices-such as smartphones,\ntablets, laptops, and desktops across different browsing sessions. Our method\nuses subtle differences in the WebAssembly JavaScript API implementation to\ndistinguish between Chromium-based browsers like Google Chrome and Microsoft\nEdge, even when identifiers such as the User-Agent are completely spoofed,\nachieving a false-positive rate of less than 1%. The fingerprint is generated\nusing a combination of CPU-bound operations, memory tasks, and I/O activities\nto capture unique browser behaviors. We validate this approach on a variety of\nplatforms, including Intel, AMD, and ARM CPUs, operating systems such as\nWindows, macOS, Android, and iOS, and in environments like VMWare, KVM, and\nVirtualBox. Extensive evaluation shows that WebAssembly-based fingerprinting\nsignificantly improves identification accuracy. We also propose mitigation\nstrategies to reduce the privacy risks associated with this method, which could\nbe integrated into future browser designs to better protect user privacy."}
{"id": "2506.00282", "title": "Shill Bidding Prevention in Decentralized Auctions Using Smart Contracts", "url": "https://arxiv.org/abs/2506.00282", "pdf": "https://arxiv.org/pdf/2506.00282", "abs": "https://arxiv.org/abs/2506.00282", "authors": ["M. A. Bouaicha", "G. Destefanis", "T. Montanaro", "N. Lasla", "L. Patrono"], "categories": ["cs.GT", "cs.CR", "cs.SE"], "comment": null, "summary": "In online auctions, fraudulent behaviors such as shill bidding pose\nsignificant risks. This paper presents a conceptual framework that applies\ndynamic, behavior-based penalties to deter auction fraud using blockchain smart\ncontracts. Unlike traditional post-auction detection methods, this approach\nprevents manipulation in real-time by introducing an economic disincentive\nsystem where penalty severity scales with suspicious bidding patterns. The\nframework employs the proposed Bid Shill Score (BSS) to evaluate nine distinct\nbidding behaviors, dynamically adjusting the penalty fees to make fraudulent\nactivity financially unaffordable while providing fair competition.\n  The system is implemented within a decentralized English auction on the\nEthereum blockchain, demonstrating how smart contracts enforce transparent\nauction rules without trusted intermediaries. Simulations confirm the\neffectiveness of the proposed model: the dynamic penalty mechanism reduces the\nprofitability of shill bidding while keeping penalties low for honest bidders.\nPerformance evaluation shows that the system introduces only moderate gas and\nlatency overhead, keeping transaction costs and response times within practical\nbounds for real-world use. The approach provides a practical method for\nbehaviour-based fraud prevention in decentralised systems where trust cannot be\nassumed."}
{"id": "2401.04139", "title": "CCNETS: A Modular Causal Learning Framework for Pattern Recognition in Imbalanced Datasets", "url": "https://arxiv.org/abs/2401.04139", "pdf": "https://arxiv.org/pdf/2401.04139", "abs": "https://arxiv.org/abs/2401.04139", "authors": ["Hanbeot Park", "Yunjeong Cho", "Hoon-Hee Kim"], "categories": ["cs.LG"], "comment": "52 pages, Hoon-Hee Kim is Corresponding Author", "summary": "Handling class imbalance remains a central challenge in machine learning,\nparticularly in pattern recognition tasks where rare but critical events-such\nas fraudulent transactions or medical anomalies-must be identified accurately.\nTraditional generative models offer a potential remedy through data\naugmentation but often treat generation and classification as independent\nprocesses, leading to distribution mismatch and limited classifier benefit. To\naddress these shortcomings, we propose Causal Cooperative Networks (CCNETS), a\nmodular learning framework that integrates generation, inference, and\nreconstruction within a unified causal paradigm. CCNETS comprises three\ncooperative modules: an Explainer for latent feature abstraction, a Reasoner\nfor label prediction, and a Producer for context-aware data generation. These\ncomponents interact through a causal feedback loop, where classification\nresults guide targeted sample synthesis. A key innovation, the Zoint mechanism,\nenables adaptive fusion of latent and observable features, enhancing semantic\nrichness and enabling robust decision-making under uncertainty. We evaluate\nCCNETS on a real-world credit card fraud detection dataset with extreme\nimbalance (fraud cases < 0.2%). Across three experimental setups-including\nsynthetic training, amplified generation, and direct classifier\ncomparison-CCNETS outperforms baseline methods, achieving higher F1 scores,\nprecision, and recall. Models trained on CCNETS-generated data also demonstrate\nsuperior generalization under limited data conditions. These results establish\nCCNETS as a scalable, interpretable, and hybrid soft computing framework. By\ncausally aligning synthetic data with classifier objectives, CCNETS advances\nimbalanced pattern recognition and opens new directions for robust, modular\nlearning in real-world applications."}
{"id": "2311.16139", "title": "GNNBleed: Inference Attacks to Unveil Private Edges in Graphs with Realistic Access to GNN Models", "url": "https://arxiv.org/abs/2311.16139", "pdf": "https://arxiv.org/pdf/2311.16139", "abs": "https://arxiv.org/abs/2311.16139", "authors": ["Zeyu Song", "Ehsanul Kabir", "Shagufta Mehnaz"], "categories": ["cs.CR", "cs.LG"], "comment": "The paper has been accepted to the PoPETs 2025", "summary": "Graph Neural Networks (GNNs) have become indispensable tools for learning\nfrom graph structured data, catering to various applications such as social\nnetwork analysis and fraud detection for financial services. At the heart of\nthese networks are the edges, which are crucial in guiding GNN models'\npredictions. In many scenarios, these edges represent sensitive information,\nsuch as personal associations or financial dealings, which require privacy\nassurance. However, their contributions to GNN model predictions may, in turn,\nbe exploited by the adversary to compromise their privacy. Motivated by these\nconflicting requirements, this paper investigates edge privacy in contexts\nwhere adversaries possess only black-box access to the target GNN model,\nrestricted further by access controls, preventing direct insights into\narbitrary node outputs. Moreover, we are the first to extensively examine\nsituations where the target graph continuously evolves, a common trait of many\nreal-world graphs. In this setting, we present a range of attacks that leverage\nthe message-passing mechanism of GNNs. We evaluated the effectiveness of our\nattacks using nine real-world datasets, encompassing both static and dynamic\ngraphs, across four different GNN architectures. The results demonstrate that\nour attack outperforms existing methods across various GNN architectures,\nconsistently achieving an F1 score of at least 0.8 in static scenarios.\nFurthermore, our attack retains robustness in dynamic graph scenarios,\nmaintaining F1 scores up to 0.8, unlike previous methods that only achieve F1\nscores around 0.2."}
{"id": "2502.19305", "title": "Corporate Fraud Detection in Rich-yet-Noisy Financial Graph", "url": "https://arxiv.org/abs/2502.19305", "pdf": "https://arxiv.org/pdf/2502.19305", "abs": "https://arxiv.org/abs/2502.19305", "authors": ["Shiqi Wang", "Zhibo Zhang", "Libing Fang", "Cam-Tu Nguyen", "Wenzhong Li"], "categories": ["cs.LG", "cs.AI", "q-fin.RM", "q-fin.ST"], "comment": null, "summary": "Corporate fraud detection aims to automatically recognize companies that\nconduct wrongful activities such as fraudulent financial statements or illegal\ninsider trading. Previous learning-based methods fail to effectively integrate\nrich interactions in the company network. To close this gap, we collect 18-year\nfinancial records in China to form three graph datasets with fraud labels. We\nanalyze the characteristics of the financial graphs, highlighting two\npronounced issues: (1) information overload: the dominance of (noisy)\nnon-company nodes over company nodes hinders the message-passing process in\nGraph Convolution Networks (GCN); and (2) hidden fraud: there exists a large\npercentage of possible undetected violations in the collected data. The hidden\nfraud problem will introduce noisy labels in the training dataset and\ncompromise fraud detection results. To handle such challenges, we propose a\nnovel graph-based method, namely, Knowledge-enhanced GCN with Robust Two-stage\nLearning (${\\rm KeGCN}_{R}$), which leverages Knowledge Graph Embeddings to\nmitigate the information overload and effectively learns rich representations.\nThe proposed model adopts a two-stage learning method to enhance robustness\nagainst hidden frauds. Extensive experimental results not only confirm the\nimportance of interactions but also show the superiority of ${\\rm KeGCN}_{R}$\nover a number of strong baselines in terms of fraud detection effectiveness and\nrobustness."}
{"id": "2505.22521", "title": "Evaluating Supervised Learning Models for Fraud Detection: A Comparative Study of Classical and Deep Architectures on Imbalanced Transaction Data", "url": "https://arxiv.org/abs/2505.22521", "pdf": "https://arxiv.org/pdf/2505.22521", "abs": "https://arxiv.org/abs/2505.22521", "authors": ["Chao Wang", "Chuanhao Nie", "Yunbo Liu"], "categories": ["cs.LG", "cs.AI"], "comment": "5 pages. Chao Wang, Chuanhao Nie, and Yunbo Liu contributed equally\n  to this work. Corresponding author: Yunbo Liu (yunbo.liu954@duke.edu).\n  Submitted to the 3rd International Conference on Management Innovation and\n  Economy Development (MIED 2025), Chongqing, China", "summary": "Fraud detection remains a critical task in high-stakes domains such as\nfinance and e-commerce, where undetected fraudulent transactions can lead to\nsignificant economic losses. In this study, we systematically compare the\nperformance of four supervised learning models - Logistic Regression, Random\nForest, Light Gradient Boosting Machine (LightGBM), and a Gated Recurrent Unit\n(GRU) network - on a large-scale, highly imbalanced online transaction dataset.\nWhile ensemble methods such as Random Forest and LightGBM demonstrated superior\nperformance in both overall and class-specific metrics, Logistic Regression\noffered a reliable and interpretable baseline. The GRU model showed strong\nrecall for the minority fraud class, though at the cost of precision,\nhighlighting a trade-off relevant for real-world deployment. Our evaluation\nemphasizes not only weighted averages but also per-class precision, recall, and\nF1-scores, providing a nuanced view of each model's effectiveness in detecting\nrare but consequential fraudulent activity. The findings underscore the\nimportance of choosing models based on the specific risk tolerance and\noperational needs of fraud detection systems."}
{"id": "2503.02857", "title": "Deepfake-Eval-2024: A Multi-Modal In-the-Wild Benchmark of Deepfakes Circulated in 2024", "url": "https://arxiv.org/abs/2503.02857", "pdf": "https://arxiv.org/pdf/2503.02857", "abs": "https://arxiv.org/abs/2503.02857", "authors": ["Nuria Alina Chandra", "Ryan Murtfeldt", "Lin Qiu", "Arnab Karmakar", "Hannah Lee", "Emmanuel Tanumihardja", "Kevin Farhat", "Ben Caffee", "Sejin Paik", "Changyeon Lee", "Jongwook Choi", "Aerin Kim", "Oren Etzioni"], "categories": ["cs.CV", "cs.AI", "cs.CY"], "comment": null, "summary": "In the age of increasingly realistic generative AI, robust deepfake detection\nis essential for mitigating fraud and disinformation. While many deepfake\ndetectors report high accuracy on academic datasets, we show that these\nacademic benchmarks are out of date and not representative of real-world\ndeepfakes. We introduce Deepfake-Eval-2024, a new deepfake detection benchmark\nconsisting of in-the-wild deepfakes collected from social media and deepfake\ndetection platform users in 2024. Deepfake-Eval-2024 consists of 45 hours of\nvideos, 56.5 hours of audio, and 1,975 images, encompassing the latest\nmanipulation technologies. The benchmark contains diverse media content from 88\ndifferent websites in 52 different languages. We find that the performance of\nopen-source state-of-the-art deepfake detection models drops precipitously when\nevaluated on Deepfake-Eval-2024, with AUC decreasing by 50% for video, 48% for\naudio, and 45% for image models compared to previous benchmarks. We also\nevaluate commercial deepfake detection models and models finetuned on\nDeepfake-Eval-2024, and find that they have superior performance to\noff-the-shelf open-source models, but do not yet reach the accuracy of deepfake\nforensic analysts. The dataset is available at\nhttps://github.com/nuriachandra/Deepfake-Eval-2024."}
{"id": "2506.02008", "title": "Big Data-Driven Fraud Detection Using Machine Learning and Real-Time Stream Processing", "url": "https://arxiv.org/abs/2506.02008", "pdf": "https://arxiv.org/pdf/2506.02008", "abs": "https://arxiv.org/abs/2506.02008", "authors": ["Chen Liu", "Hengyu Tang", "Zhixiao Yang", "Ke Zhou", "Sangwhan Cha"], "categories": ["cs.DC"], "comment": "6 pages", "summary": "In the age of digital finance, detecting fraudulent transactions and money\nlaundering is critical for financial institutions. This paper presents a\nscalable and efficient solution using Big Data tools and machine learning\nmodels. We utilize realtime data streaming platforms like Apache Kafka and\nFlink, distributed processing frameworks such as Apache Spark, and cloud\nstorage services AWS S3 and RDS. A synthetic dataset representing real-world\nAnti-Money Laundering (AML) challenges is employed to build a binary\nclassification model. Logistic Regression, Decision Tree, and Random Forest are\ntrained and evaluated using engineered features. Our system demonstrates over\n99% classification accuracy, illustrating the power of combining Big Data\narchitectures with machine learning to tackle fraud."}
{"id": "2402.18085", "title": "PITCH: AI-assisted Tagging of Deepfake Audio Calls using Challenge-Response", "url": "https://arxiv.org/abs/2402.18085", "pdf": "https://arxiv.org/pdf/2402.18085", "abs": "https://arxiv.org/abs/2402.18085", "authors": ["Govind Mittal", "Arthur Jakobsson", "Kelly O. Marshall", "Chinmay Hegde", "Nasir Memon"], "categories": ["cs.SD", "cs.CR", "eess.AS"], "comment": "To appear in ASIA CCS 2025. Human Instrument, Code and Dataset at\n  https://govindm.me/pitch", "summary": "The rise of AI voice-cloning technology, particularly audio Real-time\nDeepfakes (RTDFs), has intensified social engineering attacks by enabling\nreal-time voice impersonation that bypasses conventional enrollment-based\nauthentication. This technology represents an existential threat to phone-based\nauthentication systems, while total identity fraud losses reached $43 billion.\nUnlike traditional robocalls, these personalized AI-generated voice attacks\ntarget high-value accounts and circumvent existing defensive measures, creating\nan urgent cybersecurity challenge. To address this, we propose PITCH, a robust\nchallenge-response method to detect and tag interactive deepfake audio calls.\nWe developed a comprehensive taxonomy of audio challenges based on the human\nauditory system, linguistics, and environmental factors, yielding 20\nprospective challenges. Testing against leading voice-cloning systems using a\nnovel dataset (18,600 original and 1.6 million deepfake samples from 100\nusers), PITCH's challenges enhanced machine detection capabilities to 88.7%\nAUROC score, enabling us to identify 10 highly-effective challenges.\n  For human evaluation, we filtered a challenging, balanced subset on which\nhuman evaluators independently achieved 72.6% accuracy, while machines scored\n87.7%. Recognizing that call environments require human control, we developed a\nnovel human-AI collaborative system that tags suspicious calls as\n\"Deepfake-likely.\" Contrary to prior findings, we discovered that integrating\nhuman intuition with machine precision offers complementary advantages, giving\nusers maximum control while boosting detection accuracy to 84.5%. This\nsignificant improvement situates PITCH's potential as an AI-assisted\npre-screener for verifying calls, offering an adaptable approach to combat\nreal-time voice-cloning attacks while maintaining human decision authority."}
{"id": "2502.12904", "title": "Fraud-R1 : A Multi-Round Benchmark for Assessing the Robustness of LLM Against Augmented Fraud and Phishing Inducements", "url": "https://arxiv.org/abs/2502.12904", "pdf": "https://arxiv.org/pdf/2502.12904", "abs": "https://arxiv.org/abs/2502.12904", "authors": ["Shu Yang", "Shenzhe Zhu", "Zeyu Wu", "Keyu Wang", "Junchi Yao", "Junchao Wu", "Lijie Hu", "Mengdi Li", "Derek F. Wong", "Di Wang"], "categories": ["cs.CL"], "comment": "Accepted by ACL2025 Findings", "summary": "We introduce Fraud-R1, a benchmark designed to evaluate LLMs' ability to\ndefend against internet fraud and phishing in dynamic, real-world scenarios.\nFraud-R1 comprises 8,564 fraud cases sourced from phishing scams, fake job\npostings, social media, and news, categorized into 5 major fraud types. Unlike\nprevious benchmarks, Fraud-R1 introduces a multi-round evaluation pipeline to\nassess LLMs' resistance to fraud at different stages, including credibility\nbuilding, urgency creation, and emotional manipulation. Furthermore, we\nevaluate 15 LLMs under two settings: 1. Helpful-Assistant, where the LLM\nprovides general decision-making assistance, and 2. Role-play, where the model\nassumes a specific persona, widely used in real-world agent-based interactions.\nOur evaluation reveals the significant challenges in defending against fraud\nand phishing inducement, especially in role-play settings and fake job\npostings. Additionally, we observe a substantial performance gap between\nChinese and English, underscoring the need for improved multilingual fraud\ndetection capabilities."}
{"id": "2505.19338", "title": "Co-evolutionary Dynamics of Attack and Defence in Cybersecurity", "url": "https://arxiv.org/abs/2505.19338", "pdf": "https://arxiv.org/pdf/2505.19338", "abs": "https://arxiv.org/abs/2505.19338", "authors": ["Adeela Bashir", "Zia Ush Shamszaman", "Zhao Song", "The Anh Han"], "categories": ["cs.GT", "cs.CR", "nlin.AO"], "comment": null, "summary": "In the evolving digital landscape, it is crucial to study the dynamics of\ncyberattacks and defences. This study uses an Evolutionary Game Theory (EGT)\nframework to investigate the evolutionary dynamics of attacks and defences in\ncyberspace. We develop a two-population asymmetric game between attacker and\ndefender to capture the essential factors of costs, potential benefits, and the\nprobability of successful defences. Through mathematical analysis and numerical\nsimulations, we find that systems with high defence intensities show stability\nwith minimal attack frequencies, whereas low-defence environments show\ninstability, and are vulnerable to attacks. Furthermore, we find five\nequilibria, where the strategy pair always defend and attack emerged as the\nmost likely stable state as cyber domain is characterised by a continuous\nbattle between defenders and attackers. Our theoretical findings align with\nreal-world data from past cyber incidents, demonstrating the interdisciplinary\nimpact, such as fraud detection, risk management and cybersecurity\ndecision-making. Overall, our analysis suggests that adaptive cybersecurity\nstrategies based on EGT can improve resource allocation, enhance system\nresilience, and reduce the overall risk of cyberattacks. By incorporating\nreal-world data, this study demonstrates the applicability of EGT in addressing\nthe evolving nature of cyber threats and the need for secure digital ecosystems\nthrough strategic planning and proactive defence measures."}
{"id": "2505.18002", "title": "Rethinking Contrastive Learning in Graph Anomaly Detection: A Clean-View Perspective", "url": "https://arxiv.org/abs/2505.18002", "pdf": "https://arxiv.org/pdf/2505.18002", "abs": "https://arxiv.org/abs/2505.18002", "authors": ["Di Jin", "Jingyi Cao", "Xiaobao Wang", "Bingdao Feng", "Dongxiao He", "Longbiao Wang", "Jianwu Dang"], "categories": ["cs.LG"], "comment": null, "summary": "Graph anomaly detection aims to identify unusual patterns in graph-based\ndata, with wide applications in fields such as web security and financial fraud\ndetection. Existing methods typically rely on contrastive learning, assuming\nthat a lower similarity between a node and its local subgraph indicates\nabnormality. However, these approaches overlook a crucial limitation: the\npresence of interfering edges invalidates this assumption, since it introduces\ndisruptive noise that compromises the contrastive learning process.\nConsequently, this limitation impairs the ability to effectively learn\nmeaningful representations of normal patterns, leading to suboptimal detection\nperformance. To address this issue, we propose a Clean-View Enhanced Graph\nAnomaly Detection framework (CVGAD), which includes a multi-scale anomaly\nawareness module to identify key sources of interference in the contrastive\nlearning process. Moreover, to mitigate bias from the one-step edge removal\nprocess, we introduce a novel progressive purification module. This module\nincrementally refines the graph by iteratively identifying and removing\ninterfering edges, thereby enhancing model performance. Extensive experiments\non five benchmark datasets validate the effectiveness of our approach."}
{"id": "2505.17513", "title": "What You Read Isn't What You Hear: Linguistic Sensitivity in Deepfake Speech Detection", "url": "https://arxiv.org/abs/2505.17513", "pdf": "https://arxiv.org/pdf/2505.17513", "abs": "https://arxiv.org/abs/2505.17513", "authors": ["Binh Nguyen", "Shuji Shi", "Ryan Ofman", "Thai Le"], "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS", "53-04"], "comment": "15 pages, 2 fogures", "summary": "Recent advances in text-to-speech technologies have enabled realistic voice\ngeneration, fueling audio-based deepfake attacks such as fraud and\nimpersonation. While audio anti-spoofing systems are critical for detecting\nsuch threats, prior work has predominantly focused on acoustic-level\nperturbations, leaving the impact of linguistic variation largely unexplored.\nIn this paper, we investigate the linguistic sensitivity of both open-source\nand commercial anti-spoofing detectors by introducing transcript-level\nadversarial attacks. Our extensive evaluation reveals that even minor\nlinguistic perturbations can significantly degrade detection accuracy: attack\nsuccess rates surpass 60% on several open-source detector-voice pairs, and\nnotably one commercial detection accuracy drops from 100% on synthetic audio to\njust 32%. Through a comprehensive feature attribution analysis, we identify\nthat both linguistic complexity and model-level audio embedding similarity\ncontribute strongly to detector vulnerability. We further demonstrate the\nreal-world risk via a case study replicating the Brad Pitt audio deepfake scam,\nusing transcript adversarial attacks to completely bypass commercial detectors.\nThese results highlight the need to move beyond purely acoustic defenses and\naccount for linguistic variation in the design of robust anti-spoofing systems.\nAll source code will be publicly available."}
{"id": "2505.12594", "title": "AD-AGENT: A Multi-agent Framework for End-to-end Anomaly Detection", "url": "https://arxiv.org/abs/2505.12594", "pdf": "https://arxiv.org/pdf/2505.12594", "abs": "https://arxiv.org/abs/2505.12594", "authors": ["Tiankai Yang", "Junjun Liu", "Wingchun Siu", "Jiahang Wang", "Zhuangzhuang Qian", "Chanjuan Song", "Cheng Cheng", "Xiyang Hu", "Yue Zhao"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Anomaly detection (AD) is essential in areas such as fraud detection, network\nmonitoring, and scientific research. However, the diversity of data modalities\nand the increasing number of specialized AD libraries pose challenges for\nnon-expert users who lack in-depth library-specific knowledge and advanced\nprogramming skills. To tackle this, we present AD-AGENT, an LLM-driven\nmulti-agent framework that turns natural-language instructions into fully\nexecutable AD pipelines. AD-AGENT coordinates specialized agents for intent\nparsing, data preparation, library and model selection, documentation mining,\nand iterative code generation and debugging. Using a shared short-term\nworkspace and a long-term cache, the agents integrate popular AD libraries like\nPyOD, PyGOD, and TSLib into a unified workflow. Experiments demonstrate that\nAD-AGENT produces reliable scripts and recommends competitive models across\nlibraries. The system is open-sourced to support further research and practical\napplications in AD."}
{"id": "2412.11142", "title": "AD-LLM: Benchmarking Large Language Models for Anomaly Detection", "url": "https://arxiv.org/abs/2412.11142", "pdf": "https://arxiv.org/pdf/2412.11142", "abs": "https://arxiv.org/abs/2412.11142", "authors": ["Tiankai Yang", "Yi Nian", "Shawn Li", "Ruiyao Xu", "Yuangang Li", "Jiaqi Li", "Zhuo Xiao", "Xiyang Hu", "Ryan Rossi", "Kaize Ding", "Xia Hu", "Yue Zhao"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Anomaly detection (AD) is an important machine learning task with many\nreal-world uses, including fraud detection, medical diagnosis, and industrial\nmonitoring. Within natural language processing (NLP), AD helps detect issues\nlike spam, misinformation, and unusual user activity. Although large language\nmodels (LLMs) have had a strong impact on tasks such as text generation and\nsummarization, their potential in AD has not been studied enough. This paper\nintroduces AD-LLM, the first benchmark that evaluates how LLMs can help with\nNLP anomaly detection. We examine three key tasks: (i) zero-shot detection,\nusing LLMs' pre-trained knowledge to perform AD without tasks-specific\ntraining; (ii) data augmentation, generating synthetic data and category\ndescriptions to improve AD models; and (iii) model selection, using LLMs to\nsuggest unsupervised AD models. Through experiments with different datasets, we\nfind that LLMs can work well in zero-shot AD, that carefully designed\naugmentation methods are useful, and that explaining model selection for\nspecific datasets remains challenging. Based on these results, we outline six\nfuture research directions on LLMs for AD."}
{"id": "2505.10050", "title": "Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods", "url": "https://arxiv.org/abs/2505.10050", "pdf": "https://arxiv.org/pdf/2505.10050", "abs": "https://arxiv.org/abs/2505.10050", "authors": ["Fahad Almalki", "Mehedi Masud"], "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional machine learning models often prioritize predictive accuracy,\noften at the expense of model transparency and interpretability. The lack of\ntransparency makes it difficult for organizations to comply with regulatory\nrequirements and gain stakeholders trust. In this research, we propose a fraud\ndetection framework that combines a stacking ensemble of well-known gradient\nboosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable\nartificial intelligence (XAI) techniques are used to enhance the transparency\nand interpretability of the model's decisions. We used SHAP (SHapley Additive\nExplanations) for feature selection to identify the most important features.\nFurther efforts were made to explain the model's predictions using Local\nInterpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots\n(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection\ndataset, which includes more than 590,000 real transaction records, was used to\nevaluate the proposed model. The model achieved a high performance with an\naccuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent\nrelated approaches. These results indicate that combining high prediction\naccuracy with transparent interpretability is possible and could lead to a more\nethical and trustworthy solution in financial fraud detection."}
{"id": "2505.09593", "title": "Online Isolation Forest", "url": "https://arxiv.org/abs/2505.09593", "pdf": "https://arxiv.org/pdf/2505.09593", "abs": "https://arxiv.org/abs/2505.09593", "authors": ["Filippo Leveni", "Guilherme Weigert Cassales", "Bernhard Pfahringer", "Albert Bifet", "Giacomo Boracchi"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at International Conference on Machine Learning (ICML 2024)", "summary": "The anomaly detection literature is abundant with offline methods, which\nrequire repeated access to data in memory, and impose impractical assumptions\nwhen applied to a streaming context. Existing online anomaly detection methods\nalso generally fail to address these constraints, resorting to periodic\nretraining to adapt to the online context. We propose Online-iForest, a novel\nmethod explicitly designed for streaming conditions that seamlessly tracks the\ndata generating process as it evolves over time. Experimental validation on\nreal-world datasets demonstrated that Online-iForest is on par with online\nalternatives and closely rivals state-of-the-art offline anomaly detection\ntechniques that undergo periodic retraining. Notably, Online-iForest\nconsistently outperforms all competitors in terms of efficiency, making it a\npromising solution in applications where fast identification of anomalies is of\nprimary importance such as cybersecurity, fraud and fault detection."}
{"id": "2407.21062", "title": "Hybrid Heuristic Algorithms for Adiabatic Quantum Machine Learning Models", "url": "https://arxiv.org/abs/2407.21062", "pdf": "https://arxiv.org/pdf/2407.21062", "abs": "https://arxiv.org/abs/2407.21062", "authors": ["Bahram Alidaee", "Haibo Wang", "Lutfu Sua", "Wade Liu"], "categories": ["quant-ph", "cs.LG"], "comment": "23 pages and 7 tables", "summary": "Numerous established machine learning models and various neural network\narchitectures can be restructured as Quadratic Unconstrained Binary\nOptimization (QUBO) problems. A significant challenge in Adiabatic Quantum\nMachine Learning (AQML) is the computational demand of the training phase. To\nmitigate this, approximation techniques inspired by quantum annealing, like\nSimulated Annealing and Multiple Start Tabu Search (MSTS), have been employed\nto expedite QUBO-based AQML training. This paper introduces a novel hybrid\nalgorithm that incorporates an \"r-flip\" strategy. This strategy is aimed at\nsolving large-scale QUBO problems more effectively, offering better solution\nquality and lower computational costs compared to existing MSTS methods. The\nr-flip approach has practical applications in diverse fields, including\ncross-docking, supply chain management, machine scheduling, and fraud\ndetection. The paper details extensive computational experiments comparing this\nr-flip enhanced hybrid heuristic against a standard MSTS approach. These tests\nutilize both standard benchmark problems and three particularly large QUBO\ninstances. The results indicate that the r-flip enhanced method consistently\nproduces high-quality solutions efficiently, operating within practical time\nconstraints."}
{"id": "2505.06766", "title": "Beyond Identity: A Generalizable Approach for Deepfake Audio Detection", "url": "https://arxiv.org/abs/2505.06766", "pdf": "https://arxiv.org/pdf/2505.06766", "abs": "https://arxiv.org/abs/2505.06766", "authors": ["Yasaman Ahmadiadli", "Xiao-Ping Zhang", "Naimul Khan"], "categories": ["cs.SD", "eess.AS", "eess.SP"], "comment": "Submitted to IEEE Transactions on Biometrics, Behavior, and Identity\n  Science (T-BIOM)", "summary": "Deepfake audio presents a growing threat to digital security, due to its\npotential for social engineering, fraud, and identity misuse. However, existing\ndetection models suffer from poor generalization across datasets, due to\nimplicit identity leakage, where models inadvertently learn speaker-specific\nfeatures instead of manipulation artifacts. To the best of our knowledge, this\nis the first study to explicitly analyze and address identity leakage in the\naudio deepfake detection domain. This work proposes an identity-independent\naudio deepfake detection framework that mitigates identity leakage by\nencouraging the model to focus on forgery-specific artifacts instead of\noverfitting to speaker traits. Our approach leverages Artifact Detection\nModules (ADMs) to isolate synthetic artifacts in both time and frequency\ndomains, enhancing cross-dataset generalization. We introduce novel dynamic\nartifact generation techniques, including frequency domain swaps, time domain\nmanipulations, and background noise augmentation, to enforce learning of\ndataset-invariant features. Extensive experiments conducted on ASVspoof2019,\nADD 2022, FoR, and In-The-Wild datasets demonstrate that the proposed\nADM-enhanced models achieve F1 scores of 0.230 (ADD 2022), 0.604 (FoR), and\n0.813 (In-The-Wild), consistently outperforming the baseline. Dynamic Frequency\nSwap proves to be the most effective strategy across diverse conditions. These\nfindings emphasize the value of artifact-based learning in mitigating implicit\nidentity leakage for more generalizable audio deepfake detection."}
{"id": "2505.07852", "title": "Joint Detection of Fraud and Concept Drift inOnline Conversations with LLM-Assisted Judgment", "url": "https://arxiv.org/abs/2505.07852", "pdf": "https://arxiv.org/pdf/2505.07852", "abs": "https://arxiv.org/abs/2505.07852", "authors": ["Ali Senol", "Garima Agrawal", "Huan Liu"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Detecting fake interactions in digital communication platforms remains a\nchallenging and insufficiently addressed problem. These interactions may appear\nas harmless spam or escalate into sophisticated scam attempts, making it\ndifficult to flag malicious intent early. Traditional detection methods often\nrely on static anomaly detection techniques that fail to adapt to dynamic\nconversational shifts. One key limitation is the misinterpretation of benign\ntopic transitions referred to as concept drift as fraudulent behavior, leading\nto either false alarms or missed threats. We propose a two stage detection\nframework that first identifies suspicious conversations using a tailored\nensemble classification model. To improve the reliability of detection, we\nincorporate a concept drift analysis step using a One Class Drift Detector\n(OCDD) to isolate conversational shifts within flagged dialogues. When drift is\ndetected, a large language model (LLM) assesses whether the shift indicates\nfraudulent manipulation or a legitimate topic change. In cases where no drift\nis found, the behavior is inferred to be spam like. We validate our framework\nusing a dataset of social engineering chat scenarios and demonstrate its\npractical advantages in improving both accuracy and interpretability for real\ntime fraud detection. To contextualize the trade offs, we compare our modular\napproach against a Dual LLM baseline that performs detection and judgment using\ndifferent language models."}
{"id": "2505.04403", "title": "Blockchain Data Analytics: A Scoping Literature Review and Directions for Future Research", "url": "https://arxiv.org/abs/2505.04403", "pdf": "https://arxiv.org/pdf/2505.04403", "abs": "https://arxiv.org/abs/2505.04403", "authors": ["Marcel Bühlmann", "Hans-Georg Fill", "Simon Curty"], "categories": ["cs.ET"], "comment": "Submitted for the ACM Journal \"Distributed Ledger Technologies:\n  Research and Practice\" on March 6th 2025", "summary": "Blockchain technology has rapidly expanded beyond its original use in\ncryptocurrencies to a broad range of applications, creating vast amounts of\nimmutable, decentralized data. As blockchain adoption grows, so does the need\nfor advanced data analytics techniques to extract insights for business\nintelligence, fraud detection, financial analysis and many more. While previous\nresearch has examined specific aspects of blockchain data analytics, such as\ntransaction patterns, illegal activity detection, and data management, there\nremains a lack of comprehensive reviews that explore the full scope of\nblockchain data analytics. This study addresses this gap through a scoping\nliterature review, systematically mapping the existing research landscape,\nidentifying key topics, and highlighting emerging trends. Using established\nmethodologies for literature reviews, we analyze 466 publications, clustering\nthem into six major research themes: illegal activity detection, data\nmanagement, financial analysis, user analysis, community detection, and mining\nanalysis. Our findings reveal a strong focus on detecting illicit activities\nand financial applications, while holistic business intelligence use cases\nremain underexplored. This review provides a structured overview of blockchain\ndata analytics, identifying research gaps and proposing future directions to\nenhance the fields impact."}
{"id": "2505.04204", "title": "Cyber Security Data Science: Machine Learning Methods and their Performance on Imbalanced Datasets", "url": "https://arxiv.org/abs/2505.04204", "pdf": "https://arxiv.org/pdf/2505.04204", "abs": "https://arxiv.org/abs/2505.04204", "authors": ["Mateo Lopez-Ledezma", "Gissel Velarde"], "categories": ["cs.LG"], "comment": "13 pages, 5 figures. Digital Management and Artificial Intelligence.\n  Proceedings of the Fourth International Scientific-Practical Conference (ISPC\n  2024), Hybrid, October 10-11, 2024.\n  https://link.springer.com/chapter/10.1007/978-3-031-88052-0_45", "summary": "Cybersecurity has become essential worldwide and at all levels, concerning\nindividuals, institutions, and governments. A basic principle in cybersecurity\nis to be always alert. Therefore, automation is imperative in processes where\nthe volume of daily operations is large. Several cybersecurity applications can\nbe addressed as binary classification problems, including anomaly detection,\nfraud detection, intrusion detection, spam detection, or malware detection. We\npresent three experiments. In the first experiment, we evaluate single\nclassifiers including Random Forests, Light Gradient Boosting Machine, eXtreme\nGradient Boosting, Logistic Regression, Decision Tree, and Gradient Boosting\nDecision Tree. In the second experiment, we test different sampling techniques\nincluding over-sampling, under-sampling, Synthetic Minority Over-sampling\nTechnique, and Self-Paced Ensembling. In the last experiment, we evaluate\nSelf-Paced Ensembling and its number of base classifiers. We found that\nimbalance learning techniques had positive and negative effects, as reported in\nrelated studies. Thus, these techniques should be applied with caution.\nBesides, we found different best performers for each dataset. Therefore, we\nrecommend testing single classifiers and imbalance learning techniques for each\nnew dataset and application involving imbalanced datasets as is the case in\nseveral cyber security applications."}
{"id": "2505.02791", "title": "Scoring the European Citizen in the AI Era", "url": "https://arxiv.org/abs/2505.02791", "pdf": "https://arxiv.org/pdf/2505.02791", "abs": "https://arxiv.org/abs/2505.02791", "authors": ["Nathan Genicot"], "categories": ["cs.CY"], "comment": "19 pages", "summary": "Social scoring is one of the AI practices banned by the AI Act. This ban is\nexplicitly inspired by China, which in 2014 announced its intention to set up a\nlarge-scale government project - the Social Credit System - aiming to rate\nevery Chinese citizen according to their good behaviour, using digital\ntechnologies and AI. But in Europe, individuals are also scored by public and\nprivate bodies in a variety of contexts, such as assessing creditworthiness,\nmonitoring employee productivity, detecting social fraud or terrorist risks,\nand so on. However, the AI Act does not intend to prohibit these types of\nscoring, as they would qualify as 'high-risk AI systems', which are authorised\nwhile subject to various requirements. One might therefore think that the ban\non social scoring will have no practical effect on the scoring practices\nalready in use in Europe, and that it is merely a vague safeguard in case an\nauthoritarian power is tempted to set up such a system on European territory.\nContrary to this view, this article argues that the ban has been drafted in a\nway that is flexible and therefore likely to make it a useful tool, similar and\ncomplementary to Article 22 of the General Data Protection Regulation, to\nprotect individuals against certain forms of disproportionate use of AI-based\nscoring."}
{"id": "2505.01735", "title": "Brain-Inspired Quantum Neural Architectures for Pattern Recognition: Integrating QSNN and QLSTM", "url": "https://arxiv.org/abs/2505.01735", "pdf": "https://arxiv.org/pdf/2505.01735", "abs": "https://arxiv.org/abs/2505.01735", "authors": ["Eva Andrés", "Manuel Pegalajar Cuéllar", "Gabriel Navarro"], "categories": ["cs.ET"], "comment": null, "summary": "Recent advances in the fields of deep learning and quantum computing have\npaved the way for innovative developments in artificial intelligence. In this\nmanuscript, we leverage these cutting-edge technologies to introduce a novel\nmodel that emulates the intricate functioning of the human brain, designed\nspecifically for the detection of anomalies such as fraud in credit card\ntransactions. Leveraging the synergies of Quantum Spiking Neural Networks\n(QSNN) and Quantum Long Short-Term Memory (QLSTM) architectures, our approach\nis developed in two distinct stages, closely mirroring the information\nprocessing mechanisms found in the brain's sensory and memory systems. In the\ninitial stage, similar to the brain's hypothalamus, we extract low-level\ninformation from the data, emulating sensory data processing patterns. In the\nsubsequent stage, resembling the hippocampus, we process this information at a\nhigher level, capturing and memorizing correlated patterns. We will compare\nthis model with other quantum models such as Quantum Neural Networks among\nothers and their corresponding classical models."}
{"id": "2505.01008", "title": "Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content", "url": "https://arxiv.org/abs/2505.01008", "pdf": "https://arxiv.org/pdf/2505.01008", "abs": "https://arxiv.org/abs/2505.01008", "authors": ["Haoyue Bai", "Yiyou Sun", "Wei Cheng", "Haifeng Chen"], "categories": ["cs.LG"], "comment": "CVPR 2025", "summary": "The recent proliferation of photorealistic images created by generative\nmodels has sparked both excitement and concern, as these images are\nincreasingly indistinguishable from real ones to the human eye. While offering\nnew creative and commercial possibilities, the potential for misuse, such as in\nmisinformation and fraud, highlights the need for effective detection methods.\nCurrent detection approaches often rely on access to model weights or require\nextensive collections of real image datasets, limiting their scalability and\npractical application in real world scenarios. In this work, we introduce a\nnovel black box detection framework that requires only API access, sidestepping\nthe need for model weights or large auxiliary datasets. Our approach leverages\na corrupt and recover strategy: by masking part of an image and assessing the\nmodel ability to reconstruct it, we measure the likelihood that the image was\ngenerated by the model itself. For black-box models that do not support masked\nimage inputs, we incorporate a cost efficient surrogate model trained to align\nwith the target model distribution, enhancing detection capability. Our\nframework demonstrates strong performance, outperforming baseline methods by\n4.31% in mean average precision across eight diffusion model variant datasets."}
{"id": "2505.00946", "title": "Addressing Noise and Stochasticity in Fraud Detection for Service Networks", "url": "https://arxiv.org/abs/2505.00946", "pdf": "https://arxiv.org/pdf/2505.00946", "abs": "https://arxiv.org/abs/2505.00946", "authors": ["Wenxin Zhang", "Ding Xu", "Xi Xuan", "Lei Jiang", "Guangzhen Yao", "Renda Han", "Xiangxiang Lang", "Cuicui Luo"], "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Fraud detection is crucial in social service networks to maintain user trust\nand improve service network security. Existing spectral graph-based methods\naddress this challenge by leveraging different graph filters to capture signals\nwith different frequencies in service networks. However, most graph\nfilter-based methods struggle with deriving clean and discriminative graph\nsignals. On the one hand, they overlook the noise in the information\npropagation process, resulting in degradation of filtering ability. On the\nother hand, they fail to discriminate the frequency-specific characteristics of\ngraph signals, leading to distortion of signals fusion. To address these\nissues, we develop a novel spectral graph network based on information\nbottleneck theory (SGNN-IB) for fraud detection in service networks. SGNN-IB\nsplits the original graph into homophilic and heterophilic subgraphs to better\ncapture the signals at different frequencies. For the first limitation, SGNN-IB\napplies information bottleneck theory to extract key characteristics of encoded\nrepresentations. For the second limitation, SGNN-IB introduces prototype\nlearning to implement signal fusion, preserving the frequency-specific\ncharacteristics of signals. Extensive experiments on three real-world datasets\ndemonstrate that SGNN-IB outperforms state-of-the-art fraud detection methods."}
{"id": "2505.00137", "title": "Toward Practical Quantum Machine Learning: A Novel Hybrid Quantum LSTM for Fraud Detection", "url": "https://arxiv.org/abs/2505.00137", "pdf": "https://arxiv.org/pdf/2505.00137", "abs": "https://arxiv.org/abs/2505.00137", "authors": ["Rushikesh Ubale", "Sujan K. K.", "Sangram Deshpande", "Gregory T. Byrd"], "categories": ["quant-ph", "cs.IT", "cs.LG", "math.IT"], "comment": "11 pages ,8 figures", "summary": "We present a novel hybrid quantum-classical neural network architecture for\nfraud detection that integrates a classical Long Short-Term Memory (LSTM)\nnetwork with a variational quantum circuit. By leveraging quantum phenomena\nsuch as superposition and entanglement, our model enhances the feature\nrepresentation of sequential transaction data, capturing complex non-linear\npatterns that are challenging for purely classical models. A comprehensive data\npreprocessing pipeline is employed to clean, encode, balance, and normalize a\ncredit card fraud dataset, ensuring a fair comparison with baseline models.\nNotably, our hybrid approach achieves per-epoch training times in the range of\n45-65 seconds, which is significantly faster than similar architectures\nreported in the literature, where training typically requires several minutes\nper epoch. Both classical and quantum gradients are jointly optimized via a\nunified backpropagation procedure employing the parameter-shift rule for the\nquantum parameters. Experimental evaluations demonstrate competitive\nimprovements in accuracy, precision, recall, and F1 score relative to a\nconventional LSTM baseline. These results underscore the promise of hybrid\nquantum-classical techniques in advancing the efficiency and performance of\nfraud detection systems.\n  Keywords: Hybrid Quantum-Classical Neural Networks, Quantum Computing, Fraud\nDetection, Hybrid Quantum LSTM, Variational Quantum Circuit, Parameter-Shift\nRule, Financial Risk Analysis"}
{"id": "2504.21574", "title": "Generative AI in Financial Institution: A Global Survey of Opportunities, Threats, and Regulation", "url": "https://arxiv.org/abs/2504.21574", "pdf": "https://arxiv.org/pdf/2504.21574", "abs": "https://arxiv.org/abs/2504.21574", "authors": ["Bikash Saha", "Nanda Rani", "Sandeep Kumar Shukla"], "categories": ["cs.CR", "cs.CE"], "comment": null, "summary": "Generative Artificial Intelligence (GenAI) is rapidly reshaping the global\nfinancial landscape, offering unprecedented opportunities to enhance customer\nengagement, automate complex workflows, and extract actionable insights from\nvast financial data. This survey provides an overview of GenAI adoption across\nthe financial ecosystem, examining how banks, insurers, asset managers, and\nfintech startups worldwide are integrating large language models and other\ngenerative tools into their operations. From AI-powered virtual assistants and\npersonalized financial advisory to fraud detection and compliance automation,\nGenAI is driving innovation across functions. However, this transformation\ncomes with significant cybersecurity and ethical risks. We discuss emerging\nthreats such as AI-generated phishing, deepfake-enabled fraud, and adversarial\nattacks on AI systems, as well as concerns around bias, opacity, and data\nmisuse. The evolving global regulatory landscape is explored in depth,\nincluding initiatives by major financial regulators and international efforts\nto develop risk-based AI governance. Finally, we propose best practices for\nsecure and responsible adoption - including explainability techniques,\nadversarial testing, auditability, and human oversight. Drawing from academic\nliterature, industry case studies, and policy frameworks, this chapter offers a\nperspective on how the financial sector can harness GenAI's transformative\npotential while navigating the complex risks it introduces."}
{"id": "2502.05439", "title": "Agentic AI Systems Applied to tasks in Financial Services: Modeling and model risk management crews", "url": "https://arxiv.org/abs/2502.05439", "pdf": "https://arxiv.org/pdf/2502.05439", "abs": "https://arxiv.org/abs/2502.05439", "authors": ["Izunna Okpala", "Ashkan Golgoon", "Arjun Ravi Kannan"], "categories": ["cs.AI", "cs.CE", "cs.CL", "cs.LG", "68T01 (Primary) 68T05, 68N99, 68T05, 68T20, 68T50, 62H30, 65C20,\n  68P20 (Secondary)", "I.2.0; I.2.1; I.2.2; I.2.6; I.2.7; I.5.1; I.6.0; I.7.1"], "comment": null, "summary": "The advent of large language models has ushered in a new era of agentic\nsystems, where artificial intelligence programs exhibit remarkable autonomous\ndecision-making capabilities across diverse domains. This paper explores\nagentic system workflows in the financial services industry. In particular, we\nbuild agentic crews with human-in-the-loop module that can effectively\ncollaborate to perform complex modeling and model risk management (MRM) tasks.\nThe modeling crew consists of a judge agent and multiple agents who perform\nspecific tasks such as exploratory data analysis, feature engineering, model\nselection/hyperparameter tuning, model training, model evaluation, and writing\ndocumentation. The MRM crew consists of a judge agent along with specialized\nagents who perform tasks such as checking compliance of modeling documentation,\nmodel replication, conceptual soundness, analysis of outcomes, and writing\ndocumentation. We demonstrate the effectiveness and robustness of modeling and\nMRM crews by presenting a series of numerical examples applied to credit card\nfraud detection, credit card approval, and portfolio credit risk modeling\ndatasets."}
{"id": "2409.07956", "title": "Community detection in multi-layer networks by regularized debiased spectral clustering", "url": "https://arxiv.org/abs/2409.07956", "pdf": "https://arxiv.org/pdf/2409.07956", "abs": "https://arxiv.org/abs/2409.07956", "authors": ["Huan Qing"], "categories": ["stat.ME", "cs.SI"], "comment": "Accepted by Engineering Applications of Artificial Intelligence", "summary": "Community detection is a crucial problem in the analysis of multi-layer\nnetworks. While regularized spectral clustering methods using the classical\nregularized Laplacian matrix have shown great potential in handling sparse\nsingle-layer networks, to our knowledge, their potential in multi-layer network\ncommunity detection remains unexplored. To address this gap, in this work, we\nintroduce a new method, called regularized debiased sum of squared adjacency\nmatrices (RDSoS), to detect communities in multi-layer networks. RDSoS is\ndeveloped based on a novel regularized Laplacian matrix that regularizes the\ndebiased sum of squared adjacency matrices. In contrast, the classical\nregularized Laplacian matrix typically regularizes the adjacency matrix of a\nsingle-layer network. Therefore, at a high level, our regularized Laplacian\nmatrix extends the classical one to multi layer networks. We establish the\nconsistency property of RDSoS under the multi-layer stochastic block model\n(MLSBM) and further extend RDSoS and its theoretical results to the\ndegree-corrected version of the MLSBM model. Additionally, we introduce a sum\nof squared adjacency matrices modularity (SoS-modularity) to measure the\nquality of community partitions in multi-layer networks and estimate the number\nof communities by maximizing this metric. Our methods offer promising\napplications for predicting gene functions, improving recommender systems,\ndetecting medical insurance fraud, and facilitating link prediction.\nExperimental results demonstrate that our methods exhibit insensitivity to the\nselection of the regularizer, generally outperform state-of-the-art techniques,\nuncover the assortative property of real networks, and that our SoS-modularity\nprovides a more accurate assessment of community quality compared to the\naverage of the Newman-Girvan modularity across layers."}
{"id": "2504.19632", "title": "QFDNN: A Resource-Efficient Variational Quantum Feature Deep Neural Networks for Fraud Detection and Loan Prediction", "url": "https://arxiv.org/abs/2504.19632", "pdf": "https://arxiv.org/pdf/2504.19632", "abs": "https://arxiv.org/abs/2504.19632", "authors": ["Subham Das", "Ashtakala Meghanath", "Bikash K. Behera", "Shahid Mumtaz", "Saif Al-Kuwari", "Ahmed Farouk"], "categories": ["quant-ph", "cs.LG"], "comment": "12 pages, 6 figures, 8 tables", "summary": "Social financial technology focuses on trust, sustainability, and social\nresponsibility, which require advanced technologies to address complex\nfinancial tasks in the digital era. With the rapid growth in online\ntransactions, automating credit card fraud detection and loan eligibility\nprediction has become increasingly challenging. Classical machine learning (ML)\nmodels have been used to solve these challenges; however, these approaches\noften encounter scalability, overfitting, and high computational costs due to\ncomplexity and high-dimensional financial data. Quantum computing (QC) and\nquantum machine learning (QML) provide a promising solution to efficiently\nprocessing high-dimensional datasets and enabling real-time identification of\nsubtle fraud patterns. However, existing quantum algorithms lack robustness in\nnoisy environments and fail to optimize performance with reduced feature sets.\nTo address these limitations, we propose a quantum feature deep neural network\n(QFDNN), a novel, resource efficient, and noise-resilient quantum model that\noptimizes feature representation while requiring fewer qubits and simpler\nvariational circuits. The model is evaluated using credit card fraud detection\nand loan eligibility prediction datasets, achieving competitive accuracies of\n82.2% and 74.4%, respectively, with reduced computational overhead.\nFurthermore, we test QFDNN against six noise models, demonstrating its\nrobustness across various error conditions. Our findings highlight QFDNN\npotential to enhance trust and security in social financial technology by\naccurately detecting fraudulent transactions while supporting sustainability\nthrough its resource-efficient design and minimal computational overhead."}
{"id": "2504.14205", "title": "Dual-channel Heterophilic Message Passing for Graph Fraud Detection", "url": "https://arxiv.org/abs/2504.14205", "pdf": "https://arxiv.org/pdf/2504.14205", "abs": "https://arxiv.org/abs/2504.14205", "authors": ["Wenxin Zhang", "Jingxing Zhong", "Guangzhen Yao", "Renda Han", "Xiaojian Lin", "Zeyu Zhang", "Cuicui Luo"], "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fraudulent activities have significantly increased across various domains,\nsuch as e-commerce, online review platforms, and social networks, making fraud\ndetection a critical task. Spatial Graph Neural Networks (GNNs) have been\nsuccessfully applied to fraud detection tasks due to their strong inductive\nlearning capabilities. However, existing spatial GNN-based methods often\nenhance the graph structure by excluding heterophilic neighbors during message\npassing to align with the homophilic bias of GNNs. Unfortunately, this approach\ncan disrupt the original graph topology and increase uncertainty in\npredictions. To address these limitations, this paper proposes a novel\nframework, Dual-channel Heterophilic Message Passing (DHMP), for fraud\ndetection. DHMP leverages a heterophily separation module to divide the graph\ninto homophilic and heterophilic subgraphs, mitigating the low-pass inductive\nbias of traditional GNNs. It then applies shared weights to capture signals at\ndifferent frequencies independently and incorporates a customized sampling\nstrategy for training. This allows nodes to adaptively balance the\ncontributions of various signals based on their labels. Extensive experiments\non three real-world datasets demonstrate that DHMP outperforms existing\nmethods, highlighting the importance of separating signals with different\nfrequencies for improved fraud detection. The code is available at\nhttps://github.com/shaieesss/DHMP."}
{"id": "2504.18785", "title": "ALF: Advertiser Large Foundation Model for Multi-Modal Advertiser Understanding", "url": "https://arxiv.org/abs/2504.18785", "pdf": "https://arxiv.org/pdf/2504.18785", "abs": "https://arxiv.org/abs/2504.18785", "authors": ["Santosh Rajagopalan", "Jonathan Vronsky", "Songbai Yan", "S. Alireza Golestaneh", "Shubhra Chandra", "Min Zhou"], "categories": ["cs.LG"], "comment": null, "summary": "We present ALF (Advertiser Large Foundation model), a multi-modal transformer\narchitecture for understanding advertiser behavior and intent across text,\nimage, video and structured data modalities. Through contrastive learning and\nmulti-task optimization, ALF creates unified advertiser representations that\ncapture both content and behavioral patterns. Our model achieves\nstate-of-the-art performance on critical tasks including fraud detection,\npolicy violation identification, and advertiser similarity matching. In\nproduction deployment, ALF reduces false positives by 90% while maintaining\n99.8% precision on abuse detection tasks. The architecture's effectiveness\nstems from its novel combination of multi-modal transformations, inter-sample\nattention mechanism, spectrally normalized projections, and calibrated\nprobabilistic outputs."}
{"id": "2504.17641", "title": "PTCL: Pseudo-Label Temporal Curriculum Learning for Label-Limited Dynamic Graph", "url": "https://arxiv.org/abs/2504.17641", "pdf": "https://arxiv.org/pdf/2504.17641", "abs": "https://arxiv.org/abs/2504.17641", "authors": ["Shengtao Zhang", "Haokai Zhang", "Shiqi Lou", "Zicheng Wang", "Zinan Zeng", "Yilin Wang", "Minnan Luo"], "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 5 figures", "summary": "Dynamic node classification is critical for modeling evolving systems like\nfinancial transactions and academic collaborations. In such systems,\ndynamically capturing node information changes is critical for dynamic node\nclassification, which usually requires all labels at every timestamp. However,\nit is difficult to collect all dynamic labels in real-world scenarios due to\nhigh annotation costs and label uncertainty (e.g., ambiguous or delayed labels\nin fraud detection). In contrast, final timestamp labels are easier to obtain\nas they rely on complete temporal patterns and are usually maintained as a\nunique label for each user in many open platforms, without tracking the history\ndata. To bridge this gap, we propose PTCL(Pseudo-label Temporal Curriculum\nLearning), a pioneering method addressing label-limited dynamic node\nclassification where only final labels are available. PTCL introduces: (1) a\ntemporal decoupling architecture separating the backbone (learning time-aware\nrepresentations) and decoder (strictly aligned with final labels), which\ngenerate pseudo-labels, and (2) a Temporal Curriculum Learning strategy that\nprioritizes pseudo-labels closer to the final timestamp by assigning them\nhigher weights using an exponentially decaying function. We contribute a new\nacademic dataset (CoOAG), capturing long-range research interest in dynamic\ngraph. Experiments across real-world scenarios demonstrate PTCL's consistent\nsuperiority over other methods adapted to this task. Beyond methodology, we\npropose a unified framework FLiD (Framework for Label-Limited Dynamic Node\nClassification), consisting of a complete preparation workflow, training\npipeline, and evaluation standards, and supporting various models and datasets.\nThe code can be found at https://github.com/3205914485/FLiD."}
{"id": "2504.15491", "title": "Application of Deep Generative Models for Anomaly Detection in Complex Financial Transactions", "url": "https://arxiv.org/abs/2504.15491", "pdf": "https://arxiv.org/pdf/2504.15491", "abs": "https://arxiv.org/abs/2504.15491", "authors": ["Tengda Tang", "Jianhua Yao", "Yixian Wang", "Qiuwu Sha", "Hanrui Feng", "Zhen Xu"], "categories": ["cs.LG"], "comment": null, "summary": "This study proposes an algorithm for detecting suspicious behaviors in large\npayment flows based on deep generative models. By combining Generative\nAdversarial Networks (GAN) and Variational Autoencoders (VAE), the algorithm is\ndesigned to detect abnormal behaviors in financial transactions. First, the GAN\nis used to generate simulated data that approximates normal payment flows. The\ndiscriminator identifies anomalous patterns in transactions, enabling the\ndetection of potential fraud and money laundering behaviors. Second, a VAE is\nintroduced to model the latent distribution of payment flows, ensuring that the\ngenerated data more closely resembles real transaction features, thus improving\nthe model's detection accuracy. The method optimizes the generative\ncapabilities of both GAN and VAE, ensuring that the model can effectively\ncapture suspicious behaviors even in sparse data conditions. Experimental\nresults show that the proposed method significantly outperforms traditional\nmachine learning algorithms and other deep learning models across various\nevaluation metrics, especially in detecting rare fraudulent behaviors.\nFurthermore, this study provides a detailed comparison of performance in\nrecognizing different transaction patterns (such as normal, money laundering,\nand fraud) in large payment flows, validating the advantages of generative\nmodels in handling complex financial data."}
{"id": "2504.11808", "title": "Federated Spectral Graph Transformers Meet Neural Ordinary Differential Equations for Non-IID Graphs", "url": "https://arxiv.org/abs/2504.11808", "pdf": "https://arxiv.org/pdf/2504.11808", "abs": "https://arxiv.org/abs/2504.11808", "authors": ["Kishan Gurumurthy", "Himanshu Pal", "Charu Sharma"], "categories": ["cs.LG"], "comment": "The first two listed authors contributed equally to this work", "summary": "Graph Neural Network (GNN) research is rapidly advancing due to GNNs'\ncapacity to learn distributed representations from graph-structured data.\nHowever, centralizing large volumes of real-world graph data for GNN training\nis often impractical due to privacy concerns, regulatory restrictions, and\ncommercial competition. Federated learning (FL), a distributed learning\nparadigm, offers a solution by preserving data privacy with collaborative model\ntraining. Despite progress in training huge vision and language models,\nfederated learning for GNNs remains underexplored. To address this challenge,\nwe present a novel method for federated learning on GNNs based on spectral GNNs\nequipped with neural ordinary differential equations (ODE) for better\ninformation capture, showing promising results across both homophilic and\nheterophilic graphs. Our approach effectively handles non-Independent and\nIdentically Distributed (non-IID) data, while also achieving performance\ncomparable to existing methods that only operate on IID data. It is designed to\nbe privacy-preserving and bandwidth-optimized, making it suitable for\nreal-world applications such as social network analysis, recommendation\nsystems, and fraud detection, which often involve complex, non-IID, and\nheterophilic graph structures. Our results in the area of federated learning on\nnon-IID heterophilic graphs demonstrate significant improvements, while also\nachieving better performance on homophilic graphs. This work highlights the\npotential of federated learning in diverse and challenging graph settings.\nOpen-source code available on GitHub\n(https://github.com/SpringWiz11/Fed-GNODEFormer)."}
{"id": "2409.19022", "title": "Application of AI-based Models for Online Fraud Detection and Analysis", "url": "https://arxiv.org/abs/2409.19022", "pdf": "https://arxiv.org/pdf/2409.19022", "abs": "https://arxiv.org/abs/2409.19022", "authors": ["Antonis Papasavva", "Shane Johnson", "Ed Lowther", "Samantha Lundrigan", "Enrico Mariconti", "Anna Markovska", "Nilufer Tuptuk"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Manuscript accepted in Crime Science Journal. Please cite accordingly", "summary": "Fraud is a prevalent offence that extends beyond financial loss, causing\npsychological and physical harm to victims. The advancements in online\ncommunication technologies alowed for online fraud to thrive in this vast\nnetwork, with fraudsters increasingly using these channels for deception. With\nthe progression of technologies like AI, there is a growing concern that fraud\nwill scale up, using sophisticated methods, like deep-fakes in phishing\ncampaigns, all generated by language generation models like ChatGPT. However,\nthe application of AI in detecting and analyzing online fraud remains\nunderstudied. We conduct a Systematic Literature Review on AI and NLP\ntechniques for online fraud detection. The review adhered the PRISMA-ScR\nprotocol, with eligibility criteria including relevance to online fraud, use of\ntext data, and AI methodologies. We screened 2,457 academic records, 350 met\nour eligibility criteria, and included 223. We report the state-of-the-art NLP\ntechniques for analysing various online fraud categories; the training data\nsources; the NLP algorithms and models built; and the performance metrics\nemployed for model evaluation. We find that current research on online fraud is\ndivided into various scam activitiesand identify 16 different frauds that\nresearchers focus on. This SLR enhances the academic understanding of AI-based\ndetection methods for online fraud and offers insights for policymakers, law\nenforcement, and businesses on safeguarding against such activities. We\nconclude that focusing on specific scams lacks generalization, as multiple\nmodels are required for different fraud types. The evolving nature of scams\nlimits the effectiveness of models trained on outdated data. We also identify\nissues in data limitations, training bias reporting, and selective presentation\nof metrics in model performance reporting, which can lead to potential biases\nin model evaluation."}
{"id": "2412.18370", "title": "Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks Against GNN-Based Fraud Detectors", "url": "https://arxiv.org/abs/2412.18370", "pdf": "https://arxiv.org/pdf/2412.18370", "abs": "https://arxiv.org/abs/2412.18370", "authors": ["Jinhyeok Choi", "Heehyeon Kim", "Joyce Jiyoung Whang"], "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "19 pages, 5 figures, 12 tables, The 39th AAAI Conference on\n  Artificial Intelligence (AAAI 2025)", "summary": "Graph neural networks (GNNs) have emerged as an effective tool for fraud\ndetection, identifying fraudulent users, and uncovering malicious behaviors.\nHowever, attacks against GNN-based fraud detectors and their risks have rarely\nbeen studied, thereby leaving potential threats unaddressed. Recent findings\nsuggest that frauds are increasingly organized as gangs or groups. In this\nwork, we design attack scenarios where fraud gangs aim to make their fraud\nnodes misclassified as benign by camouflaging their illicit activities in\ncollusion. Based on these scenarios, we study adversarial attacks against\nGNN-based fraud detectors by simulating attacks of fraud gangs in three\nreal-world fraud cases: spam reviews, fake news, and medical insurance frauds.\nWe define these attacks as multi-target graph injection attacks and propose\nMonTi, a transformer-based Multi-target one-Time graph injection attack model.\nMonTi simultaneously generates attributes and edges of all attack nodes with a\ntransformer encoder, capturing interdependencies between attributes and edges\nmore effectively than most existing graph injection attack methods that\ngenerate these elements sequentially. Additionally, MonTi adaptively allocates\nthe degree budget for each attack node to explore diverse injection structures\ninvolving target, candidate, and attack nodes, unlike existing methods that fix\nthe degree budget across all attack nodes. Experiments show that MonTi\noutperforms the state-of-the-art graph injection attack methods on five\nreal-world graphs."}
{"id": "2406.15583", "title": "Detecting AI-Generated Text: Factors Influencing Detectability with Current Methods", "url": "https://arxiv.org/abs/2406.15583", "pdf": "https://arxiv.org/pdf/2406.15583", "abs": "https://arxiv.org/abs/2406.15583", "authors": ["Kathleen C. Fraser", "Hillary Dawkins", "Svetlana Kiritchenko"], "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "Large language models (LLMs) have advanced to a point that even humans have\ndifficulty discerning whether a text was generated by another human, or by a\ncomputer. However, knowing whether a text was produced by human or artificial\nintelligence (AI) is important to determining its trustworthiness, and has\napplications in many domains including detecting fraud and academic dishonesty,\nas well as combating the spread of misinformation and political propaganda. The\ntask of AI-generated text (AIGT) detection is therefore both very challenging,\nand highly critical. In this survey, we summarize state-of-the art approaches\nto AIGT detection, including watermarking, statistical and stylistic analysis,\nand machine learning classification. We also provide information about existing\ndatasets for this task. Synthesizing the research findings, we aim to provide\ninsight into the salient factors that combine to determine how \"detectable\"\nAIGT text is under different scenarios, and to make practical recommendations\nfor future work towards this significant technical and societal challenge."}
{"id": "2504.10229", "title": "ROSFD: Robust Online Streaming Fraud Detection with Resilience to Concept Drift in Data Streams", "url": "https://arxiv.org/abs/2504.10229", "pdf": "https://arxiv.org/pdf/2504.10229", "abs": "https://arxiv.org/abs/2504.10229", "authors": ["Vivek Yelleti"], "categories": ["cs.LG"], "comment": null, "summary": "Continuous generation of streaming data from diverse sources, such as online\ntransactions and digital interactions, necessitates timely fraud detection.\nTraditional batch processing methods often struggle to capture the rapidly\nevolving patterns of fraudulent activities. This paper highlights the critical\nimportance of processing streaming data for effective fraud detection. To\naddress the inherent challenges of latency, scalability, and concept drift in\nstreaming environments, we propose a robust online streaming fraud detection\n(ROSFD) framework. Our proposed framework comprises two key stages: (i) Stage\nOne: Offline Model Initialization. In this initial stage, a model is built in\noffline settings using incremental learning principles to overcome the\n\"cold-start\" problem. (ii) Stage Two: Real-time Model Adaptation. In this\ndynamic stage, drift detection algorithms (viz.,, DDM, EDDM, and ADWIN) are\nemployed to identify concept drift in the incoming data stream and\nincrementally train the model accordingly. This \"train-only-when-required\"\nstrategy drastically reduces the number of retrains needed without\nsignificantly impacting the area under the receiver operating characteristic\ncurve (AUC). Overall, ROSFD utilizing ADWIN as the drift detection method\ndemonstrated the best performance among the employed methods. In terms of model\nefficacy, Adaptive Random Forest consistently outperformed other models,\nachieving the highest AUC in four out of five datasets."}
{"id": "2504.09311", "title": "Dupin: A Parallel Framework for Densest Subgraph Discovery in Fraud Detection on Massive Graphs (Technical Report)", "url": "https://arxiv.org/abs/2504.09311", "pdf": "https://arxiv.org/pdf/2504.09311", "abs": "https://arxiv.org/abs/2504.09311", "authors": ["Jiaxin Jiang", "Siyuan Yao", "Yuchen Li", "Qiange Wang", "Bingsheng He", "Min Chen"], "categories": ["cs.DB"], "comment": null, "summary": "Detecting fraudulent activities in financial and e-commerce transaction\nnetworks is crucial. One effective method for this is Densest Subgraph\nDiscovery (DSD). However, deploying DSD methods in production systems faces\nsubstantial scalability challenges due to the predominantly sequential nature\nof existing methods, which impedes their ability to handle large-scale\ntransaction networks and results in significant detection delays. To address\nthese challenges, we introduce Dupin, a novel parallel processing framework\ndesigned for efficient DSD processing in billion-scale graphs. Dupin is powered\nby a processing engine that exploits the unique properties of the peeling\nprocess, with theoretical guarantees on detection quality and efficiency. Dupin\nprovides userfriendly APIs for flexible customization of DSD objectives and\nensures robust adaptability to diverse fraud detection scenarios. Empirical\nevaluations demonstrate that Dupin consistently outperforms several existing\nDSD methods, achieving performance improvements of up to 100 times compared to\ntraditional approaches. On billion-scale graphs, Dupin demonstrates the\npotential to enhance the prevention of fraudulent transactions from 45% to\n94.5% and reduces density error from 30% to below 5%, as supported by our\nexperimental results. These findings highlight the effectiveness of Dupin in\nreal-world applications, ensuring both speed and accuracy in fraud detection."}
{"id": "2504.08183", "title": "Detecting Credit Card Fraud via Heterogeneous Graph Neural Networks with Graph Attention", "url": "https://arxiv.org/abs/2504.08183", "pdf": "https://arxiv.org/pdf/2504.08183", "abs": "https://arxiv.org/abs/2504.08183", "authors": ["Qiuwu Sha", "Tengda Tang", "Xinyu Du", "Jie Liu", "Yixian Wang", "Yuan Sheng"], "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "This study proposes a credit card fraud detection method based on\nHeterogeneous Graph Neural Network (HGNN) to address fraud in complex\ntransaction networks. Unlike traditional machine learning methods that rely\nsolely on numerical features of transaction records, this approach constructs\nheterogeneous transaction graphs. These graphs incorporate multiple node types,\nincluding users, merchants, and transactions. By leveraging graph neural\nnetworks, the model captures higher-order transaction relationships. A Graph\nAttention Mechanism is employed to dynamically assign weights to different\ntransaction relationships. Additionally, a Temporal Decay Mechanism is\nintegrated to enhance the model's sensitivity to time-related fraud patterns.\nTo address the scarcity of fraudulent transaction samples, this study applies\nSMOTE oversampling and Cost-sensitive Learning. These techniques strengthen the\nmodel's ability to identify fraudulent transactions. Experimental results\ndemonstrate that the proposed method outperforms existing GNN models, including\nGCN, GAT, and GraphSAGE, on the IEEE-CIS Fraud Detection dataset. The model\nachieves notable improvements in both accuracy and OC-ROC. Future research may\nexplore the integration of dynamic graph neural networks and reinforcement\nlearning. Such advancements could enhance the real-time adaptability of fraud\ndetection systems and provide more intelligent solutions for financial risk\ncontrol."}
{"id": "2411.12556", "title": "UMGAD: Unsupervised Multiplex Graph Anomaly Detection", "url": "https://arxiv.org/abs/2411.12556", "pdf": "https://arxiv.org/pdf/2411.12556", "abs": "https://arxiv.org/abs/2411.12556", "authors": ["Xiang Li", "Jianpeng Qi", "Zhongying Zhao", "Guanjie Zheng", "Lei Cao", "Junyu Dong", "Yanwei Yu"], "categories": ["cs.LG"], "comment": null, "summary": "Graph anomaly detection (GAD) is a critical task in graph machine learning,\nwith the primary objective of identifying anomalous nodes that deviate\nsignificantly from the majority. This task is widely applied in various\nreal-world scenarios, including fraud detection and social network analysis.\nHowever, existing GAD methods still face two major challenges: (1) They are\noften limited to detecting anomalies in single-type interaction graphs and\nstruggle with multiple interaction types in multiplex heterogeneous graphs. (2)\nIn unsupervised scenarios, selecting appropriate anomaly score thresholds\nremains a significant challenge for accurate anomaly detection. To address the\nabove challenges, we propose a novel Unsupervised Multiplex Graph Anomaly\nDetection method, named UMGAD. We first learn multi-relational correlations\namong nodes in multiplex heterogeneous graphs and capture anomaly information\nduring node attribute and structure reconstruction through graph-masked\nautoencoder (GMAE). Then, to further extract abnormal information, we generate\nattribute-level and subgraph-level augmented-view graphs, respectively, and\nperform attribute and structure reconstruction through GMAE. Finally, we learn\nto optimize node attributes and structural features through contrastive\nlearning between original-view and augmented-view graphs to improve the model's\nability to capture anomalies. Meanwhile, we propose a new anomaly score\nthreshold selection strategy, which allows the model to be independent of\nground truth information in real unsupervised scenarios. Extensive experiments\non six datasets show that our UMGAD significantly outperforms state-of-the-art\nmethods, achieving average improvements of 12.25% in AUC and 11.29% in Macro-F1\nacross all datasets."}
{"id": "2502.15429", "title": "Pub-Guard-LLM: Detecting Fraudulent Biomedical Articles with Reliable Explanations", "url": "https://arxiv.org/abs/2502.15429", "pdf": "https://arxiv.org/pdf/2502.15429", "abs": "https://arxiv.org/abs/2502.15429", "authors": ["Lihu Chen", "Shuojie Fu", "Gabriel Freedman", "Cemre Zor", "Guy Martin", "James Kinross", "Uddhav Vaghela", "Ovidiu Serban", "Francesca Toni"], "categories": ["cs.CL"], "comment": "long paper under review", "summary": "A significant and growing number of published scientific articles is found to\ninvolve fraudulent practices, posing a serious threat to the credibility and\nsafety of research in fields such as medicine. We propose Pub-Guard-LLM, the\nfirst large language model-based system tailored to fraud detection of\nbiomedical scientific articles. We provide three application modes for\ndeploying Pub-Guard-LLM: vanilla reasoning, retrieval-augmented generation, and\nmulti-agent debate. Each mode allows for textual explanations of predictions.\nTo assess the performance of our system, we introduce an open-source benchmark,\nPubMed Retraction, comprising over 11K real-world biomedical articles,\nincluding metadata and retraction labels. We show that, across all modes,\nPub-Guard-LLM consistently surpasses the performance of various baselines and\nprovides more reliable explanations, namely explanations which are deemed more\nrelevant and coherent than those generated by the baselines when evaluated by\nmultiple assessment methods. By enhancing both detection performance and\nexplainability in scientific fraud detection, Pub-Guard-LLM contributes to\nsafeguarding research integrity with a novel, effective, open-source tool."}
{"id": "2504.05758", "title": "Addressing Class Imbalance with Probabilistic Graphical Models and Variational Inference", "url": "https://arxiv.org/abs/2504.05758", "pdf": "https://arxiv.org/pdf/2504.05758", "abs": "https://arxiv.org/abs/2504.05758", "authors": ["Yujia Lou", "Jie Liu", "Yuan Sheng", "Jiawei Wang", "Yiwei Zhang", "Yaokun Ren"], "categories": ["cs.LG"], "comment": null, "summary": "This study proposes a method for imbalanced data classification based on deep\nprobabilistic graphical models (DPGMs) to solve the problem that traditional\nmethods have insufficient learning ability for minority class samples. To\naddress the classification bias caused by class imbalance, we introduce\nvariational inference optimization probability modeling, which enables the\nmodel to adaptively adjust the representation ability of minority classes and\ncombines the class-aware weight adjustment strategy to enhance the classifier's\nsensitivity to minority classes. In addition, we combine the adversarial\nlearning mechanism to generate minority class samples in the latent space so\nthat the model can better characterize the category boundary in the\nhigh-dimensional feature space. The experiment is evaluated on the Kaggle\n\"Credit Card Fraud Detection\" dataset and compared with a variety of advanced\nimbalanced classification methods (such as GAN-based sampling, BRF,\nXGBoost-Cost Sensitive, SAAD, HAN). The results show that the method in this\nstudy has achieved the best performance in AUC, Precision, Recall and F1-score\nindicators, effectively improving the recognition rate of minority classes and\nreducing the false alarm rate. This method can be widely used in imbalanced\nclassification tasks such as financial fraud detection, medical diagnosis, and\nanomaly detection, providing a new solution for related research."}
{"id": "2504.05504", "title": "SelfMAD: Enhancing Generalization and Robustness in Morphing Attack Detection via Self-Supervised Learning", "url": "https://arxiv.org/abs/2504.05504", "pdf": "https://arxiv.org/pdf/2504.05504", "abs": "https://arxiv.org/abs/2504.05504", "authors": ["Marija Ivanovska", "Leon Todorov", "Naser Damer", "Deepak Kumar Jain", "Peter Peer", "Vitomir Štruc"], "categories": ["cs.CV"], "comment": "Accepted at IEEE International Conference on Automatic Face and\n  Gesture Recognition (FG 2025)", "summary": "With the continuous advancement of generative models, face morphing attacks\nhave become a significant challenge for existing face verification systems due\nto their potential use in identity fraud and other malicious activities.\nContemporary Morphing Attack Detection (MAD) approaches frequently rely on\nsupervised, discriminative models trained on examples of bona fide and morphed\nimages. These models typically perform well with morphs generated with\ntechniques seen during training, but often lead to sub-optimal performance when\nsubjected to novel unseen morphing techniques. While unsupervised models have\nbeen shown to perform better in terms of generalizability, they typically\nresult in higher error rates, as they struggle to effectively capture features\nof subtle artifacts. To address these shortcomings, we present SelfMAD, a novel\nself-supervised approach that simulates general morphing attack artifacts,\nallowing classifiers to learn generic and robust decision boundaries without\noverfitting to the specific artifacts induced by particular face morphing\nmethods. Through extensive experiments on widely used datasets, we demonstrate\nthat SelfMAD significantly outperforms current state-of-the-art MADs, reducing\nthe detection error by more than 64% in terms of EER when compared to the\nstrongest unsupervised competitor, and by more than 66%, when compared to the\nbest performing discriminative MAD model, tested in cross-morph settings. The\nsource code for SelfMAD is available at https://github.com/LeonTodorov/SelfMAD."}
{"id": "2504.03615", "title": "Autonomous and Self-Adapting System for Synthetic Media Detection and Attribution", "url": "https://arxiv.org/abs/2504.03615", "pdf": "https://arxiv.org/pdf/2504.03615", "abs": "https://arxiv.org/abs/2504.03615", "authors": ["Aref Azizpour", "Tai D. Nguyen", "Matthew C. Stamm"], "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Rapid advances in generative AI have enabled the creation of highly realistic\nsynthetic images, which, while beneficial in many domains, also pose serious\nrisks in terms of disinformation, fraud, and other malicious applications.\nCurrent synthetic image identification systems are typically static, relying on\nfeature representations learned from known generators; as new generative models\nemerge, these systems suffer from severe performance degradation. In this\npaper, we introduce the concept of an autonomous self-adaptive synthetic media\nidentification system -- one that not only detects synthetic images and\nattributes them to known sources but also autonomously identifies and\nincorporates novel generators without human intervention. Our approach\nleverages an open-set identification strategy with an evolvable embedding space\nthat distinguishes between known and unknown sources. By employing an\nunsupervised clustering method to aggregate unknown samples into\nhigh-confidence clusters and continuously refining its decision boundaries, our\nsystem maintains robust detection and attribution performance even as the\ngenerative landscape evolves. Extensive experiments demonstrate that our method\nsignificantly outperforms existing approaches, marking a crucial step toward\nuniversal, adaptable forensic systems in the era of rapidly advancing\ngenerative models."}
{"id": "2305.09907", "title": "Incremental Outlier Detection Modelling Using Streaming Analytics in Finance & Health Care", "url": "https://arxiv.org/abs/2305.09907", "pdf": "https://arxiv.org/pdf/2305.09907", "abs": "https://arxiv.org/abs/2305.09907", "authors": ["Vivek Yelleti", "Ch Priyanka"], "categories": ["cs.LG"], "comment": null, "summary": "In the era of real-time data, traditional methods often struggle to keep pace\nwith the dynamic nature of streaming environments. In this paper, we proposed a\nhybrid framework where in (i) stage-I follows a traditional approach where the\nmodel is built once and evaluated in a real-time environment, and (ii) stage-II\nemploys an incremental learning approach where the model is continuously\nretrained as new data arrives, enabling it to adapt and stay up to date. To\nimplement these frameworks, we employed 8 distinct state-of-the-art outlier\ndetection models, including one-class support vector machine (OCSVM), isolation\nforest adaptive sliding window approach (IForest ASD), exact storm (ES),\nangle-based outlier detection (ABOD), local outlier factor (LOF), Kitsunes\nonline algorithm (KitNet), and K-nearest neighbour conformal density and\ndistance based (KNN CAD). We evaluated the performance of these models across\nseven financial and healthcare prediction tasks, including credit card fraud\ndetection, churn prediction, Ethereum fraud detection, heart stroke prediction,\nand diabetes prediction. The results indicate that our proposed incremental\nlearning framework significantly improves performance, particularly on highly\nimbalanced datasets. Among all models, the IForest ASD model consistently\nranked among the top three best-performing models, demonstrating superior\neffectiveness across various datasets."}
{"id": "2407.05625", "title": "New User Event Prediction Through the Lens of Causal Inference", "url": "https://arxiv.org/abs/2407.05625", "pdf": "https://arxiv.org/pdf/2407.05625", "abs": "https://arxiv.org/abs/2407.05625", "authors": ["Henry Shaowu Yuchi", "Shixiang Zhu", "Li Dong", "Yigit M. Arisoy", "Matthew C. Spencer"], "categories": ["stat.ME", "cs.LG"], "comment": null, "summary": "Modeling and analysis for event series generated by users of heterogeneous\nbehavioral patterns are closely involved in our daily lives, including credit\ncard fraud detection, online platform user recommendation, and social network\nanalysis. The most commonly adopted approach to this task is to assign users to\nbehavior-based categories and analyze each of them separately. However, this\nrequires extensive data to fully understand the user behavior, presenting\nchallenges in modeling newcomers without significant historical knowledge. In\nthis work, we propose a novel discrete event prediction framework for new users\nwith limited history, without needing to know the user's category. We treat the\nuser event history as the \"treatment\" for future events and the user category\nas the key confounder. Thus, the prediction problem can be framed as\ncounterfactual outcome estimation, where each event is re-weighted by its\ninverse propensity score. We demonstrate the improved performance of the\nproposed framework with a numerical simulation study and two real-world\napplications, including Netflix rating prediction and seller contact prediction\nfor customer support at Amazon."}
{"id": "2406.06965", "title": "Evolving from Single-modal to Multi-modal Facial Deepfake Detection: Progress and Challenges", "url": "https://arxiv.org/abs/2406.06965", "pdf": "https://arxiv.org/pdf/2406.06965", "abs": "https://arxiv.org/abs/2406.06965", "authors": ["Ping Liu", "Qiqi Tao", "Joey Tianyi Zhou"], "categories": ["cs.CV"], "comment": "P. Liu is with the Department of Computer Science and Engineering,\n  University of Nevada, Reno, NV, 89512. Q. Tao and J. Zhou are with Centre for\n  Frontier AI Research (CFAR), and Institute of High Performance Computing\n  (IHPC), A*STAR, Singapore. J. Zhou is also with Centre for Advanced\n  Technologies in Online Safety (CATOS), A*STAR, Singapore. J. Zhou is the\n  corresponding author", "summary": "As synthetic media, including video, audio, and text, become increasingly\nindistinguishable from real content, the risks of misinformation, identity\nfraud, and social manipulation escalate. This survey traces the evolution of\ndeepfake detection from early single-modal methods to sophisticated multi-modal\napproaches that integrate audio-visual and text-visual cues. We present a\nstructured taxonomy of detection techniques and analyze the transition from\nGAN-based to diffusion model-driven deepfakes, which introduce new challenges\ndue to their heightened realism and robustness against detection. Unlike prior\nsurveys that primarily focus on single-modal detection or earlier deepfake\ntechniques, this work provides the most comprehensive study to date,\nencompassing the latest advancements in multi-modal deepfake detection,\ngeneralization challenges, proactive defense mechanisms, and emerging datasets\nspecifically designed to support new interpretability and reasoning tasks. We\nfurther explore the role of Vision-Language Models (VLMs) and Multimodal Large\nLanguage Models (MLLMs) in strengthening detection robustness against\nincreasingly sophisticated deepfake attacks. By systematically categorizing\nexisting methods and identifying emerging research directions, this survey\nserves as a foundation for future advancements in combating AI-generated facial\nforgeries. A curated list of all related papers can be found at\n\\href{https://github.com/qiqitao77/Comprehensive-Advances-in-Deepfake-Detection-Spanning-Diverse-Modalities}{https://github.com/qiqitao77/Awesome-Comprehensive-Deepfake-Detection}."}
{"id": "2504.02275", "title": "Enhancing Customer Contact Efficiency with Graph Neural Networks in Credit Card Fraud Detection Workflow", "url": "https://arxiv.org/abs/2504.02275", "pdf": "https://arxiv.org/pdf/2504.02275", "abs": "https://arxiv.org/abs/2504.02275", "authors": ["Menghao Huo", "Kuan Lu", "Qiang Zhu", "Zhenrui Chen"], "categories": ["cs.LG"], "comment": null, "summary": "Credit card fraud has been a persistent issue since the last century, causing\nsignificant financial losses to the industry. The most effective way to prevent\nfraud is by contacting customers to verify suspicious transactions. However,\nwhile these systems are designed to detect fraudulent activity, they often\nmistakenly flag legitimate transactions, leading to unnecessary declines that\ndisrupt the user experience and erode customer trust. Frequent false positives\ncan frustrate customers, resulting in dissatisfaction, increased complaints,\nand a diminished sense of security. To address these limitations, we propose a\nfraud detection framework incorporating Relational Graph Convolutional Networks\n(RGCN) to enhance the accuracy and efficiency of identifying fraudulent\ntransactions. By leveraging the relational structure of transaction data, our\nmodel reduces the need for direct customer confirmation while maintaining high\ndetection performance. Our experiments are conducted using the IBM credit card\ntransaction dataset to evaluate the effectiveness of this approach."}
{"id": "2504.03765", "title": "Watermarking for AI Content Detection: A Review on Text, Visual, and Audio Modalities", "url": "https://arxiv.org/abs/2504.03765", "pdf": "https://arxiv.org/pdf/2504.03765", "abs": "https://arxiv.org/abs/2504.03765", "authors": ["Lele Cao"], "categories": ["cs.CR", "68T45, 94A60, 68U10, 68P25", "I.2.7; I.4.9; H.2.8; K.4.1; K.6.5"], "comment": "Accepted by ICLR 2025 workshop on GenAI Watermarking", "summary": "The rapid advancement of generative artificial intelligence (GenAI) has\nrevolutionized content creation across text, visual, and audio domains,\nsimultaneously introducing significant risks such as misinformation, identity\nfraud, and content manipulation. This paper presents a practical survey of\nwatermarking techniques designed to proactively detect GenAI content. We\ndevelop a structured taxonomy categorizing watermarking methods for text,\nvisual, and audio modalities and critically evaluate existing approaches based\non their effectiveness, robustness, and practicality. Additionally, we identify\nkey challenges, including resistance to adversarial attacks, lack of\nstandardization across different content types, and ethical considerations\nrelated to privacy and content ownership. Finally, we discuss potential future\nresearch directions aimed at enhancing watermarking strategies to ensure\ncontent authenticity and trustworthiness. This survey serves as a foundational\nresource for researchers and practitioners seeking to understand and advance\nwatermarking techniques for AI-generated content detection."}
{"id": "2503.24115", "title": "TeleAntiFraud-28k: An Audio-Text Slow-Thinking Dataset for Telecom Fraud Detection", "url": "https://arxiv.org/abs/2503.24115", "pdf": "https://arxiv.org/pdf/2503.24115", "abs": "https://arxiv.org/abs/2503.24115", "authors": ["Zhiming Ma", "Peidong Wang", "Minhua Huang", "Jingpeng Wang", "Kai Wu", "Xiangzhao Lv", "Yachun Pang", "Yin Yang", "Wenjie Tang", "Yuchen Kang"], "categories": ["cs.CL", "cs.MM"], "comment": null, "summary": "The detection of telecom fraud faces significant challenges due to the lack\nof high-quality multimodal training data that integrates audio signals with\nreasoning-oriented textual analysis. To address this gap, we present\nTeleAntiFraud-28k, the first open-source audio-text slow-thinking dataset\nspecifically designed for automated telecom fraud analysis. Our dataset is\nconstructed through three strategies: (1) Privacy-preserved text-truth sample\ngeneration using automatically speech recognition (ASR)-transcribed call\nrecordings (with anonymized original audio), ensuring real-world consistency\nthrough text-to-speech (TTS) model regeneration; (2) Semantic enhancement via\nlarge language model (LLM)-based self-instruction sampling on authentic ASR\noutputs to expand scenario coverage; (3) Multi-agent adversarial synthesis that\nsimulates emerging fraud tactics through predefined communication scenarios and\nfraud typologies. The generated dataset contains 28,511 rigorously processed\nspeech-text pairs, complete with detailed annotations for fraud reasoning. The\ndataset is divided into three tasks: scenario classification, fraud detection,\nfraud type classification. Furthermore, we construct TeleAntiFraud-Bench, a\nstandardized evaluation benchmark comprising proportionally sampled instances\nfrom the dataset, to facilitate systematic testing of model performance on\ntelecom fraud detection tasks. We also contribute a production-optimized\nsupervised fine-tuning (SFT) model trained on hybrid real/synthetic data, while\nopen-sourcing the data processing framework to enable community-driven dataset\nexpansion. This work establishes a foundational framework for multimodal\nanti-fraud research while addressing critical challenges in data privacy and\nscenario diversity. The project will be released at\nhttps://github.com/JimmyMa99/TeleAntiFraud."}
{"id": "2504.03750", "title": "Detecting Financial Fraud with Hybrid Deep Learning: A Mix-of-Experts Approach to Sequential and Anomalous Patterns", "url": "https://arxiv.org/abs/2504.03750", "pdf": "https://arxiv.org/pdf/2504.03750", "abs": "https://arxiv.org/abs/2504.03750", "authors": ["Diego Vallarino"], "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Financial fraud detection remains a critical challenge due to the dynamic and\nadversarial nature of fraudulent behavior. As fraudsters evolve their tactics,\ndetection systems must combine robustness, adaptability, and precision. This\nstudy presents a hybrid architecture for credit card fraud detection that\nintegrates a Mixture of Experts (MoE) framework with Recurrent Neural Networks\n(RNNs), Transformer encoders, and Autoencoders. Each expert module contributes\na specialized capability: RNNs capture sequential behavior, Transformers\nextract high-order feature interactions, and Autoencoders detect anomalies\nthrough reconstruction loss. The MoE framework dynamically assigns predictive\nresponsibility among the experts, enabling adaptive and context-sensitive\ndecision-making.\n  Trained on a high-fidelity synthetic dataset that simulates real-world\ntransaction patterns and fraud typologies, the hybrid model achieved 98.7\npercent accuracy, 94.3 percent precision, and 91.5 percent recall,\noutperforming standalone models and classical machine learning baselines. The\nAutoencoder component significantly enhanced the system's ability to identify\nemerging fraud strategies and atypical behaviors.\n  Beyond technical performance, the model contributes to broader efforts in\nfinancial governance and crime prevention. It supports regulatory compliance\nwith Anti-Money Laundering (AML) and Know Your Customer (KYC) protocols and\naligns with routine activity theory by operationalizing AI as a capable\nguardian within financial ecosystems. The proposed hybrid system offers a\nscalable, modular, and regulation-aware approach to detecting increasingly\nsophisticated fraud patterns, contributing both to the advancement of\nintelligent systems and to the strengthening of institutional fraud defense\ninfrastructures."}
{"id": "2503.15896", "title": "FlowSeries: Anomaly Detection in Financial Transaction Flows", "url": "https://arxiv.org/abs/2503.15896", "pdf": "https://arxiv.org/pdf/2503.15896", "abs": "https://arxiv.org/abs/2503.15896", "authors": ["Arthur Capozzi", "Salvatore Vilella", "Dario Moncalvo", "Marco Fornasiero", "Valeria Ricci", "Silvia Ronchiadin", "Giancarlo Ruffo"], "categories": ["cs.CY", "cs.CE", "I.2.1; H.3.3"], "comment": "12 pages, 6 figures, ITADATA2024", "summary": "In recent years, the digitization and automation of anti-financial crime\n(AFC) investigative processes have faced significant challenges, particularly\nthe need for interpretability of AI model results and the lack of labeled data\nfor training. Network analysis has emerged as a valuable approach in this\ncontext.\n  In this paper, we present WeirdFlows, a top-down search pipeline for\ndetecting potentially fraudulent transactions and non-compliant agents. In a\ntransaction network, fraud attempts are often based on complex transaction\npatterns that change over time to avoid detection. The WeirdFlows pipeline\nrequires neither an a priori set of patterns nor a training set. In addition,\nby providing elements to explain the anomalies found, it facilitates and\nsupports the work of an AFC analyst.\n  We evaluate WeirdFlows on a dataset from Intesa Sanpaolo (ISP) bank,\ncomprising 80 million cross-country transactions over 15 months, benchmarking\nour implementation of the algorithm. The results, corroborated by ISP AFC\nexperts, highlight its effectiveness in identifying suspicious transactions and\nactors, particularly in the context of the economic sanctions imposed in the EU\nafter February 2022. This demonstrates \\textit{WeirdFlows}' capability to\nhandle large datasets, detect complex transaction patterns, and provide the\nnecessary interpretability for formal AFC investigations."}
{"id": "2410.20605", "title": "Design, Implementation and Practical Energy-Efficiency Evaluation of a Blockchain Based Academic Credential Verification System for Low-Power Nodes", "url": "https://arxiv.org/abs/2410.20605", "pdf": "https://arxiv.org/pdf/2410.20605", "abs": "https://arxiv.org/abs/2410.20605", "authors": ["Gabriel Fernández-Blanco", "Iván Froiz-Míguez", "Paula Fraga-Lamas", "Tiago M. Fernández-Caramés"], "categories": ["cs.DC", "cs.CR", "cs.CY", "cs.SY", "eess.SY"], "comment": null, "summary": "The educational system manages extensive documentation and paperwork, which\ncan lead to human errors and sometimes abuse or fraud, such as the\nfalsification of diplomas, certificates or other credentials. In fact, in the\nlast years, multiple cases of fraud have been detected, which have a\nsignificant cost to society, since they harm the trustworthiness of\ncertificates and academic institutions. To tackle such an issue, this article\nproposes a solution aimed at recording and verifying academic records through a\ndecentralized application that is supported by a smart contract deployed in the\nEthereum blockchain and by a decentralized storage system based on\nInter-Planetary File System (IPFS). The proposed solution is evaluated in terms\nof performance and energy-efficiency, comparing the results obtained with a\ntraditional Proof-of-Work (PoW) consensus protocol and the new\nProof-of-Authority (PoA) protocol. The results shown in this paper indicate\nthat the latter is clearly greener and demands less CPU load. Moreover, this\narticle compares the performance of a traditional computer and two SBCs (a\nRaspberry Pi 4 and an Orange Pi One), showing that is possible to make use of\nthe latter low-power devices to implement blockchain nodes but at the cost of\nhigher response latency. Furthermore, the impact of Ethereum gas limit is\nevaluated, demonstrating its significant influence on the blockchain network\nperformance. Thus, this article provides guidelines, useful practical\nevaluations and key findings that will help the next generation of green\nblockchain developers and researchers."}
{"id": "2504.00786", "title": "FeatInsight: An Online ML Feature Management System on 4Paradigm Sage-Studio Platform", "url": "https://arxiv.org/abs/2504.00786", "pdf": "https://arxiv.org/pdf/2504.00786", "abs": "https://arxiv.org/abs/2504.00786", "authors": ["Xin Tong", "Xuanhe Zhou", "Bingsheng He", "Guoliang Li", "Zirui Tang", "Wei Zhou", "Fan Wu", "Mian Lu", "Yuqiang Chen"], "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Feature management is essential for many online machine learning applications\nand can often become the performance bottleneck (e.g., taking up to 70% of the\noverall latency in sales prediction service). Improper feature configurations\n(e.g., introducing too many irrelevant features) can severely undermine the\nmodel's generalization capabilities. However, managing online ML features is\nchallenging due to (1) large-scale, complex raw data (e.g., the 2018 PHM\ndataset contains 17 tables and dozens to hundreds of columns), (2) the need for\nhigh-performance, consistent computation of interdependent features with\ncomplex patterns, and (3) the requirement for rapid updates and deployments to\naccommodate real-time data changes. In this demo, we present FeatInsight, a\nsystem that supports the entire feature lifecycle, including feature design,\nstorage, visualization, computation, verification, and lineage management.\nFeatInsight (with OpenMLDB as the execution engine) has been deployed in over\n100 real-world scenarios on 4Paradigm's Sage Studio platform, handling up to a\ntrillion-dimensional feature space and enabling millisecond-level feature\nupdates. We demonstrate how FeatInsight enhances feature design efficiency\n(e.g., for online product recommendation) and improve feature computation\nperformance (e.g., for online fraud detection). The code is available at\nhttps://github.com/4paradigm/FeatInsight."}
{"id": "2503.24259", "title": "Advances in Continual Graph Learning for Anti-Money Laundering Systems: A Comprehensive Review", "url": "https://arxiv.org/abs/2503.24259", "pdf": "https://arxiv.org/pdf/2503.24259", "abs": "https://arxiv.org/abs/2503.24259", "authors": ["Bruno Deprez", "Wei Wei", "Wouter Verbeke", "Bart Baesens", "Kevin Mets", "Tim Verdonck"], "categories": ["cs.LG"], "comment": null, "summary": "Financial institutions are required by regulation to report suspicious\nfinancial transactions related to money laundering. Therefore, they need to\nconstantly monitor vast amounts of incoming and outgoing transactions. A\nparticular challenge in detecting money laundering is that money launderers\ncontinuously adapt their tactics to evade detection. Hence, detection methods\nneed constant fine-tuning. Traditional machine learning models suffer from\ncatastrophic forgetting when fine-tuning the model on new data, thereby\nlimiting their effectiveness in dynamic environments. Continual learning\nmethods may address this issue and enhance current anti-money laundering (AML)\npractices, by allowing models to incorporate new information while retaining\nprior knowledge. Research on continual graph learning for AML, however, is\nstill scarce. In this review, we critically evaluate state-of-the-art continual\ngraph learning approaches for AML applications. We categorise methods into\nreplay-based, regularization-based, and architecture-based strategies within\nthe graph neural network (GNN) framework, and we provide in-depth experimental\nevaluations on both synthetic and real-world AML data sets that showcase the\neffect of the different hyperparameters. Our analysis demonstrates that\ncontinual learning improves model adaptability and robustness in the face of\nextreme class imbalances and evolving fraud patterns. Finally, we outline key\nchallenges and propose directions for future research."}
{"id": "2503.21463", "title": "Unveiling Latent Information in Transaction Hashes: Hypergraph Learning for Ethereum Ponzi Scheme Detection", "url": "https://arxiv.org/abs/2503.21463", "pdf": "https://arxiv.org/pdf/2503.21463", "abs": "https://arxiv.org/abs/2503.21463", "authors": ["Junhao Wu", "Yixin Yang", "Chengxiang Jin", "Silu Mu", "Xiaolei Qian", "Jiajun Zhou", "Shanqing Yu", "Qi Xuan"], "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "With the widespread adoption of Ethereum, financial frauds such as Ponzi\nschemes have become increasingly rampant in the blockchain ecosystem, posing\nsignificant threats to the security of account assets. Existing Ethereum fraud\ndetection methods typically model account transactions as graphs, but this\napproach primarily focuses on binary transactional relationships between\naccounts, failing to adequately capture the complex multi-party interaction\npatterns inherent in Ethereum. To address this, we propose a hypergraph\nmodeling method for the Ponzi scheme detection method in Ethereum, called\nHyperDet. Specifically, we treat transaction hashes as hyperedges that connect\nall the relevant accounts involved in a transaction. Additionally, we design a\ntwo-step hypergraph sampling strategy to significantly reduce computational\ncomplexity. Furthermore, we introduce a dual-channel detection module,\nincluding the hypergraph detection channel and the hyper-homo graph detection\nchannel, to be compatible with existing detection methods. Experimental results\nshow that, compared to traditional homogeneous graph-based methods, the\nhyper-homo graph detection channel achieves significant performance\nimprovements, demonstrating the superiority of hypergraph in Ponzi scheme\ndetection. This research offers innovations for modeling complex relationships\nin blockchain data."}
{"id": "2503.21160", "title": "A Data Balancing and Ensemble Learning Approach for Credit Card Fraud Detection", "url": "https://arxiv.org/abs/2503.21160", "pdf": "https://arxiv.org/pdf/2503.21160", "abs": "https://arxiv.org/abs/2503.21160", "authors": ["Yuhan Wang"], "categories": ["cs.LG"], "comment": null, "summary": "This research introduces an innovative method for identifying credit card\nfraud by combining the SMOTE-KMEANS technique with an ensemble machine learning\nmodel. The proposed model was benchmarked against traditional models such as\nlogistic regression, decision trees, random forests, and support vector\nmachines. Performance was evaluated using metrics, including accuracy, recall,\nand area under the curve (AUC). The results demonstrated that the proposed\nmodel achieved superior performance, with an AUC of 0.96 when combined with the\nSMOTE-KMEANS algorithm. This indicates a significant improvement in detecting\nfraudulent transactions while maintaining high precision and recall. The study\nalso explores the application of different oversampling techniques to enhance\nthe performance of various classifiers. The findings suggest that the proposed\nmethod is robust and effective for classification tasks on balanced datasets.\nFuture research directions include further optimization of the SMOTE-KMEANS\napproach and its integration into existing fraud detection systems to enhance\nfinancial security and consumer protection."}
{"id": "2503.18841", "title": "Unsupervised Detection of Fraudulent Transactions in E-commerce Using Contrastive Learning", "url": "https://arxiv.org/abs/2503.18841", "pdf": "https://arxiv.org/pdf/2503.18841", "abs": "https://arxiv.org/abs/2503.18841", "authors": ["Xuan Li", "Yuting Peng", "Xiaoxuan Sun", "Yifei Duan", "Zhou Fang", "Tengda Tang"], "categories": ["cs.LG"], "comment": null, "summary": "With the rapid development of e-commerce, e-commerce platforms are facing an\nincreasing number of fraud threats. Effectively identifying and preventing\nthese fraudulent activities has become a critical research problem. Traditional\nfraud detection methods typically rely on supervised learning, which requires\nlarge amounts of labeled data. However, such data is often difficult to obtain,\nand the continuous evolution of fraudulent activities further reduces the\nadaptability and effectiveness of traditional methods. To address this issue,\nthis study proposes an unsupervised e-commerce fraud detection algorithm based\non SimCLR. The algorithm leverages the contrastive learning framework to\neffectively detect fraud by learning the underlying representations of\ntransaction data in an unlabeled setting. Experimental results on the eBay\nplatform dataset show that the proposed algorithm outperforms traditional\nunsupervised methods such as K-means, Isolation Forest, and Autoencoders in\nterms of accuracy, precision, recall, and F1 score, demonstrating strong fraud\ndetection capabilities. The results confirm that the SimCLR-based unsupervised\nfraud detection method has broad application prospects in e-commerce platform\nsecurity, improving both detection accuracy and robustness. In the future, with\nthe increasing scale and diversity of datasets, the model's performance will\ncontinue to improve, and it could be integrated with real-time monitoring\nsystems to provide more efficient security for e-commerce platforms."}
{"id": "2503.18235", "title": "Enhance GNNs with Reliable Confidence Estimation via Adversarial Calibration Learning", "url": "https://arxiv.org/abs/2503.18235", "pdf": "https://arxiv.org/pdf/2503.18235", "abs": "https://arxiv.org/abs/2503.18235", "authors": ["Yilong Wang", "Jiahao Zhang", "Tianxiang Zhao", "Suhang Wang"], "categories": ["cs.LG"], "comment": null, "summary": "Despite their impressive predictive performance, GNNs often exhibit poor\nconfidence calibration, i.e., their predicted confidence scores do not\naccurately reflect true correctness likelihood. This issue raises concerns\nabout their reliability in high-stakes domains such as fraud detection, and\nrisk assessment, where well-calibrated predictions are essential for\ndecision-making. To ensure trustworthy predictions, several GNN calibration\nmethods are proposed. Though they can improve global calibration, our\nexperiments reveal that they often fail to generalize across different node\ngroups, leading to inaccurate confidence in node groups with different degree\nlevels, classes, and local structures. In certain cases, they even degrade\ncalibration compared to the original uncalibrated GNN. To address this\nchallenge, we propose a novel AdvCali framework that adaptively enhances\ncalibration across different node groups. Our method leverages adversarial\ntraining to automatically identify mis-calibrated node groups and applies a\ndifferentiable Group Expected Calibration Error (ECE) loss term to refine\nconfidence estimation within these groups. This allows the model to dynamically\nadjust its calibration strategy without relying on dataset-specific prior\nknowledge about miscalibrated subgroups. Extensive experiments on real-world\ndatasets demonstrate that our approach not only improves global calibration but\nalso significantly enhances calibration within groups defined by feature\nsimilarity, topology, and connectivity, outperforming previous methods and\ndemonstrating its effectiveness in practical scenarios."}
{"id": "2503.22710", "title": "Assessing the influence of cybersecurity threats and risks on the adoption and growth of digital banking: a systematic literature review", "url": "https://arxiv.org/abs/2503.22710", "pdf": "https://arxiv.org/pdf/2503.22710", "abs": "https://arxiv.org/abs/2503.22710", "authors": ["Md. Waliullah", "Md Zahin Hossain George", "Md Tarek Hasan", "Md Khorshed Alam", "Mosa Sumaiya Khatun Munira", "Noor Alam Siddiqui"], "categories": ["cs.CR", "cs.CY"], "comment": "32 pages, 13 figures", "summary": "The rapid digitalization of banking services has significantly transformed\nfinancial transactions, offering enhanced convenience and efficiency for\nconsumers. However, the increasing reliance on digital banking has also exposed\nfinancial institutions and users to a wide range of cybersecurity threats,\nincluding phishing, malware, ransomware, data breaches, and unauthorized\naccess. This study systematically examines the influence of cybersecurity\nthreats on digital banking security, adoption, and regulatory compliance by\nconducting a comprehensive review of 78 peer-reviewed articles published\nbetween 2015 and 2024. Using the Preferred Reporting Items for Systematic\nReviews and Meta-Analyses (PRISMA) methodology, this research critically\nevaluates the most prevalent cyber threats targeting digital banking platforms,\nthe effectiveness of modern security measures, and the role of regulatory\nframeworks in mitigating financial cybersecurity risks. The findings reveal\nthat phishing and malware attacks remain the most commonly exploited cyber\nthreats, leading to significant financial losses and consumer distrust.\nMulti-factor authentication (MFA) and biometric security have been widely\nadopted to combat unauthorized access, while AI-driven fraud detection and\nblockchain technology offer promising solutions for securing financial\ntransactions. However, the integration of third-party FinTech solutions\nintroduces additional security risks, necessitating stringent regulatory\noversight and cybersecurity protocols. The study also highlights that\ncompliance with global cybersecurity regulations, such as GDPR, PSD2, and GLBA,\nenhances digital banking security by enforcing strict authentication measures,\nencryption protocols, and real-time fraud monitoring."}
{"id": "2410.04324", "title": "Where are we in audio deepfake detection? A systematic analysis over generative and detection models", "url": "https://arxiv.org/abs/2410.04324", "pdf": "https://arxiv.org/pdf/2410.04324", "abs": "https://arxiv.org/abs/2410.04324", "authors": ["Xiang Li", "Pin-Yu Chen", "Wenqi Wei"], "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Recent advances in Text-to-Speech (TTS) and Voice-Conversion (VC) using\ngenerative Artificial Intelligence (AI) technology have made it possible to\ngenerate high-quality and realistic human-like audio. This poses growing\nchallenges in distinguishing AI-synthesized speech from the genuine human voice\nand could raise concerns about misuse for impersonation, fraud, spreading\nmisinformation, and scams. However, existing detection methods for\nAI-synthesized audio have not kept pace and often fail to generalize across\ndiverse datasets. In this paper, we introduce SONAR, a synthetic AI-Audio\nDetection Framework and Benchmark, aiming to provide a comprehensive evaluation\nfor distinguishing cutting-edge AI-synthesized auditory content. SONAR includes\na novel evaluation dataset sourced from 9 diverse audio synthesis platforms,\nincluding leading TTS providers and state-of-the-art TTS models. It is the\nfirst framework to uniformly benchmark AI-audio detection across both\ntraditional and foundation model-based detection systems. Through extensive\nexperiments, (1) we reveal the limitations of existing detection methods and\ndemonstrate that foundation models exhibit stronger generalization\ncapabilities, likely due to their model size and the scale and quality of\npretraining data. (2) Speech foundation models demonstrate robust cross-lingual\ngeneralization capabilities, maintaining strong performance across diverse\nlanguages despite being fine-tuned solely on English speech data. This finding\nalso suggests that the primary challenges in audio deepfake detection are more\nclosely tied to the realism and quality of synthetic audio rather than\nlanguage-specific characteristics. (3) We explore the effectiveness and\nefficiency of few-shot fine-tuning in improving generalization, highlighting\nits potential for tailored applications, such as personalized detection systems\nfor specific entities or individuals."}
{"id": "2503.16901", "title": "TeMP-TraG: Edge-based Temporal Message Passing in Transaction Graphs", "url": "https://arxiv.org/abs/2503.16901", "pdf": "https://arxiv.org/pdf/2503.16901", "abs": "https://arxiv.org/abs/2503.16901", "authors": ["Steve Gounoue", "Ashutosh Sao", "Simon Gottschalk"], "categories": ["cs.LG"], "comment": null, "summary": "Transaction graphs, which represent financial and trade transactions between\nentities such as bank accounts and companies, can reveal patterns indicative of\nfinancial crimes like money laundering and fraud. However, effective detection\nof such cases requires node and edge classification methods capable of\naddressing the unique challenges of transaction graphs, including rich edge\nfeatures, multigraph structures and temporal dynamics. To tackle these\nchallenges, we propose TeMP-TraG, a novel graph neural network mechanism that\nincorporates temporal dynamics into message passing. TeMP-TraG prioritises more\nrecent transactions when aggregating node messages, enabling better detection\nof time-sensitive patterns. We demonstrate that TeMP-TraG improves four\nstate-of-the-art graph neural networks by 6.19% on average. Our results\nhighlight TeMP-TraG as an advancement in leveraging transaction graphs to\ncombat financial crime."}
{"id": "2503.16847", "title": "Early-MFC: Enhanced Flow Correlation Attacks on Tor via Multi-view Triplet Networks with Early Network Traffic", "url": "https://arxiv.org/abs/2503.16847", "pdf": "https://arxiv.org/pdf/2503.16847", "abs": "https://arxiv.org/abs/2503.16847", "authors": ["Yali Yuan", "Qianqi Niu", "Yachao Yuan"], "categories": ["cs.CR"], "comment": null, "summary": "Flow correlation attacks is an efficient network attacks, aiming to expose\nthose who use anonymous network services, such as Tor. Conducting such attacks\nduring the early stages of network communication is particularly critical for\nscenarios demanding rapid decision-making, such as cybercrime detection or\nfinancial fraud prevention. Although recent studies have made progress in flow\ncorrelation attacks techniques, research specifically addressing flow\ncorrelation with early network traffic flow remains limited. Moreover, due to\nfactors such as model complexity, training costs, and real-time requirements,\nexisting technologies cannot be directly applied to flow correlation with early\nnetwork traffic flow. In this paper, we propose flow correlation attack with\nearly network traffic, named Early-MFC, based on multi-view triplet networks.\nThe proposed approach extracts multi-view traffic features from the payload at\nthe transport layer and the Inter-Packet Delay. It then integrates multi-view\nflow information, converting the extracted features into shared embeddings. By\nleveraging techniques such as metric learning and contrastive learning, the\nmethod optimizes the embeddings space by ensuring that similar flows are mapped\ncloser together while dissimilar flows are positioned farther apart. Finally,\nBayesian decision theory is applied to determine flow correlation, enabling\nhigh-accuracy flow correlation with early network traffic flow. Furthermore, we\ninvestigate flow correlation attacks under extra-early network traffic flow\nconditions. To address this challenge, we propose Early-MFC+, which utilizes\npayload data to construct embedded feature representations, ensuring robust\nperformance even with minimal packet availability."}
{"id": "2502.13308", "title": "A Label-Free Heterophily-Guided Approach for Unsupervised Graph Fraud Detection", "url": "https://arxiv.org/abs/2502.13308", "pdf": "https://arxiv.org/pdf/2502.13308", "abs": "https://arxiv.org/abs/2502.13308", "authors": ["Junjun Pan", "Yixin Liu", "Xin Zheng", "Yizhen Zheng", "Alan Wee-Chung Liew", "Fuyi Li", "Shirui Pan"], "categories": ["cs.LG"], "comment": "9 pages, 3 figures. Accepted by AAAI 2025", "summary": "Graph fraud detection (GFD) has rapidly advanced in protecting online\nservices by identifying malicious fraudsters. Recent supervised GFD research\nhighlights that heterophilic connections between fraudsters and users can\ngreatly impact detection performance, since fraudsters tend to camouflage\nthemselves by building more connections to benign users. Despite the promising\nperformance of supervised GFD methods, the reliance on labels limits their\napplications to unsupervised scenarios; Additionally, accurately capturing\ncomplex and diverse heterophily patterns without labels poses a further\nchallenge. To fill the gap, we propose a Heterophily-guided Unsupervised Graph\nfraud dEtection approach (HUGE) for unsupervised GFD, which contains two\nessential components: a heterophily estimation module and an alignment-based\nfraud detection module. In the heterophily estimation module, we design a novel\nlabel-free heterophily metric called HALO, which captures the critical graph\nproperties for GFD, enabling its outstanding ability to estimate heterophily\nfrom node attributes. In the alignment-based fraud detection module, we develop\na joint MLP-GNN architecture with ranking loss and asymmetric alignment loss.\nThe ranking loss aligns the predicted fraud score with the relative order of\nHALO, providing an extra robustness guarantee by comparing heterophily among\nnon-adjacent nodes. Moreover, the asymmetric alignment loss effectively\nutilizes structural information while alleviating the feature-smooth effects of\nGNNs. Extensive experiments on 6 datasets demonstrate that HUGE significantly\noutperforms competitors, showcasing its effectiveness and robustness."}
{"id": "2412.12370", "title": "Scam Detection for Ethereum Smart Contracts: Leveraging Graph Representation Learning for Secure Blockchain", "url": "https://arxiv.org/abs/2412.12370", "pdf": "https://arxiv.org/pdf/2412.12370", "abs": "https://arxiv.org/abs/2412.12370", "authors": ["Yihong Jin", "Ze Yang", "Xinhe Xu"], "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DC", "cs.SI", "I.2.1"], "comment": "Accepted to ISCAIT 2025", "summary": "As more and more attacks have been detected on Ethereum smart contracts, it\nhas seriously affected finance and credibility. Current anti-fraud detection\ntechniques, including code parsing or manual feature extraction, still have\nsome shortcomings, although some generalization or adaptability can be\nobtained. In the face of this situation, this paper proposes to use graphical\nrepresentation learning technology to find transaction patterns and distinguish\nmalicious transaction contracts, that is, to represent Ethereum transaction\ndata as graphs, and then use advanced ML technology to obtain reliable and\naccurate results. Taking into account the sample imbalance, we treated with\nSMOTE-ENN and tested several models, in which MLP performed better than GCN,\nbut the exact effect depends on its field trials. Our research opens up more\npossibilities for trust and security in the Ethereum ecosystem."}
{"id": "2503.14421", "title": "ExDDV: A New Dataset for Explainable Deepfake Detection in Video", "url": "https://arxiv.org/abs/2503.14421", "pdf": "https://arxiv.org/pdf/2503.14421", "abs": "https://arxiv.org/abs/2503.14421", "authors": ["Vlad Hondru", "Eduard Hogea", "Darian Onchis", "Radu Tudor Ionescu"], "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "comment": null, "summary": "The ever growing realism and quality of generated videos makes it\nincreasingly harder for humans to spot deepfake content, who need to rely more\nand more on automatic deepfake detectors. However, deepfake detectors are also\nprone to errors, and their decisions are not explainable, leaving humans\nvulnerable to deepfake-based fraud and misinformation. To this end, we\nintroduce ExDDV, the first dataset and benchmark for Explainable Deepfake\nDetection in Video. ExDDV comprises around 5.4K real and deepfake videos that\nare manually annotated with text descriptions (to explain the artifacts) and\nclicks (to point out the artifacts). We evaluate a number of vision-language\nmodels on ExDDV, performing experiments with various fine-tuning and in-context\nlearning strategies. Our results show that text and click supervision are both\nrequired to develop robust explainable models for deepfake videos, which are\nable to localize and describe the observed artifacts. Our novel dataset and\ncode to reproduce the results are available at\nhttps://github.com/vladhondru25/ExDDV."}
{"id": "2503.13923", "title": "ConSCompF: Consistency-focused Similarity Comparison Framework for Generative Large Language Models", "url": "https://arxiv.org/abs/2503.13923", "pdf": "https://arxiv.org/pdf/2503.13923", "abs": "https://arxiv.org/abs/2503.13923", "authors": ["Alexey Karev", "Dong Xu"], "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have been one of the most important discoveries\nin machine learning in recent years. LLM-based artificial intelligence (AI)\nassistants, such as ChatGPT, have consistently attracted the attention from\nresearchers, investors, and the general public, driving the rapid growth of\nthis industry. With the frequent introduction of new LLMs to the market, it\nbecomes increasingly difficult to differentiate between them, creating a demand\nfor new LLM comparison methods.\n  In this research, the Consistency-focused Similarity Comparison Framework\n(ConSCompF) for generative large language models is proposed. It compares texts\ngenerated by two LLMs and produces a similarity score, indicating the overall\ndegree of similarity between their responses. The main advantage of this\nframework is that it can operate on a small number of unlabeled data, such as\nchatbot instruction prompts, and does not require LLM developers to disclose\nany information about their product.\n  To evaluate the efficacy of ConSCompF, two experiments aimed at identifying\nsimilarities between multiple LLMs are conducted. Additionally, these\nexperiments examine the correlation between the similarity scores generated by\nConSCompF and the differences in the outputs produced by other benchmarking\ntechniques, such as ROUGE-L. Finally, a series of few-shot LLM comparison\nexperiments is conducted to evaluate the performance of ConSCompF in a few-shot\nLLM comparison scenario.\n  The proposed framework can be used for calculating similarity matrices of\nmultiple LLMs, which can be effectively visualized using principal component\nanalysis (PCA). The ConSCompF output may provide useful insights into data that\nmight have been used during LLM training and help detect possible investment\nfraud attempts."}
{"id": "2503.14541", "title": "Regulating Ai In Financial Services: Legal Frameworks And Compliance Challenges", "url": "https://arxiv.org/abs/2503.14541", "pdf": "https://arxiv.org/pdf/2503.14541", "abs": "https://arxiv.org/abs/2503.14541", "authors": ["Shahmar Mirishli"], "categories": ["cs.CY", "q-fin.GN"], "comment": null, "summary": "This article examines the evolving landscape of artificial intelligence (AI)\nregulation in financial services, detailing the legal frameworks and compliance\nchallenges posed by rapid technological adoption. By reviewing current\nlegislation, industry guidelines, and real-world use cases, it highlights how\nAI-driven processes, from fraud detection to algorithmic trading, offer\nefficiency gains yet introduce significant risks, including algorithmic bias,\ndata privacy breaches, and lack of transparency in automated decision-making.\nThe study compares regulatory approaches across major jurisdictions such as the\nEuropean Union, United States, and United Kingdom, identifying both universal\nconcerns, like the need for explainability and robust data protection, and\nregion-specific compliance requirements that impact the implementation of\nhigh-risk AI applications. Additionally, it underscores emerging areas of\nfocus, such as liability for AI-driven errors, systemic risks posed by\ninterlinked AI systems, and the ethical considerations of technology-driven\nfinancial exclusion. The findings reveal gaps in existing rules and emphasize\nthe necessity for adaptive, technology-neutral policies capable of fostering\ninnovation while safeguarding consumer rights and market integrity. The article\nconcludes by proposing a principled regulatory model that balances flexibility\nwith enforceable standards, advocating closer collaboration between\npolicymakers, financial institutions, and AI developers to ensure a secure,\nfair, and forward-looking framework for AI in finance."}
{"id": "2503.13195", "title": "Deep Learning Advancements in Anomaly Detection: A Comprehensive Survey", "url": "https://arxiv.org/abs/2503.13195", "pdf": "https://arxiv.org/pdf/2503.13195", "abs": "https://arxiv.org/abs/2503.13195", "authors": ["Haoqi Huang", "Ping Wang", "Jianhua Pei", "Jiacheng Wang", "Shahen Alexanian", "Dusit Niyato"], "categories": ["cs.LG"], "comment": null, "summary": "The rapid expansion of data from diverse sources has made anomaly detection\n(AD) increasingly essential for identifying unexpected observations that may\nsignal system failures, security breaches, or fraud. As datasets become more\ncomplex and high-dimensional, traditional detection methods struggle to\neffectively capture intricate patterns. Advances in deep learning have made AD\nmethods more powerful and adaptable, improving their ability to handle\nhigh-dimensional and unstructured data. This survey provides a comprehensive\nreview of over 180 recent studies, focusing on deep learning-based AD\ntechniques. We categorize and analyze these methods into reconstruction-based\nand prediction-based approaches, highlighting their effectiveness in modeling\ncomplex data distributions. Additionally, we explore the integration of\ntraditional and deep learning methods, highlighting how hybrid approaches\ncombine the interpretability of traditional techniques with the flexibility of\ndeep learning to enhance detection accuracy and model transparency. Finally, we\nidentify open issues and propose future research directions to advance the\nfield of AD. This review bridges gaps in existing literature and serves as a\nvaluable resource for researchers and practitioners seeking to enhance AD\ntechniques using deep learning."}
{"id": "2503.15546", "title": "Enforcing Cybersecurity Constraints for LLM-driven Robot Agents for Online Transactions", "url": "https://arxiv.org/abs/2503.15546", "pdf": "https://arxiv.org/pdf/2503.15546", "abs": "https://arxiv.org/abs/2503.15546", "authors": ["Shraddha Pradipbhai Shah", "Aditya Vilas Deshpande"], "categories": ["cs.CR", "cs.AI", "cs.CY"], "comment": null, "summary": "The integration of Large Language Models (LLMs) into autonomous robotic\nagents for conducting online transactions poses significant cybersecurity\nchallenges. This study aims to enforce robust cybersecurity constraints to\nmitigate the risks associated with data breaches, transaction fraud, and system\nmanipulation. The background focuses on the rise of LLM-driven robotic systems\nin e-commerce, finance, and service industries, alongside the vulnerabilities\nthey introduce. A novel security architecture combining blockchain technology\nwith multi-factor authentication (MFA) and real-time anomaly detection was\nimplemented to safeguard transactions. Key performance metrics such as\ntransaction integrity, response time, and breach detection accuracy were\nevaluated, showing improved security and system performance. The results\nhighlight that the proposed architecture reduced fraudulent transactions by\n90%, improved breach detection accuracy to 98%, and ensured secure transaction\nvalidation within a latency of 0.05 seconds. These findings emphasize the\nimportance of cybersecurity in the deployment of LLM-driven robotic systems and\nsuggest a framework adaptable to various online platforms."}
{"id": "2503.12163", "title": "AgentDroid: A Multi-Agent Framework for Detecting Fraudulent Android Applications", "url": "https://arxiv.org/abs/2503.12163", "pdf": "https://arxiv.org/pdf/2503.12163", "abs": "https://arxiv.org/abs/2503.12163", "authors": ["Ruwei Pan", "Hongyu Zhang", "Zhonghao Jiang", "Ran Hou"], "categories": ["cs.SE"], "comment": null, "summary": "With the increasing prevalence of fraudulent Android applications such as\nfake and malicious applications, it is crucial to detect them with high\naccuracy and adaptability. This paper introduces AgentDroid, a novel framework\nfor Android fraudulent application detection based on multi-modal analysis and\nmulti-agent systems. AgentDroid overcomes the limitations of traditional\ndetection methods such as the inability to handle multimodal data and high\nfalse alarm rates. It processes Android applications and extracts a series of\nmulti-modal data for analysis. Multiple LLM-based agents with specialized roles\nanalyze the relevant data and collaborate to detect complex fraud effectively.\nWe constructed a dataset containing various categories of fraudulent\napplications and legitimate applications and validated our framework on this\ndataset. Experimental results indicate that our multi-agent framework based on\nGPT-4o achieves an accuracy of 91.7% and an F1-Score of 91.68%, showing\nimproved detection accuracy over the baseline methods."}
{"id": "2503.12037", "title": "Unsupervised Graph Anomaly Detection via Multi-Hypersphere Heterophilic Graph Learning", "url": "https://arxiv.org/abs/2503.12037", "pdf": "https://arxiv.org/pdf/2503.12037", "abs": "https://arxiv.org/abs/2503.12037", "authors": ["Hang Ni", "Jindong Han", "Nengjun Zhu", "Hao Liu"], "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Anomaly Detection (GAD) plays a vital role in various data mining\napplications such as e-commerce fraud prevention and malicious user detection.\nRecently, Graph Neural Network (GNN) based approach has demonstrated great\neffectiveness in GAD by first encoding graph data into low-dimensional\nrepresentations and then identifying anomalies under the guidance of supervised\nor unsupervised signals. However, existing GNN-based approaches implicitly\nfollow the homophily principle (i.e., the \"like attracts like\" phenomenon) and\nfail to learn discriminative embedding for anomalies that connect vast normal\nnodes. Moreover, such approaches identify anomalies in a unified global\nperspective but overlook diversified abnormal patterns conditioned on local\ngraph context, leading to suboptimal performance. To overcome the\naforementioned limitations, in this paper, we propose a Multi-hypersphere\nHeterophilic Graph Learning (MHetGL) framework for unsupervised GAD.\nSpecifically, we first devise a Heterophilic Graph Encoding (HGE) module to\nlearn distinguishable representations for potential anomalies by purifying and\naugmenting their neighborhood in a fully unsupervised manner. Then, we propose\na Multi-Hypersphere Learning (MHL) module to enhance the detection capability\nfor context-dependent anomalies by jointly incorporating critical patterns from\nboth global and local perspectives. Extensive experiments on ten real-world\ndatasets show that MHetGL outperforms 14 baselines. Our code is publicly\navailable at https://github.com/KennyNH/MHetGL."}
{"id": "2503.11273", "title": "Financial Fraud Detection with Entropy Computing", "url": "https://arxiv.org/abs/2503.11273", "pdf": "https://arxiv.org/pdf/2503.11273", "abs": "https://arxiv.org/abs/2503.11273", "authors": ["Babak Emami", "Wesley Dyk", "David Haycraft", "Carrie Spear", "Lac Nguyen", "Nicholas Chancellor"], "categories": ["cs.LG", "cs.AI", "physics.optics", "quant-ph"], "comment": "15 pages including references and appendix, 6 figures", "summary": "We introduce CVQBoost, a novel classification algorithm that leverages early\nhardware implementing Quantum Computing Inc's Entropy Quantum Computing (EQC)\nparadigm, Dirac-3 [Nguyen et. al. arXiv:2407.04512]. We apply CVQBoost to a\nfraud detection test case and benchmark its performance against XGBoost, a\nwidely utilized ML method. Running on Dirac-3, CVQBoost demonstrates a\nsignificant runtime advantage over XGBoost, which we evaluate on\nhigh-performance hardware comprising up to 48 CPUs and four NVIDIA L4 GPUs\nusing the RAPIDS AI framework. Our results show that CVQBoost maintains\ncompetitive accuracy (measured by AUC) while significantly reducing training\ntime, particularly as dataset size and feature complexity increase. To assess\nscalability, we extend our study to large synthetic datasets ranging from 1M to\n70M samples, demonstrating that CVQBoost on Dirac-3 is well-suited for\nlarge-scale classification tasks. These findings position CVQBoost as a\npromising alternative to gradient boosting methods, offering superior\nscalability and efficiency for high-dimensional ML applications such as fraud\ndetection."}
{"id": "2503.10058", "title": "Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions", "url": "https://arxiv.org/abs/2503.10058", "pdf": "https://arxiv.org/pdf/2503.10058", "abs": "https://arxiv.org/abs/2503.10058", "authors": ["Jiani Fan", "Lwin Khin Shar", "Ruichen Zhang", "Ziyao Liu", "Wenzhuo Yang", "Dusit Niyato", "Bomin Mao", "Kwok-Yan Lam"], "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Money laundering is a financial crime that obscures the origin of illicit\nfunds, necessitating the development and enforcement of anti-money laundering\n(AML) policies by governments and organizations. The proliferation of mobile\npayment platforms and smart IoT devices has significantly complicated AML\ninvestigations. As payment networks become more interconnected, there is an\nincreasing need for efficient real-time detection to process large volumes of\ntransaction data on heterogeneous payment systems by different operators such\nas digital currencies, cryptocurrencies and account-based payments. Most of\nthese mobile payment networks are supported by connected devices, many of which\nare considered loT devices in the FinTech space that constantly generate data.\nFurthermore, the growing complexity and unpredictability of transaction\npatterns across these networks contribute to a higher incidence of false\npositives. While machine learning solutions have the potential to enhance\ndetection efficiency, their application in AML faces unique challenges, such as\naddressing privacy concerns tied to sensitive financial data and managing the\nreal-world constraint of limited data availability due to data regulations.\nExisting surveys in the AML literature broadly review machine learning\napproaches for money laundering detection, but they often lack an in-depth\nexploration of advanced deep learning techniques - an emerging field with\nsignificant potential. To address this gap, this paper conducts a comprehensive\nreview of deep learning solutions and the challenges associated with their use\nin AML. Additionally, we propose a novel framework that applies the\nleast-privilege principle by integrating machine learning techniques, codifying\nAML red flags, and employing account profiling to provide context for\npredictions and enable effective fraud detection under limited data\navailability...."}
{"id": "2503.09302", "title": "Detecting and Preventing Data Poisoning Attacks on AI Models", "url": "https://arxiv.org/abs/2503.09302", "pdf": "https://arxiv.org/pdf/2503.09302", "abs": "https://arxiv.org/abs/2503.09302", "authors": ["Halima I. Kure", "Pradipta Sarkar", "Ahmed B. Ndanusa", "Augustine O. Nwajana"], "categories": ["cs.CR", "eess.IV"], "comment": "9 pages, 8 figures", "summary": "This paper investigates the critical issue of data poisoning attacks on AI\nmodels, a growing concern in the ever-evolving landscape of artificial\nintelligence and cybersecurity. As advanced technology systems become\nincreasingly prevalent across various sectors, the need for robust defence\nmechanisms against adversarial attacks becomes paramount. The study aims to\ndevelop and evaluate novel techniques for detecting and preventing data\npoisoning attacks, focusing on both theoretical frameworks and practical\napplications. Through a comprehensive literature review, experimental\nvalidation using the CIFAR-10 and Insurance Claims datasets, and the\ndevelopment of innovative algorithms, this paper seeks to enhance the\nresilience of AI models against malicious data manipulation. The study explores\nvarious methods, including anomaly detection, robust optimization strategies,\nand ensemble learning, to identify and mitigate the effects of poisoned data\nduring model training. Experimental results indicate that data poisoning\nsignificantly degrades model performance, reducing classification accuracy by\nup to 27% in image recognition tasks (CIFAR-10) and 22% in fraud detection\nmodels (Insurance Claims dataset). The proposed defence mechanisms, including\nstatistical anomaly detection and adversarial training, successfully mitigated\npoisoning effects, improving model robustness and restoring accuracy levels by\nan average of 15-20%. The findings further demonstrate that ensemble learning\ntechniques provide an additional layer of resilience, reducing false positives\nand false negatives caused by adversarial data injections."}
{"id": "2503.09289", "title": "Unmask It! AI-Generated Product Review Detection in Dravidian Languages", "url": "https://arxiv.org/abs/2503.09289", "pdf": "https://arxiv.org/pdf/2503.09289", "abs": "https://arxiv.org/abs/2503.09289", "authors": ["Somsubhra De", "Advait Vats"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 9 figures, Accepted to DravidianLangTech Workshop\n  proceedings at NAACL 2025", "summary": "The rise of Generative AI has led to a surge in AI-generated reviews, often\nposing a serious threat to the credibility of online platforms. Reviews serve\nas the primary source of information about products and services. Authentic\nreviews play a vital role in consumer decision-making. The presence of\nfabricated content misleads consumers, undermines trust and facilitates\npotential fraud in digital marketplaces. This study focuses on detecting\nAI-generated product reviews in Tamil and Malayalam, two low-resource languages\nwhere research in this domain is relatively under-explored. We worked on a\nrange of approaches - from traditional machine learning methods to advanced\ntransformer-based models such as Indic-BERT, IndicSBERT, MuRIL, XLM-RoBERTa and\nMalayalamBERT. Our findings highlight the effectiveness of leveraging the\nstate-of-the-art transformers in accurately identifying AI-generated content,\ndemonstrating the potential in enhancing the detection of fake reviews in\nlow-resource language settings."}
{"id": "2503.08346", "title": "Pathology-Aware Adaptive Watermarking for Text-Driven Medical Image Synthesis", "url": "https://arxiv.org/abs/2503.08346", "pdf": "https://arxiv.org/pdf/2503.08346", "abs": "https://arxiv.org/abs/2503.08346", "authors": ["Chanyoung Kim", "Dayun Ju", "Jinyeong Kim", "Woojung Han", "Roberto Alcover-Couso", "Seong Jae Hwang"], "categories": ["cs.CV"], "comment": null, "summary": "As recent text-conditioned diffusion models have enabled the generation of\nhigh-quality images, concerns over their potential misuse have also grown. This\nissue is critical in the medical domain, where text-conditioned generated\nmedical images could enable insurance fraud or falsified records, highlighting\nthe urgent need for reliable safeguards against unethical use. While\nwatermarking techniques have emerged as a promising solution in general image\ndomains, their direct application to medical imaging presents significant\nchallenges. A key challenge is preserving fine-grained disease manifestations,\nas even minor distortions from a watermark may lead to clinical\nmisinterpretation, which compromises diagnostic integrity. To overcome this\ngap, we present MedSign, a deep learning-based watermarking framework\nspecifically designed for text-to-medical image synthesis, which preserves\npathologically significant regions by adaptively adjusting watermark strength.\nSpecifically, we generate a pathology localization map using cross-attention\nbetween medical text tokens and the diffusion denoising network, aggregating\ntoken-wise attention across layers, heads, and time steps. Leveraging this map,\nwe optimize the LDM decoder to incorporate watermarking during image synthesis,\nensuring cohesive integration while minimizing interference in diagnostically\ncritical regions. Experimental results show that our MedSign preserves\ndiagnostic integrity while ensuring watermark robustness, achieving\nstate-of-the-art performance in image quality and detection accuracy on\nMIMIC-CXR and OIA-ODIR datasets."}
{"id": "2503.08097", "title": "Evidential Uncertainty Probes for Graph Neural Networks", "url": "https://arxiv.org/abs/2503.08097", "pdf": "https://arxiv.org/pdf/2503.08097", "abs": "https://arxiv.org/abs/2503.08097", "authors": ["Linlin Yu", "Kangshuo Li", "Pritom Kumar Saha", "Yifei Lou", "Feng Chen"], "categories": ["cs.LG"], "comment": "AISTATS 2025", "summary": "Accurate quantification of both aleatoric and epistemic uncertainties is\nessential when deploying Graph Neural Networks (GNNs) in high-stakes\napplications such as drug discovery and financial fraud detection, where\nreliable predictions are critical. Although Evidential Deep Learning (EDL)\nefficiently quantifies uncertainty using a Dirichlet distribution over\npredictive probabilities, existing EDL-based GNN (EGNN) models require\nmodifications to the network architecture and retraining, failing to take\nadvantage of pre-trained models. We propose a plug-and-play framework for\nuncertainty quantification in GNNs that works with pre-trained models without\nthe need for retraining. Our Evidential Probing Network (EPN) uses a\nlightweight Multi-Layer-Perceptron (MLP) head to extract evidence from learned\nrepresentations, allowing efficient integration with various GNN architectures.\nWe further introduce evidence-based regularization techniques, referred to as\nEPN-reg, to enhance the estimation of epistemic uncertainty with theoretical\njustifications. Extensive experiments demonstrate that the proposed EPN-reg\nachieves state-of-the-art performance in accurate and efficient uncertainty\nquantification, making it suitable for real-world deployment."}
{"id": "2503.08734", "title": "Zero-to-One IDV: A Conceptual Model for AI-Powered Identity Verification", "url": "https://arxiv.org/abs/2503.08734", "pdf": "https://arxiv.org/pdf/2503.08734", "abs": "https://arxiv.org/abs/2503.08734", "authors": ["Aniket Vaidya", "Anurag Awasthi"], "categories": ["cs.CR", "cs.AI"], "comment": "7 pages", "summary": "In today's increasingly digital interactions, robust Identity Verification\n(IDV) is crucial for security and trust. Artificial Intelligence (AI) is\ntransforming IDV, enhancing accuracy and fraud detection. This paper introduces\n``Zero to One,'' a holistic conceptual framework for developing AI-powered IDV\nproducts. This paper outlines the foundational problem and research objectives\nthat necessitate a new framework for IDV in the age of AI. It details the\nevolution of identity verification and the current regulatory landscape to\ncontextualize the need for a robust conceptual model. The core of the paper is\nthe presentation of the ``Zero to One'' framework itself, dissecting its four\nessential components: Document Verification, Biometric Verification, Risk\nAssessment, and Orchestration. The paper concludes by discussing the\nimplications of this conceptual model and suggesting future research directions\nfocused on the framework's further development and application. The framework\naddresses security, privacy, UX, and regulatory compliance, offering a\nstructured approach to building effective IDV solutions. Successful IDV\nplatforms require a balanced conceptual understanding of verification methods,\nrisk management, and operational scalability, with AI as a key enabler. This\npaper presents the ``Zero to One'' framework as a refined conceptual model,\ndetailing verification layers, and AI's transformative role in shaping\nnext-generation IDV products."}
{"id": "2503.06500", "title": "StructVizor: Interactive Profiling of Semi-Structured Textual Data", "url": "https://arxiv.org/abs/2503.06500", "pdf": "https://arxiv.org/pdf/2503.06500", "abs": "https://arxiv.org/abs/2503.06500", "authors": ["Yanwei Huang", "Yan Miao", "Di Weng", "Adam Perer", "Yingcai Wu"], "categories": ["cs.HC"], "comment": "Accepted for CHI 2025", "summary": "Data profiling plays a critical role in understanding the structure of\ncomplex datasets and supporting numerous downstream tasks, such as social media\nanalytics and financial fraud detection. While existing research predominantly\nfocuses on structured data formats, a substantial portion of semi-structured\ntextual data still requires ad-hoc and arduous manual profiling to extract and\ncomprehend its internal structures. In this work, we propose StructVizor, an\ninteractive profiling system that facilitates sensemaking and transformation of\nsemi-structured textual data. Our tool mainly addresses two challenges: a)\nextracting and visualizing the diverse structural patterns within data, such as\nhow information is organized or related, and b) enabling users to efficiently\nperform various wrangling operations on textual data. Through automatic data\nparsing and structure mining, StructVizor enables visual analytics of\nstructural patterns, while incorporating novel interactions to enable\nprofile-based data wrangling. A comparative user study involving 12\nparticipants demonstrates the system's usability and its effectiveness in\nsupporting exploratory data analysis and transformation tasks."}
{"id": "2503.02772", "title": "ESSPI: ECDSA/Schnorr Signed Program Input for BitVMX", "url": "https://arxiv.org/abs/2503.02772", "pdf": "https://arxiv.org/pdf/2503.02772", "abs": "https://arxiv.org/abs/2503.02772", "authors": ["Sergio Demian Lerner", "Martin Jonas", "Ariel Futoransky"], "categories": ["cs.CR", "cs.DC"], "comment": null, "summary": "The BitVM and BitVMX protocols have long relied on inefficient one-time\nsignature (OTS) schemes like Lamport and Winternitz for signing program inputs.\nThese schemes exhibit significant storage overheads, hindering their practical\napplication. This paper introduces ESSPI, an optimized method leveraging\nECDSA/Schnorr signatures to sign the BitVMX program input. With Schnorr\nsignatures we achieve an optimal 1:1 data expansion, compared to the current\nknown best ratio of 1:200 based on Winternitz signatures. To accomplish this we\nintroduce 4 innovations to BitVMX: (1) a modification of the BitVMX CPU, adding\na challengeable hashing core to it, (2) a new partition-based search to detect\nfraud during hashing, (3) a new enhanced transaction DAG with added\ndata-carrying transactions with a fraud-verifying smart-contract and (4) a\nnovel timelock-based method for proving data availability to Bitcoin smart\ncontracts. The enhanced BitVMX protocol enables the verification of\nuncompressed inputs such as SPV proofs, NiPoPoWs, or longer computation\nintegrity proofs, such as STARKs."}
{"id": "2503.01686", "title": "\\textsc{Perseus}: Tracing the Masterminds Behind Cryptocurrency Pump-and-Dump Schemes", "url": "https://arxiv.org/abs/2503.01686", "pdf": "https://arxiv.org/pdf/2503.01686", "abs": "https://arxiv.org/abs/2503.01686", "authors": ["Honglin Fu", "Yebo Feng", "Cong Wu", "Jiahua Xu"], "categories": ["cs.CY", "cs.LG", "q-fin.TR"], "comment": null, "summary": "Masterminds are entities organizing, coordinating, and orchestrating\ncryptocurrency pump-and-dump schemes, a form of trade-based manipulation\nundermining market integrity and causing financial losses for unwitting\ninvestors. Previous research detects pump-and-dump activities in the market,\npredicts the target cryptocurrency, and examines investors and \\ac{osn}\nentities. However, these solutions do not address the root cause of the\nproblem. There is a critical gap in identifying and tracing the masterminds\ninvolved in these schemes. In this research, we develop a detection system\n\\textsc{Perseus}, which collects real-time data from the \\acs{osn} and\ncryptocurrency markets. \\textsc{Perseus} then constructs temporal attributed\ngraphs that preserve the direction of information diffusion and the structure\nof the community while leveraging \\ac{gnn} to identify the masterminds behind\npump-and-dump activities. Our design of \\textsc{Perseus} leads to higher F1\nscores and precision than the \\ac{sota} fraud detection method, achieving fast\ntraining and inferring speeds. Deployed in the real world from February 16 to\nOctober 9 2024, \\textsc{Perseus} successfully detects $438$ masterminds who are\nefficient in the pump-and-dump information diffusion networks. \\textsc{Perseus}\nprovides regulators with an explanation of the risks of masterminds and\noversight capabilities to mitigate the pump-and-dump schemes of cryptocurrency."}
{"id": "2406.00987", "title": "Enhancing Fairness in Unsupervised Graph Anomaly Detection through Disentanglement", "url": "https://arxiv.org/abs/2406.00987", "pdf": "https://arxiv.org/pdf/2406.00987", "abs": "https://arxiv.org/abs/2406.00987", "authors": ["Wenjing Chang", "Kay Liu", "Philip S. Yu", "Jianjun Yu"], "categories": ["cs.LG", "cs.CY", "cs.SI"], "comment": "Accepted to TMLR. Code available at\n  https://github.com/AhaChang/DEFEND", "summary": "Graph anomaly detection (GAD) is increasingly crucial in various\napplications, ranging from financial fraud detection to fake news detection.\nHowever, current GAD methods largely overlook the fairness problem, which might\nresult in discriminatory decisions skewed toward certain demographic groups\ndefined on sensitive attributes (e.g., gender, religion, ethnicity, etc.). This\ngreatly limits the applicability of these methods in real-world scenarios in\nlight of societal and ethical restrictions. To address this critical gap, we\nmake the first attempt to integrate fairness with utility in GAD\ndecision-making. Specifically, we devise a novel DisEntangle-based\nFairnEss-aware aNomaly Detection framework on the attributed graph, named\nDEFEND. DEFEND first introduces disentanglement in GNNs to capture informative\nyet sensitive-irrelevant node representations, effectively reducing societal\nbias inherent in graph representation learning. Besides, to alleviate\ndiscriminatory bias in evaluating anomalous nodes, DEFEND adopts a\nreconstruction-based anomaly detection, which concentrates solely on node\nattributes without incorporating any graph structure. Additionally, given the\ninherent association between input and sensitive attributes, DEFEND constrains\nthe correlation between the reconstruction error and the predicted sensitive\nattributes. Our empirical evaluations on real-world datasets reveal that DEFEND\nperforms effectively in GAD and significantly enhances fairness compared to\nstate-of-the-art baselines. To foster reproducibility, our code is available at\nhttps://github.com/AhaChang/DEFEND."}
{"id": "2503.01556", "title": "Effective High-order Graph Representation Learning for Credit Card Fraud Detection", "url": "https://arxiv.org/abs/2503.01556", "pdf": "https://arxiv.org/pdf/2503.01556", "abs": "https://arxiv.org/abs/2503.01556", "authors": ["Yao Zou", "Dawei Cheng"], "categories": ["cs.LG", "cs.AI", "68T07, 91B06", "I.2.6; H.2.8"], "comment": "9 pages, 5 figures, accepted at IJCAI 2024", "summary": "Credit card fraud imposes significant costs on both cardholders and issuing\nbanks. Fraudsters often disguise their crimes, such as using legitimate\ntransactions through several benign users to bypass anti-fraud detection.\nExisting graph neural network (GNN) models struggle with learning features of\ncamouflaged, indirect multi-hop transactions due to their inherent\nover-smoothing issues in deep multi-layer aggregation, presenting a major\nchallenge in detecting disguised relationships. Therefore, in this paper, we\npropose a novel High-order Graph Representation Learning model (HOGRL) to avoid\nincorporating excessive noise during the multi-layer aggregation process. In\nparticular, HOGRL learns different orders of \\emph{pure} representations\ndirectly from high-order transaction graphs. We realize this goal by\neffectively constructing high-order transaction graphs first and then learning\nthe \\emph{pure} representations of each order so that the model could identify\nfraudsters' multi-hop indirect transactions via multi-layer \\emph{pure} feature\nlearning. In addition, we introduce a mixture-of-expert attention mechanism to\nautomatically determine the importance of different orders for jointly\noptimizing fraud detection performance. We conduct extensive experiments in\nboth the open source and real-world datasets, the result demonstrates the\nsignificant improvements of our proposed HOGRL compared with state-of-the-art\nfraud detection baselines. HOGRL's superior performance also proves its\neffectiveness in addressing high-order fraud camouflage criminals."}
{"id": "2501.11430", "title": "A Survey on Diffusion Models for Anomaly Detection", "url": "https://arxiv.org/abs/2501.11430", "pdf": "https://arxiv.org/pdf/2501.11430", "abs": "https://arxiv.org/abs/2501.11430", "authors": ["Jing Liu", "Zhenchao Ma", "Zepu Wang", "Chenxuanyin Zou", "Jiayang Ren", "Zehua Wang", "Liang Song", "Bo Hu", "Yang Liu", "Victor C. M. Leung"], "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion models (DMs) have emerged as a powerful class of generative AI\nmodels, showing remarkable potential in anomaly detection (AD) tasks across\nvarious domains, such as cybersecurity, fraud detection, healthcare, and\nmanufacturing. The intersection of these two fields, termed diffusion models\nfor anomaly detection (DMAD), offers promising solutions for identifying\ndeviations in increasingly complex and high-dimensional data. In this survey,\nwe review recent advances in DMAD research. We begin by presenting the\nfundamental concepts of AD and DMs, followed by a comprehensive analysis of\nclassic DM architectures including DDPMs, DDIMs, and Score SDEs. We further\ncategorize existing DMAD methods into reconstruction-based, density-based, and\nhybrid approaches, providing detailed examinations of their methodological\ninnovations. We also explore the diverse tasks across different data\nmodalities, encompassing image, time series, video, and multimodal data\nanalysis. Furthermore, we discuss critical challenges and emerging research\ndirections, including computational efficiency, model interpretability,\nrobustness enhancement, edge-cloud collaboration, and integration with large\nlanguage models. The collection of DMAD research papers and resources is\navailable at https://github.com/fdjingliu/DMAD."}
{"id": "2502.16947", "title": "Using Machine Learning to Detect Fraudulent SMSs in Chichewa", "url": "https://arxiv.org/abs/2502.16947", "pdf": "https://arxiv.org/pdf/2502.16947", "abs": "https://arxiv.org/abs/2502.16947", "authors": ["Amelia Taylor", "Amoss Robert"], "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "SMS enabled fraud is of great concern globally. Building classifiers based on\nmachine learning for SMS fraud requires the use of suitable datasets for model\ntraining and validation. Most research has centred on the use of datasets of\nSMSs in English. This paper introduces a first dataset for SMS fraud detection\nin Chichewa, a major language in Africa, and reports on experiments with\nmachine learning algorithms for classifying SMSs in Chichewa as fraud or\nnon-fraud. We answer the broader research question of how feasible it is to\ndevelop machine learning classification models for Chichewa SMSs. To do that,\nwe created three datasets. A small dataset of SMS in Chichewa was collected\nthrough primary research from a segment of the young population. We applied a\nlabel-preserving text transformations to increase its size. The enlarged\ndataset was translated into English using two approaches: human translation and\nmachine translation. The Chichewa and the translated datasets were subjected to\nmachine classification using random forest and logistic regression. Our\nfindings indicate that both models achieved a promising accuracy of over 96% on\nthe Chichewa dataset. There was a drop in performance when moving from the\nChichewa to the translated dataset. This highlights the importance of data\npreprocessing, especially in multilingual or cross-lingual NLP tasks, and shows\nthe challenges of relying on machine-translated text for training machine\nlearning models. Our results underscore the importance of developing language\nspecific models for SMS fraud detection to optimise accuracy and performance.\nSince most machine learning models require data preprocessing, it is essential\nto investigate the impact of the reliance on English-specific tools for data\npreprocessing."}
{"id": "2410.09069", "title": "Explainable AI for Fraud Detection: An Attention-Based Ensemble of CNNs, GNNs, and A Confidence-Driven Gating Mechanism", "url": "https://arxiv.org/abs/2410.09069", "pdf": "https://arxiv.org/pdf/2410.09069", "abs": "https://arxiv.org/abs/2410.09069", "authors": ["Mehdi Hosseini Chagahi", "Niloufar Delfan", "Saeed Mohammadi Dashtaki", "Behzad Moshiri", "Md. Jalil Piran"], "categories": ["q-fin.RM", "cs.LG"], "comment": null, "summary": "The rapid expansion of e-commerce and the widespread use of credit cards in\nonline purchases and financial transactions have significantly heightened the\nimportance of promptly and accurately detecting credit card fraud (CCF). Not\nonly do fraudulent activities in financial transactions lead to substantial\nmonetary losses for banks and financial institutions, but they also undermine\nuser trust in digital services. This study presents a new stacking-based\napproach for CCF detection by adding two extra layers to the usual\nclassification process: an attention layer and a confidence-based combination\nlayer. In the attention layer, we combine soft outputs from a convolutional\nneural network (CNN) and a recurrent neural network (RNN) using the dependent\nordered weighted averaging (DOWA) operator, and from a graph neural network\n(GNN) and a long short-term memory (LSTM) network using the induced ordered\nweighted averaging (IOWA) operator. These weighted outputs capture different\npredictive signals, increasing the model's accuracy. Next, in the\nconfidence-based layer, we select whichever aggregate (DOWA or IOWA) shows\nlower uncertainty to feed into a meta-learner. To make the model more\nexplainable, we use shapley additive explanations (SHAP) to identify the top\nten most important features for distinguishing between fraud and normal\ntransactions. These features are then used in our attention-based model.\nExperiments on three datasets show that our method achieves high accuracy and\nrobust generalization, making it effective for CCF detection."}
{"id": "2502.15898", "title": "ML-Driven Approaches to Combat Medicare Fraud: Advances in Class Imbalance Solutions, Feature Engineering, Adaptive Learning, and Business Impact", "url": "https://arxiv.org/abs/2502.15898", "pdf": "https://arxiv.org/pdf/2502.15898", "abs": "https://arxiv.org/abs/2502.15898", "authors": ["Dorsa Farahmandazad", "Kasra Danesh"], "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Medicare fraud poses a substantial challenge to healthcare systems, resulting\nin significant financial losses and undermining the quality of care provided to\nlegitimate beneficiaries. This study investigates the use of machine learning\n(ML) to enhance Medicare fraud detection, addressing key challenges such as\nclass imbalance, high-dimensional data, and evolving fraud patterns. A dataset\ncomprising inpatient claims, outpatient claims, and beneficiary details was\nused to train and evaluate five ML models: Random Forest, KNN, LDA, Decision\nTree, and AdaBoost. Data preprocessing techniques included resampling SMOTE\nmethod to address the class imbalance, feature selection for dimensionality\nreduction, and aggregation of diagnostic and procedural codes. Random Forest\nemerged as the best-performing model, achieving a training accuracy of 99.2%\nand validation accuracy of 98.8%, and F1-score (98.4%). The Decision Tree also\nperformed well, achieving a validation accuracy of 96.3%. KNN and AdaBoost\ndemonstrated moderate performance, with validation accuracies of 79.2% and\n81.1%, respectively, while LDA struggled with a validation accuracy of 63.3%\nand a low recall of 16.6%. The results highlight the importance of advanced\nresampling techniques, feature engineering, and adaptive learning in detecting\nMedicare fraud effectively. This study underscores the potential of machine\nlearning in addressing the complexities of fraud detection. Future work should\nexplore explainable AI and hybrid models to improve interpretability and\nperformance, ensuring scalable and reliable fraud detection systems that\nprotect healthcare resources and beneficiaries."}
{"id": "2502.15822", "title": "Financial fraud detection system based on improved random forest and gradient boosting machine (GBM)", "url": "https://arxiv.org/abs/2502.15822", "pdf": "https://arxiv.org/pdf/2502.15822", "abs": "https://arxiv.org/abs/2502.15822", "authors": ["Tianzuo Hu"], "categories": ["q-fin.ST", "cs.LG", "q-fin.GN", "stat.AP", "stat.ML"], "comment": null, "summary": "This paper proposes a financial fraud detection system based on improved\nRandom Forest (RF) and Gradient Boosting Machine (GBM). Specifically, the\nsystem introduces a novel model architecture called GBM-SSRF (Gradient Boosting\nMachine with Simplified and Strengthened Random Forest), which cleverly\ncombines the powerful optimization capabilities of the gradient boosting\nmachine (GBM) with improved randomization. The computational efficiency and\nfeature extraction capabilities of the Simplified and Strengthened Random\nForest (SSRF) forest significantly improve the performance of financial fraud\ndetection. Although the traditional random forest model has good classification\ncapabilities, it has high computational complexity when faced with large-scale\ndata and has certain limitations in feature selection. As a commonly used\nensemble learning method, the GBM model has significant advantages in\noptimizing performance and handling nonlinear problems. However, GBM takes a\nlong time to train and is prone to overfitting problems when data samples are\nunbalanced. In response to these limitations, this paper optimizes the random\nforest based on the structure, reducing the computational complexity and\nimproving the feature selection ability through the structural simplification\nand enhancement of the random forest. In addition, the optimized random forest\nis embedded into the GBM framework, and the model can maintain efficiency and\nstability with the help of GBM's gradient optimization capability. Experiments\nshow that the GBM-SSRF model not only has good performance, but also has good\nrobustness and generalization capabilities, providing an efficient and reliable\nsolution for financial fraud detection."}
{"id": "2409.15656", "title": "The First Early Evidence of the Use of Browser Fingerprinting for Online Tracking", "url": "https://arxiv.org/abs/2409.15656", "pdf": "https://arxiv.org/pdf/2409.15656", "abs": "https://arxiv.org/abs/2409.15656", "authors": ["Zengrui Liu", "Jimmy Dani", "Yinzhi Cao", "Shujiang Wu", "Nitesh Saxena"], "categories": ["cs.CR"], "comment": null, "summary": "While advertising has become commonplace in today's online interactions,\nthere is a notable dearth of research investigating the extent to which browser\nfingerprinting is harnessed for user tracking and targeted advertising. Prior\nstudies only measured whether fingerprinting-related scripts are being run on\nthe websites but that in itself does not necessarily mean that fingerprinting\nis being used for the privacy-invasive purpose of online tracking because\nfingerprinting might be deployed for the defensive purposes of bot/fraud\ndetection and user authentication. It is imperative to address the mounting\nconcerns regarding the utilization of browser fingerprinting in the realm of\nonline advertising.\n  This paper introduces ``FPTrace'' (fingerprinting-based tracking assessment\nand comprehensive evaluation framework), a framework to assess\nfingerprinting-based user tracking by analyzing ad changes from browser\nfingerprinting adjustments. Using FPTrace, we emulate user interactions,\ncapture ad bid data, and monitor HTTP traffic. Our large-scale study reveals\nstrong evidence of browser fingerprinting for ad tracking and targeting, shown\nby bid value disparities and reduced HTTP records after fingerprinting changes.\nWe also show fingerprinting can bypass GDPR/CCPA opt-outs, enabling\nprivacy-invasive tracking.\n  In conclusion, our research unveils the widespread employment of browser\nfingerprinting in online advertising, prompting critical considerations\nregarding user privacy and data security within the digital advertising\nlandscape."}
{"id": "2409.09770", "title": "Cluster Aware Graph Anomaly Detection", "url": "https://arxiv.org/abs/2409.09770", "pdf": "https://arxiv.org/pdf/2409.09770", "abs": "https://arxiv.org/abs/2409.09770", "authors": ["Lecheng Zheng", "John R. Birge", "Haiyue Wu", "Yifang Zhang", "Jingrui He"], "categories": ["cs.LG"], "comment": "Accepted by The Web Conference 2025", "summary": "Graph anomaly detection has gained significant attention across various\ndomains, particularly in critical applications like fraud detection in\ne-commerce platforms and insider threat detection in cybersecurity. Usually,\nthese data are composed of multiple types (e.g., user information and\ntransaction records for financial data), thus exhibiting view heterogeneity.\nHowever, in the era of big data, the heterogeneity of views and the lack of\nlabel information pose substantial challenges to traditional approaches.\nExisting unsupervised graph anomaly detection methods often struggle with\nhigh-dimensionality issues, rely on strong assumptions about graph structures\nor fail to handle complex multi-view graphs. To address these challenges, we\npropose a cluster aware multi-view graph anomaly detection method, called CARE.\nOur approach captures both local and global node affinities by augmenting the\ngraph's adjacency matrix with the pseudo-label (i.e., soft membership\nassignments) without any strong assumption about the graph. To mitigate\npotential biases from the pseudo-label, we introduce a similarity-guided loss.\nTheoretically, we show that the proposed similarity-guided loss is a variant of\ncontrastive learning loss, and we present how this loss alleviates the bias\nintroduced by pseudo-label with the connection to graph spectral clustering.\nExperimental results on several datasets demonstrate the effectiveness and\nefficiency of our proposed framework. Specifically, CARE outperforms the\nsecond-best competitors by more than 39% on the Amazon dataset with respect to\nAUPRC and 18.7% on the YelpChi dataset with respect to AUROC. The code of our\nmethod is available at the GitHub link:\nhttps://github.com/zhenglecheng/CARE-demo."}
{"id": "2409.07494", "title": "Ethereum Fraud Detection via Joint Transaction Language Model and Graph Representation Learning", "url": "https://arxiv.org/abs/2409.07494", "pdf": "https://arxiv.org/pdf/2409.07494", "abs": "https://arxiv.org/abs/2409.07494", "authors": ["Jianguo Sun", "Yifan Jia", "Yanbin Wang", "Yiwei Liu", "Zhang Sheng", "Ye Tian"], "categories": ["cs.CR", "cs.LG", "q-fin.GN"], "comment": null, "summary": "Ethereum faces growing fraud threats. Current fraud detection methods,\nwhether employing graph neural networks or sequence models, fail to consider\nthe semantic information and similarity patterns within transactions. Moreover,\nthese approaches do not leverage the potential synergistic benefits of\ncombining both types of models. To address these challenges, we propose\nTLMG4Eth that combines a transaction language model with graph-based methods to\ncapture semantic, similarity, and structural features of transaction data in\nEthereum. We first propose a transaction language model that converts numerical\ntransaction data into meaningful transaction sentences, enabling the model to\nlearn explicit transaction semantics. Then, we propose a transaction attribute\nsimilarity graph to learn transaction similarity information, enabling us to\ncapture intuitive insights into transaction anomalies. Additionally, we\nconstruct an account interaction graph to capture the structural information of\nthe account transaction network. We employ a deep multi-head attention network\nto fuse transaction semantic and similarity embeddings, and ultimately propose\na joint training approach for the multi-head attention network and the account\ninteraction graph to obtain the synergistic benefits of both."}
{"id": "2502.10624", "title": "Network evasion detection with Bi-LSTM model", "url": "https://arxiv.org/abs/2502.10624", "pdf": "https://arxiv.org/pdf/2502.10624", "abs": "https://arxiv.org/abs/2502.10624", "authors": ["Kehua Chen", "Jingping Jia"], "categories": ["cs.CR", "cs.AI"], "comment": "4 pages,5 figures", "summary": "Network evasion detection aims to distinguish whether the network flow comes\nfrom link layer exists network evasion threat, which is a means to disguise the\ndata traffic on detection system by confusing the signature. Since the previous\nresearch works has all sorts of frauds, we propose a architecture with deep\nlearning network to handle this problem. In this paper, we extract the critical\ninformation as key features from data frame and also specifically propose to\nuse bidirectional long short-term memory (Bi-LSTM) neural network which shows\nan outstanding performance to trace the serial information, to encode both the\npast and future trait on the network flows. Furthermore we introduce a\nclassifier named Softmax at the bottom of Bi-LSTM, holding a character to\nselect the correct class. All experiments results shows that we can achieve a\nsignificant performance with a deep Bi-LSTM in network evasion detection and\nit's average accuracy reaches 96.1%."}
{"id": "2502.10321", "title": "Dynamic Fraud Proof", "url": "https://arxiv.org/abs/2502.10321", "pdf": "https://arxiv.org/pdf/2502.10321", "abs": "https://arxiv.org/abs/2502.10321", "authors": ["Gabriele Picco", "Andrea Fortugno"], "categories": ["cs.CR", "cs.DC"], "comment": null, "summary": "In this paper, we present a novel fraud-proof mechanism that achieves fast\nfinality and, when combined with optimistic execution, enables real-time\ntransaction processing. State-of-the-art optimistic rollups typically adopt a\n7-day challenge window, during which any honest party can raise a challenge in\ncase of fraud. We propose a new assert/challenge construction called \"Dynamic\nFraud Proofs\" that achieves sub-second finality in ideal scenarios, while\ndynamically delaying settlement in the event of fraud detection and challenge\nresolution. The system relies on 1) a dynamic challenge period and 2) a\nconfigurable number of randomly selected verifier nodes who must interactively\napprove a state commitment without raising a challenge. If these conditions are\nnot met, the state is not finalized, and the challenge period and approval\ncriteria are dynamically adjusted. We provide a detailed analysis of the\nsystem's design, explaining how it maintains the assumption of a single honest\nnode and addresses censorship attacks by inverting the traditional challenge\nprocess. Additionally, we formalize the system's probabilistic security model\nand discuss how bonding, incentives, and slashing mechanisms can encourage\nhonest behavior, thereby increasing the likelihood of fast settlement in ideal\nscenarios."}
{"id": "2205.12706", "title": "Maximum Mean Discrepancy on Exponential Windows for Online Change Detection", "url": "https://arxiv.org/abs/2205.12706", "pdf": "https://arxiv.org/pdf/2205.12706", "abs": "https://arxiv.org/abs/2205.12706", "authors": ["Florian Kalinke", "Marco Heyden", "Georg Gntuni", "Edouard Fouché", "Klemens Böhm"], "categories": ["cs.LG", "I.2.6; H.1.1"], "comment": "Published in TMLR 02/25", "summary": "Detecting changes is of fundamental importance when analyzing data streams\nand has many applications, e.g., in predictive maintenance, fraud detection, or\nmedicine. A principled approach to detect changes is to compare the\ndistributions of observations within the stream to each other via hypothesis\ntesting. Maximum mean discrepancy (MMD), a (semi-)metric on the space of\nprobability distributions, provides powerful non-parametric two-sample tests on\nkernel-enriched domains. In particular, MMD is able to detect any disparity\nbetween distributions under mild conditions. However, classical MMD estimators\nsuffer from a quadratic runtime complexity, which renders their direct use for\nchange detection in data streams impractical. In this article, we propose a new\nchange detection algorithm, called Maximum Mean Discrepancy on Exponential\nWindows (MMDEW), that combines the benefits of MMD with an efficient\ncomputation based on exponential windows. We prove that MMDEW enjoys\npolylogarithmic runtime and logarithmic memory complexity and show empirically\nthat it outperforms the state of the art on benchmark data streams."}
{"id": "2502.07694", "title": "Methodology for Identifying Social Groups within a Transactional Graph", "url": "https://arxiv.org/abs/2502.07694", "pdf": "https://arxiv.org/pdf/2502.07694", "abs": "https://arxiv.org/abs/2502.07694", "authors": ["Maxence Morin", "Baptiste Hemery", "Fabrice Jeanne", "Estelle Pawlowski-Cherrier"], "categories": ["cs.SI"], "comment": null, "summary": "Social network analysis is pivotal for organizations aiming to leverage the\nvast amounts of data generated from user interactions on social media and other\ndigital platforms. These interactions often reveal complex social structures,\nsuch as tightly-knit groups based on common interests, which are crucial for\nenhancing service personalization or fraud detection. Traditional methods like\ncommunity detection and graph matching, while useful, often fall short of\naccurately identifying specific groups of users. This paper introduces a novel\nframework specifically designed to identify groups of users within\ntransactional graphs by focusing on the contextual and structural nuances that\ndefine these groups."}
{"id": "2402.17472", "title": "RAGFormer: Learning Semantic Attributes and Topological Structure for Fraud Detection", "url": "https://arxiv.org/abs/2402.17472", "pdf": "https://arxiv.org/pdf/2402.17472", "abs": "https://arxiv.org/abs/2402.17472", "authors": ["Haolin Li", "Shuyang Jiang", "Lifeng Zhang", "Siyuan Du", "Guangnan Ye", "Hongfeng Chai"], "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Fraud detection remains a challenging task due to the complex and deceptive\nnature of fraudulent activities. Current approaches primarily concentrate on\nlearning only one perspective of the graph: either the topological structure of\nthe graph or the attributes of individual nodes. However, we conduct empirical\nstudies to reveal that these two types of features, while nearly orthogonal,\nare each independently effective. As a result, previous methods can not fully\ncapture the comprehensive characteristics of the fraud graph. To address this\ndilemma, we present a novel framework called Relation-Aware GNN with\ntransFormer~(RAGFormer) which simultaneously embeds both semantic and\ntopological features into a target node. The simple yet effective network\nconsists of a semantic encoder, a topology encoder, and an attention fusion\nmodule. The semantic encoder utilizes Transformer to learn semantic features\nand node interactions across different relations. We introduce Relation-Aware\nGNN as the topology encoder to learn topological features and node interactions\nwithin each relation. These two complementary features are interleaved through\nan attention fusion module to support prediction by both orthogonal features.\nExtensive experiments on two popular public datasets demonstrate that RAGFormer\nachieves state-of-the-art performance. The significant improvement of RAGFormer\nin an industrial credit card fraud detection dataset further validates the\napplicability of our method in real-world business scenarios."}
{"id": "2501.17903", "title": "Free Agent in Agent-Based Mixture-of-Experts Generative AI Framework", "url": "https://arxiv.org/abs/2501.17903", "pdf": "https://arxiv.org/pdf/2501.17903", "abs": "https://arxiv.org/abs/2501.17903", "authors": ["Jung-Hua Liu"], "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Multi-agent systems commonly distribute tasks among specialized, autonomous\nagents, yet they often lack mechanisms to replace or reassign underperforming\nagents in real time. Inspired by the free-agency model of Major League\nBaseball, the Reinforcement Learning Free Agent (RLFA) algorithm introduces a\nreward-based mechanism to detect and remove agents exhibiting persistent\nunderperformance and seamlessly insert more capable ones. Each agent internally\nuses a mixture-of-experts (MoE) approach, delegating incoming tasks to\nspecialized sub-models under the guidance of a gating function. A primary use\ncase is fraud detection, where RLFA promptly swaps out an agent whose detection\naccuracy dips below a preset threshold. A new agent is tested in a probationary\nmode, and upon demonstrating superior performance, fully replaces the\nunderperformer. This dynamic, free-agency cycle ensures sustained accuracy,\nquicker adaptation to emerging threats, and minimal disruption to ongoing\noperations. By continually refreshing its roster of agents, the system fosters\nongoing improvements and more resilient collaboration in multi-agent Generative\nAI environments."}
{"id": "2410.10929", "title": "ASTM :Autonomous Smart Traffic Management System Using Artificial Intelligence CNN and LSTM", "url": "https://arxiv.org/abs/2410.10929", "pdf": "https://arxiv.org/pdf/2410.10929", "abs": "https://arxiv.org/abs/2410.10929", "authors": ["Christofel Rio Goenawan"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Novel Autonomous Smart Traffic Management System using End-to-End\n  Artificial Intelligence", "summary": "In the modern world, the development of Artificial Intelligence (AI) has\ncontributed to improvements in various areas, including automation, computer\nvision, fraud detection, and more. AI can be leveraged to enhance the\nefficiency of Autonomous Smart Traffic Management (ASTM) systems and reduce\ntraffic congestion rates. This paper presents an Autonomous Smart Traffic\nManagement (STM) system that uses AI to improve traffic flow rates. The system\nemploys the YOLO V5 Convolutional Neural Network to detect vehicles in traffic\nmanagement images. Additionally, it predicts the number of vehicles for the\nnext 12 hours using a Recurrent Neural Network with Long Short-Term Memory\n(RNN-LSTM). The Smart Traffic Management Cycle Length Analysis manages the\ntraffic cycle length based on these vehicle predictions, aided by AI. From the\nresults of the RNN-LSTM model for predicting vehicle numbers over the next 12\nhours, we observe that the model predicts traffic with a Mean Squared Error\n(MSE) of 4.521 vehicles and a Root Mean Squared Error (RMSE) of 2.232 vehicles.\nAfter simulating the STM system in the CARLA simulation environment, we found\nthat the Traffic Management Congestion Flow Rate with ASTM (21 vehicles per\nminute) is 50\\% higher than the rate without STM (around 15 vehicles per\nminute). Additionally, the Traffic Management Vehicle Pass Delay with STM (5\nseconds per vehicle) is 70\\% lower than without STM (around 12 seconds per\nvehicle). These results demonstrate that the STM system using AI can increase\ntraffic flow by 50\\% and reduce vehicle pass delays by 70\\%."}
{"id": "2503.22681", "title": "detectGNN: Harnessing Graph Neural Networks for Enhanced Fraud Detection in Credit Card Transactions", "url": "https://arxiv.org/abs/2503.22681", "pdf": "https://arxiv.org/pdf/2503.22681", "abs": "https://arxiv.org/abs/2503.22681", "authors": ["Irin Sultana", "Syed Mustavi Maheen", "Naresh Kshetri", "Md Nasim Fardous Zim"], "categories": ["cs.CR"], "comment": "13 pages, 1 figure", "summary": "Credit card fraud is a major issue nowadays, costing huge money and affecting\ntrust in financial systems. Traditional fraud detection methods often fail to\ndetect advanced and growing fraud techniques. This study focuses on using Graph\nNeural Networks (GNNs) to improve fraud detection by analyzing transactions as\na network of connected data points, such as accounts, traders, and devices. The\nproposed \"detectGNN\" model uses advanced features like time-based patterns and\ndynamic updates to expose hidden fraud and improve detection accuracy. Tests\nshow that GNNs perform better than traditional methods in finding complex and\nmulti-layered fraud. The model also addresses real-time processing, data\nimbalance, and privacy concerns, making it practical for real-world use. This\nresearch shows that GNNs can provide a powerful, accurate, and a scalable\nsolution for detecting fraud. Future work will focus on making the models\neasier to understand, privacy-friendly, and adaptable to new types of fraud,\nensuring safer financial transactions in the digital world."}
{"id": "2502.03386", "title": "A Structured Reasoning Framework for Unbalanced Data Classification Using Probabilistic Models", "url": "https://arxiv.org/abs/2502.03386", "pdf": "https://arxiv.org/pdf/2502.03386", "abs": "https://arxiv.org/abs/2502.03386", "authors": ["Junliang Du", "Shiyu Dou", "Bohuan Yang", "Jiacheng Hu", "Tai An"], "categories": ["cs.LG"], "comment": null, "summary": "This paper studies a Markov network model for unbalanced data, aiming to\nsolve the problems of classification bias and insufficient minority class\nrecognition ability of traditional machine learning models in environments with\nuneven class distribution. By constructing joint probability distribution and\nconditional dependency, the model can achieve global modeling and reasoning\noptimization of sample categories. The study introduced marginal probability\nestimation and weighted loss optimization strategies, combined with\nregularization constraints and structured reasoning methods, effectively\nimproving the generalization ability and robustness of the model. In the\nexperimental stage, a real credit card fraud detection dataset was selected and\ncompared with models such as logistic regression, support vector machine,\nrandom forest and XGBoost. The experimental results show that the Markov\nnetwork performs well in indicators such as weighted accuracy, F1 score, and\nAUC-ROC, significantly outperforming traditional classification models,\ndemonstrating its strong decision-making ability and applicability in\nunbalanced data scenarios. Future research can focus on efficient model\ntraining, structural optimization, and deep learning integration in large-scale\nunbalanced data environments and promote its wide application in practical\napplications such as financial risk control, medical diagnosis, and intelligent\nmonitoring."}
{"id": "2502.02290", "title": "FRAUD-RLA: A new reinforcement learning adversarial attack against credit card fraud detection", "url": "https://arxiv.org/abs/2502.02290", "pdf": "https://arxiv.org/pdf/2502.02290", "abs": "https://arxiv.org/abs/2502.02290", "authors": ["Daniele Lunghi", "Yannick Molinghen", "Alkis Simitsis", "Tom Lenaerts", "Gianluca Bontempi"], "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Adversarial attacks pose a significant threat to data-driven systems, and\nresearchers have spent considerable resources studying them. Despite its\neconomic relevance, this trend largely overlooked the issue of credit card\nfraud detection. To address this gap, we propose a new threat model that\ndemonstrates the limitations of existing attacks and highlights the necessity\nto investigate new approaches. We then design a new adversarial attack for\ncredit card fraud detection, employing reinforcement learning to bypass\nclassifiers. This attack, called FRAUD-RLA, is designed to maximize the\nattacker's reward by optimizing the exploration-exploitation tradeoff and\nworking with significantly less required knowledge than competitors. Our\nexperiments, conducted on three different heterogeneous datasets and against\ntwo fraud detection systems, indicate that FRAUD-RLA is effective, even\nconsidering the severe limitations imposed by our threat model."}
{"id": "2501.18417", "title": "Real-Time Anomaly Detection with Synthetic Anomaly Monitoring (SAM)", "url": "https://arxiv.org/abs/2501.18417", "pdf": "https://arxiv.org/pdf/2501.18417", "abs": "https://arxiv.org/abs/2501.18417", "authors": ["Emanuele Luzio", "Moacir Antonelli Ponti"], "categories": ["cs.LG", "62H30, 68T05, 62G99, 91G80, 68M10", "I.5.4; K.6.5; I.2.6; H.4.2"], "comment": "19 pages, 3 figures, submitted for publication", "summary": "Anomaly detection is essential for identifying rare and significant events\nacross diverse domains such as finance, cybersecurity, and network monitoring.\nThis paper presents Synthetic Anomaly Monitoring (SAM), an innovative approach\nthat applies synthetic control methods from causal inference to improve both\nthe accuracy and interpretability of anomaly detection processes. By modeling\nnormal behavior through the treatment of each feature as a control unit, SAM\nidentifies anomalies as deviations within this causal framework. We conducted\nextensive experiments comparing SAM with established benchmark models,\nincluding Isolation Forest, Local Outlier Factor (LOF), k-Nearest Neighbors\n(kNN), and One-Class Support Vector Machine (SVM), across five diverse\ndatasets, including Credit Card Fraud, HTTP Dataset CSIC 2010, and KDD Cup\n1999, among others. Our results demonstrate that SAM consistently delivers\nrobust performance, highlighting its potential as a powerful tool for real-time\nanomaly detection in dynamic and complex environments."}
{"id": "2502.01193", "title": "SigN: SIMBox Activity Detection Through Latency Anomalies at the Cellular Edge", "url": "https://arxiv.org/abs/2502.01193", "pdf": "https://arxiv.org/pdf/2502.01193", "abs": "https://arxiv.org/abs/2502.01193", "authors": ["Anne Josiane Kouam", "Aline Carneiro Viana", "Philippe Martins", "Cedric Adjih", "Alain Tchana"], "categories": ["cs.NI"], "comment": null, "summary": "Despite their widespread adoption, cellular networks face growing\nvulnerabilities due to their inherent complexity and the integration of\nadvanced technologies. One of the major threats in this landscape is Voice over\nIP (VoIP) to GSM gateways, known as SIMBox devices. These devices use multiple\nSIM cards to route VoIP traffic through cellular networks, enabling\ninternational bypass fraud with losses of up to $3.11 billion annually. Beyond\nfinancial impact, SIMBox activity degrades network performance, threatens\nnational security, and facilitates eavesdropping on communications. Existing\ndetection methods for SIMBox activity are hindered by evolving fraud techniques\nand implementation complexities, limiting their practical adoption in operator\nnetworks.This paper addresses the limitations of current detection methods by\nintroducing SigN , a novel approach to identifying SIMBox activity at the\ncellular edge. The proposed method focuses on detecting remote SIM card\nassociation, a technique used by SIMBox appliances to mimic human mobility\npatterns. The method detects latency anomalies between SIMBox and standard\ndevices by analyzing cellular signaling during network attachment. Extensive\nindoor and outdoor experiments demonstrate that SIMBox devices generate\nsignificantly higher attachment latencies, particularly during the\nauthentication phase, where latency is up to 23 times greater than that of\nstandard devices. We attribute part of this overhead to immutable factors such\nas LTE authentication standards and Internet-based communication protocols.\nTherefore, our approach offers a robust, scalable, and practical solution to\nmitigate SIMBox activity risks at the network edge."}
{"id": "2502.00612", "title": "Using Causality for Enhanced Prediction of Web Traffic Time Series", "url": "https://arxiv.org/abs/2502.00612", "pdf": "https://arxiv.org/pdf/2502.00612", "abs": "https://arxiv.org/abs/2502.00612", "authors": ["Chang Tian", "Mingzhe Xing", "Zenglin Shi", "Matthew B. Blaschko", "Yinliang Yue", "Marie-Francine Moens"], "categories": ["cs.LG", "cs.NI"], "comment": "time series, web service, web traffic, causality", "summary": "Predicting web service traffic has significant social value, as it can be\napplied to various practical scenarios, including but not limited to dynamic\nresource scaling, load balancing, system anomaly detection, service-level\nagreement compliance, and fraud detection. Web service traffic is characterized\nby frequent and drastic fluctuations over time and are influenced by\nheterogeneous web user behaviors, making accurate prediction a challenging\ntask. Previous research has extensively explored statistical approaches, and\nneural networks to mine features from preceding service traffic time series for\nprediction. However, these methods have largely overlooked the causal\nrelationships between services. Drawing inspiration from causality in\necological systems, we empirically recognize the causal relationships between\nweb services. To leverage these relationships for improved web service traffic\nprediction, we propose an effective neural network module, CCMPlus, designed to\nextract causal relationship features across services. This module can be\nseamlessly integrated with existing time series models to consistently enhance\nthe performance of web service traffic predictions. We theoretically justify\nthat the causal correlation matrix generated by the CCMPlus module captures\ncausal relationships among services. Empirical results on real-world datasets\nfrom Microsoft Azure, Alibaba Group, and Ant Group confirm that our method\nsurpasses state-of-the-art approaches in Mean Squared Error (MSE) and Mean\nAbsolute Error (MAE) for predicting service traffic time series. These findings\nhighlight the efficacy of leveraging causal relationships for improved\npredictions."}
{"id": "2502.00529", "title": "Graph Data Management and Graph Machine Learning: Synergies and Opportunities", "url": "https://arxiv.org/abs/2502.00529", "pdf": "https://arxiv.org/pdf/2502.00529", "abs": "https://arxiv.org/abs/2502.00529", "authors": ["Arijit Khan", "Xiangyu Ke", "Yinghui Wu"], "categories": ["cs.DB"], "comment": "15 pages, 1 figure", "summary": "The ubiquity of machine learning, particularly deep learning, applied to\ngraphs is evident in applications ranging from cheminformatics (drug discovery)\nand bioinformatics (protein interaction prediction) to knowledge graph-based\nquery answering, fraud detection, and social network analysis. Concurrently,\ngraph data management deals with the research and development of effective,\nefficient, scalable, robust, and user-friendly systems and algorithms for\nstoring, processing, and analyzing vast quantities of heterogeneous and complex\ngraph data. Our survey provides a comprehensive overview of the synergies\nbetween graph data management and graph machine learning, illustrating how they\nintertwine and mutually reinforce each other across the entire spectrum of the\ngraph data science and machine learning pipeline. Specifically, the survey\nhighlights two crucial aspects: (1) How graph data management enhances graph\nmachine learning, including contributions such as improved graph neural network\nperformance through graph data cleaning, scalable graph embedding, efficient\ngraph-based vector data management, robust graph neural networks, user-friendly\nexplainability methods; and (2) how graph machine learning, in turn, aids in\ngraph data management, with a focus on applications like query answering over\nknowledge graphs and various data science tasks. We discuss pertinent open\nproblems and delineate crucial research directions."}
{"id": "2502.00201", "title": "Year-over-Year Developments in Financial Fraud Detection via Deep Learning: A Systematic Literature Review", "url": "https://arxiv.org/abs/2502.00201", "pdf": "https://arxiv.org/pdf/2502.00201", "abs": "https://arxiv.org/abs/2502.00201", "authors": ["Yisong Chen", "Chuqing Zhao", "Yixin Xu", "Chuanhao Nie"], "categories": ["cs.LG", "cs.AI", "q-fin.ST"], "comment": null, "summary": "This paper systematically reviews advancements in deep learning (DL)\ntechniques for financial fraud detection, a critical issue in the financial\nsector. Using the Kitchenham systematic literature review approach, 57 studies\npublished between 2019 and 2024 were analyzed. The review highlights the\neffectiveness of various deep learning models such as Convolutional Neural\nNetworks, Long Short-Term Memory, and transformers across domains such as\ncredit card transactions, insurance claims, and financial statement audits.\nPerformance metrics such as precision, recall, F1-score, and AUC-ROC were\nevaluated. Key themes explored include the impact of data privacy frameworks\nand advancements in feature engineering and data preprocessing. The study\nemphasizes challenges such as imbalanced datasets, model interpretability, and\nethical considerations, alongside opportunities for automation and\nprivacy-preserving techniques such as blockchain integration and Principal\nComponent Analysis. By examining trends over the past five years, this review\nidentifies critical gaps and promising directions for advancing DL applications\nin financial fraud detection, offering actionable insights for researchers and\npractitioners."}
{"id": "2501.19267", "title": "Transformer-Based Financial Fraud Detection with Cloud-Optimized Real-Time Streaming", "url": "https://arxiv.org/abs/2501.19267", "pdf": "https://arxiv.org/pdf/2501.19267", "abs": "https://arxiv.org/abs/2501.19267", "authors": ["Tingting Deng", "Shuochen Bi", "Jue Xiao"], "categories": ["cs.CE"], "comment": "8 Pages, 3 figures, 2 Tables. arXiv admin note: text overlap with\n  arXiv:2406.03733 by other authors", "summary": "As the financial industry becomes more interconnected and reliant on digital\nsystems, fraud detection systems must evolve to meet growing threats.\nCloud-enabled Transformer models present a transformative opportunity to\naddress these challenges. By leveraging the scalability, flexibility, and\nadvanced AI capabilities of cloud platforms, companies can deploy fraud\ndetection solutions that adapt to real-time data patterns and proactively\nrespond to evolving threats. Using the Graph self-attention Transformer neural\nnetwork module, we can directly excavate gang fraud features from the\ntransaction network without constructing complicated feature engineering.\nFinally, the fraud prediction network is combined to optimize the topological\npattern and the temporal transaction pattern to realize the high-precision\ndetection of fraudulent transactions. The results of antifraud experiments on\ncredit card transaction data show that the proposed model outperforms the 7\nbaseline models on all evaluation indicators: In the transaction fraud\ndetection task, the average accuracy (AP) increased by 20% and the area under\nthe ROC curve (AUC) increased by 2.7% on average compared with the benchmark\ngraph attention neural network (GAT), which verified the effectiveness of the\nproposed model in the detection of credit card fraud transactions."}
{"id": "2501.15290", "title": "Advanced Real-Time Fraud Detection Using RAG-Based LLMs", "url": "https://arxiv.org/abs/2501.15290", "pdf": "https://arxiv.org/pdf/2501.15290", "abs": "https://arxiv.org/abs/2501.15290", "authors": ["Gurjot Singh", "Prabhjot Singh", "Maninder Singh"], "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Artificial Intelligence has become a double edged sword in modern society\nbeing both a boon and a bane. While it empowers individuals it also enables\nmalicious actors to perpetrate scams such as fraudulent phone calls and user\nimpersonations. This growing threat necessitates a robust system to protect\nindividuals In this paper we introduce a novel real time fraud detection\nmechanism using Retrieval Augmented Generation technology to address this\nchallenge on two fronts. First our system incorporates a continuously updating\npolicy checking feature that transcribes phone calls in real time and uses RAG\nbased models to verify that the caller is not soliciting private information\nthus ensuring transparency and the authenticity of the conversation. Second we\nimplement a real time user impersonation check with a two step verification\nprocess to confirm the callers identity ensuring accountability. A key\ninnovation of our system is the ability to update policies without retraining\nthe entire model enhancing its adaptability. We validated our RAG based\napproach using synthetic call recordings achieving an accuracy of 97.98 percent\nand an F1score of 97.44 percent with 100 calls outperforming state of the art\nmethods. This robust and flexible fraud detection system is well suited for\nreal world deployment."}
{"id": "2306.01951", "title": "GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction", "url": "https://arxiv.org/abs/2306.01951", "pdf": "https://arxiv.org/pdf/2306.01951", "abs": "https://arxiv.org/abs/2306.01951", "authors": ["Amit Roy", "Juan Shu", "Jia Li", "Carl Yang", "Olivier Elshocht", "Jeroen Smeets", "Pan Li"], "categories": ["cs.LG"], "comment": "Accepted at the 17th ACM International Conference on Web Search and\n  Data Mining (WSDM-2024)", "summary": "Graph Anomaly Detection (GAD) is a technique used to identify abnormal nodes\nwithin graphs, finding applications in network security, fraud detection,\nsocial media spam detection, and various other domains. A common method for GAD\nis Graph Auto-Encoders (GAEs), which encode graph data into node\nrepresentations and identify anomalies by assessing the reconstruction quality\nof the graphs based on these representations. However, existing GAE models are\nprimarily optimized for direct link reconstruction, resulting in nodes\nconnected in the graph being clustered in the latent space. As a result, they\nexcel at detecting cluster-type structural anomalies but struggle with more\ncomplex structural anomalies that do not conform to clusters. To address this\nlimitation, we propose a novel solution called GAD-NR, a new variant of GAE\nthat incorporates neighborhood reconstruction for graph anomaly detection.\nGAD-NR aims to reconstruct the entire neighborhood of a node, encompassing the\nlocal structure, self-attributes, and neighbor attributes, based on the\ncorresponding node representation. By comparing the neighborhood reconstruction\nloss between anomalous nodes and normal nodes, GAD-NR can effectively detect\nany anomalies. Extensive experimentation conducted on six real-world datasets\nvalidates the effectiveness of GAD-NR, showcasing significant improvements (by\nup to 30% in AUC) over state-of-the-art competitors. The source code for GAD-NR\nis openly available. Importantly, the comparative analysis reveals that the\nexisting methods perform well only in detecting one or two types of anomalies\nout of the three types studied. In contrast, GAD-NR excels at detecting all\nthree types of anomalies across the datasets, demonstrating its comprehensive\nanomaly detection capabilities."}
{"id": "2501.12560", "title": "Improved Detection and Diagnosis of Faults in Deep Neural Networks Using Hierarchical and Explainable Classification", "url": "https://arxiv.org/abs/2501.12560", "pdf": "https://arxiv.org/pdf/2501.12560", "abs": "https://arxiv.org/abs/2501.12560", "authors": ["Sigma Jahan", "Mehil B Shah", "Parvez Mahbub", "Mohammad Masudur Rahman"], "categories": ["cs.SE"], "comment": null, "summary": "Deep Neural Networks (DNN) have found numerous applications in various\ndomains, including fraud detection, medical diagnosis, facial recognition, and\nautonomous driving. However, DNN-based systems often suffer from reliability\nissues due to their inherent complexity and the stochastic nature of their\nunderlying models. Unfortunately, existing techniques to detect faults in DNN\nprograms are either limited by the types of faults (e.g., hyperparameter or\nlayer) they support or the kind of information (e.g., dynamic or static) they\nuse. As a result, they might fall short of comprehensively detecting and\ndiagnosing the faults. In this paper, we present DEFault (Detect and Explain\nFault) -- a novel technique to detect and diagnose faults in DNN programs. It\nfirst captures dynamic (i.e., runtime) features during model training and\nleverages a hierarchical classification approach to detect all major fault\ncategories from the literature. Then, it captures static features (e.g., layer\ntypes) from DNN programs and leverages explainable AI methods (e.g., SHAP) to\nnarrow down the root cause of the fault. We train and evaluate DEFault on a\nlarge, diverse dataset of ~14.5K DNN programs and further validate our\ntechnique using a benchmark dataset of 52 real-life faulty DNN programs. Our\napproach achieves ~94% recall in detecting real-world faulty DNN programs and\n~63% recall in diagnosing the root causes of the faults, demonstrating 3.92% -\n11.54% higher performance than that of state-of-the-art techniques. Thus,\nDEFault has the potential to significantly improve the reliability of DNN\nprograms by effectively detecting and diagnosing the faults."}
{"id": "2501.12491", "title": "Optimizing Blockchain Analysis: Tackling Temporality and Scalability with an Incremental Approach with Metropolis-Hastings Random Walks", "url": "https://arxiv.org/abs/2501.12491", "pdf": "https://arxiv.org/pdf/2501.12491", "abs": "https://arxiv.org/abs/2501.12491", "authors": ["Junliang Luo", "Xue Liu"], "categories": ["cs.CE", "stat.ML"], "comment": "accepted at the 18th ACM International Conference on Web Search and\n  Data Mining (ACM WSDM 2025)", "summary": "Blockchain technology, with implications in the financial domain, offers data\nin the form of large-scale transaction networks. Analyzing transaction networks\nfacilitates fraud detection, market analysis, and supports government\nregulation. Despite many graph representation learning methods for transaction\nnetwork analysis, we pinpoint two salient limitations that merit more\ninvestigation. Existing methods predominantly focus on the snapshots of\ntransaction networks, sidelining the evolving nature of blockchain transaction\nnetworks. Existing methodologies may not sufficiently emphasize efficient,\nincremental learning capabilities, which are essential for addressing the\nscalability challenges in ever-expanding large-scale transaction networks. To\naddress these challenges, we employed an incremental approach for random\nwalk-based node representation learning in transaction networks. Further, we\nproposed a Metropolis-Hastings-based random walk mechanism for improved\nefficiency. The empirical evaluation conducted on blockchain transaction\ndatasets reveals comparable performance in node classification tasks while\nreducing computational overhead. Potential applications include transaction\nnetwork monitoring, the efficient classification of blockchain addresses for\nfraud detection or the identification of specialized address types within the\nnetwork."}
{"id": "2501.12430", "title": "SCFCRC: Simultaneously Counteract Feature Camouflage and Relation Camouflage for Fraud Detection", "url": "https://arxiv.org/abs/2501.12430", "pdf": "https://arxiv.org/pdf/2501.12430", "abs": "https://arxiv.org/abs/2501.12430", "authors": ["Xiaocheng Zhang", "Zhuangzhuang Ye", "GuoPing Zhao", "Jianing Wang", "Xiaohong Su"], "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In fraud detection, fraudsters often interact with many benign users,\ncamouflaging their features or relations to hide themselves. Most existing work\nconcentrates solely on either feature camouflage or relation camouflage, or\ndecoupling feature learning and relation learning to avoid the two camouflage\nfrom affecting each other. However, this inadvertently neglects the valuable\ninformation derived from features or relations, which could mutually enhance\ntheir adversarial camouflage strategies. In response to this gap, we propose\nSCFCRC, a Transformer-based fraud detector that Simultaneously Counteract\nFeature Camouflage and Relation Camouflage. SCFCRC consists of two components:\nFeature Camouflage Filter and Relation Camouflage Refiner. The feature\ncamouflage filter utilizes pseudo labels generated through label propagation to\ntrain the filter and uses contrastive learning that combines instance-wise and\nprototype-wise to improve the quality of features. The relation camouflage\nrefiner uses Mixture-of-Experts(MoE) network to disassemble the multi-relations\ngraph into multiple substructures and divide and conquer them to mitigate the\ndegradation of detection performance caused by relation camouflage.\nFurthermore, we introduce a regularization method for MoE to enhance the\nrobustness of the model. Extensive experiments on two fraud detection benchmark\ndatasets demonstrate that our method outperforms state-of-the-art baselines."}
{"id": "2501.11902", "title": "Transferable Adversarial Attacks on Audio Deepfake Detection", "url": "https://arxiv.org/abs/2501.11902", "pdf": "https://arxiv.org/pdf/2501.11902", "abs": "https://arxiv.org/abs/2501.11902", "authors": ["Muhammad Umar Farooq", "Awais Khan", "Kutub Uddin", "Khalid Mahmood Malik"], "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Audio deepfakes pose significant threats, including impersonation, fraud, and\nreputation damage. To address these risks, audio deepfake detection (ADD)\ntechniques have been developed, demonstrating success on benchmarks like\nASVspoof2019. However, their resilience against transferable adversarial\nattacks remains largely unexplored. In this paper, we introduce a transferable\nGAN-based adversarial attack framework to evaluate the effectiveness of\nstate-of-the-art (SOTA) ADD systems. By leveraging an ensemble of surrogate ADD\nmodels and a discriminator, the proposed approach generates transferable\nadversarial attacks that better reflect real-world scenarios. Unlike previous\nmethods, the proposed framework incorporates a self-supervised audio model to\nensure transcription and perceptual integrity, resulting in high-quality\nadversarial attacks. Experimental results on benchmark dataset reveal that SOTA\nADD systems exhibit significant vulnerabilities, with accuracies dropping from\n98% to 26%, 92% to 54%, and 94% to 84% in white-box, gray-box, and black-box\nscenarios, respectively. When tested in other data sets, performance drops of\n91% to 46%, and 94% to 67% were observed against the In-the-Wild and WaveFake\ndata sets, respectively. These results highlight the significant\nvulnerabilities of existing ADD systems and emphasize the need to enhance their\nrobustness against advanced adversarial threats to ensure security and\nreliability."}
{"id": "2412.16788", "title": "DCOR: Anomaly Detection in Attributed Networks via Dual Contrastive Learning Reconstruction", "url": "https://arxiv.org/abs/2412.16788", "pdf": "https://arxiv.org/pdf/2412.16788", "abs": "https://arxiv.org/abs/2412.16788", "authors": ["Hossein Rafieizadeh", "Hadi Zare", "Mohsen Ghassemi Parsa", "Hadi Davardoust", "Meshkat Shariat Bagheri"], "categories": ["cs.AI", "05C82 05C82 05C82 05C82", "I.2.6; G.2.2"], "comment": "Accepted at the Thirteenth International Conference on Complex\n  Networks and Their Applications", "summary": "Anomaly detection using a network-based approach is one of the most efficient\nways to identify abnormal events such as fraud, security breaches, and system\nfaults in a variety of applied domains. While most of the earlier works address\nthe complex nature of graph-structured data and predefined anomalies, the\nimpact of data attributes and emerging anomalies are often neglected. This\npaper introduces DCOR, a novel approach on attributed networks that integrates\nreconstruction-based anomaly detection with Contrastive Learning. Utilizing a\nGraph Neural Network (GNN) framework, DCOR contrasts the reconstructed\nadjacency and feature matrices from both the original and augmented graphs to\ndetect subtle anomalies. We employed comprehensive experimental studies on\nbenchmark datasets through standard evaluation measures. The results show that\nDCOR significantly outperforms state-of-the-art methods. Obtained results\ndemonstrate the efficacy of proposed approach in attributed networks with the\npotential of uncovering new patterns of anomalies."}
{"id": "2501.10803", "title": "\"Auntie, Please Don't Fall for Those Smooth Talkers\": How Chinese Younger Family Members Safeguard Seniors from Online Fraud", "url": "https://arxiv.org/abs/2501.10803", "pdf": "https://arxiv.org/pdf/2501.10803", "abs": "https://arxiv.org/abs/2501.10803", "authors": ["Yue Deng", "Changyang He", "Yixin Zou", "Bo Li"], "categories": ["cs.HC"], "comment": "27 pages, 3 figures. Proceedings of the 2025 CHI Conference on Human\n  Factors in Computing Systems (CHI '25), April 26-May 1, 2025, Yokohama, Japan", "summary": "Online fraud substantially harms individuals and seniors are\ndisproportionately targeted. While family is crucial for seniors, little\nresearch has empirically examined how they protect seniors against fraud. To\naddress this gap, we employed an inductive thematic analysis of 124 posts and\n16,872 comments on RedNote (Xiaohongshu), exploring the family support\necosystem for senior-targeted online fraud in China. We develop a taxonomy of\nsenior-targeted online fraud from a familial perspective, revealing younger\nmembers often spot frauds hard for seniors to detect, such as unusual charges.\nYounger family members fulfill multiple safeguarding roles, including\npreventative measures, fraud identification, fraud persuasion, loss recovery,\nand education. They also encounter numerous challenges, such as seniors'\nrefusal of help and considerable mental and financial stress. Drawing on these,\nwe develop a conceptual framework to characterize family support in\nsenior-targeted fraud, and outline implications for researchers and\npractitioners to consider the broader stakeholder ecosystem and cultural\naspects."}
{"id": "2501.10111", "title": "AI-Generated Music Detection and its Challenges", "url": "https://arxiv.org/abs/2501.10111", "pdf": "https://arxiv.org/pdf/2501.10111", "abs": "https://arxiv.org/abs/2501.10111", "authors": ["Darius Afchar", "Gabriel Meseguer-Brocal", "Romain Hennequin"], "categories": ["cs.SD", "eess.AS"], "comment": "Accepted for IEEE ICASSP 2025. arXiv admin note: substantial text\n  overlap with arXiv:2405.04181", "summary": "In the face of a new era of generative models, the detection of artificially\ngenerated content has become a matter of utmost importance. In particular, the\nability to create credible minute-long synthetic music in a few seconds on\nuser-friendly platforms poses a real threat of fraud on streaming services and\nunfair competition to human artists. This paper demonstrates the possibility\n(and surprising ease) of training classifiers on datasets comprising real audio\nand artificial reconstructions, achieving a convincing accuracy of 99.8%. To\nour knowledge, this marks the first publication of a AI-music detector, a tool\nthat will help in the regulation of synthetic media. Nevertheless, informed by\ndecades of literature on forgery detection in other fields, we stress that\ngetting a good test score is not the end of the story. We expose and discuss\nseveral facets that could be problematic with such a deployed detector:\nrobustness to audio manipulation, generalisation to unseen models. This second\npart acts as a position for future research steps in the field and a caveat to\na flourishing market of artificial content checkers."}
{"id": "2501.09239", "title": "AI-based Identity Fraud Detection: A Systematic Review", "url": "https://arxiv.org/abs/2501.09239", "pdf": "https://arxiv.org/pdf/2501.09239", "abs": "https://arxiv.org/abs/2501.09239", "authors": ["Chuo Jun Zhang", "Asif Q. Gill", "Bo Liu", "Memoona J. Anwar"], "categories": ["cs.AI"], "comment": null, "summary": "With the rapid development of digital services, a large volume of personally\nidentifiable information (PII) is stored online and is subject to cyberattacks\nsuch as Identity fraud. Most recently, the use of Artificial Intelligence (AI)\nenabled deep fake technologies has significantly increased the complexity of\nidentity fraud. Fraudsters may use these technologies to create highly\nsophisticated counterfeit personal identification documents, photos and videos.\nThese advancements in the identity fraud landscape pose challenges for identity\nfraud detection and society at large. There is a pressing need to review and\nunderstand identity fraud detection methods, their limitations and potential\nsolutions. This research aims to address this important need by using the\nwell-known systematic literature review method. This paper reviewed a selected\nset of 43 papers across 4 major academic literature databases. In particular,\nthe review results highlight the two types of identity fraud prevention and\ndetection methods, in-depth and open challenges. The results were also\nconsolidated into a taxonomy of AI-based identity fraud detection and\nprevention methods including key insights and trends. Overall, this paper\nprovides a foundational knowledge base to researchers and practitioners for\nfurther research and development in this important area of digital identity\nfraud."}
{"id": "2501.09166", "title": "Attention is All You Need Until You Need Retention", "url": "https://arxiv.org/abs/2501.09166", "pdf": "https://arxiv.org/pdf/2501.09166", "abs": "https://arxiv.org/abs/2501.09166", "authors": ["M. Murat Yaslioglu"], "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This work introduces a novel Retention Layer mechanism for Transformer based\narchitectures, addressing their inherent lack of intrinsic retention\ncapabilities. Unlike human cognition, which can encode and dynamically recall\nsymbolic templates, Generative Pretrained Transformers rely solely on fixed\npretrained weights and ephemeral context windows, limiting their adaptability.\nThe proposed Retention Layer incorporates a persistent memory module capable of\nreal time data population, dynamic recall, and guided output generation. This\nenhancement allows models to store, update, and reuse observed patterns across\nsessions, enabling incremental learning and bridging the gap between static\npretraining and dynamic, context sensitive adaptation. The Retention Layer\ndesign parallels social learning processes, encompassing attention, retention,\nreproduction, and motivation stages. Technically, it integrates a memory\nattention mechanism and episodic buffers to manage memory scalability, mitigate\noverfitting, and ensure efficient recall. Applications span adaptive personal\nassistants, real time fraud detection, autonomous robotics, content moderation,\nand healthcare diagnostics. In each domain, the retention mechanism enables\nsystems to learn incrementally, personalize outputs, and respond to evolving\nreal world challenges effectively. By emulating key aspects of human learning,\nthis retention enhanced architecture fosters a more fluid and responsive AI\nparadigm, paving the way for dynamic, session aware models that extend the\ncapabilities of traditional Transformers into domains requiring continual\nadaptation."}
{"id": "2501.07033", "title": "Detection of AI Deepfake and Fraud in Online Payments Using GAN-Based Models", "url": "https://arxiv.org/abs/2501.07033", "pdf": "https://arxiv.org/pdf/2501.07033", "abs": "https://arxiv.org/abs/2501.07033", "authors": ["Zong Ke", "Shicheng Zhou", "Yining Zhou", "Chia Hong Chang", "Rong Zhang"], "categories": ["cs.LG", "cs.CR", "cs.CV"], "comment": "The paper will be published and indexed by IEEE at 2025 8th\n  International Conference on Advanced Algorithms and Control Engineering\n  (ICAACE 2025)", "summary": "This study explores the use of Generative Adversarial Networks (GANs) to\ndetect AI deepfakes and fraudulent activities in online payment systems. With\nthe growing prevalence of deepfake technology, which can manipulate facial\nfeatures in images and videos, the potential for fraud in online transactions\nhas escalated. Traditional security systems struggle to identify these\nsophisticated forms of fraud. This research proposes a novel GAN-based model\nthat enhances online payment security by identifying subtle manipulations in\npayment images. The model is trained on a dataset consisting of real-world\nonline payment images and deepfake images generated using advanced GAN\narchitectures, such as StyleGAN and DeepFake. The results demonstrate that the\nproposed model can accurately distinguish between legitimate transactions and\ndeepfakes, achieving a high detection rate above 95%. This approach\nsignificantly improves the robustness of payment systems against AI-driven\nfraud. The paper contributes to the growing field of digital security, offering\ninsights into the application of GANs for fraud detection in financial\nservices. Keywords- Payment Security, Image Recognition, Generative Adversarial\nNetworks, AI Deepfake, Fraudulent Activities"}
{"id": "2501.02032", "title": "Dynamic Feature Fusion: Combining Global Graph Structures and Local Semantics for Blockchain Fraud Detection", "url": "https://arxiv.org/abs/2501.02032", "pdf": "https://arxiv.org/pdf/2501.02032", "abs": "https://arxiv.org/abs/2501.02032", "authors": ["Zhang Sheng", "Liangliang Song", "Yanbin Wang"], "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": null, "summary": "The advent of blockchain technology has facilitated the widespread adoption\nof smart contracts in the financial sector. However, current fraud detection\nmethodologies exhibit limitations in capturing both global structural patterns\nwithin transaction networks and local semantic relationships embedded in\ntransaction data. Most existing models focus on either structural information\nor semantic features individually, leading to suboptimal performance in\ndetecting complex fraud patterns.In this paper, we propose a dynamic feature\nfusion model that combines graph-based representation learning and semantic\nfeature extraction for blockchain fraud detection. Specifically, we construct\nglobal graph representations to model account relationships and extract local\ncontextual features from transaction data. A dynamic multimodal fusion\nmechanism is introduced to adaptively integrate these features, enabling the\nmodel to capture both structural and semantic fraud patterns effectively. We\nfurther develop a comprehensive data processing pipeline, including graph\nconstruction, temporal feature enhancement, and text preprocessing.\nExperimental results on large-scale real-world blockchain datasets demonstrate\nthat our method outperforms existing benchmarks across accuracy, F1 score, and\nrecall metrics. This work highlights the importance of integrating structural\nrelationships and semantic similarities for robust fraud detection and offers a\nscalable solution for securing blockchain systems."}
{"id": "2412.19441", "title": "Comparative Performance Analysis of Quantum Machine Learning Architectures for Credit Card Fraud Detection", "url": "https://arxiv.org/abs/2412.19441", "pdf": "https://arxiv.org/pdf/2412.19441", "abs": "https://arxiv.org/abs/2412.19441", "authors": ["Mansour El Alami", "Nouhaila Innan", "Muhammad Shafique", "Mohamed Bennai"], "categories": ["quant-ph", "cs.LG"], "comment": "12 pages, 17 figures, 7 tables, under review", "summary": "As financial fraud becomes increasingly complex, effective detection methods\nare essential. Quantum Machine Learning (QML) introduces certain capabilities\nthat may enhance both accuracy and efficiency in this area. This study examines\nhow different quantum feature map and ansatz configurations affect the\nperformance of three QML-based classifiers-the Variational Quantum Classifier\n(VQC), the Sampler Quantum Neural Network (SQNN), and the Estimator Quantum\nNeural Network (EQNN)-when applied to two non-standardized financial fraud\ndatasets. Different quantum feature map and ansatz configurations are\nevaluated, revealing distinct performance patterns. The VQC consistently\ndemonstrates strong classification results, achieving an F1 score of 0.88,\nwhile the SQNN also delivers promising outcomes. In contrast, the EQNN\nstruggles to produce robust results, emphasizing the challenges presented by\nnon-standardized data. These findings highlight the importance of careful model\nconfiguration in QML-based financial fraud detection. By showing how specific\nfeature maps and ansatz choices influence predictive success, this work guides\nresearchers and practitioners in refining QML approaches for complex financial\napplications."}
{"id": "2501.01061", "title": "An Efficient Outlier Detection Algorithm for Data Streaming", "url": "https://arxiv.org/abs/2501.01061", "pdf": "https://arxiv.org/pdf/2501.01061", "abs": "https://arxiv.org/abs/2501.01061", "authors": ["Rui Hu", "Luc", "Chen", "Yiwei Wang"], "categories": ["stat.CO", "cs.LG", "stat.AP"], "comment": "12 pages, 10 figures", "summary": "The nature of modern data is increasingly real-time, making outlier detection\ncrucial in any data-related field, such as finance for fraud detection and\nhealthcare for monitoring patient vitals. Traditional outlier detection\nmethods, such as the Local Outlier Factor (LOF) algorithm, struggle with\nreal-time data due to the need for extensive recalculations with each new data\npoint, limiting their application in real-time environments. While the\nIncremental LOF (ILOF) algorithm has been developed to tackle the challenges of\nonline anomaly detection, it remains computationally expensive when processing\nlarge streams of data points, and its detection performance may degrade after a\ncertain threshold of points have streamed in. In this paper, we propose a novel\napproach to enhance the efficiency of LOF algorithms for online anomaly\ndetection, named the Efficient Incremental LOF (EILOF) algorithm. The EILOF\nalgorithm only computes the LOF scores of new points without altering the LOF\nscores of existing data points. Although exact LOF scores have not yet been\ncomputed for the existing points in the new algorithm, datasets often contain\nnoise, and minor deviations in LOF score calculations do not necessarily\ndegrade detection performance. In fact, such deviations can sometimes enhance\noutlier detection. We systematically tested this approach on both simulated and\nreal-world datasets, demonstrating that EILOF outperforms ILOF as the volume of\nstreaming data increases across various scenarios. The EILOF algorithm not only\nsignificantly reduces computational costs, but also systematically improves\ndetection accuracy when the number of additional points increases compared to\nthe ILOF algorithm."}
{"id": "2412.18470", "title": "PonziLens+: Visualizing Bytecode Actions for Smart Ponzi Scheme Identification", "url": "https://arxiv.org/abs/2412.18470", "pdf": "https://arxiv.org/pdf/2412.18470", "abs": "https://arxiv.org/abs/2412.18470", "authors": ["Xiaolin Wen", "Tai D. Nguyen", "Shaolun Ruan", "Qiaomu Shen", "Jun Sun", "Feida Zhu", "Yong Wang"], "categories": ["cs.HC"], "comment": null, "summary": "With the prevalence of smart contracts, smart Ponzi schemes have become a\ncommon fraud on blockchain and have caused significant financial loss to\ncryptocurrency investors in the past few years. Despite the critical importance\nof detecting smart Ponzi schemes, a reliable and transparent identification\napproach adaptive to various smart Ponzi schemes is still missing. To fill the\nresearch gap, we first extract semantic-meaningful actions to represent the\nexecution behaviors specified in smart contract bytecodes, which are derived\nfrom a literature review and in-depth interviews with domain experts. We then\npropose PonziLens+, a novel visual analytic approach that provides an intuitive\nand reliable analysis of Ponzi-scheme-related features within these execution\nbehaviors. PonziLens+ has three visualization modules that intuitively reveal\nall potential behaviors of a smart contract, highlighting fraudulent features\nacross three levels of detail. It can help smart contract investors and\nauditors achieve confident identification of any smart Ponzi schemes. We\nconducted two case studies and in-depth user interviews with 12 domain experts\nand common investors to evaluate PonziLens+. The results demonstrate the\neffectiveness and usability of PonziLens+ in achieving an effective\nidentification of smart Ponzi schemes."}
{"id": "2412.18287", "title": "Semi-supervised Credit Card Fraud Detection via Attribute-Driven Graph Representation", "url": "https://arxiv.org/abs/2412.18287", "pdf": "https://arxiv.org/pdf/2412.18287", "abs": "https://arxiv.org/abs/2412.18287", "authors": ["Sheng Xiang", "Mingzhi Zhu", "Dawei Cheng", "Enxia Li", "Ruihui Zhao", "Yi Ouyang", "Ling Chen", "Yefeng Zheng"], "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": "9 pages, 5 figures, AAAI 2023, code:\n  https://github.com/AI4Risk/antifraud", "summary": "Credit card fraud incurs a considerable cost for both cardholders and issuing\nbanks. Contemporary methods apply machine learning-based classifiers to detect\nfraudulent behavior from labeled transaction records. But labeled data are\nusually a small proportion of billions of real transactions due to expensive\nlabeling costs, which implies that they do not well exploit many natural\nfeatures from unlabeled data. Therefore, we propose a semi-supervised graph\nneural network for fraud detection. Specifically, we leverage transaction\nrecords to construct a temporal transaction graph, which is composed of\ntemporal transactions (nodes) and interactions (edges) among them. Then we pass\nmessages among the nodes through a Gated Temporal Attention Network (GTAN) to\nlearn the transaction representation. We further model the fraud patterns\nthrough risk propagation among transactions. The extensive experiments are\nconducted on a real-world transaction dataset and two publicly available fraud\ndetection datasets. The result shows that our proposed method, namely GTAN,\noutperforms other state-of-the-art baselines on three fraud detection datasets.\nSemi-supervised experiments demonstrate the excellent fraud detection\nperformance of our model with only a tiny proportion of labeled data."}
{"id": "2408.00641", "title": "Enhancing Ethereum Fraud Detection via Generative and Contrastive Self-supervision", "url": "https://arxiv.org/abs/2408.00641", "pdf": "https://arxiv.org/pdf/2408.00641", "abs": "https://arxiv.org/abs/2408.00641", "authors": ["Chenxiang Jin", "Jiajun Zhou", "Chenxuan Xie", "Shanqing Yu", "Qi Xuan", "Xiaoniu Yang"], "categories": ["cs.LG"], "comment": "Accepted by IEEE Transactions on Information Forensics & Security", "summary": "The rampant fraudulent activities on Ethereum hinder the healthy development\nof the blockchain ecosystem, necessitating the reinforcement of regulations.\nHowever, multiple imbalances involving account interaction frequencies and\ninteraction types in the Ethereum transaction environment pose significant\nchallenges to data mining-based fraud detection research. To address this, we\nfirst propose the concept of meta-interactions to refine interaction behaviors\nin Ethereum, and based on this, we present a dual self-supervision enhanced\nEthereum fraud detection framework, named Meta-IFD. This framework initially\nintroduces a generative self-supervision mechanism to augment the interaction\nfeatures of accounts, followed by a contrastive self-supervision mechanism to\ndifferentiate various behavior patterns, and ultimately characterizes the\nbehavioral representations of accounts and mines potential fraud risks through\nmulti-view interaction feature learning. Extensive experiments on real Ethereum\ndatasets demonstrate the effectiveness and superiority of our framework in\ndetecting common Ethereum fraud behaviors such as Ponzi schemes and phishing\nscams. Additionally, the generative module can effectively alleviate the\ninteraction distribution imbalance in Ethereum data, while the contrastive\nmodule significantly enhances the framework's ability to distinguish different\nbehavior patterns. The source code will be available in\nhttps://github.com/GISec-Team/Meta-IFD."}
{"id": "2412.15621", "title": "Pirates of Charity: Exploring Donation-based Abuses in Social Media Platforms", "url": "https://arxiv.org/abs/2412.15621", "pdf": "https://arxiv.org/pdf/2412.15621", "abs": "https://arxiv.org/abs/2412.15621", "authors": ["Bhupendra Acharya", "Dario Lazzaro", "Antonio Emanuele Cinà", "Thorsten Holz"], "categories": ["cs.CR"], "comment": null, "summary": "With the widespread use of social media, organizations, and individuals use\nthese platforms to raise funds and support causes. Unfortunately, this has led\nto the rise of scammers in soliciting fraudulent donations. In this study, we\nconduct a large-scale analysis of donation-based scams on social media\nplatforms. More specifically, we studied profile creation and scam operation\nfraudulent donation solicitation on X, Instagram, Facebook, YouTube, and\nTelegram. By collecting data from 151,966 accounts and their 3,053,333 posts\nrelated to donations between March 2024 and May 2024, we identified 832\nscammers using various techniques to deceive users into making fraudulent\ndonations. Analyzing the fraud communication channels such as phone number,\nemail, and external URL linked, we show that these scamming accounts perform\nvarious fraudulent donation schemes, including classic abuse such as fake\nfundraising website setup, crowdsourcing fundraising, and asking users to\ncommunicate via email, phone, and pay via various payment methods. Through\ncollaboration with industry partners PayPal and cryptocurrency abuse database\nChainabuse, we further validated the scams and measured the financial losses on\nthese platforms. Our study highlights significant weaknesses in social media\nplatforms' ability to protect users from fraudulent donations. Additionally, we\nrecommended social media platforms, and financial services for taking proactive\nsteps to block these fraudulent activities. Our study provides a foundation for\nthe security community and researchers to automate detecting and mitigating\nfraudulent donation solicitation on social media platforms."}
{"id": "2412.14985", "title": "Exploration of the Dynamics of Buy and Sale of Social Media Accounts", "url": "https://arxiv.org/abs/2412.14985", "pdf": "https://arxiv.org/pdf/2412.14985", "abs": "https://arxiv.org/abs/2412.14985", "authors": ["Mario Beluri", "Bhupendra Acharya", "Soheil Khodayari", "Giada Stivala", "Giancarlo Pellegrino", "Thorsten Holz"], "categories": ["cs.CR"], "comment": null, "summary": "There has been a rise in online platforms facilitating the buying and selling\nof social media accounts. While the trade of social media profiles is not\ninherently illegal, social media platforms view such transactions as violations\nof their policies. They often take action against accounts involved in the\nmisuse of platforms for financial gain. This research conducts a comprehensive\nanalysis of marketplaces that enable the buying and selling of social media\naccounts.\n  We investigate the economic scale of account trading across five major\nplatforms: X, Instagram, Facebook, TikTok, and YouTube. From February to June\n2024, we identified 38,253 accounts advertising account sales across 11 online\nmarketplaces, covering 211 distinct categories. The total value of marketed\nsocial media accounts exceeded \\$64 million, with a median price of \\$157 per\naccount. Additionally, we analyzed the profiles of 11,457 visible advertised\naccounts, collecting their metadata and over 200,000 profile posts. By\nexamining their engagement patterns and account creation methods, we evaluated\nthe fraudulent activities commonly associated with these sold accounts. Our\nresearch reveals these marketplaces foster fraudulent activities such as bot\nfarming, harvesting accounts for future fraud, and fraudulent engagement. Such\npractices pose significant risks to social media users, who are often targeted\nby fraudulent accounts resembling legitimate profiles and employing social\nengineering tactics. We highlight social media platform weaknesses in the\nability to detect and mitigate such fraudulent accounts, thereby endangering\nusers. Alongside this, we conducted thorough disclosures with the respective\nplatforms and proposed actionable recommendations, including indicators to\nidentify and track these accounts. These measures aim to enhance proactive\ndetection and safeguard users from potential threats."}
{"id": "2412.11488", "title": "Counting Butterflies over Streaming Bipartite Graphs with Duplicate Edges", "url": "https://arxiv.org/abs/2412.11488", "pdf": "https://arxiv.org/pdf/2412.11488", "abs": "https://arxiv.org/abs/2412.11488", "authors": ["Lingkai Meng", "Long Yuan", "Xuemin Lin", "Chengjie Li", "Kai Wang", "Wenjie Zhang"], "categories": ["cs.DS"], "comment": null, "summary": "Bipartite graphs are commonly used to model relationships between two\ndistinct entities in real-world applications, such as user-product\ninteractions, user-movie ratings and collaborations between authors and\npublications. A butterfly (a 2x2 bi-clique) is a critical substructure in\nbipartite graphs, playing a significant role in tasks like community detection,\nfraud detection, and link prediction. As more real-world data is presented in a\nstreaming format, efficiently counting butterflies in streaming bipartite\ngraphs has become increasingly important. However, most existing algorithms\ntypically assume that duplicate edges are absent, which is hard to hold in\nreal-world graph streams, as a result, they tend to sample edges that appear\nmultiple times, leading to inaccurate results. The only algorithm designed to\nhandle duplicate edges is FABLE, but it suffers from significant limitations,\nincluding high variance, substantial time complexity, and memory inefficiency\ndue to its reliance on a priority queue. To overcome these limitations, we\nintroduce DEABC (Duplicate-Edge-Aware Butterfly Counting), an innovative method\nthat uses bucket-based priority sampling to accurately estimate the number of\nbutterflies, accounting for duplicate edges. Compared to existing methods,\nDEABC significantly reduces memory usage by storing only the essential sampled\nedge data while maintaining high accuracy. We provide rigorous proofs of the\nunbiasedness and variance bounds for DEABC, ensuring they achieve high\naccuracy. We compare DEABC with state-of-the-art algorithms on real-world\nstreaming bipartite graphs. The results show that our DEABC outperforms\nexisting methods in memory efficiency and accuracy, while also achieving\nsignificantly higher throughput."}
{"id": "2412.10258", "title": "Copy-Move Detection in Optical Microscopy: A Segmentation Network and A Dataset", "url": "https://arxiv.org/abs/2412.10258", "pdf": "https://arxiv.org/pdf/2412.10258", "abs": "https://arxiv.org/abs/2412.10258", "authors": ["Hao-Chiang Shao", "Yuan-Rong Liao", "Tse-Yu Tseng", "Yen-Liang Chuo", "Fong-Yi Lin"], "categories": ["eess.IV", "cs.CV"], "comment": "submitted to IEEE SPL", "summary": "With increasing revelations of academic fraud, detecting forged experimental\nimages in the biomedical field has become a public concern. The challenge lies\nin the fact that copy-move targets can include background tissue, small\nforeground objects, or both, which may be out of the training domain and\nsubject to unseen attacks, rendering standard object-detection-based approaches\nless effective. To address this, we reformulate the problem of detecting\nbiomedical copy-move forgery regions as an intra-image co-saliency detection\ntask and propose CMSeg-Net, a copy-move forgery segmentation network capable of\nidentifying unseen duplicated areas. Built on a multi-resolution\nencoder-decoder architecture, CMSeg-Net incorporates self-correlation and\ncorrelation-assisted spatial-attention modules to detect intra-image regional\nsimilarities within feature tensors at each observation scale. This design\nhelps distinguish even small copy-move targets in complex microscopic images\nfrom other similar objects. Furthermore, we created a copy-move forgery dataset\nof optical microscopic images, named FakeParaEgg, using open data from the ICIP\n2022 Challenge to support CMSeg-Net's development and verify its performance.\nExtensive experiments demonstrate that our approach outperforms previous\nstate-of-the-art methods on the FakeParaEgg dataset and other open copy-move\ndetection datasets, including CASIA-CMFD, CoMoFoD, and CMF. The FakeParaEgg\ndataset, our source code, and the CMF dataset with our manually defined\nsegmentation ground truths available at\n``https://github.com/YoursEver/FakeParaEgg''."}
{"id": "2412.08366", "title": "Backdoor attacks on DNN and GBDT -- A Case Study from the insurance domain", "url": "https://arxiv.org/abs/2412.08366", "pdf": "https://arxiv.org/pdf/2412.08366", "abs": "https://arxiv.org/abs/2412.08366", "authors": ["Robin Kühlem", "Daniel Otten", "Daniel Ludwig", "Anselm Hudde", "Alexander Rosenbaum", "Andreas Mauthe"], "categories": ["cs.LG", "I.2.m"], "comment": "40 pages, 14 figures", "summary": "Machine learning (ML) will likely play a large role in many processes in the\nfuture, also for insurance companies. However, ML models are at risk of being\nattacked and manipulated. In this work, the robustness of Gradient Boosted\nDecision Tree (GBDT) models and Deep Neural Networks (DNN) within an insurance\ncontext will be evaluated. Therefore, two GBDT models and two DNNs are trained\non two different tabular datasets from an insurance context. Past research in\nthis domain mainly used homogenous data and there are comparably few insights\nregarding heterogenous tabular data. The ML tasks performed on the datasets are\nclaim prediction (regression) and fraud detection (binary classification). For\nthe backdoor attacks different samples containing a specific pattern were\ncrafted and added to the training data. It is shown, that this type of attack\ncan be highly successful, even with a few added samples. The backdoor attacks\nworked well on the models trained on one dataset but poorly on the models\ntrained on the other. In real-world scenarios the attacker will have to face\nseveral obstacles but as attacks can work with very few added samples this risk\nshould be evaluated."}
{"id": "2412.12154", "title": "PyOD 2: A Python Library for Outlier Detection with LLM-powered Model Selection", "url": "https://arxiv.org/abs/2412.12154", "pdf": "https://arxiv.org/pdf/2412.12154", "abs": "https://arxiv.org/abs/2412.12154", "authors": ["Sihan Chen", "Zhuangzhuang Qian", "Wingchun Siu", "Xingcan Hu", "Jiaqi Li", "Shawn Li", "Yuehan Qin", "Tiankai Yang", "Zhuo Xiao", "Wanghao Ye", "Yichi Zhang", "Yushun Dong", "Yue Zhao"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Outlier detection (OD), also known as anomaly detection, is a critical\nmachine learning (ML) task with applications in fraud detection, network\nintrusion detection, clickstream analysis, recommendation systems, and social\nnetwork moderation. Among open-source libraries for outlier detection, the\nPython Outlier Detection (PyOD) library is the most widely adopted, with over\n8,500 GitHub stars, 25 million downloads, and diverse industry usage. However,\nPyOD currently faces three limitations: (1) insufficient coverage of modern\ndeep learning algorithms, (2) fragmented implementations across PyTorch and\nTensorFlow, and (3) no automated model selection, making it hard for\nnon-experts.\n  To address these issues, we present PyOD Version 2 (PyOD 2), which integrates\n12 state-of-the-art deep learning models into a unified PyTorch framework and\nintroduces a large language model (LLM)-based pipeline for automated OD model\nselection. These improvements simplify OD workflows, provide access to 45\nalgorithms, and deliver robust performance on various datasets. In this paper,\nwe demonstrate how PyOD 2 streamlines the deployment and automation of OD\nmodels and sets a new standard in both research and industry. PyOD 2 is\naccessible at\n[https://github.com/yzhao062/pyod](https://github.com/yzhao062/pyod). This\nstudy aligns with the Web Mining and Content Analysis track, addressing topics\nsuch as the robustness of Web mining methods and the quality of\nalgorithmically-generated Web data."}
{"id": "2408.04967", "title": "ADD 2023: Towards Audio Deepfake Detection and Analysis in the Wild", "url": "https://arxiv.org/abs/2408.04967", "pdf": "https://arxiv.org/pdf/2408.04967", "abs": "https://arxiv.org/abs/2408.04967", "authors": ["Jiangyan Yi", "Chu Yuan Zhang", "Jianhua Tao", "Chenglong Wang", "Xinrui Yan", "Yong Ren", "Hao Gu", "Junzuo Zhou"], "categories": ["eess.AS", "cs.SD"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "The growing prominence of the field of audio deepfake detection is driven by\nits wide range of applications, notably in protecting the public from potential\nfraud and other malicious activities, prompting the need for greater attention\nand research in this area. The ADD 2023 challenge goes beyond binary real/fake\nclassification by emulating real-world scenarios, such as the identification of\nmanipulated intervals in partially fake audio and determining the source\nresponsible for generating any fake audio, both with real-life implications,\nnotably in audio forensics, law enforcement, and construction of reliable and\ntrustworthy evidence. To further foster research in this area, in this article,\nwe describe the dataset that was used in the fake game, manipulation region\nlocation and deepfake algorithm recognition tracks of the challenge. We also\nfocus on the analysis of the technical methodologies by the top-performing\nparticipants in each task and note the commonalities and differences in their\napproaches. Finally, we discuss the current technical limitations as identified\nthrough the technical analysis, and provide a roadmap for future research\ndirections. The dataset is available for download at\nhttp://addchallenge.cn/downloadADD2023."}
{"id": "2412.08082", "title": "FaceTracer: Unveiling Source Identities from Swapped Face Images and Videos for Fraud Prevention", "url": "https://arxiv.org/abs/2412.08082", "pdf": "https://arxiv.org/pdf/2412.08082", "abs": "https://arxiv.org/abs/2412.08082", "authors": ["Zhongyi Zhang", "Jie Zhang", "Wenbo Zhou", "Xinghui Zhou", "Qing Guo", "Weiming Zhang", "Tianwei Zhang", "Nenghai Yu"], "categories": ["cs.CV"], "comment": "17 pages, 18 figures, under review", "summary": "Face-swapping techniques have advanced rapidly with the evolution of deep\nlearning, leading to widespread use and growing concerns about potential\nmisuse, especially in cases of fraud. While many efforts have focused on\ndetecting swapped face images or videos, these methods are insufficient for\ntracing the malicious users behind fraudulent activities. Intrusive\nwatermark-based approaches also fail to trace unmarked identities, limiting\ntheir practical utility. To address these challenges, we introduce FaceTracer,\nthe first non-intrusive framework specifically designed to trace the identity\nof the source person from swapped face images or videos. Specifically,\nFaceTracer leverages a disentanglement module that effectively suppresses\nidentity information related to the target person while isolating the identity\nfeatures of the source person. This allows us to extract robust identity\ninformation that can directly link the swapped face back to the original\nindividual, aiding in uncovering the actors behind fraudulent activities.\nExtensive experiments demonstrate FaceTracer's effectiveness across various\nface-swapping techniques, successfully identifying the source person in swapped\ncontent and enabling the tracing of malicious actors involved in fraudulent\nactivities. Additionally, FaceTracer shows strong transferability to unseen\nface-swapping methods including commercial applications and robustness against\ntransmission distortions and adaptive attacks."}
{"id": "2412.07437", "title": "Impact of Sampling Techniques and Data Leakage on XGBoost Performance in Credit Card Fraud Detection", "url": "https://arxiv.org/abs/2412.07437", "pdf": "https://arxiv.org/pdf/2412.07437", "abs": "https://arxiv.org/abs/2412.07437", "authors": ["Siyaxolisa Kabane"], "categories": ["cs.LG", "62H30"], "comment": "19 pages, 4 figures", "summary": "Credit card fraud detection remains a critical challenge in financial\nsecurity, with machine learning models like XGBoost(eXtreme gradient boosting)\nemerging as powerful tools for identifying fraudulent transactions. However,\nthe inherent class imbalance in credit card transaction datasets poses\nsignificant challenges for model performance. Although sampling techniques are\ncommonly used to address this imbalance, their implementation sometimes\nprecedes the train-test split, potentially introducing data leakage.\n  This study presents a comparative analysis of XGBoost's performance in credit\ncard fraud detection under three scenarios: Firstly without any imbalance\nhandling techniques, secondly with sampling techniques applied only to the\ntraining set after the train-test split, and third with sampling techniques\napplied before the train-test split. We utilized a dataset from Kaggle of\n284,807 credit card transactions, containing 0.172\\% fraudulent cases, to\nevaluate these approaches.\n  Our findings show that although sampling strategies enhance model\nperformance, the reliability of results is greatly impacted by when they are\napplied. Due to a data leakage issue that frequently occurs in machine learning\nmodels during the sampling phase, XGBoost models trained on data where sampling\nwas applied prior to the train-test split may have displayed artificially\ninflated performance metrics. Surprisingly, models trained with sampling\ntechniques applied solely to the training set demonstrated significantly lower\nresults than those with pre-split sampling, all the while preserving the\nintegrity of the evaluation process."}
{"id": "2412.09640", "title": "Blockchain Data Analysis in the Era of Large-Language Models", "url": "https://arxiv.org/abs/2412.09640", "pdf": "https://arxiv.org/pdf/2412.09640", "abs": "https://arxiv.org/abs/2412.09640", "authors": ["Kentaroh Toyoda", "Xiao Wang", "Mingzhe Li", "Bo Gao", "Yuan Wang", "Qingsong Wei"], "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Blockchain data analysis is essential for deriving insights, tracking\ntransactions, identifying patterns, and ensuring the integrity and security of\ndecentralized networks. It plays a key role in various areas, such as fraud\ndetection, regulatory compliance, smart contract auditing, and decentralized\nfinance (DeFi) risk management. However, existing blockchain data analysis\ntools face challenges, including data scarcity, the lack of generalizability,\nand the lack of reasoning capability.\n  We believe large language models (LLMs) can mitigate these challenges;\nhowever, we have not seen papers discussing LLM integration in blockchain data\nanalysis in a comprehensive and systematic way. This paper systematically\nexplores potential techniques and design patterns in LLM-integrated blockchain\ndata analysis. We also outline prospective research opportunities and\nchallenges, emphasizing the need for further exploration in this promising\nfield. This paper aims to benefit a diverse audience spanning academia,\nindustry, and policy-making, offering valuable insights into the integration of\nLLMs in blockchain data analysis."}
{"id": "2412.04784", "title": "NLP-ADBench: NLP Anomaly Detection Benchmark", "url": "https://arxiv.org/abs/2412.04784", "pdf": "https://arxiv.org/pdf/2412.04784", "abs": "https://arxiv.org/abs/2412.04784", "authors": ["Yuangang Li", "Jiaqi Li", "Zhuo Xiao", "Tiankai Yang", "Yi Nian", "Xiyang Hu", "Yue Zhao"], "categories": ["cs.CL", "cs.LG"], "comment": "The project is available at https://github.com/USC-FORTIS/NLP-ADBench", "summary": "Anomaly detection (AD) is a critical machine learning task with diverse\napplications in web systems, including fraud detection, content moderation, and\nuser behavior analysis. Despite its significance, AD in natural language\nprocessing (NLP) remains underexplored, limiting advancements in detecting\nanomalies in text data such as harmful content, phishing attempts, or spam\nreviews. In this paper, we introduce NLP-ADBench, the most comprehensive\nbenchmark for NLP anomaly detection (NLP-AD), comprising eight curated datasets\nand evaluations of nineteen state-of-the-art algorithms. These include three\nend-to-end methods and sixteen two-step algorithms that apply traditional\nanomaly detection techniques to language embeddings generated by\nbert-base-uncased and OpenAI's text-embedding-3-large models.\n  Our results reveal critical insights and future directions for NLP-AD.\nNotably, no single model excels across all datasets, highlighting the need for\nautomated model selection. Moreover, two-step methods leveraging\ntransformer-based embeddings consistently outperform specialized end-to-end\napproaches, with OpenAI embeddings demonstrating superior performance over BERT\nembeddings. By releasing NLP-ADBench at\nhttps://github.com/USC-FORTIS/NLP-ADBench, we provide a standardized framework\nfor evaluating NLP-AD methods, fostering the development of innovative\napproaches. This work fills a crucial gap in the field and establishes a\nfoundation for advancing NLP anomaly detection, particularly in the context of\nimproving the safety and reliability of web-based systems."}
{"id": "2402.08918", "title": "SimMLP: Training MLPs on Graphs without Supervision", "url": "https://arxiv.org/abs/2402.08918", "pdf": "https://arxiv.org/pdf/2402.08918", "abs": "https://arxiv.org/abs/2402.08918", "authors": ["Zehong Wang", "Zheyuan Zhang", "Chuxu Zhang", "Yanfang Ye"], "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": "New Version: arXiv:2412.03864", "summary": "Graph Neural Networks (GNNs) have demonstrated their effectiveness in various\ngraph learning tasks, yet their reliance on neighborhood aggregation during\ninference poses challenges for deployment in latency-sensitive applications,\nsuch as real-time financial fraud detection. To address this limitation, recent\nstudies have proposed distilling knowledge from teacher GNNs into student\nMulti-Layer Perceptrons (MLPs) trained on node content, aiming to accelerate\ninference. However, these approaches often inadequately explore structural\ninformation when inferring unseen nodes. To this end, we introduce SimMLP, a\nSelf-supervised framework for learning MLPs on graphs, designed to fully\nintegrate rich structural information into MLPs. Notably, SimMLP is the first\nMLP-learning method that can achieve equivalence to GNNs in the optimal case.\nThe key idea is to employ self-supervised learning to align the representations\nencoded by graph context-aware GNNs and neighborhood dependency-free MLPs,\nthereby fully integrating the structural information into MLPs. We provide a\ncomprehensive theoretical analysis, demonstrating the equivalence between\nSimMLP and GNNs based on mutual information and inductive bias, highlighting\nSimMLP's advanced structural learning capabilities. Additionally, we conduct\nextensive experiments on 20 benchmark datasets, covering node classification,\nlink prediction, and graph classification, to showcase SimMLP's superiority\nover state-of-the-art baselines, particularly in scenarios involving unseen\nnodes (e.g., inductive and cold-start node classification) where structural\ninsights are crucial. Our codes are available at:\nhttps://github.com/Zehong-Wang/SimMLP."}
{"id": "2412.03864", "title": "Training MLPs on Graphs without Supervision", "url": "https://arxiv.org/abs/2412.03864", "pdf": "https://arxiv.org/pdf/2412.03864", "abs": "https://arxiv.org/abs/2412.03864", "authors": ["Zehong Wang", "Zheyuan Zhang", "Chuxu Zhang", "Yanfang Ye"], "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": "Accepted by WSDM 25", "summary": "Graph Neural Networks (GNNs) have demonstrated their effectiveness in various\ngraph learning tasks, yet their reliance on neighborhood aggregation during\ninference poses challenges for deployment in latency-sensitive applications,\nsuch as real-time financial fraud detection. To address this limitation, recent\nstudies have proposed distilling knowledge from teacher GNNs into student\nMulti-Layer Perceptrons (MLPs) trained on node content, aiming to accelerate\ninference. However, these approaches often inadequately explore structural\ninformation when inferring unseen nodes. To this end, we introduce SimMLP, a\nSelf-supervised framework for learning MLPs on graphs, designed to fully\nintegrate rich structural information into MLPs. Notably, SimMLP is the first\nMLP-learning method that can achieve equivalence to GNNs in the optimal case.\nThe key idea is to employ self-supervised learning to align the representations\nencoded by graph context-aware GNNs and neighborhood dependency-free MLPs,\nthereby fully integrating the structural information into MLPs. We provide a\ncomprehensive theoretical analysis, demonstrating the equivalence between\nSimMLP and GNNs based on mutual information and inductive bias, highlighting\nSimMLP's advanced structural learning capabilities. Additionally, we conduct\nextensive experiments on 20 benchmark datasets, covering node classification,\nlink prediction, and graph classification, to showcase SimMLP's superiority\nover state-of-the-art baselines, particularly in scenarios involving unseen\nnodes (e.g., inductive and cold-start node classification) where structural\ninsights are crucial. Our codes are available at:\nhttps://github.com/Zehong-Wang/SimMLP."}
{"id": "2411.19457", "title": "Multi-task CNN Behavioral Embedding Model For Transaction Fraud Detection", "url": "https://arxiv.org/abs/2411.19457", "pdf": "https://arxiv.org/pdf/2411.19457", "abs": "https://arxiv.org/abs/2411.19457", "authors": ["Bo Qu", "Zhurong Wang", "Minghao Gu", "Daisuke Yagi", "Yang Zhao", "Yinan Shan", "Frank Zahradnik"], "categories": ["cs.LG"], "comment": "7 pages, 2 figures, ICDMW 2024", "summary": "The burgeoning e-Commerce sector requires advanced solutions for the\ndetection of transaction fraud. With an increasing risk of financial\ninformation theft and account takeovers, deep learning methods have become\nintegral to the embedding of behavior sequence data in fraud detection.\nHowever, these methods often struggle to balance modeling capabilities and\nefficiency and incorporate domain knowledge. To address these issues, we\nintroduce the multitask CNN behavioral Embedding Model for Transaction Fraud\nDetection. Our contributions include 1) introducing a single-layer CNN design\nfeaturing multirange kernels which outperform LSTM and Transformer models in\nterms of scalability and domain-focused inductive bias, and 2) the integration\nof positional encoding with CNN to introduce sequence-order signals enhancing\noverall performance, and 3) implementing multitask learning with randomly\nassigned label weights, thus removing the need for manual tuning. Testing on\nreal-world data reveals our model's enhanced performance of downstream\ntransaction models and comparable competitiveness with the Transformer Time\nSeries (TST) model."}
{"id": "2412.04495", "title": "Artificial intelligence and cybersecurity in banking sector: opportunities and risks", "url": "https://arxiv.org/abs/2412.04495", "pdf": "https://arxiv.org/pdf/2412.04495", "abs": "https://arxiv.org/abs/2412.04495", "authors": ["Ana Kovacevic", "Sonja D. Radenkovic", "Dragana Nikolic"], "categories": ["cs.CR"], "comment": null, "summary": "The rapid advancements in artificial intelligence (AI) have presented new\nopportunities for enhancing efficiency and economic competitiveness across\nvarious industries, espcially in banking. Machine learning (ML), as a subset of\nartificial intelligence, enables systems to adapt and learn from vast datasets,\nrevolutionizing decision-making processes, fraud detection, and customer\nservice automation. However, these innovations also introduce new challenges,\nparticularly in the realm of cybersecurity. Adversarial attacks, such as data\npoisoning and evasion attacks, represent critical threats to machine learning\nmodels, exploiting vulnerabilities to manipulate outcomes or compromise\nsensitive information. Furthermore, this study highlights the dual-use nature\nof AI tools, which can be used by malicious users. To address these challenges,\nthe paper emphasizes the importance of developing machine learning models with\nkey characteristics such as security, trust, resilience and robustness. These\nfeatures are essential to mitigating risks and ensuring the secure deployment\nof AI technologies in banking sectors, where the protection of financial data\nis paramount. The findings underscore the urgent need for enhanced\ncybersecurity frameworks and continuous improvements in defensive mechanisms.\nBy exploring both opportunities and risks, this paper aims to guide the\nresponsible integration of AI in the banking sector, paving the way for\ninnovation while safeguarding against emerging threats."}
{"id": "2402.14708", "title": "CaT-GNN: Enhancing Credit Card Fraud Detection via Causal Temporal Graph Neural Networks", "url": "https://arxiv.org/abs/2402.14708", "pdf": "https://arxiv.org/pdf/2402.14708", "abs": "https://arxiv.org/abs/2402.14708", "authors": ["Yifan Duan", "Guibin Zhang", "Shilong Wang", "Xiaojiang Peng", "Wang Ziqi", "Junyuan Mao", "Hao Wu", "Xinke Jiang", "Kun Wang"], "categories": ["cs.LG", "cs.AI", "q-fin.ST"], "comment": null, "summary": "Credit card fraud poses a significant threat to the economy. While Graph\nNeural Network (GNN)-based fraud detection methods perform well, they often\noverlook the causal effect of a node's local structure on predictions. This\npaper introduces a novel method for credit card fraud detection, the\n\\textbf{\\underline{Ca}}usal \\textbf{\\underline{T}}emporal\n\\textbf{\\underline{G}}raph \\textbf{\\underline{N}}eural \\textbf{N}etwork\n(CaT-GNN), which leverages causal invariant learning to reveal inherent\ncorrelations within transaction data. By decomposing the problem into discovery\nand intervention phases, CaT-GNN identifies causal nodes within the transaction\ngraph and applies a causal mixup strategy to enhance the model's robustness and\ninterpretability. CaT-GNN consists of two key components: Causal-Inspector and\nCausal-Intervener. The Causal-Inspector utilizes attention weights in the\ntemporal attention mechanism to identify causal and environment nodes without\nintroducing additional parameters. Subsequently, the Causal-Intervener performs\na causal mixup enhancement on environment nodes based on the set of nodes.\nEvaluated on three datasets, including a private financial dataset and two\npublic datasets, CaT-GNN demonstrates superior performance over existing\nstate-of-the-art methods. Our findings highlight the potential of integrating\ncausal reasoning with graph neural networks to improve fraud detection\ncapabilities in financial transactions."}
{"id": "2411.14957", "title": "Information Extraction from Heterogeneous Documents without Ground Truth Labels using Synthetic Label Generation and Knowledge Distillation", "url": "https://arxiv.org/abs/2411.14957", "pdf": "https://arxiv.org/pdf/2411.14957", "abs": "https://arxiv.org/abs/2411.14957", "authors": ["Aniket Bhattacharyya", "Anurag Tripathi"], "categories": ["cs.CL"], "comment": "Accepted to WACV 2025", "summary": "Invoices and receipts submitted by employees are visually rich documents\n(VRDs) with textual, visual and layout information. To protect against the risk\nof fraud and abuse, it is crucial for organizations to efficiently extract\ndesired information from submitted receipts. This helps in the assessment of\nkey factors such as appropriateness of the expense claim, adherence to spending\nand transaction policies, the validity of the receipt, as well as downstream\nanomaly detection at various levels. These documents are heterogeneous, with\nmultiple formats and languages, uploaded with different image qualities, and\noften do not contain ground truth labels for the efficient training of models.\nIn this paper we propose Task Aware Instruction-based Labelling (TAIL), a\nmethod for synthetic label generation in VRD corpuses without labels, and\nfine-tune a multimodal Visually Rich Document Understanding Model (VRDU) on\nTAIL labels using response-based knowledge distillation without using the\nteacher model's weights or training dataset to conditionally generate\nannotations in the appropriate format. Using a benchmark external dataset where\nground truth labels are available, we demonstrate conditions under which our\napproach performs at par with Claude 3 Sonnet through empirical studies. We\nthen show that the resulting model performs at par or better on the internal\nexpense documents of a large multinational organization than state-of-the-art\nLMM (large multimodal model) Claude 3 Sonnet while being 85% less costly and\n~5X faster, and outperforms layout-aware baselines by more than 10% in Average\nNormalized Levenshtein Similarity (ANLS) scores due to its ability to reason\nand extract information from rare formats. Finally, we illustrate the usage of\nour approach in overpayment prevention."}
{"id": "2402.05396", "title": "TASER: Temporal Adaptive Sampling for Fast and Accurate Dynamic Graph Representation Learning", "url": "https://arxiv.org/abs/2402.05396", "pdf": "https://arxiv.org/pdf/2402.05396", "abs": "https://arxiv.org/abs/2402.05396", "authors": ["Gangda Deng", "Hongkuan Zhou", "Hanqing Zeng", "Yinglong Xia", "Christopher Leung", "Jianbo Li", "Rajgopal Kannan", "Viktor Prasanna"], "categories": ["cs.LG", "cs.AI"], "comment": "IPDPS 2024", "summary": "Recently, Temporal Graph Neural Networks (TGNNs) have demonstrated\nstate-of-the-art performance in various high-impact applications, including\nfraud detection and content recommendation. Despite the success of TGNNs, they\nare prone to the prevalent noise found in real-world dynamic graphs like\ntime-deprecated links and skewed interaction distribution. The noise causes two\ncritical issues that significantly compromise the accuracy of TGNNs: (1) models\nare supervised by inferior interactions, and (2) noisy input induces high\nvariance in the aggregated messages. However, current TGNN denoising techniques\ndo not consider the diverse and dynamic noise pattern of each node. In\naddition, they also suffer from the excessive mini-batch generation overheads\ncaused by traversing more neighbors. We believe the remedy for fast and\naccurate TGNNs lies in temporal adaptive sampling. In this work, we propose\nTASER, the first adaptive sampling method for TGNNs optimized for accuracy,\nefficiency, and scalability. TASER adapts its mini-batch selection based on\ntraining dynamics and temporal neighbor selection based on the contextual,\nstructural, and temporal properties of past interactions. To alleviate the\nbottleneck in mini-batch generation, TASER implements a pure GPU-based temporal\nneighbor finder and a dedicated GPU feature cache. We evaluate the performance\nof TASER using two state-of-the-art backbone TGNNs. On five popular datasets,\nTASER outperforms the corresponding baselines by an average of 2.3% in Mean\nReciprocal Rank (MRR) while achieving an average of 5.1x speedup in training\ntime."}
